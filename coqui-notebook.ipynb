{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Africas Talking-Mozilla Common Voice Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main notebook used in model development. For experimentation use notebooks in the `misc_notebooks` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is originally a submission to the Africa's Talking x Mozilla Common Voice Hackathon, from October 13th through November"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objectives\n",
    ">> The main objective is to build a deep learning model that is capable of inferring `text` having been conditioned on `voice` sequences.\n",
    "\n",
    "The model is expected to achieve best performance on the selected evaluation metrics:\n",
    "* Character Error Rate\n",
    "* Word Error Rate\n",
    "* Phone Error Rate\n",
    "* Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used is sourced from Mozilla's site [here](https://commonvoice.mozilla.org/en/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scripts import coqui_data_prepper\n",
    "# import scripts/to_csv.py as to_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read `tsv` files\n",
    "test_df = pd.read_csv('sw/test.tsv', delimiter='\\t')\n",
    "train_df = pd.read_csv('sw/train.tsv', delimiter='\\t')\n",
    "# reported_df = pd.read_csv('sw/reported.tsv', engine='c', delimiter='\\t') # causing EOF error in reading, possibly corrupt or inconsistent\n",
    "# others_df = pd.read_csv('sw/other.tsv', delimiter='\\t') # causing EOF error in reading, possibly corrupt or inconsistent\n",
    "invalidated_df = pd.read_csv('sw/invalidated.tsv', delimiter='\\t')\n",
    "dev_df = pd.read_csv('sw/dev.tsv', delimiter='\\t')\n",
    "durations_df = pd.read_csv('sw/clip_durations.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect some of these DataFrames to get our bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37083656.mp3</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085166.mp3</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085182.mp3</td>\n",
       "      <td>Hawai ni kuzuri</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085525.mp3</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085535.mp3</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "1  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "2  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "3  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "4  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_37083656.mp3   \n",
       "1  common_voice_sw_37085166.mp3   \n",
       "2  common_voice_sw_37085182.mp3   \n",
       "3  common_voice_sw_37085525.mp3   \n",
       "4  common_voice_sw_37085535.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  yeyote yule atakaepatikana akiandamana katika ...         2           0   \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...         3           1   \n",
       "2                                    Hawai ni kuzuri         2           0   \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...        13           3   \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...         2           1   \n",
       "\n",
       "        age  gender accents variant locale  segment  \n",
       "0  twenties  female     NaN     NaN     sw      NaN  \n",
       "1  twenties  female     NaN     NaN     sw      NaN  \n",
       "2  twenties  female     NaN     NaN     sw      NaN  \n",
       "3  twenties  female     NaN     NaN     sw      NaN  \n",
       "4  twenties  female     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011544b78c18417a5869b8e70ebc7675c7eb3b517754b8...</td>\n",
       "      <td>common_voice_sw_37190902.mp3</td>\n",
       "      <td>Tuma pesa sahii.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0133d8ddf5c1a3c678fde017e0b07d2835bfd707d5b3ec...</td>\n",
       "      <td>common_voice_sw_31428161.mp3</td>\n",
       "      <td>wachambuzi wa soka wanamtaja Messi kama nyota ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01c95772efd3fbe4a1122206c7474c77ed6591c8c9fb00...</td>\n",
       "      <td>common_voice_sw_30317714.mp3</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023711185d4404ff398c2697f2e72868d1ecf69a92b581...</td>\n",
       "      <td>common_voice_sw_32116997.mp3</td>\n",
       "      <td>Sote twesangaa twelipomuona mwalimu Ali apika</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0244639ffd7ec755a01b21ea204735ca3c44443e9cf46c...</td>\n",
       "      <td>common_voice_sw_29002392.mp3</td>\n",
       "      <td>Inajulikana kama shina la Warangi.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  011544b78c18417a5869b8e70ebc7675c7eb3b517754b8...   \n",
       "1  0133d8ddf5c1a3c678fde017e0b07d2835bfd707d5b3ec...   \n",
       "2  01c95772efd3fbe4a1122206c7474c77ed6591c8c9fb00...   \n",
       "3  023711185d4404ff398c2697f2e72868d1ecf69a92b581...   \n",
       "4  0244639ffd7ec755a01b21ea204735ca3c44443e9cf46c...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_37190902.mp3   \n",
       "1  common_voice_sw_31428161.mp3   \n",
       "2  common_voice_sw_30317714.mp3   \n",
       "3  common_voice_sw_32116997.mp3   \n",
       "4  common_voice_sw_29002392.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0                                   Tuma pesa sahii.         2           0   \n",
       "1  wachambuzi wa soka wanamtaja Messi kama nyota ...         2           0   \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...         2           1   \n",
       "3      Sote twesangaa twelipomuona mwalimu Ali apika         2           1   \n",
       "4                 Inajulikana kama shina la Warangi.         2           0   \n",
       "\n",
       "        age  gender accents variant locale  segment  \n",
       "0       NaN     NaN     NaN     NaN     sw      NaN  \n",
       "1  twenties  female     NaN     NaN     sw      NaN  \n",
       "2       NaN     NaN     NaN     NaN     sw      NaN  \n",
       "3  twenties    male     NaN     NaN     sw      NaN  \n",
       "4       NaN     NaN     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628088.mp3</td>\n",
       "      <td>Mbali na kuwa afisa wa serikali Jokate pia ni ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628121.mp3</td>\n",
       "      <td>Kukosa pesa ni hatari sana</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628126.mp3</td>\n",
       "      <td>Jina Karagwe linatokana na kilima kinachopatik...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628160.mp3</td>\n",
       "      <td>sokwe wanaopatikana mahale ni aina adimu zaidi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628161.mp3</td>\n",
       "      <td>mamba wa mto naili wana sumu kali inayoozesha ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "1  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "2  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "3  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "4  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_30628088.mp3   \n",
       "1  common_voice_sw_30628121.mp3   \n",
       "2  common_voice_sw_30628126.mp3   \n",
       "3  common_voice_sw_30628160.mp3   \n",
       "4  common_voice_sw_30628161.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  Mbali na kuwa afisa wa serikali Jokate pia ni ...         2           0   \n",
       "1                         Kukosa pesa ni hatari sana         3           1   \n",
       "2  Jina Karagwe linatokana na kilima kinachopatik...         2           0   \n",
       "3  sokwe wanaopatikana mahale ni aina adimu zaidi...         2           0   \n",
       "4  mamba wa mto naili wana sumu kali inayoozesha ...         3           0   \n",
       "\n",
       "        age gender accents variant locale  segment  \n",
       "0  twenties   male     NaN     NaN     sw      NaN  \n",
       "1  twenties   male     NaN     NaN     sw      NaN  \n",
       "2  twenties   male     NaN     NaN     sw      NaN  \n",
       "3  twenties   male     NaN     NaN     sw      NaN  \n",
       "4  twenties   male     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev_df\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the path to reflect the relative path in this directory. We can then create new dfs to be used to train on coqui_stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_prefix(df, prefix):\n",
    "  \"\"\"Attaches a prefix to all entries in the column 'path' of a dataframe.\n",
    "\n",
    "  Args:\n",
    "    df: A Pandas dataframe with the column 'path'.\n",
    "    prefix: The prefix to attach to the entries in the column 'path'.\n",
    "\n",
    "  Returns:\n",
    "    A Pandas dataframe with the column 'path' updated to include the prefix.\n",
    "  \"\"\"\n",
    "\n",
    "  df[\"path\"] = df[\"path\"].apply(lambda x: prefix + x)\n",
    "  return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of Pandas DataFrames\n",
    "df_list = [train_df, dev_df, test_df]\n",
    "\n",
    "# iterate over the dfs and attatch directory prefix on each\n",
    "for df, df_name in zip(df_list, [\"train\", \"dev\", \"test\"]):\n",
    "    df = df\n",
    "\n",
    "    prefixed_df = attach_prefix(df, \"sw/clips/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37083656.mp3</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37085166.mp3</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37085182.mp3</td>\n",
       "      <td>Hawai ni kuzuri</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37085525.mp3</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37085535.mp3</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "1  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "2  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "3  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "4  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "\n",
       "                                    path  \\\n",
       "0  sw/clips/common_voice_sw_37083656.mp3   \n",
       "1  sw/clips/common_voice_sw_37085166.mp3   \n",
       "2  sw/clips/common_voice_sw_37085182.mp3   \n",
       "3  sw/clips/common_voice_sw_37085525.mp3   \n",
       "4  sw/clips/common_voice_sw_37085535.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  yeyote yule atakaepatikana akiandamana katika ...         2           0   \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...         3           1   \n",
       "2                                    Hawai ni kuzuri         2           0   \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...        13           3   \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...         2           1   \n",
       "\n",
       "        age  gender accents variant locale  segment  \n",
       "0  twenties  female     NaN     NaN     sw      NaN  \n",
       "1  twenties  female     NaN     NaN     sw      NaN  \n",
       "2  twenties  female     NaN     NaN     sw      NaN  \n",
       "3  twenties  female     NaN     NaN     sw      NaN  \n",
       "4  twenties  female     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628088.mp3</td>\n",
       "      <td>Mbali na kuwa afisa wa serikali Jokate pia ni ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628121.mp3</td>\n",
       "      <td>Kukosa pesa ni hatari sana</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628126.mp3</td>\n",
       "      <td>Jina Karagwe linatokana na kilima kinachopatik...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628160.mp3</td>\n",
       "      <td>sokwe wanaopatikana mahale ni aina adimu zaidi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628161.mp3</td>\n",
       "      <td>mamba wa mto naili wana sumu kali inayoozesha ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "1  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "2  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "3  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "4  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "\n",
       "                                    path  \\\n",
       "0  sw/clips/common_voice_sw_30628088.mp3   \n",
       "1  sw/clips/common_voice_sw_30628121.mp3   \n",
       "2  sw/clips/common_voice_sw_30628126.mp3   \n",
       "3  sw/clips/common_voice_sw_30628160.mp3   \n",
       "4  sw/clips/common_voice_sw_30628161.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  Mbali na kuwa afisa wa serikali Jokate pia ni ...         2           0   \n",
       "1                         Kukosa pesa ni hatari sana         3           1   \n",
       "2  Jina Karagwe linatokana na kilima kinachopatik...         2           0   \n",
       "3  sokwe wanaopatikana mahale ni aina adimu zaidi...         2           0   \n",
       "4  mamba wa mto naili wana sumu kali inayoozesha ...         3           0   \n",
       "\n",
       "        age gender accents variant locale  segment  \n",
       "0  twenties   male     NaN     NaN     sw      NaN  \n",
       "1  twenties   male     NaN     NaN     sw      NaN  \n",
       "2  twenties   male     NaN     NaN     sw      NaN  \n",
       "3  twenties   male     NaN     NaN     sw      NaN  \n",
       "4  twenties   male     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coqui-STT requires data to be in a specific format before training begins, i.e:\n",
    "* wav_filename: PATH to the wav files ( not mp3; format not supported)\n",
    "* wav_filesize: size of each wav clip in bytes\n",
    "* transcript: the sentence column transcribed for each clip\n",
    "\n",
    "**Note**: there are scripts to convert mp3 to wav and to do this preprocessing in the scripts module incuded in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_to_wav(df, label):\n",
    "  \"\"\"Converts all MP3 files in the `path` column to WAV files and saves them to a new directory (test, train, or dev) in the same folder as the original MP3 files.\n",
    "  Resamples at 16Khz\n",
    "  Args:\n",
    "    df: A Pandas DataFrame.\n",
    "    label: The label for the new directory (test, train, or dev).\n",
    "\n",
    "  Returns:\n",
    "    A Pandas DataFrame with the `path` column updated to point to the new WAV files.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a new directory for the WAV files.\n",
    "  new_dir = os.path.join(df['path'].iloc[0].split('/')[0], label)\n",
    "  os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "  # Iterate over the DataFrame and convert each MP3 file to WAV.\n",
    "  for i in range(len(df)):\n",
    "    mp3_path = df['path'].iloc[i]\n",
    "    wav_path = os.path.join(new_dir, os.path.basename(mp3_path).replace('.mp3', '.wav'))\n",
    "\n",
    "    # Convert the MP3 file to WAV.\n",
    "    audio = AudioSegment.from_mp3(mp3_path)\n",
    "    audio.export(wav_path, format='wav')\n",
    "\n",
    "    # Update the `path` column to point to the new WAV file.\n",
    "    df.loc[i, 'path'] = wav_path\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> **NOTE**: the 3 cells below need only be ran once and they may take some time to run as they are parsing a rather large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train_df clips to .wav\n",
    "# train_df = convert_mp3_to_wav(train_df, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dev_df clips to .wav\n",
    "# tdev_df = convert_mp3_to_wav(dev_df, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test_df clips to .wav\n",
    "# test_df = convert_mp3_to_wav(test_df, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we have already ran the notebook and obtained formatted csv files. We will re-read them to avoid having to process and format them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read formatted csv files\n",
    "train_df = pd.read_csv('sw/train.csv')\n",
    "test_df = pd.read_csv('sw/test.csv')\n",
    "dev_df = pd.read_csv('sw/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary script to do further data formatting; not required after converting to csv\n",
    "# dfs = [train_df, test_df, dev_df]\n",
    "\n",
    "# for df in dfs:\n",
    "#     df['wav_filename'] = df['wav_filename'].str.replace('sw/', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/common_voice_sw_37083656.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/common_voice_sw_37085166.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/common_voice_sw_37085182.wav</td>\n",
       "      <td>191276</td>\n",
       "      <td>hawai ni kuzuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/common_voice_sw_37085525.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/common_voice_sw_37085535.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_filename  wav_filesize  \\\n",
       "0  train/common_voice_sw_37083656.wav        359468   \n",
       "1  train/common_voice_sw_37085166.wav        391724   \n",
       "2  train/common_voice_sw_37085182.wav        191276   \n",
       "3  train/common_voice_sw_37085525.wav        391724   \n",
       "4  train/common_voice_sw_37085535.wav        391724   \n",
       "\n",
       "                                          transcript  \n",
       "0  yeyote yule atakaepatikana akiandamana katika ...  \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...  \n",
       "2                                    hawai ni kuzuri  \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...  \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/common_voice_sw_37190902.wav</td>\n",
       "      <td>225836</td>\n",
       "      <td>tuma pesa sahii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/common_voice_sw_31428161.wav</td>\n",
       "      <td>502316</td>\n",
       "      <td>wachambuzi wa soka wanamtaja messi kama nyota ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/common_voice_sw_30317714.wav</td>\n",
       "      <td>331820</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/common_voice_sw_32116997.wav</td>\n",
       "      <td>640556</td>\n",
       "      <td>sote twesangaa twelipomuona mwalimu ali apika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/common_voice_sw_29002392.wav</td>\n",
       "      <td>294956</td>\n",
       "      <td>inajulikana kama shina la warangi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wav_filename  wav_filesize  \\\n",
       "0  test/common_voice_sw_37190902.wav        225836   \n",
       "1  test/common_voice_sw_31428161.wav        502316   \n",
       "2  test/common_voice_sw_30317714.wav        331820   \n",
       "3  test/common_voice_sw_32116997.wav        640556   \n",
       "4  test/common_voice_sw_29002392.wav        294956   \n",
       "\n",
       "                                          transcript  \n",
       "0                                    tuma pesa sahii  \n",
       "1  wachambuzi wa soka wanamtaja messi kama nyota ...  \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...  \n",
       "3      sote twesangaa twelipomuona mwalimu ali apika  \n",
       "4                  inajulikana kama shina la warangi  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format acceptable: checking clip directories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format acceptable: checking clip directories\n",
      "Format acceptable: checking clip directories\n"
     ]
    }
   ],
   "source": [
    "# format DFs for training (Repetitive), needs to be better implemented (DRY)\n",
    "train_df = coqui_data_prepper.format_df(train_df, 'train')\n",
    "dev_df = coqui_data_prepper.format_df(dev_df, 'dev')\n",
    "test_df = coqui_data_prepper.format_df(test_df, label='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> **END NOTE**: try commenting the cells above if they have already be ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/common_voice_sw_37083656.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/common_voice_sw_37085166.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/common_voice_sw_37085182.wav</td>\n",
       "      <td>191276</td>\n",
       "      <td>hawai ni kuzuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/common_voice_sw_37085525.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/common_voice_sw_37085535.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_filename  wav_filesize  \\\n",
       "0  train/common_voice_sw_37083656.wav        359468   \n",
       "1  train/common_voice_sw_37085166.wav        391724   \n",
       "2  train/common_voice_sw_37085182.wav        191276   \n",
       "3  train/common_voice_sw_37085525.wav        391724   \n",
       "4  train/common_voice_sw_37085535.wav        391724   \n",
       "\n",
       "                                          transcript  \n",
       "0  yeyote yule atakaepatikana akiandamana katika ...  \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...  \n",
       "2                                    hawai ni kuzuri  \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...  \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/common_voice_sw_37190902.wav</td>\n",
       "      <td>225836</td>\n",
       "      <td>tuma pesa sahii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/common_voice_sw_31428161.wav</td>\n",
       "      <td>502316</td>\n",
       "      <td>wachambuzi wa soka wanamtaja messi kama nyota ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/common_voice_sw_30317714.wav</td>\n",
       "      <td>331820</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/common_voice_sw_32116997.wav</td>\n",
       "      <td>640556</td>\n",
       "      <td>sote twesangaa twelipomuona mwalimu ali apika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/common_voice_sw_29002392.wav</td>\n",
       "      <td>294956</td>\n",
       "      <td>inajulikana kama shina la warangi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wav_filename  wav_filesize  \\\n",
       "0  test/common_voice_sw_37190902.wav        225836   \n",
       "1  test/common_voice_sw_31428161.wav        502316   \n",
       "2  test/common_voice_sw_30317714.wav        331820   \n",
       "3  test/common_voice_sw_32116997.wav        640556   \n",
       "4  test/common_voice_sw_29002392.wav        294956   \n",
       "\n",
       "                                          transcript  \n",
       "0                                    tuma pesa sahii  \n",
       "1  wachambuzi wa soka wanamtaja messi kama nyota ...  \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...  \n",
       "3      sote twesangaa twelipomuona mwalimu ali apika  \n",
       "4                  inajulikana kama shina la warangi  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert transcript to lower case characters\n",
    "def to_lower(df, column_name):\n",
    "  \"\"\"Converts all characters in a column to lowercase.\n",
    "\n",
    "  Args:\n",
    "    df: A Pandas DataFrame.\n",
    "    column_name: The name of the column to convert to lowercase.\n",
    "\n",
    "  Returns:\n",
    "    A Pandas DataFrame with the column `column_name` converted to lowercase.\n",
    "  \"\"\"\n",
    "\n",
    "  df[column_name] = df[column_name].str.lower()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = to_lower(train_df, 'transcript')\n",
    "dev_df = to_lower(dev_df, 'transcript')\n",
    "test_df = to_lower(test_df, 'transcript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and unnecessay whitespace\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove underscores\n",
    "    text = text.replace('_', '')\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing to 'transcript' column in train_df\n",
    "train_df['transcript'] = train_df['transcript'].apply(preprocess_text)\n",
    "\n",
    "# Apply preprocessing to 'transcript' column in dev_df\n",
    "dev_df['transcript'] = dev_df['transcript'].apply(preprocess_text)\n",
    "\n",
    "# Apply preprocessing to 'transcript' column in test_df\n",
    "test_df['transcript'] = test_df['transcript'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/common_voice_sw_37083656.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/common_voice_sw_37085166.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/common_voice_sw_37085182.wav</td>\n",
       "      <td>191276</td>\n",
       "      <td>hawai ni kuzuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/common_voice_sw_37085525.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/common_voice_sw_37085535.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_filename  wav_filesize  \\\n",
       "0  train/common_voice_sw_37083656.wav        359468   \n",
       "1  train/common_voice_sw_37085166.wav        391724   \n",
       "2  train/common_voice_sw_37085182.wav        191276   \n",
       "3  train/common_voice_sw_37085525.wav        391724   \n",
       "4  train/common_voice_sw_37085535.wav        391724   \n",
       "\n",
       "                                          transcript  \n",
       "0  yeyote yule atakaepatikana akiandamana katika ...  \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...  \n",
       "2                                    hawai ni kuzuri  \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...  \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev/common_voice_sw_30628088.wav</td>\n",
       "      <td>322604</td>\n",
       "      <td>mbali na kuwa afisa wa serikali jokate pia ni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev/common_voice_sw_30628121.wav</td>\n",
       "      <td>225836</td>\n",
       "      <td>kukosa pesa ni hatari sana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev/common_voice_sw_30628126.wav</td>\n",
       "      <td>375596</td>\n",
       "      <td>jina karagwe linatokana na kilima kinachopatik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev/common_voice_sw_30628160.wav</td>\n",
       "      <td>336428</td>\n",
       "      <td>sokwe wanaopatikana mahale ni aina adimu zaidi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev/common_voice_sw_30628161.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>mamba wa mto naili wana sumu kali inayoozesha ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       wav_filename  wav_filesize  \\\n",
       "0  dev/common_voice_sw_30628088.wav        322604   \n",
       "1  dev/common_voice_sw_30628121.wav        225836   \n",
       "2  dev/common_voice_sw_30628126.wav        375596   \n",
       "3  dev/common_voice_sw_30628160.wav        336428   \n",
       "4  dev/common_voice_sw_30628161.wav        359468   \n",
       "\n",
       "                                          transcript  \n",
       "0  mbali na kuwa afisa wa serikali jokate pia ni ...  \n",
       "1                         kukosa pesa ni hatari sana  \n",
       "2  jina karagwe linatokana na kilima kinachopatik...  \n",
       "3  sokwe wanaopatikana mahale ni aina adimu zaidi...  \n",
       "4  mamba wa mto naili wana sumu kali inayoozesha ...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/common_voice_sw_37190902.wav</td>\n",
       "      <td>225836</td>\n",
       "      <td>tuma pesa sahii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/common_voice_sw_31428161.wav</td>\n",
       "      <td>502316</td>\n",
       "      <td>wachambuzi wa soka wanamtaja messi kama nyota ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/common_voice_sw_30317714.wav</td>\n",
       "      <td>331820</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/common_voice_sw_32116997.wav</td>\n",
       "      <td>640556</td>\n",
       "      <td>sote twesangaa twelipomuona mwalimu ali apika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/common_voice_sw_29002392.wav</td>\n",
       "      <td>294956</td>\n",
       "      <td>inajulikana kama shina la warangi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wav_filename  wav_filesize  \\\n",
       "0  test/common_voice_sw_37190902.wav        225836   \n",
       "1  test/common_voice_sw_31428161.wav        502316   \n",
       "2  test/common_voice_sw_30317714.wav        331820   \n",
       "3  test/common_voice_sw_32116997.wav        640556   \n",
       "4  test/common_voice_sw_29002392.wav        294956   \n",
       "\n",
       "                                          transcript  \n",
       "0                                    tuma pesa sahii  \n",
       "1  wachambuzi wa soka wanamtaja messi kama nyota ...  \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...  \n",
       "3      sote twesangaa twelipomuona mwalimu ali apika  \n",
       "4                  inajulikana kama shina la warangi  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to convert the *train*, *dev* and *test* tsc files to csv to work with `coqui`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of Pandas DataFrames\n",
    "df_list = [train_df, dev_df, test_df]\n",
    "\n",
    "# Create the sw/ directory if it does not exist\n",
    "csv_directory_path = \"sw/\"\n",
    "if not os.path.exists(csv_directory_path):\n",
    "    os.makedirs(csv_directory_path)\n",
    "\n",
    "# Iterate over the list of DataFrames and save each DataFrame to a CSV file\n",
    "for df, df_name in zip(df_list, [\"train\", \"dev\", \"test\"]):\n",
    "\n",
    "    # Join the DataFrame name with the CSV directory path\n",
    "    csv_file_path = os.path.join(csv_directory_path, df_name + \".csv\")\n",
    "\n",
    "    # Save the DataFrame to the CSV file\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv training files are saved, but the `transcript` columns need additional preprocessing e.g **tokenization** to work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect alphabet\n",
    "import chardet\n",
    "\n",
    "def detect_characters_in_dataframes(train_df, dev_df, test_df, alphabet_file_path):\n",
    "  \"\"\"Detects all the characters in the column 'transcript' for dataframes 'train_df, dev_df and test_df' and saves them to a file.\n",
    "\n",
    "  Args:\n",
    "    train_df: A Pandas dataframe containing the training data.\n",
    "    dev_df: A Pandas dataframe containing the development data.\n",
    "    test_df: A Pandas dataframe containing the test data.\n",
    "    alphabet_file_path: The path to the file to save the alphabet to.\n",
    "  \"\"\"\n",
    "\n",
    "  alphabet = set()\n",
    "\n",
    "  for df in [train_df, dev_df, test_df]:\n",
    "    transcripts = df[\"transcript\"]\n",
    "\n",
    "    for transcript in transcripts:\n",
    "      characters = chardet.detect(transcript.encode())[\"encoding\"]\n",
    "\n",
    "      for character in characters:\n",
    "        alphabet.add(character)\n",
    "\n",
    "  with open(alphabet_file_path, \"w\") as alphabet_file:\n",
    "    for character in alphabet:\n",
    "      alphabet_file.write(character + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above detects alphabet characters in the corpus. It is (optionally) ran in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet_file_path = \"sw/alphabet.txt\"\n",
    "\n",
    "# detect_characters_in_dataframes(train_df, dev_df, test_df, alphabet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZE DEFAULT HYPERPARAMETERS (Coqui-stt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I --alphabet_config_path not specified, but all input datasets are present and in the same folder (--train_files, --dev_files and --test_files), and an alphabet.txt file was found alongside the sets (sw/alphabet.txt). Will use this alphabet file for this run.\n"
     ]
    }
   ],
   "source": [
    "from coqui_stt_training.util.config import initialize_globals_from_args\n",
    "\n",
    "initialize_globals_from_args(\n",
    "    checkpoint_dir=\"ckpt_dir\",\n",
    "    train_files=[\"sw/train.csv\"],\n",
    "    dev_files=[\"sw/dev.csv\"],\n",
    "    test_files=[\"sw/test.csv\"],\n",
    "    load_train=\"init\",\n",
    "    n_hidden=100,\n",
    "    epochs=2,\n",
    "    train_batch_size=1,\n",
    "    dev_batch_size=1,\n",
    "    test_batch_size= 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m coqui_stt_training.train --train_files sw/train.csv --dev_files sw/dev.csv --test_files sw/test.csv --checkpoint_dir ckpt_dir --n_hidden 100 --epochs 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Performing dummy training to check for memory problems.\n",
      "I If the following process crashes, you likely have batch sizes that are too big for your available system memory (or GPU memory).\n",
      "I Initializing all variables.\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 1806.064331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 2 | Loss: 1506.971375\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 1351.944580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 1351.944580\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:01 | Steps: 1 | Loss: 812.518127 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 3 | Loss: 709.431641 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 3 | Loss: 709.431641 | Dataset: sw/dev.csv\n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:06.484964\n",
      "I Dummy run finished without problems, now starting real training process.\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 142.881897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 140.196945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 5 | Loss: 129.433104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 7 | Loss: 113.601940\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 8 | Loss: 107.577549\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 12 | Loss: 93.518360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 18 | Loss: 98.121516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 21 | Loss: 90.834554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 23 | Loss: 90.294288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 25 | Loss: 86.981880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 29 | Loss: 82.831740\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 32 | Loss: 80.460395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 34 | Loss: 79.610699\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 37 | Loss: 77.179297\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 39 | Loss: 76.446725\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 41 | Loss: 75.807861\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 44 | Loss: 73.573554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 47 | Loss: 71.489737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 50 | Loss: 70.359481\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 52 | Loss: 69.344974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 54 | Loss: 68.302823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 57 | Loss: 67.018540\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 60 | Loss: 66.525124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 62 | Loss: 67.283181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 65 | Loss: 66.384099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 67 | Loss: 65.706970\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 69 | Loss: 65.205865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 73 | Loss: 64.446977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 75 | Loss: 63.828848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 77 | Loss: 64.365597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 80 | Loss: 63.727202\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 82 | Loss: 63.473686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 85 | Loss: 62.813676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 87 | Loss: 62.648322\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 89 | Loss: 62.400161\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 90 | Loss: 62.078422\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 94 | Loss: 61.395668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 96 | Loss: 61.355269\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 99 | Loss: 61.397711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 101 | Loss: 61.123291\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 105 | Loss: 61.225397\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 109 | Loss: 61.219358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 113 | Loss: 60.471386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 117 | Loss: 60.117979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 119 | Loss: 59.819723\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 123 | Loss: 59.723230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 126 | Loss: 59.655654\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 129 | Loss: 59.633183\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 132 | Loss: 59.567777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 134 | Loss: 59.452322\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 137 | Loss: 59.179481\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 141 | Loss: 60.155622\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 145 | Loss: 59.702975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 148 | Loss: 59.710343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 151 | Loss: 59.609930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 154 | Loss: 60.867583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 156 | Loss: 60.716518\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 159 | Loss: 60.445036\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 161 | Loss: 60.370682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 163 | Loss: 60.104423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 166 | Loss: 59.848860\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 169 | Loss: 59.859495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 172 | Loss: 60.432555\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 174 | Loss: 60.100371\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 176 | Loss: 60.118019\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 178 | Loss: 59.978170\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 180 | Loss: 59.977793\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 183 | Loss: 59.968744\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 185 | Loss: 60.402794\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 189 | Loss: 60.624543\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 192 | Loss: 60.560829\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 194 | Loss: 60.382862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 195 | Loss: 60.470663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 197 | Loss: 60.385043\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 199 | Loss: 60.311485\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 202 | Loss: 60.346186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 204 | Loss: 60.164146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 207 | Loss: 60.187880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 209 | Loss: 60.074431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 213 | Loss: 59.906758\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 215 | Loss: 59.769258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 219 | Loss: 59.786103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 223 | Loss: 59.639103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 227 | Loss: 59.443004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 229 | Loss: 59.352986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 232 | Loss: 59.478631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 233 | Loss: 59.579898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 237 | Loss: 59.274287\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 240 | Loss: 59.090379\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 243 | Loss: 59.255325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 245 | Loss: 59.216658\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 247 | Loss: 59.040273\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 249 | Loss: 58.909022\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 253 | Loss: 58.798226\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 255 | Loss: 58.691924\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 259 | Loss: 58.514990\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 262 | Loss: 58.587427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 264 | Loss: 59.102242\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 267 | Loss: 59.312164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 271 | Loss: 59.508519\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 274 | Loss: 59.473958\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 277 | Loss: 59.416408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 280 | Loss: 59.452107\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 282 | Loss: 59.694930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 284 | Loss: 59.660783\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 287 | Loss: 59.697052\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 290 | Loss: 59.726783\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 292 | Loss: 59.660030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 295 | Loss: 59.567567\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 298 | Loss: 59.396055\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 301 | Loss: 59.328259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 303 | Loss: 59.351631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 305 | Loss: 59.300321\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 308 | Loss: 59.205331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 311 | Loss: 59.331731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 315 | Loss: 59.212339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 317 | Loss: 59.290936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 321 | Loss: 60.004555\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 323 | Loss: 60.167893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 327 | Loss: 60.248374\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 330 | Loss: 60.158860\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 331 | Loss: 60.151198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 335 | Loss: 60.173096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 337 | Loss: 60.158400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 339 | Loss: 60.501623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 342 | Loss: 61.165891\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 345 | Loss: 61.119722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 347 | Loss: 61.195766\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 349 | Loss: 61.212618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 351 | Loss: 61.206787\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 353 | Loss: 61.342883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 356 | Loss: 61.512433\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 357 | Loss: 61.460155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 360 | Loss: 61.483851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 361 | Loss: 61.464752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 365 | Loss: 61.363545\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 368 | Loss: 61.291661\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 370 | Loss: 61.180577\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 371 | Loss: 61.156514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 375 | Loss: 61.006420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 379 | Loss: 60.922968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 381 | Loss: 60.827280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 384 | Loss: 60.804904\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 385 | Loss: 60.754438\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 387 | Loss: 60.707189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 391 | Loss: 60.494168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 393 | Loss: 60.473174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 396 | Loss: 60.444211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 398 | Loss: 60.506701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 399 | Loss: 60.511074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 402 | Loss: 60.535646\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 404 | Loss: 60.555521\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 407 | Loss: 60.698272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 409 | Loss: 60.768116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 413 | Loss: 60.664562\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 416 | Loss: 60.627934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 418 | Loss: 60.585941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 420 | Loss: 60.556075\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 423 | Loss: 60.649038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 427 | Loss: 60.813395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 429 | Loss: 60.910069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 431 | Loss: 60.849883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 433 | Loss: 61.076012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 435 | Loss: 61.149533\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 437 | Loss: 61.150165\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 439 | Loss: 61.186749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 442 | Loss: 61.215280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 444 | Loss: 61.238976\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 448 | Loss: 61.245380\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 450 | Loss: 61.227683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 453 | Loss: 61.213150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 456 | Loss: 61.144916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 459 | Loss: 61.090067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 461 | Loss: 61.020671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 463 | Loss: 60.945226\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 467 | Loss: 60.817873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 470 | Loss: 60.814604\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 472 | Loss: 60.740683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 475 | Loss: 60.733249\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 477 | Loss: 60.755416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 481 | Loss: 60.922168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 485 | Loss: 60.844436\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 487 | Loss: 60.812768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 490 | Loss: 60.798957\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 492 | Loss: 60.825418\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 494 | Loss: 60.959266\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 497 | Loss: 61.216989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 499 | Loss: 61.204731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 502 | Loss: 61.229328\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 504 | Loss: 61.421544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 505 | Loss: 61.504717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 509 | Loss: 61.562934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 512 | Loss: 61.603360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 514 | Loss: 61.643731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 517 | Loss: 61.720581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 519 | Loss: 61.697592\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 522 | Loss: 61.703757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 524 | Loss: 61.666663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 527 | Loss: 61.609056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 530 | Loss: 61.630613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 532 | Loss: 61.617843\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 535 | Loss: 61.568544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 538 | Loss: 61.482241\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 540 | Loss: 61.499831\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 543 | Loss: 61.432108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 545 | Loss: 61.460276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 549 | Loss: 61.353655\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 551 | Loss: 61.294279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 555 | Loss: 61.185372\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 558 | Loss: 61.280317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 560 | Loss: 61.315465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 563 | Loss: 61.338415\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 566 | Loss: 61.281878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 568 | Loss: 61.277388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 570 | Loss: 61.349523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 572 | Loss: 61.442838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 575 | Loss: 61.525088\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 578 | Loss: 61.693774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 580 | Loss: 61.724899\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 583 | Loss: 61.666252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 586 | Loss: 61.559679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 587 | Loss: 61.526914\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 590 | Loss: 61.482656\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 593 | Loss: 61.488224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 595 | Loss: 61.591695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 599 | Loss: 61.937179\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 602 | Loss: 61.956309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 605 | Loss: 61.921558\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 609 | Loss: 62.046184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 611 | Loss: 62.086096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 613 | Loss: 62.163458\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 617 | Loss: 62.163929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 619 | Loss: 62.138080\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 621 | Loss: 62.093081\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 624 | Loss: 62.062682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 626 | Loss: 62.126494\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 629 | Loss: 62.074941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 632 | Loss: 62.024888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 634 | Loss: 62.017665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 636 | Loss: 61.970593\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 639 | Loss: 61.902278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 643 | Loss: 61.909511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 646 | Loss: 61.862188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 648 | Loss: 61.806254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 650 | Loss: 61.797711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 653 | Loss: 61.766667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 655 | Loss: 61.770148\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 657 | Loss: 61.743400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 659 | Loss: 61.741583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 662 | Loss: 61.730057\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 664 | Loss: 61.828523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 667 | Loss: 61.798927\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 670 | Loss: 61.771528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 673 | Loss: 61.786338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 677 | Loss: 61.801172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 679 | Loss: 61.863682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 682 | Loss: 61.870528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 685 | Loss: 61.826016\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 687 | Loss: 61.787623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 691 | Loss: 61.948489\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 694 | Loss: 62.024986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 696 | Loss: 62.395194\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 699 | Loss: 62.374746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 701 | Loss: 62.413987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 704 | Loss: 62.483388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 707 | Loss: 62.642902\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 710 | Loss: 62.692029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 713 | Loss: 62.680682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 715 | Loss: 62.658855\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 718 | Loss: 62.637099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 721 | Loss: 62.620155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 724 | Loss: 62.616400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 726 | Loss: 62.560480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 728 | Loss: 62.595889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 731 | Loss: 62.542692\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 733 | Loss: 62.535852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 736 | Loss: 62.600041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 737 | Loss: 62.620532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 741 | Loss: 62.624561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 743 | Loss: 62.686126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 746 | Loss: 62.703330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 749 | Loss: 62.704386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 751 | Loss: 62.711834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 754 | Loss: 62.719554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 756 | Loss: 62.773526\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 759 | Loss: 62.810494\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 762 | Loss: 62.858730\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 765 | Loss: 62.815457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 767 | Loss: 62.896878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 770 | Loss: 62.998347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 773 | Loss: 62.966173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 777 | Loss: 62.953868\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 779 | Loss: 62.982079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 781 | Loss: 62.980942\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 783 | Loss: 62.956984\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 786 | Loss: 63.030357\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 789 | Loss: 63.150492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 792 | Loss: 63.277423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 793 | Loss: 63.299918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 796 | Loss: 63.342609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 799 | Loss: 63.375478\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 801 | Loss: 63.433065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 804 | Loss: 63.533438\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 808 | Loss: 63.564985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 812 | Loss: 63.597640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 814 | Loss: 63.603185\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 818 | Loss: 63.588447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 821 | Loss: 63.565162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 822 | Loss: 63.575331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 826 | Loss: 63.564790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 829 | Loss: 63.595586\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 831 | Loss: 63.594335\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 834 | Loss: 63.573458\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 837 | Loss: 63.538874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 839 | Loss: 63.530937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 842 | Loss: 63.511308\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 845 | Loss: 63.515707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 848 | Loss: 63.497041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 850 | Loss: 63.559688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 852 | Loss: 63.639425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 855 | Loss: 63.717396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 858 | Loss: 63.697917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 861 | Loss: 63.747277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 863 | Loss: 63.750485\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 865 | Loss: 63.780801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 868 | Loss: 63.926887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 871 | Loss: 63.961993\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 873 | Loss: 63.996310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 875 | Loss: 64.016879\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 878 | Loss: 63.996471\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 881 | Loss: 63.960131\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 883 | Loss: 63.938129\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 885 | Loss: 63.993845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 887 | Loss: 64.067398\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 889 | Loss: 64.131182\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 892 | Loss: 64.190926\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 894 | Loss: 64.319822\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 896 | Loss: 64.382628\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 899 | Loss: 64.447221\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 902 | Loss: 64.451952\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 905 | Loss: 64.641862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 907 | Loss: 64.670050\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 910 | Loss: 64.809579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 912 | Loss: 64.804198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 915 | Loss: 64.755086\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 918 | Loss: 64.789108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 921 | Loss: 64.861968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 923 | Loss: 64.860137\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 926 | Loss: 64.861883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 928 | Loss: 64.858092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 931 | Loss: 64.852281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 934 | Loss: 64.855420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 937 | Loss: 64.820920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 940 | Loss: 64.803159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 942 | Loss: 64.819317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 945 | Loss: 64.792349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 947 | Loss: 64.802239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 950 | Loss: 64.795557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 952 | Loss: 64.815589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 955 | Loss: 64.790217\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 957 | Loss: 64.780320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 959 | Loss: 64.805610\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 961 | Loss: 64.869788\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 963 | Loss: 64.953227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 966 | Loss: 64.940573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 969 | Loss: 65.015504\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 970 | Loss: 65.006331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 972 | Loss: 65.086915\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 975 | Loss: 65.087690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 978 | Loss: 65.031030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 981 | Loss: 65.054284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 983 | Loss: 65.079815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 986 | Loss: 65.116817\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 988 | Loss: 65.134364\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 991 | Loss: 65.151104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 993 | Loss: 65.176724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 996 | Loss: 65.294090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 999 | Loss: 65.443564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1001 | Loss: 65.462215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1004 | Loss: 65.490681\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1007 | Loss: 65.461864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1010 | Loss: 65.506222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1013 | Loss: 65.485340\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1015 | Loss: 65.517224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1017 | Loss: 65.547012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1018 | Loss: 65.541779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1020 | Loss: 65.557569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1022 | Loss: 65.601706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1025 | Loss: 65.730641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1028 | Loss: 65.846491\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1030 | Loss: 66.000301\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1033 | Loss: 65.976313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1036 | Loss: 65.972057\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1039 | Loss: 65.964544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1042 | Loss: 66.125358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1045 | Loss: 66.151569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1048 | Loss: 66.226211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1050 | Loss: 66.304037\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1053 | Loss: 66.351382\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1055 | Loss: 66.364205\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1058 | Loss: 66.389273\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1061 | Loss: 66.404265\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1064 | Loss: 66.397341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1066 | Loss: 66.387789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1069 | Loss: 66.428297\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1072 | Loss: 66.444737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1074 | Loss: 66.451688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1077 | Loss: 66.449719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1080 | Loss: 66.428141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1082 | Loss: 66.418388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1084 | Loss: 66.407930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1087 | Loss: 66.405389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1089 | Loss: 66.396730\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1092 | Loss: 66.328517\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1094 | Loss: 66.347580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1097 | Loss: 66.367350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1100 | Loss: 66.378827\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1102 | Loss: 66.373439\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1104 | Loss: 66.377692\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1107 | Loss: 66.433613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1110 | Loss: 66.453342\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1112 | Loss: 66.512672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1114 | Loss: 66.463407\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1116 | Loss: 66.436868\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1119 | Loss: 66.429136\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1121 | Loss: 66.442134\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1123 | Loss: 66.486200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1126 | Loss: 66.489948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1128 | Loss: 66.534969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1131 | Loss: 66.585120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1133 | Loss: 66.624206\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1135 | Loss: 66.649782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1137 | Loss: 66.657134\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1140 | Loss: 66.602441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1142 | Loss: 66.597580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1145 | Loss: 66.634120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1147 | Loss: 66.603496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1150 | Loss: 66.595128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1154 | Loss: 66.751722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1156 | Loss: 66.828607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1159 | Loss: 66.916542\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1161 | Loss: 67.012140\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1164 | Loss: 67.087317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1166 | Loss: 67.164740\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1168 | Loss: 67.185595\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1171 | Loss: 67.163038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1173 | Loss: 67.218391\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1176 | Loss: 67.300796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1179 | Loss: 67.295416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1181 | Loss: 67.369614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1184 | Loss: 67.301657\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1187 | Loss: 67.374186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1190 | Loss: 67.409433\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1193 | Loss: 67.428527\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1195 | Loss: 67.427445\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1197 | Loss: 67.410083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1200 | Loss: 67.403411\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1203 | Loss: 67.405773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1205 | Loss: 67.414551\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1207 | Loss: 67.402094\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1210 | Loss: 67.420893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1213 | Loss: 67.438002\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1215 | Loss: 67.431017\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1217 | Loss: 67.446065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1220 | Loss: 67.455503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1222 | Loss: 67.435933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1224 | Loss: 67.427215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1227 | Loss: 67.425367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1230 | Loss: 67.475129\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1232 | Loss: 67.448818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1235 | Loss: 67.423500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1238 | Loss: 67.375705\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1240 | Loss: 67.382604\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1243 | Loss: 67.354839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1246 | Loss: 67.372078\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1250 | Loss: 67.442320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1253 | Loss: 67.419108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1256 | Loss: 67.440710\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1260 | Loss: 67.461335\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1262 | Loss: 67.496560\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1265 | Loss: 67.489492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1267 | Loss: 67.483995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1270 | Loss: 67.532155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1273 | Loss: 67.519166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1275 | Loss: 67.611481\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1278 | Loss: 67.666280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1280 | Loss: 67.686850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1284 | Loss: 67.686237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1286 | Loss: 67.681761\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1289 | Loss: 67.701901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1291 | Loss: 67.732819\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1294 | Loss: 67.699443\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1296 | Loss: 67.653732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1299 | Loss: 67.635828\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1302 | Loss: 67.641145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1305 | Loss: 67.674146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1306 | Loss: 67.698668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1309 | Loss: 67.755077\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1312 | Loss: 67.858587\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1314 | Loss: 67.910064\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1316 | Loss: 68.039428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1319 | Loss: 68.210318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1321 | Loss: 68.192035\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1324 | Loss: 68.193067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1327 | Loss: 68.181616\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1329 | Loss: 68.220755\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1332 | Loss: 68.310197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1334 | Loss: 68.342939\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1336 | Loss: 68.350396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1339 | Loss: 68.381665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1341 | Loss: 68.474535\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1343 | Loss: 68.567967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1345 | Loss: 68.597804\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1348 | Loss: 68.610828\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1350 | Loss: 68.607930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1353 | Loss: 68.591147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1355 | Loss: 68.605850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1358 | Loss: 68.650162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1360 | Loss: 68.658408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1364 | Loss: 68.641023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1366 | Loss: 68.663094\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1370 | Loss: 68.694143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1373 | Loss: 68.696624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1376 | Loss: 68.685979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1379 | Loss: 68.673083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1382 | Loss: 68.686509\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1385 | Loss: 68.681878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1387 | Loss: 68.666340\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1390 | Loss: 68.670329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1393 | Loss: 68.722597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1395 | Loss: 68.747524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1398 | Loss: 68.756373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1400 | Loss: 68.822210\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1402 | Loss: 68.814514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1404 | Loss: 68.820461\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1407 | Loss: 68.863394\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1409 | Loss: 68.853635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1412 | Loss: 68.875695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1414 | Loss: 68.933638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1416 | Loss: 68.996188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1419 | Loss: 69.104255\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1421 | Loss: 69.105015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1424 | Loss: 69.079809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1426 | Loss: 69.099253\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1429 | Loss: 69.059304\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1431 | Loss: 69.073025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1433 | Loss: 69.113457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1436 | Loss: 69.193807\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1438 | Loss: 69.262897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1441 | Loss: 69.281627\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1443 | Loss: 69.263888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1445 | Loss: 69.270328\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1448 | Loss: 69.300618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1450 | Loss: 69.294568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1453 | Loss: 69.266996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1455 | Loss: 69.322609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1457 | Loss: 69.311550\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1460 | Loss: 69.261948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1463 | Loss: 69.331679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1466 | Loss: 69.353922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1468 | Loss: 69.358010\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1470 | Loss: 69.372840\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1474 | Loss: 69.333111\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1476 | Loss: 69.421463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1479 | Loss: 69.533452\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1481 | Loss: 69.558206\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1484 | Loss: 69.613636\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1487 | Loss: 69.636792\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1488 | Loss: 69.621256\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1492 | Loss: 69.658110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1495 | Loss: 69.697179\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1498 | Loss: 69.669477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1501 | Loss: 69.661954\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1503 | Loss: 69.652637\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1506 | Loss: 69.643723\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1509 | Loss: 69.636151\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1511 | Loss: 69.641866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1514 | Loss: 69.673565\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1516 | Loss: 69.697103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1519 | Loss: 69.724710\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1522 | Loss: 69.711581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1524 | Loss: 69.704508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1526 | Loss: 69.702373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1529 | Loss: 69.695050\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1531 | Loss: 69.693930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1534 | Loss: 69.678003\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1536 | Loss: 69.664863\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1539 | Loss: 69.688267\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1540 | Loss: 69.680661\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1544 | Loss: 69.665408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1546 | Loss: 69.655444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1548 | Loss: 69.659200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1550 | Loss: 69.665155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1552 | Loss: 69.658125\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1555 | Loss: 69.638544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1557 | Loss: 69.643928\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1559 | Loss: 69.659349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1561 | Loss: 69.710072\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1564 | Loss: 69.755014\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1566 | Loss: 69.738869\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1569 | Loss: 69.796241\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1571 | Loss: 69.822463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1574 | Loss: 69.778416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1577 | Loss: 69.787354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1579 | Loss: 69.750171\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1582 | Loss: 69.778068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1584 | Loss: 69.803246\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1586 | Loss: 69.850068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1589 | Loss: 69.910708\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1592 | Loss: 69.923032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1594 | Loss: 69.938508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1597 | Loss: 70.016326\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1598 | Loss: 70.020546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1602 | Loss: 70.125038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1605 | Loss: 70.070422\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1607 | Loss: 70.052342\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1608 | Loss: 70.041772\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1612 | Loss: 69.991569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1614 | Loss: 70.012283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1617 | Loss: 70.030372\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1619 | Loss: 70.021484\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1621 | Loss: 70.098320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1623 | Loss: 70.171571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1626 | Loss: 70.194272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1629 | Loss: 70.242056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1631 | Loss: 70.240371\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1634 | Loss: 70.340335\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1636 | Loss: 70.384141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1638 | Loss: 70.434085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1640 | Loss: 70.449436\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1642 | Loss: 70.463382\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1645 | Loss: 70.490200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1648 | Loss: 70.504916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1651 | Loss: 70.584229\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1652 | Loss: 70.574272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1655 | Loss: 70.595724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1658 | Loss: 70.617310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1660 | Loss: 70.637062\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1662 | Loss: 70.614251\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1664 | Loss: 70.625341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1667 | Loss: 70.582602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1669 | Loss: 70.582550\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1671 | Loss: 70.566613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1674 | Loss: 70.608132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1677 | Loss: 70.616904\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1678 | Loss: 70.623864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1681 | Loss: 70.643118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1684 | Loss: 70.662234\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1686 | Loss: 70.679882\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1688 | Loss: 70.667950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1691 | Loss: 70.651167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1693 | Loss: 70.651354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1696 | Loss: 70.648722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1699 | Loss: 70.648564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1701 | Loss: 70.656213\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1703 | Loss: 70.653877\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1706 | Loss: 70.619770\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1708 | Loss: 70.604193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1711 | Loss: 70.573809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1714 | Loss: 70.561047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1717 | Loss: 70.666795\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1718 | Loss: 70.689754\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1722 | Loss: 70.726450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1724 | Loss: 70.746384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1727 | Loss: 70.793097\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1729 | Loss: 70.785506\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1732 | Loss: 70.811694\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1735 | Loss: 70.858156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1737 | Loss: 70.892529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1740 | Loss: 70.907732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1743 | Loss: 70.923825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1744 | Loss: 70.938785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1748 | Loss: 70.994224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1750 | Loss: 71.018987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1753 | Loss: 71.024603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1755 | Loss: 71.096945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1757 | Loss: 71.178759\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1759 | Loss: 71.208360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1762 | Loss: 71.222046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1764 | Loss: 71.225250\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1767 | Loss: 71.267159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1770 | Loss: 71.286356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1773 | Loss: 71.299301\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1776 | Loss: 71.292153\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1779 | Loss: 71.299742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1781 | Loss: 71.276217\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1784 | Loss: 71.315973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1787 | Loss: 71.399835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1789 | Loss: 71.412886\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1792 | Loss: 71.480681\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1794 | Loss: 71.519367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1796 | Loss: 71.588060\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1799 | Loss: 71.586946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1801 | Loss: 71.591327\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1803 | Loss: 71.580707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1805 | Loss: 71.590824\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1808 | Loss: 71.639288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1811 | Loss: 71.692487\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1813 | Loss: 71.749180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1816 | Loss: 71.829217\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1818 | Loss: 71.871927\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1820 | Loss: 71.905393\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1822 | Loss: 71.941713\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1825 | Loss: 71.948589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1827 | Loss: 71.936338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1829 | Loss: 71.971805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1831 | Loss: 71.981962\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1834 | Loss: 71.998019\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1836 | Loss: 72.021459\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1839 | Loss: 72.050143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1842 | Loss: 72.040529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1844 | Loss: 72.022064\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1847 | Loss: 72.064875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1849 | Loss: 72.077489\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1851 | Loss: 72.087467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1853 | Loss: 72.109068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1856 | Loss: 72.113371\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1858 | Loss: 72.105077\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1861 | Loss: 72.132175\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1863 | Loss: 72.161608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1865 | Loss: 72.156193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1868 | Loss: 72.151379\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1871 | Loss: 72.159901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1874 | Loss: 72.131196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1876 | Loss: 72.122018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1878 | Loss: 72.126931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1882 | Loss: 72.152977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1885 | Loss: 72.162588\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1888 | Loss: 72.146613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1890 | Loss: 72.180030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1892 | Loss: 72.189883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1895 | Loss: 72.177384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1898 | Loss: 72.480527\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1901 | Loss: 72.506124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1903 | Loss: 72.544350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1905 | Loss: 72.559556\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1908 | Loss: 72.651381\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1910 | Loss: 72.662950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1912 | Loss: 72.669385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1915 | Loss: 72.678433\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1917 | Loss: 72.706800\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1920 | Loss: 72.705031\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1923 | Loss: 72.686735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1926 | Loss: 72.705757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1929 | Loss: 72.785852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1931 | Loss: 72.767142\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1934 | Loss: 72.755490\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1936 | Loss: 72.784740\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1939 | Loss: 72.879234\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1942 | Loss: 72.910267\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1944 | Loss: 72.980132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1946 | Loss: 73.012708\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1948 | Loss: 73.020504\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1951 | Loss: 73.031644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1954 | Loss: 73.005594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1956 | Loss: 73.050956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1959 | Loss: 73.096238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1962 | Loss: 73.089780\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1965 | Loss: 73.138110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1967 | Loss: 73.129727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1969 | Loss: 73.132556\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1972 | Loss: 73.152338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1974 | Loss: 73.191463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1977 | Loss: 73.178806\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1979 | Loss: 73.165893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1982 | Loss: 73.240658\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1985 | Loss: 73.307253\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1987 | Loss: 73.336159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1990 | Loss: 73.341135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1992 | Loss: 73.340469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1995 | Loss: 73.373997\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1998 | Loss: 73.375159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 2000 | Loss: 73.374620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 2003 | Loss: 73.389448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 2006 | Loss: 73.426562\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 2009 | Loss: 73.469391\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 2012 | Loss: 73.562042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 2014 | Loss: 73.594281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 2017 | Loss: 73.662851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 2018 | Loss: 73.687583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 2021 | Loss: 73.708673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 2024 | Loss: 73.749237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 2026 | Loss: 73.779237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 2028 | Loss: 73.793158\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 2032 | Loss: 73.785191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 2034 | Loss: 73.848643\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 2036 | Loss: 73.885548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 2039 | Loss: 73.894171\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 2042 | Loss: 73.943912\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 2045 | Loss: 73.964054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 2048 | Loss: 73.975220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 2051 | Loss: 73.976684\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 2054 | Loss: 73.958294\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 2057 | Loss: 73.929069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 2059 | Loss: 73.905471\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 2062 | Loss: 73.960672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 2065 | Loss: 74.016170\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 2067 | Loss: 74.049034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 2069 | Loss: 74.045757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 2072 | Loss: 74.054738\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2075 | Loss: 74.056192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2078 | Loss: 74.081390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2081 | Loss: 74.079207\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2083 | Loss: 74.077997\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2084 | Loss: 74.089752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2088 | Loss: 74.062652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2091 | Loss: 74.061482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2093 | Loss: 74.050699\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2096 | Loss: 74.057580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2099 | Loss: 74.064617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2101 | Loss: 74.083581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2104 | Loss: 74.052541\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2107 | Loss: 74.037222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2109 | Loss: 74.036491\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2112 | Loss: 74.030954\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2114 | Loss: 74.044532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2116 | Loss: 74.068252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2118 | Loss: 74.120128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2121 | Loss: 74.169710\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2124 | Loss: 74.261998\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2127 | Loss: 74.293115\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2129 | Loss: 74.340786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2131 | Loss: 74.366927\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2133 | Loss: 74.348947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2135 | Loss: 74.343114\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2138 | Loss: 74.302674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2141 | Loss: 74.270705\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2144 | Loss: 74.246024\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2146 | Loss: 74.247674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2149 | Loss: 74.290335\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2152 | Loss: 74.282238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2154 | Loss: 74.299770\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2157 | Loss: 74.293040\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2160 | Loss: 74.280485\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2163 | Loss: 74.333783\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2166 | Loss: 74.399624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2169 | Loss: 74.416333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2171 | Loss: 74.406992\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2173 | Loss: 74.397634\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2176 | Loss: 74.374693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2179 | Loss: 74.337625\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2182 | Loss: 74.373561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2184 | Loss: 74.402878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2188 | Loss: 74.428563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2191 | Loss: 74.435185\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2194 | Loss: 74.442262\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2196 | Loss: 74.456395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2198 | Loss: 74.477061\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2201 | Loss: 74.499425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2203 | Loss: 74.555614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2205 | Loss: 74.566320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2207 | Loss: 74.572228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2210 | Loss: 74.601544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2212 | Loss: 74.625005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2215 | Loss: 74.599307\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2217 | Loss: 74.592653\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2220 | Loss: 74.638432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2222 | Loss: 74.662954\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2224 | Loss: 74.709797\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2227 | Loss: 74.751921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2229 | Loss: 74.786946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2232 | Loss: 74.817381\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2234 | Loss: 74.815641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2237 | Loss: 74.857282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2239 | Loss: 74.907800\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2242 | Loss: 74.922589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2245 | Loss: 74.986314\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2247 | Loss: 74.998195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2250 | Loss: 75.024329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2253 | Loss: 75.011182\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2256 | Loss: 75.050387\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2258 | Loss: 75.052023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2261 | Loss: 75.033641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2263 | Loss: 75.027535\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2265 | Loss: 75.059412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2267 | Loss: 75.072193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2270 | Loss: 75.128520\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2272 | Loss: 75.160669\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2274 | Loss: 75.182707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2277 | Loss: 75.204448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2279 | Loss: 75.199345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2282 | Loss: 75.244329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2285 | Loss: 75.259410\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2288 | Loss: 75.318480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2290 | Loss: 75.307470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2293 | Loss: 75.312669\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2295 | Loss: 75.309765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2298 | Loss: 75.309055\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2301 | Loss: 75.290810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2304 | Loss: 75.279166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2306 | Loss: 75.252839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2309 | Loss: 75.262001\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2311 | Loss: 75.269506\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2313 | Loss: 75.263218\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2316 | Loss: 75.269206\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2319 | Loss: 75.268511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2322 | Loss: 75.278428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2324 | Loss: 75.275514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2327 | Loss: 75.277666\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2329 | Loss: 75.271305\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2332 | Loss: 75.252981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2334 | Loss: 75.234514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2337 | Loss: 75.243425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2340 | Loss: 75.278288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2343 | Loss: 75.297065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2345 | Loss: 75.285033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2348 | Loss: 75.285259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2350 | Loss: 75.305022\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2353 | Loss: 75.313342\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2355 | Loss: 75.341438\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2358 | Loss: 75.376354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2360 | Loss: 75.414472\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2362 | Loss: 75.460187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2365 | Loss: 75.536210\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2367 | Loss: 75.590571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2369 | Loss: 75.629896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2372 | Loss: 75.654749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2374 | Loss: 75.652908\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2377 | Loss: 75.659674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2379 | Loss: 75.666486\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2382 | Loss: 75.651659\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2385 | Loss: 75.667455\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2387 | Loss: 75.675857\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2390 | Loss: 75.721906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2393 | Loss: 75.739023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2395 | Loss: 75.773457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2397 | Loss: 75.805862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2400 | Loss: 75.841162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2402 | Loss: 75.833917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2404 | Loss: 75.833717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2407 | Loss: 75.875146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2409 | Loss: 75.873254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2412 | Loss: 75.893196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2415 | Loss: 75.967071\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2417 | Loss: 76.016255\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2420 | Loss: 76.031629\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2423 | Loss: 76.056969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2426 | Loss: 76.093023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2428 | Loss: 76.123292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2431 | Loss: 76.131474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 12:31:19.133362: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: ValueError: Alphabet cannot encode transcript \"kocha wa real madrid alikuwa vincent del bosque\" while processing sample \"sw/train/common_voice_sw_30111211.wav\", check that your alphabet contains all characters in the training corpus. Missing characters are: ['q'].\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 188, in generate_values\n",
      "    sample.transcript, Config.alphabet, context=sample.sample_id\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/text.py\", line 22, in text_to_char_array\n",
      "    list(ch for ch in transcript if not alphabet.CanEncodeSingle(ch)),\n",
      "\n",
      "ValueError: Alphabet cannot encode transcript \"kocha wa real madrid alikuwa vincent del bosque\" while processing sample \"sw/train/common_voice_sw_30111211.wav\", check that your alphabet contains all characters in the training corpus. Missing characters are: ['q'].\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ValueError: Alphabet cannot encode transcript \"kocha wa real madrid alikuwa vincent del bosque\" while processing sample \"sw/train/common_voice_sw_30111211.wav\", check that your alphabet contains all characters in the training corpus. Missing characters are: ['q'].\nTraceback (most recent call last):\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n    ret = func(*args)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 188, in generate_values\n    sample.transcript, Config.alphabet, context=sample.sample_id\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/text.py\", line 22, in text_to_char_array\n    list(ch for ch in transcript if not alphabet.CanEncodeSingle(ch)),\n\nValueError: Alphabet cannot encode transcript \"kocha wa real madrid alikuwa vincent del bosque\" while processing sample \"sw/train/common_voice_sw_30111211.wav\", check that your alphabet contains all characters in the training corpus. Missing characters are: ['q'].\n\n\n\t [[{{node PyFunc}}]]\n\t [[tower_0/IteratorGetNext]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: Alphabet cannot encode transcript \"kocha wa real madrid alikuwa vincent del bosque\" while processing sample \"sw/train/common_voice_sw_30111211.wav\", check that your alphabet contains all characters in the training corpus. Missing characters are: ['q'].\nTraceback (most recent call last):\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n    ret = func(*args)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 188, in generate_values\n    sample.transcript, Config.alphabet, context=sample.sample_id\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/text.py\", line 22, in text_to_char_array\n    list(ch for ch in transcript if not alphabet.CanEncodeSingle(ch)),\n\nValueError: Alphabet cannot encode transcript \"kocha wa real madrid alikuwa vincent del bosque\" while processing sample \"sw/train/common_voice_sw_30111211.wav\", check that your alphabet contains all characters in the training corpus. Missing characters are: ['q'].\n\n\n\t [[{{node PyFunc}}]]\n\t [[tower_0/IteratorGetNext]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1448578/1933779721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;34m\"Dummy run finished without problems, now starting real training process.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         )\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mtrain_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent_load\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/train.py\u001b[0m in \u001b[0;36mtrain_impl\u001b[0;34m(epochs, reverse, limit, write, silent_load)\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0mlog_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training epoch %d...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_init_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 log_progress(\n\u001b[1;32m    576\u001b[0m                     \u001b[0;34m\"Finished training epoch %d - loss: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/train.py\u001b[0m in \u001b[0;36mrun_set\u001b[0;34m(set_name, epoch, init_op, dataset)\u001b[0m\n\u001b[1;32m    526\u001b[0m                             \u001b[0mstep_summaries_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                         ],\n\u001b[0;32m--> 528\u001b[0;31m                         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mepoch_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m                     )\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: Alphabet cannot encode transcript \"kocha wa real madrid alikuwa vincent del bosque\" while processing sample \"sw/train/common_voice_sw_30111211.wav\", check that your alphabet contains all characters in the training corpus. Missing characters are: ['q'].\nTraceback (most recent call last):\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n    ret = func(*args)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 188, in generate_values\n    sample.transcript, Config.alphabet, context=sample.sample_id\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/text.py\", line 22, in text_to_char_array\n    list(ch for ch in transcript if not alphabet.CanEncodeSingle(ch)),\n\nValueError: Alphabet cannot encode transcript \"kocha wa real madrid alikuwa vincent del bosque\" while processing sample \"sw/train/common_voice_sw_30111211.wav\", check that your alphabet contains all characters in the training corpus. Missing characters are: ['q'].\n\n\n\t [[{{node PyFunc}}]]\n\t [[tower_0/IteratorGetNext]]"
     ]
    }
   ],
   "source": [
    "# Kick off training job; configures CUDA to only use one GPU\n",
    "from coqui_stt_training.train import train\n",
    "\n",
    "# use maximum one GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pretrained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
