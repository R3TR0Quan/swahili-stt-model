{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Africas Talking-Mozilla Common Voice Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main notebook used in model development. For experimentation use notebooks in the `misc_notebooks` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is originally a submission to the Africa's Talking x Mozilla Common Voice Hackathon, from October 13th through November"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objectives\n",
    ">> The main objective is to build a deep learning model that is capable of inferring `text` having been conditioned on `voice` sequences.\n",
    "\n",
    "The model is expected to achieve best performance on the selected evaluation metrics:\n",
    "* Character Error Rate\n",
    "* Word Error Rate\n",
    "* Phone Error Rate\n",
    "* Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used is sourced from Mozilla's site [here](https://commonvoice.mozilla.org/en/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scripts import coqui_data_prepper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read `tsv` files\n",
    "test_df = pd.read_csv('sw/test.tsv', delimiter='\\t')\n",
    "train_df = pd.read_csv('sw/train.tsv', delimiter='\\t')\n",
    "# reported_df = pd.read_csv('sw/reported.tsv', engine='c', delimiter='\\t') # causing EOF error in reading, possibly corrupt or inconsistent\n",
    "# others_df = pd.read_csv('sw/other.tsv', delimiter='\\t') # causing EOF error in reading, possibly corrupt or inconsistent\n",
    "invalidated_df = pd.read_csv('sw/invalidated.tsv', delimiter='\\t')\n",
    "dev_df = pd.read_csv('sw/dev.tsv', delimiter='\\t')\n",
    "durations_df = pd.read_csv('sw/clip_durations.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect some of these DataFrames to get our bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37083656.mp3</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085166.mp3</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085182.mp3</td>\n",
       "      <td>Hawai ni kuzuri</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085525.mp3</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085535.mp3</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "1  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "2  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "3  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "4  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_37083656.mp3   \n",
       "1  common_voice_sw_37085166.mp3   \n",
       "2  common_voice_sw_37085182.mp3   \n",
       "3  common_voice_sw_37085525.mp3   \n",
       "4  common_voice_sw_37085535.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  yeyote yule atakaepatikana akiandamana katika ...         2           0   \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...         3           1   \n",
       "2                                    Hawai ni kuzuri         2           0   \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...        13           3   \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...         2           1   \n",
       "\n",
       "        age  gender accents variant locale  segment  \n",
       "0  twenties  female     NaN     NaN     sw      NaN  \n",
       "1  twenties  female     NaN     NaN     sw      NaN  \n",
       "2  twenties  female     NaN     NaN     sw      NaN  \n",
       "3  twenties  female     NaN     NaN     sw      NaN  \n",
       "4  twenties  female     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011544b78c18417a5869b8e70ebc7675c7eb3b517754b8...</td>\n",
       "      <td>common_voice_sw_37190902.mp3</td>\n",
       "      <td>Tuma pesa sahii.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0133d8ddf5c1a3c678fde017e0b07d2835bfd707d5b3ec...</td>\n",
       "      <td>common_voice_sw_31428161.mp3</td>\n",
       "      <td>wachambuzi wa soka wanamtaja Messi kama nyota ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01c95772efd3fbe4a1122206c7474c77ed6591c8c9fb00...</td>\n",
       "      <td>common_voice_sw_30317714.mp3</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023711185d4404ff398c2697f2e72868d1ecf69a92b581...</td>\n",
       "      <td>common_voice_sw_32116997.mp3</td>\n",
       "      <td>Sote twesangaa twelipomuona mwalimu Ali apika</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0244639ffd7ec755a01b21ea204735ca3c44443e9cf46c...</td>\n",
       "      <td>common_voice_sw_29002392.mp3</td>\n",
       "      <td>Inajulikana kama shina la Warangi.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  011544b78c18417a5869b8e70ebc7675c7eb3b517754b8...   \n",
       "1  0133d8ddf5c1a3c678fde017e0b07d2835bfd707d5b3ec...   \n",
       "2  01c95772efd3fbe4a1122206c7474c77ed6591c8c9fb00...   \n",
       "3  023711185d4404ff398c2697f2e72868d1ecf69a92b581...   \n",
       "4  0244639ffd7ec755a01b21ea204735ca3c44443e9cf46c...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_37190902.mp3   \n",
       "1  common_voice_sw_31428161.mp3   \n",
       "2  common_voice_sw_30317714.mp3   \n",
       "3  common_voice_sw_32116997.mp3   \n",
       "4  common_voice_sw_29002392.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0                                   Tuma pesa sahii.         2           0   \n",
       "1  wachambuzi wa soka wanamtaja Messi kama nyota ...         2           0   \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...         2           1   \n",
       "3      Sote twesangaa twelipomuona mwalimu Ali apika         2           1   \n",
       "4                 Inajulikana kama shina la Warangi.         2           0   \n",
       "\n",
       "        age  gender accents variant locale  segment  \n",
       "0       NaN     NaN     NaN     NaN     sw      NaN  \n",
       "1  twenties  female     NaN     NaN     sw      NaN  \n",
       "2       NaN     NaN     NaN     NaN     sw      NaN  \n",
       "3  twenties    male     NaN     NaN     sw      NaN  \n",
       "4       NaN     NaN     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628088.mp3</td>\n",
       "      <td>Mbali na kuwa afisa wa serikali Jokate pia ni ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628121.mp3</td>\n",
       "      <td>Kukosa pesa ni hatari sana</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628126.mp3</td>\n",
       "      <td>Jina Karagwe linatokana na kilima kinachopatik...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628160.mp3</td>\n",
       "      <td>sokwe wanaopatikana mahale ni aina adimu zaidi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628161.mp3</td>\n",
       "      <td>mamba wa mto naili wana sumu kali inayoozesha ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "1  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "2  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "3  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "4  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_30628088.mp3   \n",
       "1  common_voice_sw_30628121.mp3   \n",
       "2  common_voice_sw_30628126.mp3   \n",
       "3  common_voice_sw_30628160.mp3   \n",
       "4  common_voice_sw_30628161.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  Mbali na kuwa afisa wa serikali Jokate pia ni ...         2           0   \n",
       "1                         Kukosa pesa ni hatari sana         3           1   \n",
       "2  Jina Karagwe linatokana na kilima kinachopatik...         2           0   \n",
       "3  sokwe wanaopatikana mahale ni aina adimu zaidi...         2           0   \n",
       "4  mamba wa mto naili wana sumu kali inayoozesha ...         3           0   \n",
       "\n",
       "        age gender accents variant locale  segment  \n",
       "0  twenties   male     NaN     NaN     sw      NaN  \n",
       "1  twenties   male     NaN     NaN     sw      NaN  \n",
       "2  twenties   male     NaN     NaN     sw      NaN  \n",
       "3  twenties   male     NaN     NaN     sw      NaN  \n",
       "4  twenties   male     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev_df\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the path to reflect the relative path in this directory. We can then create new dfs to be used to train on coqui_stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_prefix(df, prefix):\n",
    "  \"\"\"Attaches a prefix to all entries in the column 'path' of a dataframe.\n",
    "\n",
    "  Args:\n",
    "    df: A Pandas dataframe with the column 'path'.\n",
    "    prefix: The prefix to attach to the entries in the column 'path'.\n",
    "\n",
    "  Returns:\n",
    "    A Pandas dataframe with the column 'path' updated to include the prefix.\n",
    "  \"\"\"\n",
    "\n",
    "  df[\"path\"] = df[\"path\"].apply(lambda x: prefix + x)\n",
    "  return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of Pandas DataFrames\n",
    "df_list = [train_df, dev_df, test_df]\n",
    "\n",
    "# iterate over the dfs and attatch directory prefix on each\n",
    "for df, df_name in zip(df_list, [\"train\", \"dev\", \"test\"]):\n",
    "    df = df\n",
    "\n",
    "    prefixed_df = attach_prefix(df, \"sw/clips/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37083656.mp3</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37085166.mp3</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37085182.mp3</td>\n",
       "      <td>Hawai ni kuzuri</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37085525.mp3</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>sw/clips/common_voice_sw_37085535.mp3</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "1  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "2  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "3  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "4  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "\n",
       "                                    path  \\\n",
       "0  sw/clips/common_voice_sw_37083656.mp3   \n",
       "1  sw/clips/common_voice_sw_37085166.mp3   \n",
       "2  sw/clips/common_voice_sw_37085182.mp3   \n",
       "3  sw/clips/common_voice_sw_37085525.mp3   \n",
       "4  sw/clips/common_voice_sw_37085535.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  yeyote yule atakaepatikana akiandamana katika ...         2           0   \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...         3           1   \n",
       "2                                    Hawai ni kuzuri         2           0   \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...        13           3   \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...         2           1   \n",
       "\n",
       "        age  gender accents variant locale  segment  \n",
       "0  twenties  female     NaN     NaN     sw      NaN  \n",
       "1  twenties  female     NaN     NaN     sw      NaN  \n",
       "2  twenties  female     NaN     NaN     sw      NaN  \n",
       "3  twenties  female     NaN     NaN     sw      NaN  \n",
       "4  twenties  female     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628088.mp3</td>\n",
       "      <td>Mbali na kuwa afisa wa serikali Jokate pia ni ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628121.mp3</td>\n",
       "      <td>Kukosa pesa ni hatari sana</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628126.mp3</td>\n",
       "      <td>Jina Karagwe linatokana na kilima kinachopatik...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628160.mp3</td>\n",
       "      <td>sokwe wanaopatikana mahale ni aina adimu zaidi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>sw/clips/common_voice_sw_30628161.mp3</td>\n",
       "      <td>mamba wa mto naili wana sumu kali inayoozesha ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "1  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "2  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "3  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "4  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "\n",
       "                                    path  \\\n",
       "0  sw/clips/common_voice_sw_30628088.mp3   \n",
       "1  sw/clips/common_voice_sw_30628121.mp3   \n",
       "2  sw/clips/common_voice_sw_30628126.mp3   \n",
       "3  sw/clips/common_voice_sw_30628160.mp3   \n",
       "4  sw/clips/common_voice_sw_30628161.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  Mbali na kuwa afisa wa serikali Jokate pia ni ...         2           0   \n",
       "1                         Kukosa pesa ni hatari sana         3           1   \n",
       "2  Jina Karagwe linatokana na kilima kinachopatik...         2           0   \n",
       "3  sokwe wanaopatikana mahale ni aina adimu zaidi...         2           0   \n",
       "4  mamba wa mto naili wana sumu kali inayoozesha ...         3           0   \n",
       "\n",
       "        age gender accents variant locale  segment  \n",
       "0  twenties   male     NaN     NaN     sw      NaN  \n",
       "1  twenties   male     NaN     NaN     sw      NaN  \n",
       "2  twenties   male     NaN     NaN     sw      NaN  \n",
       "3  twenties   male     NaN     NaN     sw      NaN  \n",
       "4  twenties   male     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coqui-STT requires data to be in a specific format before training begins, i.e:\n",
    "* wav_filename: PATH to the wav files ( not mp3; format not supported)\n",
    "* wav_filesize: size of each wav clip in bytes\n",
    "* transcript: the sentence column transcribed for each clip\n",
    "\n",
    "**Note**: there are scripts to convert mp3 to wav and to do this preprocessing in the scripts module incuded in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_to_wav(df, label):\n",
    "  \"\"\"Converts all MP3 files in the `path` column to WAV files and saves them to a new directory (test, train, or dev) in the same folder as the original MP3 files.\n",
    "  Resamples at 16Khz\n",
    "  Args:\n",
    "    df: A Pandas DataFrame.\n",
    "    label: The label for the new directory (test, train, or dev).\n",
    "\n",
    "  Returns:\n",
    "    A Pandas DataFrame with the `path` column updated to point to the new WAV files.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a new directory for the WAV files.\n",
    "  new_dir = os.path.join(df['path'].iloc[0].split('/')[0], label)\n",
    "  os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "  # Iterate over the DataFrame and convert each MP3 file to WAV.\n",
    "  for i in range(len(df)):\n",
    "    mp3_path = df['path'].iloc[i]\n",
    "    wav_path = os.path.join(new_dir, os.path.basename(mp3_path).replace('.mp3', '.wav'))\n",
    "\n",
    "    # Convert the MP3 file to WAV.\n",
    "    audio = AudioSegment.from_mp3(mp3_path)\n",
    "    audio.export(wav_path, format='wav')\n",
    "\n",
    "    # Update the `path` column to point to the new WAV file.\n",
    "    df.loc[i, 'path'] = wav_path\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> **NOTE**: the 3 cells below need only be ran once and they may take some time to run as they are parsing a rather large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train_df clips to .wav\n",
    "# train_df = convert_mp3_to_wav(train_df, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dev_df clips to .wav\n",
    "# dev_df = convert_mp3_to_wav(dev_df, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test_df clips to .wav\n",
    "# test_df = convert_mp3_to_wav(test_df, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we have already ran the notebook and obtained formatted csv files. We will re-read them to avoid having to process and format them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read formatted csv files\n",
    "train_df = pd.read_csv('sw/train.csv')\n",
    "test_df = pd.read_csv('sw/test.csv')\n",
    "dev_df = pd.read_csv('sw/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary script to do further data formatting; not required after converting to csv\n",
    "# dfs = [train_df, test_df, dev_df]\n",
    "\n",
    "# for df in dfs:\n",
    "#     df['wav_filename'] = df['wav_filename'].str.replace('sw/', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/common_voice_sw_37083656.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/common_voice_sw_37085166.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/common_voice_sw_37085182.wav</td>\n",
       "      <td>191276</td>\n",
       "      <td>hawai ni kuzuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/common_voice_sw_37085525.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/common_voice_sw_37085535.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_filename  wav_filesize  \\\n",
       "0  train/common_voice_sw_37083656.wav        359468   \n",
       "1  train/common_voice_sw_37085166.wav        391724   \n",
       "2  train/common_voice_sw_37085182.wav        191276   \n",
       "3  train/common_voice_sw_37085525.wav        391724   \n",
       "4  train/common_voice_sw_37085535.wav        391724   \n",
       "\n",
       "                                          transcript  \n",
       "0  yeyote yule atakaepatikana akiandamana katika ...  \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...  \n",
       "2                                    hawai ni kuzuri  \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...  \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/common_voice_sw_37190902.wav</td>\n",
       "      <td>225836</td>\n",
       "      <td>tuma pesa sahii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/common_voice_sw_31428161.wav</td>\n",
       "      <td>502316</td>\n",
       "      <td>wachambuzi wa soka wanamtaja messi kama nyota ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/common_voice_sw_30317714.wav</td>\n",
       "      <td>331820</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/common_voice_sw_32116997.wav</td>\n",
       "      <td>640556</td>\n",
       "      <td>sote twesangaa twelipomuona mwalimu ali apika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/common_voice_sw_29002392.wav</td>\n",
       "      <td>294956</td>\n",
       "      <td>inajulikana kama shina la warangi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wav_filename  wav_filesize  \\\n",
       "0  test/common_voice_sw_37190902.wav        225836   \n",
       "1  test/common_voice_sw_31428161.wav        502316   \n",
       "2  test/common_voice_sw_30317714.wav        331820   \n",
       "3  test/common_voice_sw_32116997.wav        640556   \n",
       "4  test/common_voice_sw_29002392.wav        294956   \n",
       "\n",
       "                                          transcript  \n",
       "0                                    tuma pesa sahii  \n",
       "1  wachambuzi wa soka wanamtaja messi kama nyota ...  \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...  \n",
       "3      sote twesangaa twelipomuona mwalimu ali apika  \n",
       "4                  inajulikana kama shina la warangi  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format acceptable: checking clip directories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format acceptable: checking clip directories\n",
      "Format acceptable: checking clip directories\n"
     ]
    }
   ],
   "source": [
    "# format DFs for training (Repetitive), needs to be better implemented (DRY)\n",
    "train_df = coqui_data_prepper.format_df(train_df, 'train')\n",
    "dev_df = coqui_data_prepper.format_df(dev_df, 'dev')\n",
    "test_df = coqui_data_prepper.format_df(test_df, label='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> **END NOTE**: try commenting the cells above if they have already be ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/common_voice_sw_37083656.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/common_voice_sw_37085166.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/common_voice_sw_37085182.wav</td>\n",
       "      <td>191276</td>\n",
       "      <td>hawai ni kuzuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/common_voice_sw_37085525.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/common_voice_sw_37085535.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_filename  wav_filesize  \\\n",
       "0  train/common_voice_sw_37083656.wav        359468   \n",
       "1  train/common_voice_sw_37085166.wav        391724   \n",
       "2  train/common_voice_sw_37085182.wav        191276   \n",
       "3  train/common_voice_sw_37085525.wav        391724   \n",
       "4  train/common_voice_sw_37085535.wav        391724   \n",
       "\n",
       "                                          transcript  \n",
       "0  yeyote yule atakaepatikana akiandamana katika ...  \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...  \n",
       "2                                    hawai ni kuzuri  \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...  \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/common_voice_sw_37190902.wav</td>\n",
       "      <td>225836</td>\n",
       "      <td>tuma pesa sahii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/common_voice_sw_31428161.wav</td>\n",
       "      <td>502316</td>\n",
       "      <td>wachambuzi wa soka wanamtaja messi kama nyota ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/common_voice_sw_30317714.wav</td>\n",
       "      <td>331820</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/common_voice_sw_32116997.wav</td>\n",
       "      <td>640556</td>\n",
       "      <td>sote twesangaa twelipomuona mwalimu ali apika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/common_voice_sw_29002392.wav</td>\n",
       "      <td>294956</td>\n",
       "      <td>inajulikana kama shina la warangi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wav_filename  wav_filesize  \\\n",
       "0  test/common_voice_sw_37190902.wav        225836   \n",
       "1  test/common_voice_sw_31428161.wav        502316   \n",
       "2  test/common_voice_sw_30317714.wav        331820   \n",
       "3  test/common_voice_sw_32116997.wav        640556   \n",
       "4  test/common_voice_sw_29002392.wav        294956   \n",
       "\n",
       "                                          transcript  \n",
       "0                                    tuma pesa sahii  \n",
       "1  wachambuzi wa soka wanamtaja messi kama nyota ...  \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...  \n",
       "3      sote twesangaa twelipomuona mwalimu ali apika  \n",
       "4                  inajulikana kama shina la warangi  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert transcript to lower case characters\n",
    "def to_lower(df, column_name):\n",
    "  \"\"\"Converts all characters in a column to lowercase.\n",
    "\n",
    "  Args:\n",
    "    df: A Pandas DataFrame.\n",
    "    column_name: The name of the column to convert to lowercase.\n",
    "\n",
    "  Returns:\n",
    "    A Pandas DataFrame with the column `column_name` converted to lowercase.\n",
    "  \"\"\"\n",
    "\n",
    "  df[column_name] = df[column_name].str.lower()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = to_lower(train_df, 'transcript')\n",
    "dev_df = to_lower(dev_df, 'transcript')\n",
    "test_df = to_lower(test_df, 'transcript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and unnecessay whitespace\n",
    "import re\n",
    "\n",
    "def clean_punctiations(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove underscores\n",
    "    text = text.replace('_', '')\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing to 'transcript' column in train_df\n",
    "train_df['transcript'] = train_df['transcript'].apply(clean_punctiations)\n",
    "\n",
    "# Apply preprocessing to 'transcript' column in dev_df\n",
    "dev_df['transcript'] = dev_df['transcript'].apply(clean_punctiations)\n",
    "\n",
    "# Apply preprocessing to 'transcript' column in test_df\n",
    "test_df['transcript'] = test_df['transcript'].apply(clean_punctiations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/common_voice_sw_37083656.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/common_voice_sw_37085166.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/common_voice_sw_37085182.wav</td>\n",
       "      <td>191276</td>\n",
       "      <td>hawai ni kuzuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/common_voice_sw_37085525.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/common_voice_sw_37085535.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_filename  wav_filesize  \\\n",
       "0  train/common_voice_sw_37083656.wav        359468   \n",
       "1  train/common_voice_sw_37085166.wav        391724   \n",
       "2  train/common_voice_sw_37085182.wav        191276   \n",
       "3  train/common_voice_sw_37085525.wav        391724   \n",
       "4  train/common_voice_sw_37085535.wav        391724   \n",
       "\n",
       "                                          transcript  \n",
       "0  yeyote yule atakaepatikana akiandamana katika ...  \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...  \n",
       "2                                    hawai ni kuzuri  \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...  \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev/common_voice_sw_30628088.wav</td>\n",
       "      <td>322604</td>\n",
       "      <td>mbali na kuwa afisa wa serikali jokate pia ni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev/common_voice_sw_30628121.wav</td>\n",
       "      <td>225836</td>\n",
       "      <td>kukosa pesa ni hatari sana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev/common_voice_sw_30628126.wav</td>\n",
       "      <td>375596</td>\n",
       "      <td>jina karagwe linatokana na kilima kinachopatik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev/common_voice_sw_30628160.wav</td>\n",
       "      <td>336428</td>\n",
       "      <td>sokwe wanaopatikana mahale ni aina adimu zaidi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev/common_voice_sw_30628161.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>mamba wa mto naili wana sumu kali inayoozesha ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       wav_filename  wav_filesize  \\\n",
       "0  dev/common_voice_sw_30628088.wav        322604   \n",
       "1  dev/common_voice_sw_30628121.wav        225836   \n",
       "2  dev/common_voice_sw_30628126.wav        375596   \n",
       "3  dev/common_voice_sw_30628160.wav        336428   \n",
       "4  dev/common_voice_sw_30628161.wav        359468   \n",
       "\n",
       "                                          transcript  \n",
       "0  mbali na kuwa afisa wa serikali jokate pia ni ...  \n",
       "1                         kukosa pesa ni hatari sana  \n",
       "2  jina karagwe linatokana na kilima kinachopatik...  \n",
       "3  sokwe wanaopatikana mahale ni aina adimu zaidi...  \n",
       "4  mamba wa mto naili wana sumu kali inayoozesha ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/common_voice_sw_37190902.wav</td>\n",
       "      <td>225836</td>\n",
       "      <td>tuma pesa sahii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/common_voice_sw_31428161.wav</td>\n",
       "      <td>502316</td>\n",
       "      <td>wachambuzi wa soka wanamtaja messi kama nyota ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/common_voice_sw_30317714.wav</td>\n",
       "      <td>331820</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/common_voice_sw_32116997.wav</td>\n",
       "      <td>640556</td>\n",
       "      <td>sote twesangaa twelipomuona mwalimu ali apika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/common_voice_sw_29002392.wav</td>\n",
       "      <td>294956</td>\n",
       "      <td>inajulikana kama shina la warangi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wav_filename  wav_filesize  \\\n",
       "0  test/common_voice_sw_37190902.wav        225836   \n",
       "1  test/common_voice_sw_31428161.wav        502316   \n",
       "2  test/common_voice_sw_30317714.wav        331820   \n",
       "3  test/common_voice_sw_32116997.wav        640556   \n",
       "4  test/common_voice_sw_29002392.wav        294956   \n",
       "\n",
       "                                          transcript  \n",
       "0                                    tuma pesa sahii  \n",
       "1  wachambuzi wa soka wanamtaja messi kama nyota ...  \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...  \n",
       "3      sote twesangaa twelipomuona mwalimu ali apika  \n",
       "4                  inajulikana kama shina la warangi  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with accented characters\n",
    "from unidecode import unidecode\n",
    "\n",
    "dataframes = [train_df, test_df, dev_df]\n",
    "\n",
    "# Loop through each DataFrame\n",
    "for df in dataframes:\n",
    "    # Replace accented characters in the 'transcript' column\n",
    "    df['transcript'] = df['transcript'].apply(unidecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/common_voice_sw_37083656.wav</td>\n",
       "      <td>359468</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/common_voice_sw_37085166.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/common_voice_sw_37085182.wav</td>\n",
       "      <td>191276</td>\n",
       "      <td>hawai ni kuzuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/common_voice_sw_37085525.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/common_voice_sw_37085535.wav</td>\n",
       "      <td>391724</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wav_filename  wav_filesize  \\\n",
       "0  train/common_voice_sw_37083656.wav        359468   \n",
       "1  train/common_voice_sw_37085166.wav        391724   \n",
       "2  train/common_voice_sw_37085182.wav        191276   \n",
       "3  train/common_voice_sw_37085525.wav        391724   \n",
       "4  train/common_voice_sw_37085535.wav        391724   \n",
       "\n",
       "                                          transcript  \n",
       "0  yeyote yule atakaepatikana akiandamana katika ...  \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...  \n",
       "2                                    hawai ni kuzuri  \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...  \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to convert the *train*, *dev* and *test* tsc files to csv to work with `coqui`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of Pandas DataFrames\n",
    "df_list = [train_df, dev_df, test_df]\n",
    "\n",
    "# Create the sw/ directory if it does not exist\n",
    "csv_directory_path = \"sw/\"\n",
    "if not os.path.exists(csv_directory_path):\n",
    "    os.makedirs(csv_directory_path)\n",
    "\n",
    "# Iterate over the list of DataFrames and save each DataFrame to a CSV file\n",
    "for df, df_name in zip(df_list, [\"train\", \"dev\", \"test\"]):\n",
    "\n",
    "    # Join the DataFrame name with the CSV directory path\n",
    "    csv_file_path = os.path.join(csv_directory_path, df_name + \".csv\")\n",
    "\n",
    "    # Save the DataFrame to the CSV file\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv training files are saved, but the `transcript` columns need additional preprocessing e.g **tokenization** to work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_unique_characters_to_file(dataframes):\n",
    "    unique_chars = set()\n",
    "\n",
    "    for df in dataframes:\n",
    "        for transcript in df['transcript']:\n",
    "            unique_chars.update(set(transcript))\n",
    "\n",
    "    unique_chars_list = sorted(list(unique_chars))\n",
    "\n",
    "    with open('sw/alphabet.txt', 'w') as file:\n",
    "        for char in unique_chars_list:\n",
    "            file.write(char + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above detects alphabet characters in the corpus. It is (optionally) ran in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_df, test_df, dev_df]\n",
    "\n",
    "save_unique_characters_to_file(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZE DEFAULT HYPERPARAMETERS (Coqui-stt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I --alphabet_config_path not specified, but all input datasets are present and in the same folder (--train_files, --dev_files and --test_files), and an alphabet.txt file was found alongside the sets (sw/alphabet.txt). Will use this alphabet file for this run.\n"
     ]
    }
   ],
   "source": [
    "from coqui_stt_training.util.config import initialize_globals_from_args\n",
    "\n",
    "initialize_globals_from_args(\n",
    "    checkpoint_dir=\"ckpt_dir\",\n",
    "    train_files=[\"sw/train.csv\"],\n",
    "    dev_files=[\"sw/dev.csv\"],\n",
    "    test_files=[\"sw/test.csv\"],\n",
    "    load_train=\"init\",\n",
    "    n_hidden=100,\n",
    "    epochs=2,\n",
    "    train_batch_size=4,\n",
    "    dev_batch_size=4,\n",
    "    test_batch_size= 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m coqui_stt_training.train --train_files sw/train.csv --dev_files sw/dev.csv --test_files sw/test.csv --checkpoint_dir ckpt_dir --n_hidden 100 --epochs 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Performing dummy training to check for memory problems.\n",
      "I If the following process crashes, you likely have batch sizes that are too big for your available system memory (or GPU memory).\n",
      "I Initializing all variables.\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 1 | Loss: 1456.354736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 2 | Loss: 1284.129517\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 1160.014038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 1160.014038\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 666.262268 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 2 | Loss: 670.714813 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 3 | Loss: 675.881165 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 3 | Loss: 675.881165 | Dataset: sw/dev.csv\n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:05.871073\n",
      "I Dummy run finished without problems, now starting real training process.\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 158.892578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 2 | Loss: 158.408745\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 142.009215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 122.793532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 9 | Loss: 110.631054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 12 | Loss: 97.413109\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 14 | Loss: 91.330938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 16 | Loss: 89.182969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 19 | Loss: 83.750429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 22 | Loss: 80.211488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 24 | Loss: 77.867600\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 26 | Loss: 76.751794\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 29 | Loss: 74.159655\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 31 | Loss: 72.884434\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 33 | Loss: 71.991891\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 36 | Loss: 71.328748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 38 | Loss: 70.570732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 40 | Loss: 70.686142\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 43 | Loss: 69.968983\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 45 | Loss: 69.177762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 48 | Loss: 69.175682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 51 | Loss: 68.278664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 53 | Loss: 67.773352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 55 | Loss: 67.194583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 58 | Loss: 66.583809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 61 | Loss: 65.908918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 63 | Loss: 65.421529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 66 | Loss: 65.381677\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 68 | Loss: 65.645742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 70 | Loss: 65.362203\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 72 | Loss: 65.469191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 74 | Loss: 65.130389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 77 | Loss: 64.633178\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 79 | Loss: 64.558893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 81 | Loss: 65.457386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 83 | Loss: 65.119004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 86 | Loss: 65.895026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 88 | Loss: 65.858276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 90 | Loss: 66.013930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 92 | Loss: 65.788368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 95 | Loss: 65.270658\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 97 | Loss: 64.981712\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 99 | Loss: 64.672715\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 101 | Loss: 64.733239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 104 | Loss: 64.744720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 106 | Loss: 64.786015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 108 | Loss: 64.951669\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 111 | Loss: 65.155549\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 113 | Loss: 65.125840\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 116 | Loss: 64.805571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 119 | Loss: 64.586667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 122 | Loss: 64.541528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 124 | Loss: 64.937826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 127 | Loss: 65.321197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 130 | Loss: 65.426244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 132 | Loss: 65.306700\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 134 | Loss: 65.188169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 136 | Loss: 65.092829\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 138 | Loss: 64.901313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 141 | Loss: 64.880640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 144 | Loss: 65.156053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 147 | Loss: 64.976591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 149 | Loss: 65.106388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 151 | Loss: 65.372833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 153 | Loss: 65.485535\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 156 | Loss: 65.435280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 158 | Loss: 65.366170\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 160 | Loss: 65.217999\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 163 | Loss: 65.057697\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 165 | Loss: 64.956671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 167 | Loss: 65.033268\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 170 | Loss: 65.111719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 173 | Loss: 65.066992\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 175 | Loss: 65.469819\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 178 | Loss: 65.759982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 180 | Loss: 65.711238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 182 | Loss: 65.670937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 184 | Loss: 65.653863\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 186 | Loss: 65.712849\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 189 | Loss: 65.765038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 191 | Loss: 65.838994\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 193 | Loss: 65.940338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 195 | Loss: 65.933819\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 198 | Loss: 66.209524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 201 | Loss: 66.438964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 204 | Loss: 66.472283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 206 | Loss: 66.457591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 209 | Loss: 66.413087\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 211 | Loss: 66.355757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 214 | Loss: 66.531116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 216 | Loss: 66.566106\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 219 | Loss: 66.818573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 222 | Loss: 66.871605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 224 | Loss: 67.107905\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 226 | Loss: 67.287979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 229 | Loss: 67.481353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 231 | Loss: 67.557290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 234 | Loss: 67.520053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 236 | Loss: 67.448774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 239 | Loss: 67.398589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 241 | Loss: 67.525877\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 244 | Loss: 67.653895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 246 | Loss: 67.659212\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 249 | Loss: 67.826732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 251 | Loss: 67.990247\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 253 | Loss: 67.970994\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 255 | Loss: 68.017383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 258 | Loss: 68.415020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 261 | Loss: 68.537570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 264 | Loss: 68.764390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 267 | Loss: 68.771382\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 269 | Loss: 68.833020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 271 | Loss: 68.756120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 274 | Loss: 68.693162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 277 | Loss: 68.739649\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 279 | Loss: 68.748936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 281 | Loss: 68.784602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 283 | Loss: 68.875700\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 285 | Loss: 68.892323\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 287 | Loss: 68.889141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 290 | Loss: 69.214266\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 293 | Loss: 69.412215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 295 | Loss: 69.543659\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 298 | Loss: 69.642260\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 301 | Loss: 69.615806\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 303 | Loss: 69.635176\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 306 | Loss: 69.633607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 308 | Loss: 69.647175\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 310 | Loss: 69.578403\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 312 | Loss: 69.647024\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 315 | Loss: 69.644831\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 317 | Loss: 69.656505\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 319 | Loss: 69.831871\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 321 | Loss: 69.872551\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 324 | Loss: 69.840679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 326 | Loss: 69.844048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 329 | Loss: 70.239135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 332 | Loss: 70.383006\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 335 | Loss: 70.629388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 337 | Loss: 70.806466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 339 | Loss: 70.822037\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 342 | Loss: 70.876733\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 344 | Loss: 70.866006\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 346 | Loss: 70.851864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 348 | Loss: 70.871987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 350 | Loss: 70.988447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 352 | Loss: 71.032807\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 354 | Loss: 71.149302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 356 | Loss: 71.222339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 359 | Loss: 71.325219\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 362 | Loss: 71.419285\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 364 | Loss: 71.435985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 367 | Loss: 71.472118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 369 | Loss: 71.538224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 372 | Loss: 71.745483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 374 | Loss: 71.807678\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 377 | Loss: 71.773950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 380 | Loss: 71.886749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 382 | Loss: 71.854837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 384 | Loss: 71.840209\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 387 | Loss: 71.840389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 389 | Loss: 71.814180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 391 | Loss: 71.926453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 393 | Loss: 71.950935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 396 | Loss: 71.956045\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 72.071963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 400 | Loss: 72.252837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 403 | Loss: 72.164707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 405 | Loss: 72.220920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 408 | Loss: 72.430619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 410 | Loss: 72.625128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 412 | Loss: 72.702688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 414 | Loss: 72.784722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 417 | Loss: 72.802833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 420 | Loss: 72.870547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 423 | Loss: 72.909875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 426 | Loss: 72.904838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 428 | Loss: 72.835535\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 431 | Loss: 73.006483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 433 | Loss: 73.060377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 436 | Loss: 73.187678\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 439 | Loss: 73.402810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 441 | Loss: 73.477103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 444 | Loss: 73.551996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 447 | Loss: 73.657653\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 449 | Loss: 73.853469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 452 | Loss: 73.908420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 455 | Loss: 74.208500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 458 | Loss: 74.301622\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 460 | Loss: 74.380542\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 462 | Loss: 74.443702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 464 | Loss: 74.480288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:25 | Steps: 467 | Loss: 74.538683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 470 | Loss: 74.532750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 473 | Loss: 74.600967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 475 | Loss: 74.810374\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 477 | Loss: 74.948686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 479 | Loss: 74.987521\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 482 | Loss: 75.046611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 484 | Loss: 75.071650\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:26 | Steps: 487 | Loss: 75.315177\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 490 | Loss: 75.362428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 492 | Loss: 75.404969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 495 | Loss: 75.456929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 497 | Loss: 75.626810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 499 | Loss: 75.657726\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 501 | Loss: 75.703821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 503 | Loss: 75.874254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:27 | Steps: 505 | Loss: 76.011187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 508 | Loss: 76.126511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 510 | Loss: 76.270180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 512 | Loss: 76.357131\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 514 | Loss: 76.333592\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 517 | Loss: 76.448673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 519 | Loss: 76.452568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 521 | Loss: 76.481470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:28 | Steps: 524 | Loss: 76.459400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 526 | Loss: 76.458853\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 529 | Loss: 76.489059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 532 | Loss: 76.741750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 534 | Loss: 76.726336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 537 | Loss: 76.682562\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 540 | Loss: 76.711471\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 542 | Loss: 76.880402\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:29 | Steps: 545 | Loss: 76.808397\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 547 | Loss: 76.889211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 549 | Loss: 76.921505\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 551 | Loss: 77.037371\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 553 | Loss: 77.117815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 556 | Loss: 77.226338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 558 | Loss: 77.354707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 561 | Loss: 77.532873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:30 | Steps: 564 | Loss: 77.626114\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 566 | Loss: 77.630019\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 568 | Loss: 77.768960\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 570 | Loss: 77.827579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 572 | Loss: 77.946986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 575 | Loss: 77.948635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 577 | Loss: 77.915262\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 580 | Loss: 77.949747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:31 | Steps: 582 | Loss: 77.957134\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 583 | Loss: 77.947267\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 585 | Loss: 77.991627\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 587 | Loss: 78.021421\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 589 | Loss: 78.113248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 592 | Loss: 78.416145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 595 | Loss: 78.486893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 597 | Loss: 78.532785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:32 | Steps: 600 | Loss: 78.709400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 602 | Loss: 78.743444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 604 | Loss: 78.921188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 606 | Loss: 79.016148\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 608 | Loss: 79.122742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 610 | Loss: 79.254208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 612 | Loss: 79.315020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 614 | Loss: 79.337857\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 616 | Loss: 79.412397\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:33 | Steps: 618 | Loss: 79.467059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 621 | Loss: 79.526825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 623 | Loss: 79.557960\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 626 | Loss: 79.540599\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 629 | Loss: 79.557353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 631 | Loss: 79.593622\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 633 | Loss: 79.677465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 636 | Loss: 79.755702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:34 | Steps: 638 | Loss: 79.706108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 640 | Loss: 79.743543\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 643 | Loss: 79.845936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 645 | Loss: 79.926709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 647 | Loss: 80.005226\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 649 | Loss: 80.077022\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 651 | Loss: 80.097512\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 654 | Loss: 80.134564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:35 | Steps: 656 | Loss: 80.217060\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 658 | Loss: 80.274535\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 660 | Loss: 80.348723\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 663 | Loss: 80.381051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 665 | Loss: 80.502931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 667 | Loss: 80.607830\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 669 | Loss: 80.704652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 671 | Loss: 80.776614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 673 | Loss: 80.837609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:36 | Steps: 675 | Loss: 80.905024\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 677 | Loss: 80.952421\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 679 | Loss: 80.974227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 682 | Loss: 81.141068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 684 | Loss: 81.203933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 686 | Loss: 81.239630\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 688 | Loss: 81.284705\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 690 | Loss: 81.273739\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 692 | Loss: 81.315289\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:37 | Steps: 694 | Loss: 81.307630\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 696 | Loss: 81.367777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 699 | Loss: 81.475179\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 701 | Loss: 81.491941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 703 | Loss: 81.580262\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 705 | Loss: 81.614385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 707 | Loss: 81.631350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 709 | Loss: 81.665791\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:38 | Steps: 712 | Loss: 81.759394\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 714 | Loss: 81.886881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 716 | Loss: 82.011047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 718 | Loss: 82.064689\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 721 | Loss: 82.151183\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 723 | Loss: 82.200613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 725 | Loss: 82.229833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 727 | Loss: 82.320749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:39 | Steps: 729 | Loss: 82.346513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 732 | Loss: 82.336753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 735 | Loss: 82.476591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 737 | Loss: 82.582817\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 739 | Loss: 82.626013\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 741 | Loss: 82.692143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 743 | Loss: 82.756608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 745 | Loss: 82.788171\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:40 | Steps: 748 | Loss: 82.777184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 750 | Loss: 82.818187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 752 | Loss: 82.898296\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 754 | Loss: 82.881030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 756 | Loss: 82.898679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 758 | Loss: 82.895118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 760 | Loss: 82.930893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 762 | Loss: 82.885696\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 764 | Loss: 82.958073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:41 | Steps: 766 | Loss: 82.948606\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 768 | Loss: 82.962072\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 770 | Loss: 83.005534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 772 | Loss: 82.993110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 774 | Loss: 83.053174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 776 | Loss: 83.100720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 778 | Loss: 83.178644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 781 | Loss: 83.296420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:42 | Steps: 783 | Loss: 83.295056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 785 | Loss: 83.354497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 787 | Loss: 83.419291\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 789 | Loss: 83.406568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 791 | Loss: 83.443840\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 793 | Loss: 83.559071\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 795 | Loss: 83.589584\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 797 | Loss: 83.597135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 799 | Loss: 83.689282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:43 | Steps: 801 | Loss: 83.798320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 803 | Loss: 83.882585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 806 | Loss: 83.916652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 808 | Loss: 83.924850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 810 | Loss: 83.927021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 812 | Loss: 83.916486\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 814 | Loss: 83.947837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 816 | Loss: 84.028489\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:44 | Steps: 818 | Loss: 84.050844\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 820 | Loss: 84.126035\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 822 | Loss: 84.135021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 824 | Loss: 84.161198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 826 | Loss: 84.208765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 828 | Loss: 84.208256\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 830 | Loss: 84.229924\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 832 | Loss: 84.287158\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 834 | Loss: 84.372402\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:45 | Steps: 836 | Loss: 84.383460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 839 | Loss: 84.421074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 841 | Loss: 84.372331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 843 | Loss: 84.389347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 845 | Loss: 84.418267\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 847 | Loss: 84.428389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 849 | Loss: 84.580475\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 851 | Loss: 84.618120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:46 | Steps: 853 | Loss: 84.633219\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 855 | Loss: 84.706531\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 857 | Loss: 84.749420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 859 | Loss: 84.773562\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 861 | Loss: 84.863145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 863 | Loss: 84.930256\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 865 | Loss: 84.961590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 867 | Loss: 85.030824\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:47 | Steps: 869 | Loss: 85.126009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 871 | Loss: 85.179441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 873 | Loss: 85.227174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 875 | Loss: 85.292536\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 877 | Loss: 85.348670\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 879 | Loss: 85.338859\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 881 | Loss: 85.327739\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 883 | Loss: 85.374899\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:48 | Steps: 886 | Loss: 85.442002\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 888 | Loss: 85.483635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 890 | Loss: 85.473688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 892 | Loss: 85.510392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 894 | Loss: 85.516632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 896 | Loss: 85.534592\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 898 | Loss: 85.547588\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 900 | Loss: 85.601270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 902 | Loss: 85.609407\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:49 | Steps: 904 | Loss: 85.624121\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 906 | Loss: 85.666676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 908 | Loss: 85.684862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 910 | Loss: 85.663866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 912 | Loss: 85.674111\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 914 | Loss: 85.706083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 916 | Loss: 85.779311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 918 | Loss: 85.845366\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:50 | Steps: 920 | Loss: 85.832305\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 922 | Loss: 85.898953\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 924 | Loss: 85.892310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 926 | Loss: 85.916763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 928 | Loss: 85.959777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 930 | Loss: 86.057642\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 932 | Loss: 86.078611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 934 | Loss: 86.134872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 936 | Loss: 86.165974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:51 | Steps: 938 | Loss: 86.203876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 940 | Loss: 86.236570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 942 | Loss: 86.321745\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 944 | Loss: 86.384042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 946 | Loss: 86.419731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 948 | Loss: 86.442903\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 950 | Loss: 86.468017\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 952 | Loss: 86.500008\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:52 | Steps: 954 | Loss: 86.501545\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 956 | Loss: 86.512329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 958 | Loss: 86.528918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 960 | Loss: 86.609053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 962 | Loss: 86.647619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 964 | Loss: 86.679570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 966 | Loss: 86.718892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 968 | Loss: 86.724005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:53 | Steps: 970 | Loss: 86.749241\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 972 | Loss: 86.766680\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 974 | Loss: 86.756083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 976 | Loss: 86.754750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 978 | Loss: 86.750789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 980 | Loss: 86.786235\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 982 | Loss: 86.853264\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 984 | Loss: 86.883012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 986 | Loss: 86.858977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:54 | Steps: 988 | Loss: 86.888746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 990 | Loss: 86.864194\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 992 | Loss: 86.876325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 994 | Loss: 86.909947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 996 | Loss: 86.949553\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 998 | Loss: 86.953412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 1000 | Loss: 87.005144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 1002 | Loss: 86.972696\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:55 | Steps: 1004 | Loss: 86.990524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1006 | Loss: 87.033802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1008 | Loss: 87.058153\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1010 | Loss: 87.135140\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1012 | Loss: 87.145742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1014 | Loss: 87.168338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1016 | Loss: 87.177205\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1018 | Loss: 87.169925\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1020 | Loss: 87.178434\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:56 | Steps: 1022 | Loss: 87.271801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 1024 | Loss: 87.323027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 1026 | Loss: 87.374481\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 1028 | Loss: 87.421078\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 1030 | Loss: 87.457646\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 1032 | Loss: 87.440238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 1034 | Loss: 87.499056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 1036 | Loss: 87.513228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:57 | Steps: 1038 | Loss: 87.519786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 1040 | Loss: 87.487949\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 1042 | Loss: 87.535969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 1044 | Loss: 87.563543\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 1046 | Loss: 87.567310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 1048 | Loss: 87.609293\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 1050 | Loss: 87.614683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 1052 | Loss: 87.626189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:58 | Steps: 1054 | Loss: 87.646188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 1056 | Loss: 87.617603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 1058 | Loss: 87.620476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 1060 | Loss: 87.613496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 1062 | Loss: 87.649474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 1064 | Loss: 87.650960\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 1066 | Loss: 87.669675\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 1068 | Loss: 87.709442\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:59 | Steps: 1070 | Loss: 87.728739\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 1072 | Loss: 87.768106\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 1074 | Loss: 87.747625\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 1076 | Loss: 87.765528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 1078 | Loss: 87.774847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 1080 | Loss: 87.770264\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 1082 | Loss: 87.806773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 1084 | Loss: 87.860422\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:00 | Steps: 1086 | Loss: 87.889180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1088 | Loss: 87.917463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1090 | Loss: 87.925486\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1092 | Loss: 87.950649\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1094 | Loss: 87.975906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1096 | Loss: 88.017298\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1098 | Loss: 88.036453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1100 | Loss: 88.060009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1102 | Loss: 88.076090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:01 | Steps: 1104 | Loss: 88.109648\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 1106 | Loss: 88.147466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 1108 | Loss: 88.136276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 1110 | Loss: 88.169790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 1112 | Loss: 88.184618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 1114 | Loss: 88.189548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 1116 | Loss: 88.154244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 1118 | Loss: 88.186711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:02 | Steps: 1120 | Loss: 88.295005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 1122 | Loss: 88.360055\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 1124 | Loss: 88.388406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 1126 | Loss: 88.404266\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 1128 | Loss: 88.477086\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 1130 | Loss: 88.488115\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 1132 | Loss: 88.494720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 1134 | Loss: 88.502577\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:03 | Steps: 1136 | Loss: 88.498098\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 1138 | Loss: 88.514366\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 1140 | Loss: 88.563935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 1142 | Loss: 88.576536\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 1144 | Loss: 88.608173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 1146 | Loss: 88.590680\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 1148 | Loss: 88.595097\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 1150 | Loss: 88.578675\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:04 | Steps: 1152 | Loss: 88.556951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1154 | Loss: 88.575847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1156 | Loss: 88.570992\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1158 | Loss: 88.587599\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1160 | Loss: 88.618706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1162 | Loss: 88.655785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1164 | Loss: 88.700380\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1166 | Loss: 88.702928\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:05 | Steps: 1168 | Loss: 88.708428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1170 | Loss: 88.709474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1172 | Loss: 88.722996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1174 | Loss: 88.734065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1176 | Loss: 88.760617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1178 | Loss: 88.817069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1180 | Loss: 88.832000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1182 | Loss: 88.834288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1184 | Loss: 88.815233\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1186 | Loss: 88.831361\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1188 | Loss: 88.834550\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1190 | Loss: 88.835317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1192 | Loss: 88.856978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1194 | Loss: 88.832808\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1196 | Loss: 88.879968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1198 | Loss: 88.930237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:07 | Steps: 1200 | Loss: 88.969317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1202 | Loss: 89.007185\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1204 | Loss: 89.001117\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1206 | Loss: 89.015067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1208 | Loss: 89.040553\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1210 | Loss: 89.077280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1212 | Loss: 89.148190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1214 | Loss: 89.226278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:08 | Steps: 1216 | Loss: 89.252221\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1218 | Loss: 89.268474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1220 | Loss: 89.283719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1222 | Loss: 89.261518\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1224 | Loss: 89.240457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1226 | Loss: 89.287623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1228 | Loss: 89.289769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1230 | Loss: 89.306033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:09 | Steps: 1232 | Loss: 89.308961\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1234 | Loss: 89.312753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1236 | Loss: 89.316232\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1238 | Loss: 89.378122\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1240 | Loss: 89.386736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1242 | Loss: 89.384981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1244 | Loss: 89.411632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1246 | Loss: 89.424013\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:10 | Steps: 1248 | Loss: 89.429594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1250 | Loss: 89.421510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1252 | Loss: 89.431223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1254 | Loss: 89.459278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1256 | Loss: 89.436168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1258 | Loss: 89.457162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1260 | Loss: 89.458524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1262 | Loss: 89.472923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:11 | Steps: 1264 | Loss: 89.470073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1266 | Loss: 89.469652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1268 | Loss: 89.458663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1270 | Loss: 89.453073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1272 | Loss: 89.463287\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1274 | Loss: 89.434704\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1276 | Loss: 89.440704\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1278 | Loss: 89.493881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:12 | Steps: 1280 | Loss: 89.527851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1282 | Loss: 89.546646\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1284 | Loss: 89.563093\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1286 | Loss: 89.592672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1288 | Loss: 89.572450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1290 | Loss: 89.564223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1292 | Loss: 89.588731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1294 | Loss: 89.578749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:13 | Steps: 1296 | Loss: 89.634649\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1298 | Loss: 89.647326\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1300 | Loss: 89.631508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1302 | Loss: 89.664451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1304 | Loss: 89.685824\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1306 | Loss: 89.690688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1308 | Loss: 89.669115\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:14 | Steps: 1310 | Loss: 89.683900\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1312 | Loss: 89.738717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1314 | Loss: 89.785215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1316 | Loss: 89.792465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1318 | Loss: 89.799299\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1320 | Loss: 89.751736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1322 | Loss: 89.744436\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1324 | Loss: 89.747924\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:15 | Steps: 1326 | Loss: 89.747771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1328 | Loss: 89.805653\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1330 | Loss: 89.791697\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1332 | Loss: 89.780995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1334 | Loss: 89.780167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1336 | Loss: 89.828122\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1338 | Loss: 89.839048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1340 | Loss: 89.832507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:16 | Steps: 1342 | Loss: 89.861865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1344 | Loss: 89.872604\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1346 | Loss: 89.879790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1348 | Loss: 89.868997\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1350 | Loss: 89.858622\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1352 | Loss: 89.862724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1354 | Loss: 89.847746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1356 | Loss: 89.846397\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:17 | Steps: 1358 | Loss: 89.845901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1360 | Loss: 89.842717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1362 | Loss: 89.850207\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1364 | Loss: 89.885357\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1366 | Loss: 89.924779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1368 | Loss: 89.939418\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1370 | Loss: 89.966352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:18 | Steps: 1372 | Loss: 89.958249\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1374 | Loss: 89.963564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1376 | Loss: 89.955539\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1378 | Loss: 89.987325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1380 | Loss: 90.004475\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1382 | Loss: 90.030860\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1384 | Loss: 90.067804\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1386 | Loss: 90.065806\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:19 | Steps: 1388 | Loss: 90.080106\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1390 | Loss: 90.068484\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1392 | Loss: 90.113273\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1394 | Loss: 90.099703\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1396 | Loss: 90.101825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1398 | Loss: 90.097227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1400 | Loss: 90.104432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1402 | Loss: 90.102004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:20 | Steps: 1404 | Loss: 90.095839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1406 | Loss: 90.072200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1408 | Loss: 90.114948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1410 | Loss: 90.141674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1412 | Loss: 90.126236\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1414 | Loss: 90.120457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1416 | Loss: 90.118402\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1418 | Loss: 90.107319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:21 | Steps: 1420 | Loss: 90.118966\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1422 | Loss: 90.162053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1424 | Loss: 90.162004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1426 | Loss: 90.169046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1428 | Loss: 90.176945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1430 | Loss: 90.159797\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1432 | Loss: 90.180988\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1434 | Loss: 90.191620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:22 | Steps: 1436 | Loss: 90.201413\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1438 | Loss: 90.213344\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1440 | Loss: 90.199363\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1442 | Loss: 90.187350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1444 | Loss: 90.198254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1446 | Loss: 90.238812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1448 | Loss: 90.220557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:23 | Steps: 1450 | Loss: 90.228835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1452 | Loss: 90.248583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1454 | Loss: 90.257779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1456 | Loss: 90.265274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1458 | Loss: 90.252237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1460 | Loss: 90.252149\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1462 | Loss: 90.257451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1464 | Loss: 90.266570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:24 | Steps: 1466 | Loss: 90.244697\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1468 | Loss: 90.246354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1470 | Loss: 90.235789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1472 | Loss: 90.224548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1474 | Loss: 90.220630\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1476 | Loss: 90.240545\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1478 | Loss: 90.244311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1480 | Loss: 90.253236\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:25 | Steps: 1482 | Loss: 90.277449\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1484 | Loss: 90.280109\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1486 | Loss: 90.306536\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1488 | Loss: 90.301945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1490 | Loss: 90.302618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1492 | Loss: 90.312399\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1494 | Loss: 90.316717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1496 | Loss: 90.351521\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:26 | Steps: 1498 | Loss: 90.361593\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1500 | Loss: 90.387130\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1502 | Loss: 90.397661\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1504 | Loss: 90.378912\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1506 | Loss: 90.380317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1508 | Loss: 90.433035\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1510 | Loss: 90.409816\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:27 | Steps: 1512 | Loss: 90.386815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1514 | Loss: 90.384100\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1516 | Loss: 90.385378\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1518 | Loss: 90.397113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1520 | Loss: 90.383609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1522 | Loss: 90.392455\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1524 | Loss: 90.383460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1526 | Loss: 90.416855\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:28 | Steps: 1528 | Loss: 90.448525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1530 | Loss: 90.471779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1532 | Loss: 90.450028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1534 | Loss: 90.454003\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1536 | Loss: 90.441437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1538 | Loss: 90.437552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1540 | Loss: 90.428757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:29 | Steps: 1542 | Loss: 90.449899\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1544 | Loss: 90.508268\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1546 | Loss: 90.528039\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1548 | Loss: 90.550924\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1550 | Loss: 90.568767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1552 | Loss: 90.579701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1554 | Loss: 90.559484\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1556 | Loss: 90.521828\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:30 | Steps: 1558 | Loss: 90.553078\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1560 | Loss: 90.559417\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1562 | Loss: 90.546150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1564 | Loss: 90.550171\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1566 | Loss: 90.536412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1568 | Loss: 90.528192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1570 | Loss: 90.517289\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1572 | Loss: 90.555753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:31 | Steps: 1574 | Loss: 90.569885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1576 | Loss: 90.572412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1578 | Loss: 90.567082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1580 | Loss: 90.573672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1582 | Loss: 90.575074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1584 | Loss: 90.587710\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1586 | Loss: 90.580395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:32 | Steps: 1588 | Loss: 90.557607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1590 | Loss: 90.545676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1592 | Loss: 90.550838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1594 | Loss: 90.554577\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1596 | Loss: 90.547814\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1598 | Loss: 90.542732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1600 | Loss: 90.541887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1602 | Loss: 90.543543\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 1604 | Loss: 90.558356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1606 | Loss: 90.569532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1608 | Loss: 90.595021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1610 | Loss: 90.566789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1612 | Loss: 90.560393\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1614 | Loss: 90.551720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1616 | Loss: 90.535219\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1618 | Loss: 90.540775\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:34 | Steps: 1620 | Loss: 90.534853\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1622 | Loss: 90.573895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1624 | Loss: 90.563681\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1626 | Loss: 90.563630\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1628 | Loss: 90.554026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1630 | Loss: 90.538543\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1632 | Loss: 90.546646\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1634 | Loss: 90.550230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:35 | Steps: 1636 | Loss: 90.567358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1638 | Loss: 90.582457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1640 | Loss: 90.597474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1642 | Loss: 90.587139\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1644 | Loss: 90.619482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1646 | Loss: 90.626311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1648 | Loss: 90.621472\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1650 | Loss: 90.611802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:36 | Steps: 1652 | Loss: 90.593550\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1654 | Loss: 90.585648\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1656 | Loss: 90.617238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1658 | Loss: 90.656974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1660 | Loss: 90.699063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1662 | Loss: 90.719981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1664 | Loss: 90.709213\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:37 | Steps: 1666 | Loss: 90.702635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1668 | Loss: 90.718644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1670 | Loss: 90.723497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1672 | Loss: 90.708782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1674 | Loss: 90.707368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1676 | Loss: 90.699676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1678 | Loss: 90.697495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:38 | Steps: 1680 | Loss: 90.680759\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1682 | Loss: 90.650865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1684 | Loss: 90.670473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1686 | Loss: 90.685377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1688 | Loss: 90.696105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1690 | Loss: 90.705156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1692 | Loss: 90.723377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1694 | Loss: 90.747718\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:39 | Steps: 1696 | Loss: 90.732780\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1698 | Loss: 90.728989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1700 | Loss: 90.742030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1702 | Loss: 90.746219\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1704 | Loss: 90.735835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1706 | Loss: 90.719763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1708 | Loss: 90.705403\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1710 | Loss: 90.690344\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:40 | Steps: 1712 | Loss: 90.688444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1714 | Loss: 90.699518\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1716 | Loss: 90.699410\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1718 | Loss: 90.712356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1720 | Loss: 90.767887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1722 | Loss: 90.780939\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1724 | Loss: 90.788333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:41 | Steps: 1726 | Loss: 90.811741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1728 | Loss: 90.838635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1730 | Loss: 90.822456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1732 | Loss: 90.820478\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1734 | Loss: 90.815720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1736 | Loss: 90.813540\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1738 | Loss: 90.818835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:42 | Steps: 1740 | Loss: 90.842473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1742 | Loss: 90.852276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1744 | Loss: 90.856582\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1746 | Loss: 90.856945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1748 | Loss: 90.858583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1750 | Loss: 90.875471\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1752 | Loss: 90.873216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1754 | Loss: 90.861921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:43 | Steps: 1756 | Loss: 90.880324\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1758 | Loss: 90.873435\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1760 | Loss: 90.880740\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1762 | Loss: 90.902786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1764 | Loss: 90.907662\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1766 | Loss: 90.889159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1768 | Loss: 90.897312\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:44 | Steps: 1770 | Loss: 90.879781\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1772 | Loss: 90.912858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1774 | Loss: 90.931168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1776 | Loss: 90.946799\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1778 | Loss: 90.962892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1780 | Loss: 90.960766\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1782 | Loss: 90.953841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1784 | Loss: 90.945206\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:45 | Steps: 1786 | Loss: 90.936041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1788 | Loss: 90.936762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1790 | Loss: 90.974829\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1792 | Loss: 91.001048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1794 | Loss: 91.000319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1796 | Loss: 91.028302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1798 | Loss: 91.028559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:46 | Steps: 1800 | Loss: 91.044323\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1802 | Loss: 91.046674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1804 | Loss: 91.029243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1806 | Loss: 91.043549\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1808 | Loss: 91.040022\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1810 | Loss: 91.038283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1812 | Loss: 91.019896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1814 | Loss: 91.004954\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:47 | Steps: 1816 | Loss: 90.992982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1818 | Loss: 90.984936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1820 | Loss: 91.008667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1822 | Loss: 91.026791\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1824 | Loss: 91.015885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1826 | Loss: 91.025812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1828 | Loss: 91.031783\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:48 | Steps: 1830 | Loss: 91.031557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1832 | Loss: 91.013304\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1834 | Loss: 90.999573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1836 | Loss: 90.994968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1838 | Loss: 90.975858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1840 | Loss: 90.948626\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1842 | Loss: 90.936925\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1844 | Loss: 90.929683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:49 | Steps: 1846 | Loss: 90.922225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1848 | Loss: 90.915023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1850 | Loss: 90.908826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1852 | Loss: 90.943495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1854 | Loss: 90.954565\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1856 | Loss: 90.949254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1858 | Loss: 90.948292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:50 | Steps: 1860 | Loss: 90.965907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1862 | Loss: 90.979345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1864 | Loss: 90.972395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1866 | Loss: 90.962919\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1868 | Loss: 90.959288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1870 | Loss: 90.947825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1872 | Loss: 90.981160\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1874 | Loss: 90.996324\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:51 | Steps: 1876 | Loss: 91.010985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1878 | Loss: 91.006574\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1880 | Loss: 90.988021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1882 | Loss: 91.021464\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1884 | Loss: 91.018391\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1886 | Loss: 91.000919\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1888 | Loss: 91.016467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:52 | Steps: 1890 | Loss: 91.001325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1892 | Loss: 91.014099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1894 | Loss: 91.010451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1896 | Loss: 91.015152\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1898 | Loss: 91.018202\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1900 | Loss: 91.016537\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1902 | Loss: 91.030937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:53 | Steps: 1904 | Loss: 91.056565\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1906 | Loss: 91.075546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1908 | Loss: 91.100120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1910 | Loss: 91.099519\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1912 | Loss: 91.105656\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1914 | Loss: 91.103676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1916 | Loss: 91.084994\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:54 | Steps: 1918 | Loss: 91.075144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1920 | Loss: 91.070762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1922 | Loss: 91.088067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1924 | Loss: 91.125070\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1926 | Loss: 91.147276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1928 | Loss: 91.163324\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1930 | Loss: 91.172826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1932 | Loss: 91.169664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:55 | Steps: 1934 | Loss: 91.152782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1936 | Loss: 91.148388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1938 | Loss: 91.150167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1940 | Loss: 91.142972\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1942 | Loss: 91.138105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1944 | Loss: 91.142782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1946 | Loss: 91.126651\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:56 | Steps: 1948 | Loss: 91.108695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 1950 | Loss: 91.092083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 1952 | Loss: 91.080991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 1954 | Loss: 91.093637\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 1956 | Loss: 91.098991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 1958 | Loss: 91.097145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 1960 | Loss: 91.098784\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 1962 | Loss: 91.099488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:57 | Steps: 1964 | Loss: 91.112661\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 1966 | Loss: 91.105163\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 1968 | Loss: 91.089238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 1970 | Loss: 91.069991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 1972 | Loss: 91.080637\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 1974 | Loss: 91.087201\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 1976 | Loss: 91.065805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:58 | Steps: 1978 | Loss: 91.064542\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 1980 | Loss: 91.056405\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 1982 | Loss: 91.038701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 1984 | Loss: 91.034400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 1986 | Loss: 91.037578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 1988 | Loss: 91.062721\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 1990 | Loss: 91.091852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:01:59 | Steps: 1992 | Loss: 91.094858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 1994 | Loss: 91.068768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 1996 | Loss: 91.068534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 1998 | Loss: 91.062476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2000 | Loss: 91.075694\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2002 | Loss: 91.077387\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2004 | Loss: 91.092682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2006 | Loss: 91.126695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:00 | Steps: 2008 | Loss: 91.127147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2010 | Loss: 91.129631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2012 | Loss: 91.118731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2014 | Loss: 91.145817\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2016 | Loss: 91.130007\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2018 | Loss: 91.138869\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:01 | Steps: 2020 | Loss: 91.113602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2022 | Loss: 91.111274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2024 | Loss: 91.105428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2026 | Loss: 91.106757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2028 | Loss: 91.103901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2030 | Loss: 91.095205\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2032 | Loss: 91.093789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:02 | Steps: 2034 | Loss: 91.097844\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2036 | Loss: 91.072939\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2038 | Loss: 91.066252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2040 | Loss: 91.079539\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2042 | Loss: 91.100429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2044 | Loss: 91.089468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2046 | Loss: 91.085388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2048 | Loss: 91.070420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:03 | Steps: 2050 | Loss: 91.061525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2052 | Loss: 91.045638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2054 | Loss: 91.032443\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2056 | Loss: 91.025344\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2058 | Loss: 91.023559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2060 | Loss: 91.072816\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2062 | Loss: 91.096520\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:04 | Steps: 2064 | Loss: 91.102265\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2066 | Loss: 91.117972\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2068 | Loss: 91.116749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2070 | Loss: 91.098513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2072 | Loss: 91.105494\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2074 | Loss: 91.088099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2076 | Loss: 91.082564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2078 | Loss: 91.074532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:05 | Steps: 2080 | Loss: 91.058198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2082 | Loss: 91.033658\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2084 | Loss: 91.033764\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2086 | Loss: 91.051707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2088 | Loss: 91.077803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2090 | Loss: 91.074428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2092 | Loss: 91.068184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:06 | Steps: 2094 | Loss: 91.083406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2096 | Loss: 91.089679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2098 | Loss: 91.098663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2100 | Loss: 91.094005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2102 | Loss: 91.074022\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2104 | Loss: 91.058432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2106 | Loss: 91.054451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:07 | Steps: 2108 | Loss: 91.062066\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2110 | Loss: 91.045945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2112 | Loss: 91.041743\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2114 | Loss: 91.025910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2116 | Loss: 91.036469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2118 | Loss: 91.039513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2120 | Loss: 91.029956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:08 | Steps: 2122 | Loss: 91.021450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2124 | Loss: 91.040373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2126 | Loss: 91.075734\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2127 | Loss: 91.082696\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2129 | Loss: 91.089412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2131 | Loss: 91.098111\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2133 | Loss: 91.094427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2135 | Loss: 91.087349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:09 | Steps: 2137 | Loss: 91.087299\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2139 | Loss: 91.095826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2141 | Loss: 91.089771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2143 | Loss: 91.108938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2145 | Loss: 91.109687\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2147 | Loss: 91.119693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2149 | Loss: 91.111600\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:10 | Steps: 2151 | Loss: 91.110153\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2153 | Loss: 91.087768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2155 | Loss: 91.103048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2157 | Loss: 91.088122\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2159 | Loss: 91.079779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2161 | Loss: 91.078931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2163 | Loss: 91.091856\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:11 | Steps: 2165 | Loss: 91.110515\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2167 | Loss: 91.110254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2169 | Loss: 91.137689\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2171 | Loss: 91.126465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2173 | Loss: 91.124106\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2175 | Loss: 91.112801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2177 | Loss: 91.089788\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:12 | Steps: 2179 | Loss: 91.086382\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2181 | Loss: 91.112483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2183 | Loss: 91.141700\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2185 | Loss: 91.167006\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2187 | Loss: 91.169517\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2189 | Loss: 91.174667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2191 | Loss: 91.169435\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:13 | Steps: 2193 | Loss: 91.141459\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2195 | Loss: 91.150702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2197 | Loss: 91.145505\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2199 | Loss: 91.145875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2201 | Loss: 91.145368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2203 | Loss: 91.132008\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2205 | Loss: 91.115462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:14 | Steps: 2207 | Loss: 91.102433\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2209 | Loss: 91.119209\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2211 | Loss: 91.123259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2213 | Loss: 91.112082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2215 | Loss: 91.111418\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2217 | Loss: 91.111005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2219 | Loss: 91.108823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:15 | Steps: 2221 | Loss: 91.086007\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2223 | Loss: 91.059588\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2225 | Loss: 91.048488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2227 | Loss: 91.045364\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2229 | Loss: 91.040523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2231 | Loss: 91.024794\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2233 | Loss: 91.019399\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:16 | Steps: 2235 | Loss: 91.008856\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2237 | Loss: 90.999583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2239 | Loss: 90.985973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2241 | Loss: 90.974729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2243 | Loss: 90.993114\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2245 | Loss: 90.991897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2247 | Loss: 90.980677\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2249 | Loss: 90.982619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:17 | Steps: 2251 | Loss: 90.991753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:18 | Steps: 2253 | Loss: 90.987843\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:18 | Steps: 2255 | Loss: 90.990973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:18 | Steps: 2257 | Loss: 90.990860\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:18 | Steps: 2259 | Loss: 90.966051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:18 | Steps: 2261 | Loss: 90.963935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:18 | Steps: 2263 | Loss: 90.955951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:18 | Steps: 2265 | Loss: 90.961846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:19 | Steps: 2267 | Loss: 90.959869\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:19 | Steps: 2269 | Loss: 90.951373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:19 | Steps: 2271 | Loss: 90.945396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:19 | Steps: 2273 | Loss: 90.985633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:19 | Steps: 2275 | Loss: 90.980503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:19 | Steps: 2277 | Loss: 90.979444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:19 | Steps: 2279 | Loss: 90.974105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:20 | Steps: 2281 | Loss: 90.968002\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:20 | Steps: 2283 | Loss: 90.967786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:20 | Steps: 2285 | Loss: 90.961981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:20 | Steps: 2287 | Loss: 90.962141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:20 | Steps: 2289 | Loss: 90.983281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:20 | Steps: 2291 | Loss: 90.989601\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:20 | Steps: 2293 | Loss: 90.988023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:21 | Steps: 2295 | Loss: 90.992347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:21 | Steps: 2297 | Loss: 90.997107\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:21 | Steps: 2299 | Loss: 90.977485\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:21 | Steps: 2301 | Loss: 91.010253\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:21 | Steps: 2303 | Loss: 90.993543\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:21 | Steps: 2305 | Loss: 91.005069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:21 | Steps: 2307 | Loss: 91.018616\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:22 | Steps: 2309 | Loss: 91.025276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:22 | Steps: 2311 | Loss: 91.014972\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:22 | Steps: 2313 | Loss: 91.004092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:22 | Steps: 2315 | Loss: 90.995138\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:22 | Steps: 2317 | Loss: 90.984982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:22 | Steps: 2319 | Loss: 90.980707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:22 | Steps: 2321 | Loss: 90.979174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:23 | Steps: 2323 | Loss: 90.965018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:23 | Steps: 2325 | Loss: 90.984168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:23 | Steps: 2327 | Loss: 91.003095\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:23 | Steps: 2329 | Loss: 91.016845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:23 | Steps: 2331 | Loss: 91.020898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:23 | Steps: 2333 | Loss: 91.023211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:23 | Steps: 2335 | Loss: 91.011988\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:24 | Steps: 2337 | Loss: 91.005741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:24 | Steps: 2339 | Loss: 90.979497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:24 | Steps: 2341 | Loss: 90.958707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:24 | Steps: 2343 | Loss: 90.939563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:24 | Steps: 2345 | Loss: 90.932595\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:24 | Steps: 2347 | Loss: 90.922292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:24 | Steps: 2349 | Loss: 90.913306\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:25 | Steps: 2351 | Loss: 90.902112\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:25 | Steps: 2353 | Loss: 90.899073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:25 | Steps: 2355 | Loss: 90.884041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:25 | Steps: 2357 | Loss: 90.878404\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:25 | Steps: 2359 | Loss: 90.871691\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:25 | Steps: 2361 | Loss: 90.887134\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:25 | Steps: 2363 | Loss: 90.899916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:26 | Steps: 2365 | Loss: 90.893227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:26 | Steps: 2367 | Loss: 90.890695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:26 | Steps: 2369 | Loss: 90.888430\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:26 | Steps: 2371 | Loss: 90.878492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:26 | Steps: 2373 | Loss: 90.860545\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:26 | Steps: 2375 | Loss: 90.846864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:26 | Steps: 2377 | Loss: 90.825467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:27 | Steps: 2379 | Loss: 90.827937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:27 | Steps: 2381 | Loss: 90.826639\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:27 | Steps: 2383 | Loss: 90.812909\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:27 | Steps: 2385 | Loss: 90.802984\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:27 | Steps: 2387 | Loss: 90.795893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:27 | Steps: 2389 | Loss: 90.784168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:27 | Steps: 2391 | Loss: 90.793457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:28 | Steps: 2393 | Loss: 90.780332\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:28 | Steps: 2395 | Loss: 90.800469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:28 | Steps: 2397 | Loss: 90.821926\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:28 | Steps: 2399 | Loss: 90.827424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:28 | Steps: 2401 | Loss: 90.817534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:28 | Steps: 2403 | Loss: 90.793277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:28 | Steps: 2405 | Loss: 90.779967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:29 | Steps: 2407 | Loss: 90.768092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:29 | Steps: 2409 | Loss: 90.755986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:29 | Steps: 2410 | Loss: 90.752073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:29 | Steps: 2412 | Loss: 90.752345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:29 | Steps: 2414 | Loss: 90.749936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:29 | Steps: 2416 | Loss: 90.748251\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:29 | Steps: 2418 | Loss: 90.744877\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:30 | Steps: 2420 | Loss: 90.746433\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:30 | Steps: 2422 | Loss: 90.774970\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:30 | Steps: 2424 | Loss: 90.770764\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:30 | Steps: 2426 | Loss: 90.780078\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:30 | Steps: 2428 | Loss: 90.777473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:30 | Steps: 2430 | Loss: 90.762983\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:30 | Steps: 2432 | Loss: 90.765326\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:31 | Steps: 2434 | Loss: 90.777501\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:31 | Steps: 2436 | Loss: 90.786681\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:31 | Steps: 2438 | Loss: 90.792301\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:31 | Steps: 2440 | Loss: 90.798621\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:31 | Steps: 2442 | Loss: 90.806491\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:31 | Steps: 2444 | Loss: 90.793850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:31 | Steps: 2446 | Loss: 90.801304\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:32 | Steps: 2448 | Loss: 90.807842\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:32 | Steps: 2450 | Loss: 90.817942\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:32 | Steps: 2452 | Loss: 90.806960\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:32 | Steps: 2454 | Loss: 90.806593\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:32 | Steps: 2456 | Loss: 90.805077\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:32 | Steps: 2458 | Loss: 90.798248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:32 | Steps: 2460 | Loss: 90.787879\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:33 | Steps: 2462 | Loss: 90.792352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:33 | Steps: 2464 | Loss: 90.787084\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:33 | Steps: 2466 | Loss: 90.792720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:33 | Steps: 2468 | Loss: 90.809348\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:33 | Steps: 2470 | Loss: 90.809861\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:33 | Steps: 2472 | Loss: 90.847189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:33 | Steps: 2474 | Loss: 90.864686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:34 | Steps: 2476 | Loss: 90.863326\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:34 | Steps: 2478 | Loss: 90.855872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:34 | Steps: 2480 | Loss: 90.862773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:34 | Steps: 2482 | Loss: 90.834068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:34 | Steps: 2484 | Loss: 90.806972\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:34 | Steps: 2486 | Loss: 90.790476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:34 | Steps: 2488 | Loss: 90.796493\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:35 | Steps: 2490 | Loss: 90.790676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:35 | Steps: 2492 | Loss: 90.785881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:35 | Steps: 2494 | Loss: 90.777825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:35 | Steps: 2496 | Loss: 90.774132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:35 | Steps: 2498 | Loss: 90.763419\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:35 | Steps: 2500 | Loss: 90.753488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:35 | Steps: 2502 | Loss: 90.754876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:36 | Steps: 2504 | Loss: 90.761532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:36 | Steps: 2506 | Loss: 90.788348\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:36 | Steps: 2508 | Loss: 90.778507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:36 | Steps: 2510 | Loss: 90.779180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:36 | Steps: 2512 | Loss: 90.773182\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:36 | Steps: 2514 | Loss: 90.784184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:36 | Steps: 2516 | Loss: 90.774445\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:37 | Steps: 2518 | Loss: 90.758502\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:37 | Steps: 2520 | Loss: 90.742026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:37 | Steps: 2522 | Loss: 90.747811\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:37 | Steps: 2524 | Loss: 90.743813\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:37 | Steps: 2526 | Loss: 90.723309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:37 | Steps: 2528 | Loss: 90.706904\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:37 | Steps: 2530 | Loss: 90.697942\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:38 | Steps: 2532 | Loss: 90.693186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:38 | Steps: 2534 | Loss: 90.701463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:38 | Steps: 2536 | Loss: 90.700411\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:38 | Steps: 2538 | Loss: 90.692096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:38 | Steps: 2540 | Loss: 90.700866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:38 | Steps: 2542 | Loss: 90.689503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:38 | Steps: 2544 | Loss: 90.686358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:39 | Steps: 2546 | Loss: 90.679788\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:39 | Steps: 2548 | Loss: 90.660654\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:39 | Steps: 2550 | Loss: 90.666206\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:39 | Steps: 2552 | Loss: 90.661956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:39 | Steps: 2554 | Loss: 90.647040\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:39 | Steps: 2556 | Loss: 90.656950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:39 | Steps: 2558 | Loss: 90.652314\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:40 | Steps: 2560 | Loss: 90.653317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:40 | Steps: 2562 | Loss: 90.658304\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:40 | Steps: 2564 | Loss: 90.652257\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:40 | Steps: 2566 | Loss: 90.653693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:40 | Steps: 2568 | Loss: 90.648589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:40 | Steps: 2570 | Loss: 90.662911\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:40 | Steps: 2572 | Loss: 90.673726\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:41 | Steps: 2574 | Loss: 90.659137\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:41 | Steps: 2576 | Loss: 90.661848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:41 | Steps: 2578 | Loss: 90.652763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:41 | Steps: 2580 | Loss: 90.645209\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:41 | Steps: 2582 | Loss: 90.639974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:41 | Steps: 2584 | Loss: 90.659484\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:42 | Steps: 2586 | Loss: 90.665956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:42 | Steps: 2588 | Loss: 90.671009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:42 | Steps: 2590 | Loss: 90.661598\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:42 | Steps: 2592 | Loss: 90.679223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:42 | Steps: 2594 | Loss: 90.671514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:42 | Steps: 2596 | Loss: 90.659701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:42 | Steps: 2598 | Loss: 90.670340\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:43 | Steps: 2600 | Loss: 90.656573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:43 | Steps: 2602 | Loss: 90.657034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:43 | Steps: 2604 | Loss: 90.645895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:43 | Steps: 2606 | Loss: 90.632974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:43 | Steps: 2607 | Loss: 90.635316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:43 | Steps: 2609 | Loss: 90.631439\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:43 | Steps: 2611 | Loss: 90.619743\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:44 | Steps: 2613 | Loss: 90.615082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:44 | Steps: 2615 | Loss: 90.620259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:44 | Steps: 2617 | Loss: 90.616899\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:44 | Steps: 2619 | Loss: 90.641474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:44 | Steps: 2621 | Loss: 90.633735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:44 | Steps: 2623 | Loss: 90.636752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:44 | Steps: 2625 | Loss: 90.641613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:45 | Steps: 2627 | Loss: 90.634733\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:45 | Steps: 2629 | Loss: 90.629328\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:45 | Steps: 2631 | Loss: 90.608323\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:45 | Steps: 2633 | Loss: 90.642046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:45 | Steps: 2635 | Loss: 90.633583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:45 | Steps: 2637 | Loss: 90.619282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:45 | Steps: 2638 | Loss: 90.619862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:46 | Steps: 2640 | Loss: 90.613823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:46 | Steps: 2642 | Loss: 90.609380\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:46 | Steps: 2644 | Loss: 90.601509\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:46 | Steps: 2646 | Loss: 90.599885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:46 | Steps: 2648 | Loss: 90.597483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:46 | Steps: 2650 | Loss: 90.586769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:46 | Steps: 2652 | Loss: 90.587621\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:47 | Steps: 2654 | Loss: 90.595447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:47 | Steps: 2656 | Loss: 90.588849\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:47 | Steps: 2657 | Loss: 90.582934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:47 | Steps: 2659 | Loss: 90.574462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:47 | Steps: 2661 | Loss: 90.563202\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:47 | Steps: 2663 | Loss: 90.560651\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:47 | Steps: 2665 | Loss: 90.559148\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:48 | Steps: 2667 | Loss: 90.571819\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:48 | Steps: 2669 | Loss: 90.555732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:48 | Steps: 2671 | Loss: 90.546509\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:48 | Steps: 2673 | Loss: 90.533610\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:48 | Steps: 2675 | Loss: 90.520217\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:48 | Steps: 2677 | Loss: 90.524881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:48 | Steps: 2679 | Loss: 90.524329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:49 | Steps: 2681 | Loss: 90.505099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:49 | Steps: 2683 | Loss: 90.496252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:49 | Steps: 2685 | Loss: 90.490590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:49 | Steps: 2687 | Loss: 90.475575\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:49 | Steps: 2689 | Loss: 90.465168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:49 | Steps: 2691 | Loss: 90.452265\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:49 | Steps: 2693 | Loss: 90.446552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:50 | Steps: 2695 | Loss: 90.438987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:50 | Steps: 2697 | Loss: 90.444064\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:50 | Steps: 2699 | Loss: 90.441798\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:50 | Steps: 2701 | Loss: 90.434060\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:50 | Steps: 2703 | Loss: 90.438513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:50 | Steps: 2705 | Loss: 90.446665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:50 | Steps: 2707 | Loss: 90.449704\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:51 | Steps: 2709 | Loss: 90.446815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:51 | Steps: 2711 | Loss: 90.456030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:51 | Steps: 2713 | Loss: 90.445585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:51 | Steps: 2715 | Loss: 90.435700\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:51 | Steps: 2717 | Loss: 90.438006\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:51 | Steps: 2719 | Loss: 90.427174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:51 | Steps: 2721 | Loss: 90.440318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:52 | Steps: 2723 | Loss: 90.435449\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:52 | Steps: 2725 | Loss: 90.456466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:52 | Steps: 2727 | Loss: 90.461228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:52 | Steps: 2729 | Loss: 90.456861\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:52 | Steps: 2731 | Loss: 90.462601\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:52 | Steps: 2733 | Loss: 90.461570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:52 | Steps: 2735 | Loss: 90.440435\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:53 | Steps: 2737 | Loss: 90.437006\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:53 | Steps: 2739 | Loss: 90.429124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:53 | Steps: 2741 | Loss: 90.426321\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:53 | Steps: 2743 | Loss: 90.426790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:53 | Steps: 2745 | Loss: 90.435000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:53 | Steps: 2747 | Loss: 90.421666\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:54 | Steps: 2749 | Loss: 90.407670\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:54 | Steps: 2751 | Loss: 90.421614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:54 | Steps: 2753 | Loss: 90.424315\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:54 | Steps: 2754 | Loss: 90.420888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:54 | Steps: 2756 | Loss: 90.440336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:54 | Steps: 2758 | Loss: 90.451034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:54 | Steps: 2760 | Loss: 90.465631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:55 | Steps: 2762 | Loss: 90.465279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:55 | Steps: 2764 | Loss: 90.458583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:55 | Steps: 2766 | Loss: 90.445876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:55 | Steps: 2768 | Loss: 90.432252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:55 | Steps: 2769 | Loss: 90.431406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:55 | Steps: 2771 | Loss: 90.415690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:55 | Steps: 2773 | Loss: 90.425279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:56 | Steps: 2775 | Loss: 90.440946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:56 | Steps: 2777 | Loss: 90.451939\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:56 | Steps: 2779 | Loss: 90.460863\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:56 | Steps: 2781 | Loss: 90.462049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:56 | Steps: 2783 | Loss: 90.450972\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:56 | Steps: 2785 | Loss: 90.458026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:56 | Steps: 2787 | Loss: 90.441225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:57 | Steps: 2789 | Loss: 90.444383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:57 | Steps: 2791 | Loss: 90.436649\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:57 | Steps: 2793 | Loss: 90.430448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:57 | Steps: 2795 | Loss: 90.431874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:57 | Steps: 2797 | Loss: 90.421482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:57 | Steps: 2799 | Loss: 90.409028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:58 | Steps: 2801 | Loss: 90.408419\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:58 | Steps: 2803 | Loss: 90.399117\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:58 | Steps: 2805 | Loss: 90.385132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:58 | Steps: 2807 | Loss: 90.376723\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:58 | Steps: 2809 | Loss: 90.383777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:58 | Steps: 2810 | Loss: 90.391074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:58 | Steps: 2812 | Loss: 90.385006\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:59 | Steps: 2814 | Loss: 90.379839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:59 | Steps: 2816 | Loss: 90.381812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:59 | Steps: 2818 | Loss: 90.381578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:59 | Steps: 2820 | Loss: 90.386902\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:59 | Steps: 2822 | Loss: 90.370966\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:59 | Steps: 2824 | Loss: 90.363096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:02:59 | Steps: 2826 | Loss: 90.350372\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:00 | Steps: 2828 | Loss: 90.335335\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:00 | Steps: 2830 | Loss: 90.327677\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:00 | Steps: 2832 | Loss: 90.333408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:00 | Steps: 2834 | Loss: 90.334430\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:00 | Steps: 2836 | Loss: 90.326218\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:00 | Steps: 2838 | Loss: 90.309745\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:00 | Steps: 2840 | Loss: 90.301208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:01 | Steps: 2842 | Loss: 90.285034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:01 | Steps: 2844 | Loss: 90.277407\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:01 | Steps: 2846 | Loss: 90.275426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:01 | Steps: 2848 | Loss: 90.268706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:01 | Steps: 2850 | Loss: 90.251368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:01 | Steps: 2852 | Loss: 90.271947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:01 | Steps: 2854 | Loss: 90.265439\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:02 | Steps: 2856 | Loss: 90.274248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:02 | Steps: 2858 | Loss: 90.266690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:02 | Steps: 2860 | Loss: 90.268641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:02 | Steps: 2862 | Loss: 90.271193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:02 | Steps: 2864 | Loss: 90.260065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:02 | Steps: 2866 | Loss: 90.244754\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:03 | Steps: 2868 | Loss: 90.244156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:03 | Steps: 2870 | Loss: 90.263966\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:03 | Steps: 2872 | Loss: 90.273560\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:03 | Steps: 2874 | Loss: 90.263792\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:03 | Steps: 2876 | Loss: 90.259064\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:03 | Steps: 2878 | Loss: 90.254614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:03 | Steps: 2880 | Loss: 90.269354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:04 | Steps: 2882 | Loss: 90.266817\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:04 | Steps: 2884 | Loss: 90.272110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:04 | Steps: 2886 | Loss: 90.268407\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:04 | Steps: 2888 | Loss: 90.266726\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:04 | Steps: 2890 | Loss: 90.273431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:04 | Steps: 2892 | Loss: 90.291479\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:05 | Steps: 2894 | Loss: 90.292288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:05 | Steps: 2896 | Loss: 90.292743\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:05 | Steps: 2898 | Loss: 90.271077\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:05 | Steps: 2900 | Loss: 90.281208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:05 | Steps: 2902 | Loss: 90.263796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:05 | Steps: 2904 | Loss: 90.276092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:05 | Steps: 2906 | Loss: 90.302078\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:06 | Steps: 2908 | Loss: 90.312408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:06 | Steps: 2910 | Loss: 90.320794\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:06 | Steps: 2912 | Loss: 90.326166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:06 | Steps: 2914 | Loss: 90.320257\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:06 | Steps: 2916 | Loss: 90.318002\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:06 | Steps: 2918 | Loss: 90.308565\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:06 | Steps: 2920 | Loss: 90.303284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:07 | Steps: 2922 | Loss: 90.304309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:07 | Steps: 2924 | Loss: 90.307287\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:07 | Steps: 2926 | Loss: 90.305634\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:07 | Steps: 2928 | Loss: 90.331287\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:07 | Steps: 2930 | Loss: 90.336036\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:07 | Steps: 2932 | Loss: 90.350937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:08 | Steps: 2934 | Loss: 90.349776\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:08 | Steps: 2936 | Loss: 90.345782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:08 | Steps: 2938 | Loss: 90.342362\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:08 | Steps: 2940 | Loss: 90.335508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:08 | Steps: 2942 | Loss: 90.309374\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:08 | Steps: 2944 | Loss: 90.295642\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:08 | Steps: 2946 | Loss: 90.318853\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:09 | Steps: 2948 | Loss: 90.312655\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:09 | Steps: 2950 | Loss: 90.305812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:09 | Steps: 2952 | Loss: 90.304693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:09 | Steps: 2954 | Loss: 90.305337\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:09 | Steps: 2956 | Loss: 90.297147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:09 | Steps: 2958 | Loss: 90.292775\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:09 | Steps: 2960 | Loss: 90.301590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:10 | Steps: 2962 | Loss: 90.315013\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:10 | Steps: 2964 | Loss: 90.307298\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:10 | Steps: 2966 | Loss: 90.297030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:10 | Steps: 2968 | Loss: 90.286048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:10 | Steps: 2970 | Loss: 90.282845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:10 | Steps: 2972 | Loss: 90.288354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:11 | Steps: 2974 | Loss: 90.288008\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:11 | Steps: 2976 | Loss: 90.280694\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:11 | Steps: 2978 | Loss: 90.272683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:11 | Steps: 2979 | Loss: 90.264711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:11 | Steps: 2981 | Loss: 90.247366\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:11 | Steps: 2983 | Loss: 90.249082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:11 | Steps: 2985 | Loss: 90.253475\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:12 | Steps: 2987 | Loss: 90.248105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:12 | Steps: 2989 | Loss: 90.237811\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:12 | Steps: 2991 | Loss: 90.227714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:12 | Steps: 2993 | Loss: 90.223724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:12 | Steps: 2995 | Loss: 90.216513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:12 | Steps: 2997 | Loss: 90.200809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:12 | Steps: 2999 | Loss: 90.188408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:13 | Steps: 3001 | Loss: 90.204370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:13 | Steps: 3003 | Loss: 90.191655\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:13 | Steps: 3005 | Loss: 90.202424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:13 | Steps: 3007 | Loss: 90.196767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:13 | Steps: 3009 | Loss: 90.193036\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:13 | Steps: 3011 | Loss: 90.200768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:13 | Steps: 3013 | Loss: 90.200073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:14 | Steps: 3014 | Loss: 90.199687\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:14 | Steps: 3016 | Loss: 90.230762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:14 | Steps: 3018 | Loss: 90.218150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:14 | Steps: 3020 | Loss: 90.204945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:14 | Steps: 3022 | Loss: 90.200937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:14 | Steps: 3024 | Loss: 90.198082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:14 | Steps: 3026 | Loss: 90.192109\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:15 | Steps: 3028 | Loss: 90.196038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:15 | Steps: 3030 | Loss: 90.198007\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:15 | Steps: 3032 | Loss: 90.195600\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:15 | Steps: 3034 | Loss: 90.214635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:15 | Steps: 3036 | Loss: 90.218409\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:15 | Steps: 3038 | Loss: 90.207402\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:16 | Steps: 3040 | Loss: 90.244642\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:16 | Steps: 3042 | Loss: 90.245665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:16 | Steps: 3044 | Loss: 90.262969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:16 | Steps: 3046 | Loss: 90.270299\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:16 | Steps: 3048 | Loss: 90.277257\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:16 | Steps: 3050 | Loss: 90.275973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:16 | Steps: 3052 | Loss: 90.266967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:17 | Steps: 3054 | Loss: 90.262243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:17 | Steps: 3056 | Loss: 90.277239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:17 | Steps: 3058 | Loss: 90.271510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:17 | Steps: 3060 | Loss: 90.267781\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:17 | Steps: 3062 | Loss: 90.299679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:17 | Steps: 3064 | Loss: 90.288553\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:17 | Steps: 3066 | Loss: 90.288898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:18 | Steps: 3068 | Loss: 90.310050\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:18 | Steps: 3070 | Loss: 90.309888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:18 | Steps: 3072 | Loss: 90.302445\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:18 | Steps: 3074 | Loss: 90.299507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:18 | Steps: 3076 | Loss: 90.301220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:18 | Steps: 3078 | Loss: 90.299871\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:19 | Steps: 3080 | Loss: 90.293100\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:19 | Steps: 3082 | Loss: 90.283991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:19 | Steps: 3084 | Loss: 90.276085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:19 | Steps: 3086 | Loss: 90.265854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:19 | Steps: 3088 | Loss: 90.258000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:19 | Steps: 3090 | Loss: 90.256169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:19 | Steps: 3092 | Loss: 90.245294\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:20 | Steps: 3094 | Loss: 90.273268\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:20 | Steps: 3096 | Loss: 90.281220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:20 | Steps: 3098 | Loss: 90.282435\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:20 | Steps: 3100 | Loss: 90.284771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:20 | Steps: 3102 | Loss: 90.279368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:20 | Steps: 3104 | Loss: 90.283319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:21 | Steps: 3106 | Loss: 90.266885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:21 | Steps: 3108 | Loss: 90.246722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:21 | Steps: 3110 | Loss: 90.274848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:21 | Steps: 3112 | Loss: 90.267733\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:21 | Steps: 3113 | Loss: 90.264216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:21 | Steps: 3115 | Loss: 90.255625\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:21 | Steps: 3117 | Loss: 90.251113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:21 | Steps: 3119 | Loss: 90.251671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:22 | Steps: 3121 | Loss: 90.243919\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:22 | Steps: 3123 | Loss: 90.236158\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:22 | Steps: 3125 | Loss: 90.236220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:22 | Steps: 3127 | Loss: 90.235491\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:22 | Steps: 3129 | Loss: 90.241102\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:22 | Steps: 3130 | Loss: 90.243470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:22 | Steps: 3132 | Loss: 90.232595\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:23 | Steps: 3134 | Loss: 90.234640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:23 | Steps: 3135 | Loss: 90.228244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:23 | Steps: 3137 | Loss: 90.220156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:23 | Steps: 3139 | Loss: 90.211532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:23 | Steps: 3141 | Loss: 90.194379\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:23 | Steps: 3143 | Loss: 90.177765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:24 | Steps: 3145 | Loss: 90.174026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:24 | Steps: 3147 | Loss: 90.173656\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:24 | Steps: 3149 | Loss: 90.179219\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:24 | Steps: 3151 | Loss: 90.158692\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:24 | Steps: 3153 | Loss: 90.153247\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:24 | Steps: 3154 | Loss: 90.149231\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:24 | Steps: 3156 | Loss: 90.143306\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:25 | Steps: 3158 | Loss: 90.133539\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:25 | Steps: 3159 | Loss: 90.132422\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:25 | Steps: 3161 | Loss: 90.131562\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:25 | Steps: 3163 | Loss: 90.122521\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:25 | Steps: 3165 | Loss: 90.120591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:25 | Steps: 3167 | Loss: 90.133366\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:25 | Steps: 3169 | Loss: 90.130065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:26 | Steps: 3171 | Loss: 90.124323\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:26 | Steps: 3173 | Loss: 90.136427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:26 | Steps: 3175 | Loss: 90.134162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:26 | Steps: 3177 | Loss: 90.129786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:26 | Steps: 3179 | Loss: 90.122356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:26 | Steps: 3181 | Loss: 90.111342\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:26 | Steps: 3183 | Loss: 90.100018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:27 | Steps: 3185 | Loss: 90.108552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:27 | Steps: 3187 | Loss: 90.107035\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:27 | Steps: 3189 | Loss: 90.107802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:27 | Steps: 3191 | Loss: 90.120203\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:27 | Steps: 3193 | Loss: 90.112778\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:27 | Steps: 3195 | Loss: 90.113147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:28 | Steps: 3197 | Loss: 90.107180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:28 | Steps: 3199 | Loss: 90.109148\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:28 | Steps: 3200 | Loss: 90.112004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:28 | Steps: 3202 | Loss: 90.104549\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:28 | Steps: 3204 | Loss: 90.102813\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:28 | Steps: 3206 | Loss: 90.112332\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:28 | Steps: 3208 | Loss: 90.103392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:29 | Steps: 3210 | Loss: 90.110898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:29 | Steps: 3212 | Loss: 90.106970\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:29 | Steps: 3214 | Loss: 90.094796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:29 | Steps: 3216 | Loss: 90.100147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:29 | Steps: 3217 | Loss: 90.101211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:29 | Steps: 3219 | Loss: 90.097902\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:29 | Steps: 3220 | Loss: 90.098602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:29 | Steps: 3222 | Loss: 90.104639\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:30 | Steps: 3224 | Loss: 90.112721\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:30 | Steps: 3226 | Loss: 90.104408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:30 | Steps: 3228 | Loss: 90.112021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:30 | Steps: 3230 | Loss: 90.107279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:30 | Steps: 3232 | Loss: 90.111850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:30 | Steps: 3234 | Loss: 90.121488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:31 | Steps: 3235 | Loss: 90.124362\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:31 | Steps: 3237 | Loss: 90.133768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:31 | Steps: 3239 | Loss: 90.122660\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:31 | Steps: 3241 | Loss: 90.123051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:31 | Steps: 3243 | Loss: 90.126090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:31 | Steps: 3245 | Loss: 90.123906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:31 | Steps: 3247 | Loss: 90.120096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:32 | Steps: 3248 | Loss: 90.115463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:32 | Steps: 3250 | Loss: 90.110546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:32 | Steps: 3252 | Loss: 90.113408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:32 | Steps: 3254 | Loss: 90.102453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:32 | Steps: 3256 | Loss: 90.107630\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:32 | Steps: 3258 | Loss: 90.101958\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:32 | Steps: 3260 | Loss: 90.124927\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:33 | Steps: 3262 | Loss: 90.140523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:33 | Steps: 3264 | Loss: 90.156900\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:33 | Steps: 3266 | Loss: 90.172597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:33 | Steps: 3268 | Loss: 90.166957\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:33 | Steps: 3270 | Loss: 90.174312\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:33 | Steps: 3272 | Loss: 90.158806\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:33 | Steps: 3274 | Loss: 90.141282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:34 | Steps: 3276 | Loss: 90.154404\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:34 | Steps: 3278 | Loss: 90.156147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:34 | Steps: 3280 | Loss: 90.153990\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:34 | Steps: 3281 | Loss: 90.152257\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:34 | Steps: 3283 | Loss: 90.142646\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:34 | Steps: 3285 | Loss: 90.143987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:34 | Steps: 3287 | Loss: 90.134866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:35 | Steps: 3289 | Loss: 90.135260\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:35 | Steps: 3291 | Loss: 90.128030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:35 | Steps: 3293 | Loss: 90.121346\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:35 | Steps: 3295 | Loss: 90.118621\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:35 | Steps: 3297 | Loss: 90.131239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:35 | Steps: 3298 | Loss: 90.136293\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:35 | Steps: 3300 | Loss: 90.129459\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:36 | Steps: 3302 | Loss: 90.126140\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:36 | Steps: 3304 | Loss: 90.121743\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:36 | Steps: 3306 | Loss: 90.125478\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:36 | Steps: 3307 | Loss: 90.123819\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:36 | Steps: 3309 | Loss: 90.128156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:36 | Steps: 3311 | Loss: 90.131028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:36 | Steps: 3313 | Loss: 90.129016\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:37 | Steps: 3315 | Loss: 90.118001\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:37 | Steps: 3317 | Loss: 90.108254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:37 | Steps: 3319 | Loss: 90.100971\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:37 | Steps: 3320 | Loss: 90.104852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:37 | Steps: 3322 | Loss: 90.108480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:37 | Steps: 3324 | Loss: 90.109824\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:37 | Steps: 3325 | Loss: 90.099259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:38 | Steps: 3327 | Loss: 90.088100\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:38 | Steps: 3329 | Loss: 90.077825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:38 | Steps: 3331 | Loss: 90.069981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:38 | Steps: 3333 | Loss: 90.063413\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:38 | Steps: 3335 | Loss: 90.053124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:38 | Steps: 3337 | Loss: 90.054204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:39 | Steps: 3339 | Loss: 90.077331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:39 | Steps: 3341 | Loss: 90.111453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:39 | Steps: 3343 | Loss: 90.108230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:39 | Steps: 3345 | Loss: 90.118451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:39 | Steps: 3347 | Loss: 90.117171\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:39 | Steps: 3349 | Loss: 90.106941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:39 | Steps: 3351 | Loss: 90.101389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:40 | Steps: 3353 | Loss: 90.092774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:40 | Steps: 3355 | Loss: 90.084789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:40 | Steps: 3357 | Loss: 90.098386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:40 | Steps: 3359 | Loss: 90.089003\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:40 | Steps: 3361 | Loss: 90.082618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:40 | Steps: 3363 | Loss: 90.091790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:41 | Steps: 3365 | Loss: 90.088611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:41 | Steps: 3367 | Loss: 90.083916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:41 | Steps: 3369 | Loss: 90.090238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:41 | Steps: 3371 | Loss: 90.111960\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:41 | Steps: 3373 | Loss: 90.112885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:41 | Steps: 3374 | Loss: 90.112289\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:41 | Steps: 3376 | Loss: 90.106821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:42 | Steps: 3378 | Loss: 90.107128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:42 | Steps: 3380 | Loss: 90.115177\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:42 | Steps: 3382 | Loss: 90.108763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:42 | Steps: 3384 | Loss: 90.108389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:42 | Steps: 3386 | Loss: 90.115378\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:42 | Steps: 3388 | Loss: 90.118923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:42 | Steps: 3390 | Loss: 90.117835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:43 | Steps: 3392 | Loss: 90.116818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:43 | Steps: 3393 | Loss: 90.124017\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:43 | Steps: 3395 | Loss: 90.125405\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:43 | Steps: 3397 | Loss: 90.120190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:43 | Steps: 3399 | Loss: 90.138363\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:43 | Steps: 3401 | Loss: 90.130987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:44 | Steps: 3403 | Loss: 90.127428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:44 | Steps: 3405 | Loss: 90.122898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:44 | Steps: 3407 | Loss: 90.132744\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:44 | Steps: 3409 | Loss: 90.142985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:44 | Steps: 3411 | Loss: 90.133650\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:44 | Steps: 3413 | Loss: 90.138565\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:44 | Steps: 3415 | Loss: 90.141640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:45 | Steps: 3417 | Loss: 90.139676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:45 | Steps: 3419 | Loss: 90.132816\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:45 | Steps: 3421 | Loss: 90.128672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:45 | Steps: 3423 | Loss: 90.121430\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:45 | Steps: 3425 | Loss: 90.112463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:45 | Steps: 3427 | Loss: 90.100322\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:46 | Steps: 3429 | Loss: 90.119723\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:46 | Steps: 3431 | Loss: 90.142104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:46 | Steps: 3433 | Loss: 90.146464\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:46 | Steps: 3435 | Loss: 90.151908\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:46 | Steps: 3437 | Loss: 90.150750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:46 | Steps: 3439 | Loss: 90.149351\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:47 | Steps: 3441 | Loss: 90.121792\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:47 | Steps: 3443 | Loss: 90.109347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:47 | Steps: 3445 | Loss: 90.131308\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:47 | Steps: 3447 | Loss: 90.130597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:47 | Steps: 3449 | Loss: 90.120858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:47 | Steps: 3451 | Loss: 90.114164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:47 | Steps: 3452 | Loss: 90.115691\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:48 | Steps: 3454 | Loss: 90.106617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:48 | Steps: 3456 | Loss: 90.101486\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:48 | Steps: 3458 | Loss: 90.097872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:48 | Steps: 3460 | Loss: 90.089039\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:48 | Steps: 3462 | Loss: 90.084633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:48 | Steps: 3463 | Loss: 90.078657\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:48 | Steps: 3465 | Loss: 90.090025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:49 | Steps: 3467 | Loss: 90.081752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:49 | Steps: 3469 | Loss: 90.077985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:49 | Steps: 3471 | Loss: 90.071294\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:49 | Steps: 3473 | Loss: 90.067382\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:49 | Steps: 3475 | Loss: 90.060930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:49 | Steps: 3477 | Loss: 90.048990\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:49 | Steps: 3479 | Loss: 90.035403\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:50 | Steps: 3481 | Loss: 90.025691\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:50 | Steps: 3483 | Loss: 90.018120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:50 | Steps: 3485 | Loss: 90.019925\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:50 | Steps: 3487 | Loss: 90.018885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:50 | Steps: 3489 | Loss: 90.005209\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:50 | Steps: 3490 | Loss: 90.001905\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:51 | Steps: 3492 | Loss: 89.995875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:51 | Steps: 3494 | Loss: 89.986247\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:51 | Steps: 3496 | Loss: 89.983479\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:51 | Steps: 3498 | Loss: 89.973056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:51 | Steps: 3500 | Loss: 89.976307\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:51 | Steps: 3502 | Loss: 89.968151\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:51 | Steps: 3504 | Loss: 89.964343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:52 | Steps: 3506 | Loss: 89.976133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:52 | Steps: 3508 | Loss: 89.975057\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:52 | Steps: 3510 | Loss: 89.966542\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:52 | Steps: 3512 | Loss: 89.971865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:52 | Steps: 3514 | Loss: 89.964122\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:52 | Steps: 3516 | Loss: 89.953045\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:53 | Steps: 3518 | Loss: 89.953056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:53 | Steps: 3520 | Loss: 89.949526\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:53 | Steps: 3522 | Loss: 89.943333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:53 | Steps: 3524 | Loss: 89.933632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:53 | Steps: 3526 | Loss: 89.933362\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:53 | Steps: 3528 | Loss: 89.942014\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:53 | Steps: 3530 | Loss: 89.942991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:54 | Steps: 3532 | Loss: 89.933467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:54 | Steps: 3534 | Loss: 89.929213\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:54 | Steps: 3535 | Loss: 89.929190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:54 | Steps: 3537 | Loss: 89.934841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:54 | Steps: 3539 | Loss: 89.939080\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:54 | Steps: 3541 | Loss: 89.926906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:55 | Steps: 3543 | Loss: 89.932899\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:55 | Steps: 3545 | Loss: 89.922852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:55 | Steps: 3547 | Loss: 89.919065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:55 | Steps: 3549 | Loss: 89.915790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:55 | Steps: 3551 | Loss: 89.914665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:55 | Steps: 3553 | Loss: 89.917473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:55 | Steps: 3555 | Loss: 89.921447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:56 | Steps: 3557 | Loss: 89.922875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:56 | Steps: 3559 | Loss: 89.940294\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:56 | Steps: 3561 | Loss: 89.935387\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:56 | Steps: 3563 | Loss: 89.927027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:56 | Steps: 3565 | Loss: 89.931499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:56 | Steps: 3567 | Loss: 89.922046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:57 | Steps: 3569 | Loss: 89.916827\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:57 | Steps: 3571 | Loss: 89.909685\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:57 | Steps: 3573 | Loss: 89.899701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:57 | Steps: 3575 | Loss: 89.891742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:57 | Steps: 3577 | Loss: 89.886619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:57 | Steps: 3578 | Loss: 89.880851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:57 | Steps: 3580 | Loss: 89.874718\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:58 | Steps: 3582 | Loss: 89.874965\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:58 | Steps: 3583 | Loss: 89.873885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:58 | Steps: 3585 | Loss: 89.876842\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:58 | Steps: 3587 | Loss: 89.884785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:58 | Steps: 3589 | Loss: 89.900566\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:58 | Steps: 3591 | Loss: 89.911765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:59 | Steps: 3593 | Loss: 89.919453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:59 | Steps: 3595 | Loss: 89.914480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:59 | Steps: 3597 | Loss: 89.915553\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:59 | Steps: 3599 | Loss: 89.896072\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:59 | Steps: 3601 | Loss: 89.889073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:03:59 | Steps: 3603 | Loss: 89.903683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:00 | Steps: 3605 | Loss: 89.898849\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:00 | Steps: 3607 | Loss: 89.900234\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:00 | Steps: 3609 | Loss: 89.902359\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:00 | Steps: 3611 | Loss: 89.900950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:00 | Steps: 3613 | Loss: 89.900869\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:00 | Steps: 3615 | Loss: 89.894735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:00 | Steps: 3617 | Loss: 89.886315\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:01 | Steps: 3619 | Loss: 89.877959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:01 | Steps: 3621 | Loss: 89.877779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:01 | Steps: 3623 | Loss: 89.894193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:01 | Steps: 3625 | Loss: 89.896481\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:01 | Steps: 3627 | Loss: 89.895225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:01 | Steps: 3629 | Loss: 89.894405\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:02 | Steps: 3631 | Loss: 89.901384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:02 | Steps: 3633 | Loss: 89.898300\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:02 | Steps: 3635 | Loss: 89.905240\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:02 | Steps: 3637 | Loss: 89.892383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:02 | Steps: 3639 | Loss: 89.889789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:02 | Steps: 3641 | Loss: 89.887243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:03 | Steps: 3643 | Loss: 89.891076\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:03 | Steps: 3645 | Loss: 89.887053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:03 | Steps: 3647 | Loss: 89.896071\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:03 | Steps: 3649 | Loss: 89.883329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:03 | Steps: 3651 | Loss: 89.887825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:03 | Steps: 3653 | Loss: 89.886278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:03 | Steps: 3655 | Loss: 89.877921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:04 | Steps: 3657 | Loss: 89.870975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:04 | Steps: 3659 | Loss: 89.867769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:04 | Steps: 3661 | Loss: 89.868547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:04 | Steps: 3663 | Loss: 89.875427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:04 | Steps: 3665 | Loss: 89.871837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:04 | Steps: 3666 | Loss: 89.865996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:04 | Steps: 3668 | Loss: 89.863276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:05 | Steps: 3670 | Loss: 89.873410\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:05 | Steps: 3672 | Loss: 89.880457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:05 | Steps: 3674 | Loss: 89.883903\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:05 | Steps: 3676 | Loss: 89.881191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:05 | Steps: 3677 | Loss: 89.881993\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:05 | Steps: 3679 | Loss: 89.886668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:06 | Steps: 3681 | Loss: 89.883110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:06 | Steps: 3683 | Loss: 89.881679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:06 | Steps: 3685 | Loss: 89.871228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:06 | Steps: 3687 | Loss: 89.865525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:06 | Steps: 3689 | Loss: 89.856203\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:06 | Steps: 3691 | Loss: 89.851401\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:07 | Steps: 3693 | Loss: 89.849192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:07 | Steps: 3695 | Loss: 89.856777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:07 | Steps: 3697 | Loss: 89.870828\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:07 | Steps: 3699 | Loss: 89.879447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:07 | Steps: 3700 | Loss: 89.882803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:07 | Steps: 3702 | Loss: 89.883596\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:07 | Steps: 3704 | Loss: 89.879498\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:08 | Steps: 3706 | Loss: 89.876711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:08 | Steps: 3708 | Loss: 89.874388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:08 | Steps: 3710 | Loss: 89.879189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:08 | Steps: 3712 | Loss: 89.881031\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:08 | Steps: 3714 | Loss: 89.861701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:08 | Steps: 3716 | Loss: 89.874908\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:09 | Steps: 3718 | Loss: 89.863264\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:09 | Steps: 3720 | Loss: 89.858794\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:09 | Steps: 3722 | Loss: 89.859911\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:09 | Steps: 3724 | Loss: 89.860146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:09 | Steps: 3726 | Loss: 89.863714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:09 | Steps: 3728 | Loss: 89.862497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:10 | Steps: 3730 | Loss: 89.872343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:10 | Steps: 3732 | Loss: 89.866724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:10 | Steps: 3734 | Loss: 89.875523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:10 | Steps: 3735 | Loss: 89.877076\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:10 | Steps: 3737 | Loss: 89.883673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:10 | Steps: 3739 | Loss: 89.867304\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:10 | Steps: 3741 | Loss: 89.864809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:11 | Steps: 3743 | Loss: 89.853956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:11 | Steps: 3745 | Loss: 89.855487\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:11 | Steps: 3746 | Loss: 89.854206\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:11 | Steps: 3748 | Loss: 89.847116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:11 | Steps: 3750 | Loss: 89.841837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:11 | Steps: 3752 | Loss: 89.843467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:11 | Steps: 3754 | Loss: 89.844563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:12 | Steps: 3756 | Loss: 89.842737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:12 | Steps: 3758 | Loss: 89.846517\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:12 | Steps: 3760 | Loss: 89.850914\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:12 | Steps: 3762 | Loss: 89.848686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:12 | Steps: 3764 | Loss: 89.835631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:12 | Steps: 3766 | Loss: 89.831608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:13 | Steps: 3768 | Loss: 89.810942\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:13 | Steps: 3770 | Loss: 89.793203\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:13 | Steps: 3771 | Loss: 89.786974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:13 | Steps: 3773 | Loss: 89.799066\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:13 | Steps: 3775 | Loss: 89.793193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:13 | Steps: 3777 | Loss: 89.791803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:14 | Steps: 3779 | Loss: 89.792891\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:14 | Steps: 3781 | Loss: 89.792173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:14 | Steps: 3783 | Loss: 89.782845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:14 | Steps: 3785 | Loss: 89.779842\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:14 | Steps: 3786 | Loss: 89.780862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:14 | Steps: 3788 | Loss: 89.781541\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:14 | Steps: 3790 | Loss: 89.780338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:15 | Steps: 3792 | Loss: 89.803906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:15 | Steps: 3794 | Loss: 89.802321\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:15 | Steps: 3796 | Loss: 89.798032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:15 | Steps: 3798 | Loss: 89.789987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:15 | Steps: 3799 | Loss: 89.791164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:15 | Steps: 3801 | Loss: 89.798845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:15 | Steps: 3803 | Loss: 89.803548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:16 | Steps: 3805 | Loss: 89.806820\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:16 | Steps: 3807 | Loss: 89.815484\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:16 | Steps: 3808 | Loss: 89.816594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:16 | Steps: 3810 | Loss: 89.803870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:16 | Steps: 3812 | Loss: 89.795896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:16 | Steps: 3814 | Loss: 89.787309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:17 | Steps: 3816 | Loss: 89.786360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:17 | Steps: 3818 | Loss: 89.788172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:17 | Steps: 3820 | Loss: 89.779734\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:17 | Steps: 3822 | Loss: 89.771640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:17 | Steps: 3824 | Loss: 89.766316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:17 | Steps: 3826 | Loss: 89.762668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:17 | Steps: 3828 | Loss: 89.756997\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:18 | Steps: 3830 | Loss: 89.748056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:18 | Steps: 3832 | Loss: 89.738858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:18 | Steps: 3834 | Loss: 89.738360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:18 | Steps: 3836 | Loss: 89.742352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:18 | Steps: 3838 | Loss: 89.738197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:18 | Steps: 3840 | Loss: 89.766557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:19 | Steps: 3842 | Loss: 89.777064\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:19 | Steps: 3844 | Loss: 89.771863\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:19 | Steps: 3846 | Loss: 89.765585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:19 | Steps: 3848 | Loss: 89.769581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:19 | Steps: 3850 | Loss: 89.766763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:19 | Steps: 3852 | Loss: 89.757610\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:20 | Steps: 3854 | Loss: 89.753609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:20 | Steps: 3856 | Loss: 89.752060\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:20 | Steps: 3857 | Loss: 89.749228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:20 | Steps: 3859 | Loss: 89.750908\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:20 | Steps: 3861 | Loss: 89.760539\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:20 | Steps: 3863 | Loss: 89.760852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:20 | Steps: 3865 | Loss: 89.759678\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:21 | Steps: 3867 | Loss: 89.766197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:21 | Steps: 3868 | Loss: 89.778339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:21 | Steps: 3870 | Loss: 89.778745\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:21 | Steps: 3872 | Loss: 89.776133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:21 | Steps: 3874 | Loss: 89.772790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:21 | Steps: 3875 | Loss: 89.769279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:21 | Steps: 3877 | Loss: 89.787214\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:22 | Steps: 3879 | Loss: 89.787442\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:22 | Steps: 3881 | Loss: 89.803207\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:22 | Steps: 3883 | Loss: 89.809643\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:22 | Steps: 3885 | Loss: 89.800375\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:22 | Steps: 3886 | Loss: 89.812955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:22 | Steps: 3888 | Loss: 89.815824\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:23 | Steps: 3890 | Loss: 89.807750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:23 | Steps: 3892 | Loss: 89.809448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:23 | Steps: 3894 | Loss: 89.808402\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:23 | Steps: 3895 | Loss: 89.811204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:23 | Steps: 3897 | Loss: 89.814686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:23 | Steps: 3899 | Loss: 89.820594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:23 | Steps: 3901 | Loss: 89.816945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:24 | Steps: 3903 | Loss: 89.834600\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:24 | Steps: 3904 | Loss: 89.841873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:24 | Steps: 3906 | Loss: 89.839831\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:24 | Steps: 3908 | Loss: 89.838522\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:24 | Steps: 3910 | Loss: 89.833497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:24 | Steps: 3911 | Loss: 89.825286\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:24 | Steps: 3913 | Loss: 89.824500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:25 | Steps: 3915 | Loss: 89.834563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:25 | Steps: 3917 | Loss: 89.849443\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:25 | Steps: 3919 | Loss: 89.860133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:25 | Steps: 3921 | Loss: 89.851217\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:25 | Steps: 3923 | Loss: 89.843568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:25 | Steps: 3925 | Loss: 89.849974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:26 | Steps: 3927 | Loss: 89.843439\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:26 | Steps: 3929 | Loss: 89.837849\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:26 | Steps: 3931 | Loss: 89.825504\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:26 | Steps: 3933 | Loss: 89.828173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:26 | Steps: 3935 | Loss: 89.822687\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:26 | Steps: 3937 | Loss: 89.822150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:27 | Steps: 3939 | Loss: 89.827343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:27 | Steps: 3941 | Loss: 89.826769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:27 | Steps: 3943 | Loss: 89.833898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:27 | Steps: 3945 | Loss: 89.832550\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:27 | Steps: 3947 | Loss: 89.846310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:27 | Steps: 3948 | Loss: 89.849030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:28 | Steps: 3950 | Loss: 89.845830\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:28 | Steps: 3952 | Loss: 89.843871\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:28 | Steps: 3954 | Loss: 89.845362\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:28 | Steps: 3955 | Loss: 89.838080\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:28 | Steps: 3957 | Loss: 89.846941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:28 | Steps: 3959 | Loss: 89.864146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:28 | Steps: 3961 | Loss: 89.854814\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:29 | Steps: 3963 | Loss: 89.850612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:29 | Steps: 3965 | Loss: 89.848847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:29 | Steps: 3967 | Loss: 89.852062\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:29 | Steps: 3968 | Loss: 89.846999\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:29 | Steps: 3970 | Loss: 89.846512\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:29 | Steps: 3972 | Loss: 89.841566\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:29 | Steps: 3974 | Loss: 89.841488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:30 | Steps: 3976 | Loss: 89.838318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:30 | Steps: 3978 | Loss: 89.836591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:30 | Steps: 3980 | Loss: 89.843725\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:30 | Steps: 3982 | Loss: 89.856280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:30 | Steps: 3984 | Loss: 89.850881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:30 | Steps: 3986 | Loss: 89.846574\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:31 | Steps: 3988 | Loss: 89.851345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:31 | Steps: 3990 | Loss: 89.852358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:31 | Steps: 3991 | Loss: 89.857614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:31 | Steps: 3993 | Loss: 89.855089\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:31 | Steps: 3995 | Loss: 89.846327\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:31 | Steps: 3997 | Loss: 89.837720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:32 | Steps: 3999 | Loss: 89.827205\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:32 | Steps: 4001 | Loss: 89.841244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:32 | Steps: 4002 | Loss: 89.841674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:32 | Steps: 4004 | Loss: 89.836896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:32 | Steps: 4006 | Loss: 89.823956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:32 | Steps: 4008 | Loss: 89.819041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:32 | Steps: 4010 | Loss: 89.809051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:33 | Steps: 4012 | Loss: 89.813771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:33 | Steps: 4013 | Loss: 89.814482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:33 | Steps: 4015 | Loss: 89.809556\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:33 | Steps: 4016 | Loss: 89.807246\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:33 | Steps: 4018 | Loss: 89.805942\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:33 | Steps: 4020 | Loss: 89.815877\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:33 | Steps: 4022 | Loss: 89.807735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:34 | Steps: 4024 | Loss: 89.819686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:34 | Steps: 4026 | Loss: 89.836154\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:34 | Steps: 4028 | Loss: 89.832934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:34 | Steps: 4030 | Loss: 89.829469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:34 | Steps: 4032 | Loss: 89.835672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:34 | Steps: 4034 | Loss: 89.837405\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:35 | Steps: 4036 | Loss: 89.842938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:35 | Steps: 4038 | Loss: 89.841368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:35 | Steps: 4040 | Loss: 89.849349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:35 | Steps: 4042 | Loss: 89.839520\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:35 | Steps: 4044 | Loss: 89.836423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:35 | Steps: 4046 | Loss: 89.842615\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:36 | Steps: 4048 | Loss: 89.840973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:36 | Steps: 4050 | Loss: 89.853240\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:36 | Steps: 4052 | Loss: 89.860349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:36 | Steps: 4054 | Loss: 89.873424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:36 | Steps: 4056 | Loss: 89.869406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:36 | Steps: 4058 | Loss: 89.871383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:37 | Steps: 4060 | Loss: 89.869401\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:37 | Steps: 4061 | Loss: 89.868221\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:37 | Steps: 4063 | Loss: 89.870858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:37 | Steps: 4065 | Loss: 89.862662\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:37 | Steps: 4067 | Loss: 89.853171\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:38 | Steps: 4068 | Loss: 89.850612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:38 | Steps: 4070 | Loss: 89.843010\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:38 | Steps: 4072 | Loss: 89.844333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:38 | Steps: 4073 | Loss: 89.844053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:38 | Steps: 4075 | Loss: 89.839908\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:38 | Steps: 4077 | Loss: 89.843500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:39 | Steps: 4079 | Loss: 89.826679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:39 | Steps: 4081 | Loss: 89.836508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:39 | Steps: 4083 | Loss: 89.868605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:39 | Steps: 4085 | Loss: 89.863356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:39 | Steps: 4087 | Loss: 89.868554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:39 | Steps: 4089 | Loss: 89.875584\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:40 | Steps: 4091 | Loss: 89.872045\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:40 | Steps: 4093 | Loss: 89.862548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:40 | Steps: 4095 | Loss: 89.866788\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:40 | Steps: 4097 | Loss: 89.863423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:40 | Steps: 4099 | Loss: 89.859491\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:40 | Steps: 4101 | Loss: 89.849664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:41 | Steps: 4103 | Loss: 89.842690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:41 | Steps: 4105 | Loss: 89.842190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:41 | Steps: 4106 | Loss: 89.848012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:41 | Steps: 4108 | Loss: 89.864793\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:41 | Steps: 4110 | Loss: 89.885126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:41 | Steps: 4112 | Loss: 89.887293\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:41 | Steps: 4114 | Loss: 89.876469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:42 | Steps: 4116 | Loss: 89.877685\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:42 | Steps: 4117 | Loss: 89.881086\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:42 | Steps: 4119 | Loss: 89.881144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:42 | Steps: 4121 | Loss: 89.870854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:42 | Steps: 4123 | Loss: 89.872728\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:42 | Steps: 4125 | Loss: 89.888601\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:43 | Steps: 4127 | Loss: 89.887347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:43 | Steps: 4129 | Loss: 89.886000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:43 | Steps: 4131 | Loss: 89.885191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:43 | Steps: 4133 | Loss: 89.892280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:43 | Steps: 4135 | Loss: 89.883708\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:43 | Steps: 4137 | Loss: 89.872989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:44 | Steps: 4139 | Loss: 89.882727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:44 | Steps: 4140 | Loss: 89.888792\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:44 | Steps: 4142 | Loss: 89.893975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:44 | Steps: 4144 | Loss: 89.883877\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:44 | Steps: 4146 | Loss: 89.880965\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:44 | Steps: 4148 | Loss: 89.882643\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:44 | Steps: 4150 | Loss: 89.883503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:45 | Steps: 4152 | Loss: 89.882882\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:45 | Steps: 4154 | Loss: 89.875579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:45 | Steps: 4156 | Loss: 89.866691\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:45 | Steps: 4158 | Loss: 89.857598\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:45 | Steps: 4160 | Loss: 89.851582\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:45 | Steps: 4162 | Loss: 89.842018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:46 | Steps: 4164 | Loss: 89.842670\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:46 | Steps: 4165 | Loss: 89.844847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:46 | Steps: 4167 | Loss: 89.845477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:46 | Steps: 4169 | Loss: 89.852353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:46 | Steps: 4171 | Loss: 89.836753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:46 | Steps: 4173 | Loss: 89.832688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:47 | Steps: 4175 | Loss: 89.823042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:47 | Steps: 4177 | Loss: 89.816325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:47 | Steps: 4179 | Loss: 89.815477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:47 | Steps: 4181 | Loss: 89.815859\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:47 | Steps: 4182 | Loss: 89.820875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:47 | Steps: 4184 | Loss: 89.820633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:47 | Steps: 4186 | Loss: 89.823437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:48 | Steps: 4188 | Loss: 89.821634\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:48 | Steps: 4190 | Loss: 89.831059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:48 | Steps: 4192 | Loss: 89.834319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:48 | Steps: 4194 | Loss: 89.833640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:48 | Steps: 4196 | Loss: 89.838406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:48 | Steps: 4198 | Loss: 89.837091\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:49 | Steps: 4199 | Loss: 89.830057\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:49 | Steps: 4201 | Loss: 89.817840\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:49 | Steps: 4203 | Loss: 89.808456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:49 | Steps: 4205 | Loss: 89.804798\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:49 | Steps: 4207 | Loss: 89.807933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:49 | Steps: 4209 | Loss: 89.801120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:49 | Steps: 4210 | Loss: 89.803279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:50 | Steps: 4212 | Loss: 89.797839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:50 | Steps: 4214 | Loss: 89.794791\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:50 | Steps: 4216 | Loss: 89.790150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:50 | Steps: 4218 | Loss: 89.796888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:50 | Steps: 4220 | Loss: 89.803852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:50 | Steps: 4222 | Loss: 89.802557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:51 | Steps: 4224 | Loss: 89.800339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:51 | Steps: 4226 | Loss: 89.801798\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:51 | Steps: 4228 | Loss: 89.804049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:51 | Steps: 4230 | Loss: 89.815836\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:51 | Steps: 4232 | Loss: 89.812235\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:51 | Steps: 4234 | Loss: 89.806539\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:52 | Steps: 4236 | Loss: 89.798191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:52 | Steps: 4238 | Loss: 89.800269\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:52 | Steps: 4240 | Loss: 89.798997\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:52 | Steps: 4242 | Loss: 89.804253\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:52 | Steps: 4244 | Loss: 89.807854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:52 | Steps: 4246 | Loss: 89.809790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:53 | Steps: 4248 | Loss: 89.819842\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:53 | Steps: 4250 | Loss: 89.814532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:53 | Steps: 4252 | Loss: 89.812170\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:53 | Steps: 4254 | Loss: 89.803450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:53 | Steps: 4256 | Loss: 89.812235\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:53 | Steps: 4258 | Loss: 89.813695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:54 | Steps: 4260 | Loss: 89.824365\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:54 | Steps: 4262 | Loss: 89.837375\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:54 | Steps: 4264 | Loss: 89.826282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:54 | Steps: 4266 | Loss: 89.813699\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:54 | Steps: 4268 | Loss: 89.814875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:54 | Steps: 4270 | Loss: 89.817538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:55 | Steps: 4272 | Loss: 89.818034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:55 | Steps: 4274 | Loss: 89.819937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:55 | Steps: 4276 | Loss: 89.813473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:55 | Steps: 4278 | Loss: 89.811517\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:55 | Steps: 4280 | Loss: 89.810420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:55 | Steps: 4281 | Loss: 89.806689\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:56 | Steps: 4283 | Loss: 89.808281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:56 | Steps: 4285 | Loss: 89.807080\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:56 | Steps: 4287 | Loss: 89.805620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:56 | Steps: 4289 | Loss: 89.812392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:56 | Steps: 4291 | Loss: 89.807616\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:56 | Steps: 4293 | Loss: 89.827892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:57 | Steps: 4295 | Loss: 89.845901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:57 | Steps: 4297 | Loss: 89.852592\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:57 | Steps: 4298 | Loss: 89.860473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:57 | Steps: 4300 | Loss: 89.862876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:57 | Steps: 4302 | Loss: 89.870668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:57 | Steps: 4304 | Loss: 89.866554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:58 | Steps: 4306 | Loss: 89.869806\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:58 | Steps: 4308 | Loss: 89.856189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:58 | Steps: 4310 | Loss: 89.862204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:58 | Steps: 4312 | Loss: 89.866613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:58 | Steps: 4314 | Loss: 89.863397\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:58 | Steps: 4315 | Loss: 89.858421\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:58 | Steps: 4317 | Loss: 89.862118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:59 | Steps: 4318 | Loss: 89.865270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:59 | Steps: 4320 | Loss: 89.866099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:59 | Steps: 4322 | Loss: 89.855986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:59 | Steps: 4324 | Loss: 89.848779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:59 | Steps: 4326 | Loss: 89.842085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:04:59 | Steps: 4328 | Loss: 89.837205\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:00 | Steps: 4330 | Loss: 89.836913\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:00 | Steps: 4331 | Loss: 89.832155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:00 | Steps: 4333 | Loss: 89.832014\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:00 | Steps: 4335 | Loss: 89.830801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:00 | Steps: 4337 | Loss: 89.835075\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:00 | Steps: 4339 | Loss: 89.842975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:00 | Steps: 4340 | Loss: 89.841730\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:01 | Steps: 4342 | Loss: 89.840742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:01 | Steps: 4344 | Loss: 89.832370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:01 | Steps: 4346 | Loss: 89.827640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:01 | Steps: 4348 | Loss: 89.819916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:01 | Steps: 4349 | Loss: 89.815043\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:01 | Steps: 4351 | Loss: 89.823098\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:02 | Steps: 4353 | Loss: 89.829276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:02 | Steps: 4355 | Loss: 89.828950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:02 | Steps: 4356 | Loss: 89.824059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:02 | Steps: 4358 | Loss: 89.813197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:02 | Steps: 4360 | Loss: 89.813711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:02 | Steps: 4362 | Loss: 89.808632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:02 | Steps: 4364 | Loss: 89.794675\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:03 | Steps: 4366 | Loss: 89.789925\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:03 | Steps: 4368 | Loss: 89.786642\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:03 | Steps: 4370 | Loss: 89.784052\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:03 | Steps: 4372 | Loss: 89.783351\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:03 | Steps: 4374 | Loss: 89.784466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:03 | Steps: 4375 | Loss: 89.796775\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:04 | Steps: 4377 | Loss: 89.810646\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:04 | Steps: 4378 | Loss: 89.812158\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:04 | Steps: 4380 | Loss: 89.814110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:04 | Steps: 4382 | Loss: 89.817437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:04 | Steps: 4383 | Loss: 89.823101\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:04 | Steps: 4385 | Loss: 89.832103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:04 | Steps: 4387 | Loss: 89.826479\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:05 | Steps: 4388 | Loss: 89.827698\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:05 | Steps: 4389 | Loss: 89.821258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:05 | Steps: 4391 | Loss: 89.818358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:05 | Steps: 4393 | Loss: 89.815600\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:05 | Steps: 4395 | Loss: 89.808703\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:05 | Steps: 4396 | Loss: 89.808448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:05 | Steps: 4397 | Loss: 89.810559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:05 | Steps: 4399 | Loss: 89.815838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:06 | Steps: 4401 | Loss: 89.831934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:06 | Steps: 4403 | Loss: 89.836156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:06 | Steps: 4405 | Loss: 89.838318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:06 | Steps: 4407 | Loss: 89.839103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:06 | Steps: 4409 | Loss: 89.840044\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:06 | Steps: 4410 | Loss: 89.840889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:07 | Steps: 4412 | Loss: 89.856883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:07 | Steps: 4414 | Loss: 89.863802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:07 | Steps: 4416 | Loss: 89.866280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:07 | Steps: 4418 | Loss: 89.876451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:07 | Steps: 4420 | Loss: 89.862889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:07 | Steps: 4422 | Loss: 89.860199\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:08 | Steps: 4423 | Loss: 89.867836\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:08 | Steps: 4425 | Loss: 89.870753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:08 | Steps: 4427 | Loss: 89.865189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:08 | Steps: 4429 | Loss: 89.868603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:08 | Steps: 4431 | Loss: 89.875453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:08 | Steps: 4433 | Loss: 89.878847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:09 | Steps: 4435 | Loss: 89.883620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:09 | Steps: 4437 | Loss: 89.879785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:09 | Steps: 4439 | Loss: 89.867126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:09 | Steps: 4440 | Loss: 89.873538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:09 | Steps: 4442 | Loss: 89.874815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:09 | Steps: 4444 | Loss: 89.873485\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:10 | Steps: 4446 | Loss: 89.863931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:10 | Steps: 4447 | Loss: 89.864411\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:10 | Steps: 4449 | Loss: 89.855766\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:10 | Steps: 4451 | Loss: 89.855448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:10 | Steps: 4453 | Loss: 89.861967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:10 | Steps: 4454 | Loss: 89.857196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:10 | Steps: 4456 | Loss: 89.846897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:10 | Steps: 4457 | Loss: 89.845598\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:11 | Steps: 4459 | Loss: 89.845968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:11 | Steps: 4461 | Loss: 89.841102\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:11 | Steps: 4463 | Loss: 89.834578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:11 | Steps: 4464 | Loss: 89.835701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:11 | Steps: 4466 | Loss: 89.830561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:11 | Steps: 4468 | Loss: 89.832674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:12 | Steps: 4470 | Loss: 89.825827\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:12 | Steps: 4472 | Loss: 89.823628\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:12 | Steps: 4474 | Loss: 89.827929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:12 | Steps: 4476 | Loss: 89.829227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:12 | Steps: 4478 | Loss: 89.823032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:12 | Steps: 4480 | Loss: 89.829947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:13 | Steps: 4482 | Loss: 89.834295\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:13 | Steps: 4484 | Loss: 89.837957\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:13 | Steps: 4486 | Loss: 89.855895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:13 | Steps: 4488 | Loss: 89.859430\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:13 | Steps: 4490 | Loss: 89.851652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:13 | Steps: 4492 | Loss: 89.848774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:14 | Steps: 4494 | Loss: 89.833239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:14 | Steps: 4496 | Loss: 89.833571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:14 | Steps: 4498 | Loss: 89.833360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:14 | Steps: 4500 | Loss: 89.826722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:14 | Steps: 4502 | Loss: 89.829150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:14 | Steps: 4504 | Loss: 89.824367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:15 | Steps: 4506 | Loss: 89.820204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:15 | Steps: 4507 | Loss: 89.815203\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:15 | Steps: 4509 | Loss: 89.814524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:15 | Steps: 4511 | Loss: 89.818169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:15 | Steps: 4513 | Loss: 89.816426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:15 | Steps: 4514 | Loss: 89.815313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:16 | Steps: 4516 | Loss: 89.812624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:16 | Steps: 4518 | Loss: 89.807779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:16 | Steps: 4520 | Loss: 89.820755\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:16 | Steps: 4522 | Loss: 89.818440\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:16 | Steps: 4524 | Loss: 89.817197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:16 | Steps: 4526 | Loss: 89.810882\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:16 | Steps: 4527 | Loss: 89.811184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:17 | Steps: 4529 | Loss: 89.806637\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:17 | Steps: 4530 | Loss: 89.808571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:17 | Steps: 4532 | Loss: 89.803604\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:17 | Steps: 4534 | Loss: 89.813249\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:17 | Steps: 4536 | Loss: 89.810493\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:17 | Steps: 4538 | Loss: 89.800431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:18 | Steps: 4539 | Loss: 89.798910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:18 | Steps: 4541 | Loss: 89.796878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:18 | Steps: 4543 | Loss: 89.800564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:18 | Steps: 4545 | Loss: 89.808963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:18 | Steps: 4547 | Loss: 89.808073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:18 | Steps: 4549 | Loss: 89.800673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:19 | Steps: 4551 | Loss: 89.795985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:19 | Steps: 4553 | Loss: 89.790823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:19 | Steps: 4555 | Loss: 89.782862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:19 | Steps: 4556 | Loss: 89.780354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:19 | Steps: 4558 | Loss: 89.776516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:19 | Steps: 4559 | Loss: 89.775305\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:19 | Steps: 4561 | Loss: 89.779037\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:20 | Steps: 4563 | Loss: 89.768485\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:20 | Steps: 4565 | Loss: 89.771008\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:20 | Steps: 4566 | Loss: 89.767834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:20 | Steps: 4568 | Loss: 89.777279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:20 | Steps: 4570 | Loss: 89.771231\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:20 | Steps: 4572 | Loss: 89.768363\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:21 | Steps: 4574 | Loss: 89.778126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:21 | Steps: 4576 | Loss: 89.777730\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:21 | Steps: 4578 | Loss: 89.782465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:21 | Steps: 4580 | Loss: 89.801237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:21 | Steps: 4581 | Loss: 89.798895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:21 | Steps: 4583 | Loss: 89.789613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:21 | Steps: 4584 | Loss: 89.784302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:22 | Steps: 4586 | Loss: 89.784446\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:22 | Steps: 4588 | Loss: 89.784389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:22 | Steps: 4590 | Loss: 89.780733\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:22 | Steps: 4591 | Loss: 89.783929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:22 | Steps: 4593 | Loss: 89.785647\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:22 | Steps: 4594 | Loss: 89.792359\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:22 | Steps: 4596 | Loss: 89.788198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:23 | Steps: 4598 | Loss: 89.796120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:23 | Steps: 4599 | Loss: 89.795126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:23 | Steps: 4601 | Loss: 89.799271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:23 | Steps: 4603 | Loss: 89.795768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:23 | Steps: 4605 | Loss: 89.802826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:23 | Steps: 4607 | Loss: 89.806717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:24 | Steps: 4609 | Loss: 89.813054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:24 | Steps: 4611 | Loss: 89.812796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:24 | Steps: 4613 | Loss: 89.820468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:24 | Steps: 4614 | Loss: 89.818731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:24 | Steps: 4616 | Loss: 89.812048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:24 | Steps: 4618 | Loss: 89.808750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:25 | Steps: 4620 | Loss: 89.818343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:25 | Steps: 4622 | Loss: 89.827958\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:25 | Steps: 4624 | Loss: 89.834742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:25 | Steps: 4625 | Loss: 89.837633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:25 | Steps: 4627 | Loss: 89.840605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:25 | Steps: 4629 | Loss: 89.838760\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:26 | Steps: 4631 | Loss: 89.834158\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:26 | Steps: 4633 | Loss: 89.851516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:26 | Steps: 4634 | Loss: 89.850077\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:26 | Steps: 4636 | Loss: 89.849134\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:26 | Steps: 4637 | Loss: 89.844511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:26 | Steps: 4639 | Loss: 89.843387\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:27 | Steps: 4641 | Loss: 89.841592\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:27 | Steps: 4643 | Loss: 89.833894\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:27 | Steps: 4645 | Loss: 89.834887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:27 | Steps: 4647 | Loss: 89.831154\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:27 | Steps: 4649 | Loss: 89.825254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:27 | Steps: 4651 | Loss: 89.824291\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:28 | Steps: 4653 | Loss: 89.821668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:28 | Steps: 4655 | Loss: 89.816589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:28 | Steps: 4656 | Loss: 89.812602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:28 | Steps: 4658 | Loss: 89.816892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:28 | Steps: 4660 | Loss: 89.815385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:28 | Steps: 4662 | Loss: 89.822559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:28 | Steps: 4663 | Loss: 89.829655\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:29 | Steps: 4665 | Loss: 89.843617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:29 | Steps: 4667 | Loss: 89.843063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:29 | Steps: 4669 | Loss: 89.853729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:29 | Steps: 4670 | Loss: 89.862870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:29 | Steps: 4672 | Loss: 89.864935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:29 | Steps: 4674 | Loss: 89.861124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:30 | Steps: 4676 | Loss: 89.847363\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:30 | Steps: 4678 | Loss: 89.843450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:30 | Steps: 4679 | Loss: 89.838885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:30 | Steps: 4681 | Loss: 89.839865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:30 | Steps: 4683 | Loss: 89.839804\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:30 | Steps: 4685 | Loss: 89.837969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:30 | Steps: 4687 | Loss: 89.837139\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:31 | Steps: 4689 | Loss: 89.832815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:31 | Steps: 4691 | Loss: 89.826640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:31 | Steps: 4693 | Loss: 89.822830\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:31 | Steps: 4694 | Loss: 89.817670\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:31 | Steps: 4696 | Loss: 89.818963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:31 | Steps: 4698 | Loss: 89.831749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:32 | Steps: 4700 | Loss: 89.831585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:32 | Steps: 4701 | Loss: 89.829474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:32 | Steps: 4703 | Loss: 89.822595\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:32 | Steps: 4705 | Loss: 89.823990\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:32 | Steps: 4707 | Loss: 89.828096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:32 | Steps: 4709 | Loss: 89.834178\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:33 | Steps: 4711 | Loss: 89.832056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:33 | Steps: 4713 | Loss: 89.833059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:33 | Steps: 4715 | Loss: 89.836812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:33 | Steps: 4717 | Loss: 89.831038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:33 | Steps: 4719 | Loss: 89.824276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:33 | Steps: 4721 | Loss: 89.817766\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:34 | Steps: 4723 | Loss: 89.807810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:34 | Steps: 4725 | Loss: 89.805950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:34 | Steps: 4727 | Loss: 89.814641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:34 | Steps: 4729 | Loss: 89.814510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:34 | Steps: 4730 | Loss: 89.810260\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:34 | Steps: 4732 | Loss: 89.806697\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:34 | Steps: 4733 | Loss: 89.804583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:35 | Steps: 4735 | Loss: 89.801375\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:35 | Steps: 4737 | Loss: 89.794564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:35 | Steps: 4739 | Loss: 89.785054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:35 | Steps: 4741 | Loss: 89.782978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:35 | Steps: 4743 | Loss: 89.780680\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:35 | Steps: 4745 | Loss: 89.782584\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:36 | Steps: 4747 | Loss: 89.780681\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:36 | Steps: 4749 | Loss: 89.782185\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:36 | Steps: 4751 | Loss: 89.788736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:36 | Steps: 4753 | Loss: 89.787003\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:36 | Steps: 4755 | Loss: 89.783462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:37 | Steps: 4757 | Loss: 89.792343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:37 | Steps: 4759 | Loss: 89.784975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:37 | Steps: 4760 | Loss: 89.785531\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:37 | Steps: 4762 | Loss: 89.788533\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:37 | Steps: 4764 | Loss: 89.786371\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:37 | Steps: 4766 | Loss: 89.787133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:38 | Steps: 4768 | Loss: 89.785303\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:38 | Steps: 4770 | Loss: 89.781931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:38 | Steps: 4772 | Loss: 89.783954\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:38 | Steps: 4774 | Loss: 89.787450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:38 | Steps: 4775 | Loss: 89.788280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:38 | Steps: 4777 | Loss: 89.805469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:39 | Steps: 4779 | Loss: 89.805560\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:39 | Steps: 4781 | Loss: 89.806640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:39 | Steps: 4783 | Loss: 89.809054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:39 | Steps: 4784 | Loss: 89.809805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:39 | Steps: 4786 | Loss: 89.810511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:39 | Steps: 4788 | Loss: 89.815591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:39 | Steps: 4790 | Loss: 89.808354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:40 | Steps: 4791 | Loss: 89.809432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:40 | Steps: 4793 | Loss: 89.814178\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:40 | Steps: 4795 | Loss: 89.813724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:40 | Steps: 4797 | Loss: 89.820409\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:40 | Steps: 4799 | Loss: 89.831854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:40 | Steps: 4801 | Loss: 89.835521\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:41 | Steps: 4802 | Loss: 89.830056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:41 | Steps: 4804 | Loss: 89.841172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:41 | Steps: 4806 | Loss: 89.843567\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:41 | Steps: 4808 | Loss: 89.832778\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:41 | Steps: 4810 | Loss: 89.833190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:41 | Steps: 4812 | Loss: 89.824410\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:42 | Steps: 4814 | Loss: 89.817645\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:42 | Steps: 4816 | Loss: 89.818709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:42 | Steps: 4818 | Loss: 89.812936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:42 | Steps: 4820 | Loss: 89.811618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:42 | Steps: 4821 | Loss: 89.808771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:42 | Steps: 4823 | Loss: 89.808187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:42 | Steps: 4824 | Loss: 89.807780\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:43 | Steps: 4826 | Loss: 89.805278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:43 | Steps: 4828 | Loss: 89.802211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:43 | Steps: 4830 | Loss: 89.798040\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:43 | Steps: 4832 | Loss: 89.796822\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:43 | Steps: 4834 | Loss: 89.799104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:43 | Steps: 4836 | Loss: 89.807393\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:44 | Steps: 4838 | Loss: 89.817245\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:44 | Steps: 4840 | Loss: 89.832502\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:44 | Steps: 4842 | Loss: 89.837432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:44 | Steps: 4844 | Loss: 89.836779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:44 | Steps: 4846 | Loss: 89.827862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:44 | Steps: 4848 | Loss: 89.816118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:45 | Steps: 4850 | Loss: 89.809581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:45 | Steps: 4852 | Loss: 89.811918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:45 | Steps: 4854 | Loss: 89.811313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:45 | Steps: 4856 | Loss: 89.805464\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:45 | Steps: 4858 | Loss: 89.798182\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:46 | Steps: 4860 | Loss: 89.794254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:46 | Steps: 4862 | Loss: 89.791962\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:46 | Steps: 4864 | Loss: 89.791780\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:46 | Steps: 4866 | Loss: 89.789463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:46 | Steps: 4867 | Loss: 89.793131\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:46 | Steps: 4869 | Loss: 89.801702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:47 | Steps: 4871 | Loss: 89.801866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:47 | Steps: 4873 | Loss: 89.805587\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:47 | Steps: 4874 | Loss: 89.807797\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:47 | Steps: 4876 | Loss: 89.821736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:47 | Steps: 4878 | Loss: 89.823317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:47 | Steps: 4880 | Loss: 89.817719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:48 | Steps: 4882 | Loss: 89.809496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:48 | Steps: 4884 | Loss: 89.811932\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:48 | Steps: 4886 | Loss: 89.814741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:48 | Steps: 4888 | Loss: 89.823334\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:48 | Steps: 4890 | Loss: 89.825201\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:48 | Steps: 4892 | Loss: 89.817831\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:49 | Steps: 4894 | Loss: 89.813588\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:49 | Steps: 4896 | Loss: 89.806486\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:49 | Steps: 4898 | Loss: 89.804443\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:49 | Steps: 4900 | Loss: 89.800006\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:49 | Steps: 4901 | Loss: 89.795968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:49 | Steps: 4903 | Loss: 89.790385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:50 | Steps: 4905 | Loss: 89.793643\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:50 | Steps: 4907 | Loss: 89.793185\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:50 | Steps: 4908 | Loss: 89.799062\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:50 | Steps: 4910 | Loss: 89.810898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:50 | Steps: 4912 | Loss: 89.821186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:50 | Steps: 4914 | Loss: 89.823768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:51 | Steps: 4916 | Loss: 89.821790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:51 | Steps: 4918 | Loss: 89.827901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:51 | Steps: 4920 | Loss: 89.823312\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:51 | Steps: 4922 | Loss: 89.816941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:51 | Steps: 4924 | Loss: 89.822360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:51 | Steps: 4926 | Loss: 89.824605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:52 | Steps: 4928 | Loss: 89.816836\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:52 | Steps: 4930 | Loss: 89.822781\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:52 | Steps: 4931 | Loss: 89.827353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:52 | Steps: 4933 | Loss: 89.822083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:52 | Steps: 4935 | Loss: 89.833087\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:52 | Steps: 4937 | Loss: 89.832223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:53 | Steps: 4938 | Loss: 89.837224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:53 | Steps: 4940 | Loss: 89.838451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:53 | Steps: 4941 | Loss: 89.838497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:53 | Steps: 4943 | Loss: 89.833556\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:53 | Steps: 4945 | Loss: 89.829020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:53 | Steps: 4947 | Loss: 89.829742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:53 | Steps: 4948 | Loss: 89.833828\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:54 | Steps: 4950 | Loss: 89.824481\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:54 | Steps: 4951 | Loss: 89.821685\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:54 | Steps: 4953 | Loss: 89.824822\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:54 | Steps: 4955 | Loss: 89.824767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:54 | Steps: 4956 | Loss: 89.824469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:54 | Steps: 4958 | Loss: 89.830617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:55 | Steps: 4960 | Loss: 89.843145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:55 | Steps: 4962 | Loss: 89.831627\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:55 | Steps: 4964 | Loss: 89.836727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:55 | Steps: 4966 | Loss: 89.837025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:55 | Steps: 4968 | Loss: 89.830222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:55 | Steps: 4970 | Loss: 89.837083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:56 | Steps: 4971 | Loss: 89.831425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:56 | Steps: 4973 | Loss: 89.842857\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:56 | Steps: 4975 | Loss: 89.841114\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:56 | Steps: 4977 | Loss: 89.848389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:56 | Steps: 4978 | Loss: 89.852263\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:56 | Steps: 4980 | Loss: 89.848247\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:56 | Steps: 4982 | Loss: 89.845303\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:57 | Steps: 4984 | Loss: 89.849087\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:57 | Steps: 4986 | Loss: 89.845412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:57 | Steps: 4987 | Loss: 89.841552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:57 | Steps: 4989 | Loss: 89.838391\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:58 | Steps: 4991 | Loss: 89.842727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:58 | Steps: 4992 | Loss: 89.842156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:58 | Steps: 4994 | Loss: 89.845829\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:58 | Steps: 4996 | Loss: 89.847714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:58 | Steps: 4997 | Loss: 89.847675\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:58 | Steps: 4999 | Loss: 89.863910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:58 | Steps: 5001 | Loss: 89.867496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:59 | Steps: 5003 | Loss: 89.863505\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:59 | Steps: 5004 | Loss: 89.860296\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:59 | Steps: 5006 | Loss: 89.861297\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:59 | Steps: 5008 | Loss: 89.847665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:59 | Steps: 5010 | Loss: 89.841199\n",
      "Epoch 0 |   Training | Elapsed Time: 0:05:59 | Steps: 5012 | Loss: 89.843971\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:00 | Steps: 5014 | Loss: 89.841528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:00 | Steps: 5016 | Loss: 89.838848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:00 | Steps: 5018 | Loss: 89.838357\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:00 | Steps: 5020 | Loss: 89.837660\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:00 | Steps: 5022 | Loss: 89.837290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:00 | Steps: 5024 | Loss: 89.844015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:01 | Steps: 5026 | Loss: 89.839993\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:01 | Steps: 5028 | Loss: 89.840572\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:01 | Steps: 5030 | Loss: 89.839591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:01 | Steps: 5031 | Loss: 89.833312\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:01 | Steps: 5033 | Loss: 89.842641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:01 | Steps: 5035 | Loss: 89.842602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:02 | Steps: 5037 | Loss: 89.847754\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:02 | Steps: 5039 | Loss: 89.843361\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:02 | Steps: 5040 | Loss: 89.843290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:02 | Steps: 5042 | Loss: 89.840845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:02 | Steps: 5044 | Loss: 89.845638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:02 | Steps: 5046 | Loss: 89.847842\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:03 | Steps: 5048 | Loss: 89.850224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:03 | Steps: 5050 | Loss: 89.843456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:03 | Steps: 5052 | Loss: 89.839732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:03 | Steps: 5054 | Loss: 89.833619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:03 | Steps: 5055 | Loss: 89.827800\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:03 | Steps: 5057 | Loss: 89.828332\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:04 | Steps: 5059 | Loss: 89.825566\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:04 | Steps: 5061 | Loss: 89.814036\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:04 | Steps: 5062 | Loss: 89.808242\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:04 | Steps: 5064 | Loss: 89.802615\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:04 | Steps: 5066 | Loss: 89.793452\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:04 | Steps: 5067 | Loss: 89.788973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:04 | Steps: 5069 | Loss: 89.783416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:05 | Steps: 5071 | Loss: 89.777724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:05 | Steps: 5072 | Loss: 89.774987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:05 | Steps: 5074 | Loss: 89.770873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:05 | Steps: 5076 | Loss: 89.772705\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:05 | Steps: 5078 | Loss: 89.764530\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:06 | Steps: 5080 | Loss: 89.773001\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:06 | Steps: 5082 | Loss: 89.770704\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:06 | Steps: 5084 | Loss: 89.782047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:06 | Steps: 5086 | Loss: 89.792222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:06 | Steps: 5088 | Loss: 89.790573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:06 | Steps: 5090 | Loss: 89.787431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:07 | Steps: 5092 | Loss: 89.788208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:07 | Steps: 5094 | Loss: 89.792773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:07 | Steps: 5095 | Loss: 89.787892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:07 | Steps: 5097 | Loss: 89.785420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:07 | Steps: 5099 | Loss: 89.783727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:07 | Steps: 5101 | Loss: 89.778780\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:08 | Steps: 5103 | Loss: 89.788953\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:08 | Steps: 5105 | Loss: 89.795366\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:08 | Steps: 5107 | Loss: 89.798931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:08 | Steps: 5109 | Loss: 89.802900\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:08 | Steps: 5110 | Loss: 89.803990\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:08 | Steps: 5112 | Loss: 89.803866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:09 | Steps: 5114 | Loss: 89.804352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:09 | Steps: 5115 | Loss: 89.807741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:09 | Steps: 5117 | Loss: 89.809294\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:09 | Steps: 5119 | Loss: 89.811302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:09 | Steps: 5121 | Loss: 89.803108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:09 | Steps: 5123 | Loss: 89.798698\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:10 | Steps: 5124 | Loss: 89.796332\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:10 | Steps: 5126 | Loss: 89.789524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:10 | Steps: 5128 | Loss: 89.784234\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:10 | Steps: 5130 | Loss: 89.788089\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:10 | Steps: 5132 | Loss: 89.791552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:10 | Steps: 5134 | Loss: 89.797189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:11 | Steps: 5136 | Loss: 89.807983\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:11 | Steps: 5138 | Loss: 89.809614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:11 | Steps: 5140 | Loss: 89.801705\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:11 | Steps: 5142 | Loss: 89.811763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:11 | Steps: 5143 | Loss: 89.813390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:11 | Steps: 5145 | Loss: 89.809679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:12 | Steps: 5147 | Loss: 89.804410\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:12 | Steps: 5149 | Loss: 89.797768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:12 | Steps: 5150 | Loss: 89.802280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:12 | Steps: 5152 | Loss: 89.811891\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:12 | Steps: 5154 | Loss: 89.815918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:12 | Steps: 5156 | Loss: 89.820065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:13 | Steps: 5158 | Loss: 89.814026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:13 | Steps: 5160 | Loss: 89.803852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:13 | Steps: 5162 | Loss: 89.801763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:13 | Steps: 5164 | Loss: 89.800490\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:13 | Steps: 5166 | Loss: 89.802633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:13 | Steps: 5168 | Loss: 89.804012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:14 | Steps: 5169 | Loss: 89.804794\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:14 | Steps: 5171 | Loss: 89.811124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:14 | Steps: 5173 | Loss: 89.807852\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:14 | Steps: 5174 | Loss: 89.807996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:14 | Steps: 5176 | Loss: 89.807768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:14 | Steps: 5178 | Loss: 89.808356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:15 | Steps: 5180 | Loss: 89.806022\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:15 | Steps: 5182 | Loss: 89.813699\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:15 | Steps: 5184 | Loss: 89.807998\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:15 | Steps: 5186 | Loss: 89.821256\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:15 | Steps: 5188 | Loss: 89.824547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:15 | Steps: 5190 | Loss: 89.821184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:16 | Steps: 5191 | Loss: 89.823275\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:16 | Steps: 5193 | Loss: 89.826695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:16 | Steps: 5195 | Loss: 89.812753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:16 | Steps: 5196 | Loss: 89.807624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:16 | Steps: 5198 | Loss: 89.817349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:16 | Steps: 5200 | Loss: 89.809639\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:17 | Steps: 5201 | Loss: 89.807190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:17 | Steps: 5203 | Loss: 89.809089\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:17 | Steps: 5205 | Loss: 89.815212\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:17 | Steps: 5206 | Loss: 89.811124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:17 | Steps: 5208 | Loss: 89.805956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:17 | Steps: 5210 | Loss: 89.807302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:18 | Steps: 5212 | Loss: 89.810377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:18 | Steps: 5214 | Loss: 89.807837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:18 | Steps: 5216 | Loss: 89.805293\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:18 | Steps: 5218 | Loss: 89.801836\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:18 | Steps: 5220 | Loss: 89.812755\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:18 | Steps: 5221 | Loss: 89.805980\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:18 | Steps: 5223 | Loss: 89.805079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:19 | Steps: 5224 | Loss: 89.802552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:19 | Steps: 5226 | Loss: 89.799074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:19 | Steps: 5228 | Loss: 89.803648\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:19 | Steps: 5229 | Loss: 89.809418\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:19 | Steps: 5231 | Loss: 89.812901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:19 | Steps: 5233 | Loss: 89.804708\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:20 | Steps: 5235 | Loss: 89.798665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:20 | Steps: 5237 | Loss: 89.791298\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:20 | Steps: 5239 | Loss: 89.783548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:20 | Steps: 5241 | Loss: 89.792496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:20 | Steps: 5243 | Loss: 89.798959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:20 | Steps: 5245 | Loss: 89.797747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:21 | Steps: 5247 | Loss: 89.787310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:21 | Steps: 5248 | Loss: 89.786568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:21 | Steps: 5250 | Loss: 89.781124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:21 | Steps: 5251 | Loss: 89.779391\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:21 | Steps: 5252 | Loss: 89.777331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:21 | Steps: 5254 | Loss: 89.775228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:21 | Steps: 5256 | Loss: 89.768556\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:22 | Steps: 5258 | Loss: 89.765808\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:22 | Steps: 5260 | Loss: 89.770805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:22 | Steps: 5261 | Loss: 89.769907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:22 | Steps: 5263 | Loss: 89.782817\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:22 | Steps: 5265 | Loss: 89.781706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:22 | Steps: 5267 | Loss: 89.776833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:23 | Steps: 5269 | Loss: 89.772744\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:23 | Steps: 5270 | Loss: 89.772225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:23 | Steps: 5272 | Loss: 89.770984\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:23 | Steps: 5273 | Loss: 89.774147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:23 | Steps: 5275 | Loss: 89.773566\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:23 | Steps: 5277 | Loss: 89.779394\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:24 | Steps: 5278 | Loss: 89.785181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:24 | Steps: 5280 | Loss: 89.781445\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:24 | Steps: 5282 | Loss: 89.777138\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:24 | Steps: 5284 | Loss: 89.776747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:24 | Steps: 5285 | Loss: 89.780582\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:24 | Steps: 5286 | Loss: 89.781155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:25 | Steps: 5287 | Loss: 89.778907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:25 | Steps: 5289 | Loss: 89.776425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:25 | Steps: 5291 | Loss: 89.774922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:25 | Steps: 5293 | Loss: 89.778254\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:25 | Steps: 5295 | Loss: 89.784814\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:25 | Steps: 5297 | Loss: 89.792201\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:26 | Steps: 5299 | Loss: 89.794426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:26 | Steps: 5301 | Loss: 89.796721\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:26 | Steps: 5303 | Loss: 89.803803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:26 | Steps: 5305 | Loss: 89.802034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:26 | Steps: 5306 | Loss: 89.809293\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:26 | Steps: 5308 | Loss: 89.807637\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:27 | Steps: 5310 | Loss: 89.803330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:27 | Steps: 5311 | Loss: 89.804477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:27 | Steps: 5313 | Loss: 89.802441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:27 | Steps: 5315 | Loss: 89.800350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:27 | Steps: 5316 | Loss: 89.802380\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:27 | Steps: 5317 | Loss: 89.805718\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:28 | Steps: 5319 | Loss: 89.809480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:28 | Steps: 5321 | Loss: 89.814870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:28 | Steps: 5323 | Loss: 89.818813\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:28 | Steps: 5325 | Loss: 89.816617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:28 | Steps: 5327 | Loss: 89.814073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:28 | Steps: 5329 | Loss: 89.812378\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:29 | Steps: 5331 | Loss: 89.810687\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:29 | Steps: 5333 | Loss: 89.810709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:29 | Steps: 5334 | Loss: 89.809444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:29 | Steps: 5335 | Loss: 89.808317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:29 | Steps: 5337 | Loss: 89.806790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:29 | Steps: 5339 | Loss: 89.807834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:29 | Steps: 5340 | Loss: 89.806239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:30 | Steps: 5341 | Loss: 89.802796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:30 | Steps: 5343 | Loss: 89.805576\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:30 | Steps: 5345 | Loss: 89.802043\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:30 | Steps: 5346 | Loss: 89.799988\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:30 | Steps: 5348 | Loss: 89.795612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:30 | Steps: 5349 | Loss: 89.795080\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:31 | Steps: 5351 | Loss: 89.797399\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:31 | Steps: 5353 | Loss: 89.802068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:31 | Steps: 5355 | Loss: 89.797544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:31 | Steps: 5357 | Loss: 89.812871\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:31 | Steps: 5359 | Loss: 89.816929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:31 | Steps: 5361 | Loss: 89.825104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:32 | Steps: 5362 | Loss: 89.825576\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:32 | Steps: 5363 | Loss: 89.823695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:32 | Steps: 5365 | Loss: 89.821518\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:32 | Steps: 5366 | Loss: 89.818617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:32 | Steps: 5368 | Loss: 89.821435\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:32 | Steps: 5369 | Loss: 89.815624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:32 | Steps: 5371 | Loss: 89.808744\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:33 | Steps: 5373 | Loss: 89.804362\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:33 | Steps: 5374 | Loss: 89.818456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:33 | Steps: 5375 | Loss: 89.814374\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:33 | Steps: 5376 | Loss: 89.815884\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:33 | Steps: 5378 | Loss: 89.816060\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:33 | Steps: 5380 | Loss: 89.816994\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:33 | Steps: 5382 | Loss: 89.813297\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:34 | Steps: 5384 | Loss: 89.815047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:34 | Steps: 5386 | Loss: 89.812471\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:34 | Steps: 5388 | Loss: 89.809482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:34 | Steps: 5390 | Loss: 89.824168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:34 | Steps: 5392 | Loss: 89.819874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:35 | Steps: 5394 | Loss: 89.816568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:35 | Steps: 5396 | Loss: 89.813823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:35 | Steps: 5398 | Loss: 89.810388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:35 | Steps: 5400 | Loss: 89.819324\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:35 | Steps: 5402 | Loss: 89.822272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:36 | Steps: 5404 | Loss: 89.813457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:36 | Steps: 5405 | Loss: 89.811900\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:36 | Steps: 5406 | Loss: 89.811186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:36 | Steps: 5408 | Loss: 89.816493\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:36 | Steps: 5409 | Loss: 89.817752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:36 | Steps: 5410 | Loss: 89.818850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:36 | Steps: 5412 | Loss: 89.817227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:37 | Steps: 5414 | Loss: 89.816512\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:37 | Steps: 5416 | Loss: 89.809048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:37 | Steps: 5418 | Loss: 89.810490\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:37 | Steps: 5420 | Loss: 89.803517\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:37 | Steps: 5422 | Loss: 89.800589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:37 | Steps: 5424 | Loss: 89.800205\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:38 | Steps: 5425 | Loss: 89.798173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:38 | Steps: 5427 | Loss: 89.793180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:38 | Steps: 5429 | Loss: 89.793213\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:38 | Steps: 5431 | Loss: 89.818950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:38 | Steps: 5433 | Loss: 89.820503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:38 | Steps: 5434 | Loss: 89.829216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:39 | Steps: 5436 | Loss: 89.829158\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:39 | Steps: 5438 | Loss: 89.822146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:39 | Steps: 5439 | Loss: 89.819999\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:39 | Steps: 5440 | Loss: 89.818327\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:39 | Steps: 5442 | Loss: 89.815888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:39 | Steps: 5444 | Loss: 89.820933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:39 | Steps: 5446 | Loss: 89.825804\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:40 | Steps: 5448 | Loss: 89.826858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:40 | Steps: 5450 | Loss: 89.830100\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:40 | Steps: 5451 | Loss: 89.830038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:40 | Steps: 5453 | Loss: 89.833967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:40 | Steps: 5454 | Loss: 89.836918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:40 | Steps: 5456 | Loss: 89.837873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:41 | Steps: 5458 | Loss: 89.847226\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:41 | Steps: 5460 | Loss: 89.841834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:41 | Steps: 5462 | Loss: 89.840456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:41 | Steps: 5464 | Loss: 89.842144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:41 | Steps: 5466 | Loss: 89.839045\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:41 | Steps: 5468 | Loss: 89.843395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:42 | Steps: 5470 | Loss: 89.847185\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:42 | Steps: 5471 | Loss: 89.851133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:42 | Steps: 5473 | Loss: 89.850631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:42 | Steps: 5475 | Loss: 89.862930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:42 | Steps: 5477 | Loss: 89.858151\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:42 | Steps: 5478 | Loss: 89.857156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:43 | Steps: 5480 | Loss: 89.854204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:43 | Steps: 5481 | Loss: 89.863487\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:43 | Steps: 5483 | Loss: 89.850189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:43 | Steps: 5484 | Loss: 89.849774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:43 | Steps: 5486 | Loss: 89.858027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:43 | Steps: 5488 | Loss: 89.852104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:44 | Steps: 5490 | Loss: 89.847828\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:44 | Steps: 5492 | Loss: 89.848854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:44 | Steps: 5494 | Loss: 89.847021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:44 | Steps: 5496 | Loss: 89.841712\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:44 | Steps: 5498 | Loss: 89.841723\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:45 | Steps: 5500 | Loss: 89.836943\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:45 | Steps: 5501 | Loss: 89.833747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:45 | Steps: 5503 | Loss: 89.829965\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:45 | Steps: 5505 | Loss: 89.829907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:45 | Steps: 5507 | Loss: 89.832984\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:45 | Steps: 5509 | Loss: 89.843900\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:46 | Steps: 5511 | Loss: 89.847495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:46 | Steps: 5512 | Loss: 89.845588\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:46 | Steps: 5514 | Loss: 89.845092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:46 | Steps: 5515 | Loss: 89.845118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:46 | Steps: 5517 | Loss: 89.845751\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:46 | Steps: 5519 | Loss: 89.836192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:47 | Steps: 5521 | Loss: 89.831707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:47 | Steps: 5523 | Loss: 89.834522\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:47 | Steps: 5525 | Loss: 89.835385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:47 | Steps: 5527 | Loss: 89.830185\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:47 | Steps: 5529 | Loss: 89.827620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:48 | Steps: 5531 | Loss: 89.834537\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:48 | Steps: 5532 | Loss: 89.835068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:48 | Steps: 5533 | Loss: 89.834499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:48 | Steps: 5535 | Loss: 89.833518\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:48 | Steps: 5537 | Loss: 89.824573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:48 | Steps: 5538 | Loss: 89.820726\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:48 | Steps: 5540 | Loss: 89.833226\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:49 | Steps: 5542 | Loss: 89.831301\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:49 | Steps: 5544 | Loss: 89.828713\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:49 | Steps: 5546 | Loss: 89.827450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:49 | Steps: 5548 | Loss: 89.827953\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:49 | Steps: 5549 | Loss: 89.821664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:49 | Steps: 5551 | Loss: 89.815352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:50 | Steps: 5553 | Loss: 89.808483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:50 | Steps: 5554 | Loss: 89.806912\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:50 | Steps: 5556 | Loss: 89.796986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:50 | Steps: 5557 | Loss: 89.802615\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:50 | Steps: 5559 | Loss: 89.811354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:50 | Steps: 5561 | Loss: 89.815845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:51 | Steps: 5563 | Loss: 89.806786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:51 | Steps: 5565 | Loss: 89.807544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:51 | Steps: 5566 | Loss: 89.806511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:51 | Steps: 5568 | Loss: 89.804359\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:51 | Steps: 5570 | Loss: 89.801165\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:51 | Steps: 5571 | Loss: 89.799843\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:52 | Steps: 5573 | Loss: 89.795707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:52 | Steps: 5575 | Loss: 89.798836\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:52 | Steps: 5576 | Loss: 89.804281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:52 | Steps: 5577 | Loss: 89.802887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:52 | Steps: 5579 | Loss: 89.806878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:52 | Steps: 5581 | Loss: 89.815709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:52 | Steps: 5582 | Loss: 89.819750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:53 | Steps: 5584 | Loss: 89.820822\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:53 | Steps: 5586 | Loss: 89.825261\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:53 | Steps: 5587 | Loss: 89.829516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:53 | Steps: 5588 | Loss: 89.834133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:53 | Steps: 5590 | Loss: 89.837571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:53 | Steps: 5592 | Loss: 89.841781\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:53 | Steps: 5594 | Loss: 89.839216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:54 | Steps: 5596 | Loss: 89.849144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:54 | Steps: 5597 | Loss: 89.848650\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:54 | Steps: 5598 | Loss: 89.844633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:54 | Steps: 5599 | Loss: 89.846042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:54 | Steps: 5600 | Loss: 89.845809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:54 | Steps: 5602 | Loss: 89.845617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:54 | Steps: 5604 | Loss: 89.844747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:55 | Steps: 5606 | Loss: 89.846750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:55 | Steps: 5608 | Loss: 89.850134\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:55 | Steps: 5610 | Loss: 89.846858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:55 | Steps: 5611 | Loss: 89.845169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:55 | Steps: 5613 | Loss: 89.852159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:56 | Steps: 5615 | Loss: 89.856085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:56 | Steps: 5616 | Loss: 89.859027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:56 | Steps: 5618 | Loss: 89.855951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:56 | Steps: 5619 | Loss: 89.857713\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:56 | Steps: 5621 | Loss: 89.864593\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:56 | Steps: 5623 | Loss: 89.869377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:56 | Steps: 5625 | Loss: 89.871088\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:57 | Steps: 5627 | Loss: 89.870005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:57 | Steps: 5628 | Loss: 89.869237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:57 | Steps: 5629 | Loss: 89.863778\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:57 | Steps: 5631 | Loss: 89.861553\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:57 | Steps: 5632 | Loss: 89.864842\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:57 | Steps: 5634 | Loss: 89.867896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:58 | Steps: 5636 | Loss: 89.867652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:58 | Steps: 5638 | Loss: 89.873791\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:58 | Steps: 5640 | Loss: 89.863818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:58 | Steps: 5642 | Loss: 89.873308\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:58 | Steps: 5643 | Loss: 89.870354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:58 | Steps: 5645 | Loss: 89.869346\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:59 | Steps: 5647 | Loss: 89.871496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:59 | Steps: 5649 | Loss: 89.858347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:59 | Steps: 5650 | Loss: 89.857645\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:59 | Steps: 5652 | Loss: 89.864143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:59 | Steps: 5654 | Loss: 89.861270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:06:59 | Steps: 5656 | Loss: 89.856613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:00 | Steps: 5657 | Loss: 89.853114\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:00 | Steps: 5658 | Loss: 89.853472\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:00 | Steps: 5660 | Loss: 89.853765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:00 | Steps: 5661 | Loss: 89.853404\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:00 | Steps: 5663 | Loss: 89.850611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:00 | Steps: 5664 | Loss: 89.848596\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:00 | Steps: 5666 | Loss: 89.848421\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:01 | Steps: 5668 | Loss: 89.853451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:01 | Steps: 5670 | Loss: 89.854423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:01 | Steps: 5671 | Loss: 89.850922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:01 | Steps: 5673 | Loss: 89.846399\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:01 | Steps: 5674 | Loss: 89.850909\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:01 | Steps: 5676 | Loss: 89.855881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:01 | Steps: 5678 | Loss: 89.858580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:02 | Steps: 5679 | Loss: 89.859091\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:02 | Steps: 5681 | Loss: 89.865687\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:02 | Steps: 5683 | Loss: 89.872303\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:02 | Steps: 5685 | Loss: 89.868500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:02 | Steps: 5686 | Loss: 89.865427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:02 | Steps: 5688 | Loss: 89.869075\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:03 | Steps: 5689 | Loss: 89.873284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:03 | Steps: 5691 | Loss: 89.862869\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:03 | Steps: 5692 | Loss: 89.857599\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:03 | Steps: 5694 | Loss: 89.850069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:03 | Steps: 5696 | Loss: 89.847377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:03 | Steps: 5697 | Loss: 89.854423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:03 | Steps: 5698 | Loss: 89.857228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:04 | Steps: 5700 | Loss: 89.854224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:04 | Steps: 5702 | Loss: 89.851714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:04 | Steps: 5704 | Loss: 89.845679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:04 | Steps: 5706 | Loss: 89.838491\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:04 | Steps: 5707 | Loss: 89.840019\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:04 | Steps: 5708 | Loss: 89.837775\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:04 | Steps: 5709 | Loss: 89.835674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:05 | Steps: 5711 | Loss: 89.831735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:05 | Steps: 5713 | Loss: 89.829528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:05 | Steps: 5715 | Loss: 89.829798\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:05 | Steps: 5717 | Loss: 89.846441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:05 | Steps: 5719 | Loss: 89.844395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:05 | Steps: 5721 | Loss: 89.844421\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:06 | Steps: 5722 | Loss: 89.843161\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:06 | Steps: 5724 | Loss: 89.841440\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:06 | Steps: 5726 | Loss: 89.848786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:06 | Steps: 5727 | Loss: 89.851019\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:06 | Steps: 5729 | Loss: 89.857899\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:06 | Steps: 5731 | Loss: 89.862264\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:07 | Steps: 5733 | Loss: 89.859096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:07 | Steps: 5735 | Loss: 89.857369\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:07 | Steps: 5736 | Loss: 89.855330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:07 | Steps: 5738 | Loss: 89.854591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:07 | Steps: 5739 | Loss: 89.857581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:07 | Steps: 5740 | Loss: 89.862571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:08 | Steps: 5742 | Loss: 89.867653\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:08 | Steps: 5744 | Loss: 89.858118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:08 | Steps: 5745 | Loss: 89.857442\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:08 | Steps: 5747 | Loss: 89.857862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:08 | Steps: 5749 | Loss: 89.857580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:08 | Steps: 5751 | Loss: 89.850263\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:09 | Steps: 5753 | Loss: 89.846311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:09 | Steps: 5755 | Loss: 89.844767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:09 | Steps: 5756 | Loss: 89.846210\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:09 | Steps: 5758 | Loss: 89.852153\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:09 | Steps: 5760 | Loss: 89.858699\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:09 | Steps: 5761 | Loss: 89.856167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:10 | Steps: 5762 | Loss: 89.856120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:10 | Steps: 5763 | Loss: 89.855682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:10 | Steps: 5764 | Loss: 89.853038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:10 | Steps: 5765 | Loss: 89.862689\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:10 | Steps: 5766 | Loss: 89.864399\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:10 | Steps: 5768 | Loss: 89.870878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:10 | Steps: 5770 | Loss: 89.865731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:10 | Steps: 5771 | Loss: 89.865695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:11 | Steps: 5773 | Loss: 89.864154\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:11 | Steps: 5774 | Loss: 89.862485\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:11 | Steps: 5775 | Loss: 89.863026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:11 | Steps: 5776 | Loss: 89.865880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:11 | Steps: 5778 | Loss: 89.861937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:11 | Steps: 5780 | Loss: 89.858330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:12 | Steps: 5782 | Loss: 89.860756\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:12 | Steps: 5783 | Loss: 89.860155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:12 | Steps: 5784 | Loss: 89.857725\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:12 | Steps: 5785 | Loss: 89.853026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:12 | Steps: 5787 | Loss: 89.855891\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:12 | Steps: 5788 | Loss: 89.859855\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:12 | Steps: 5790 | Loss: 89.857161\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:13 | Steps: 5792 | Loss: 89.864208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:13 | Steps: 5793 | Loss: 89.866438\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:13 | Steps: 5794 | Loss: 89.873321\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:13 | Steps: 5796 | Loss: 89.877420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:13 | Steps: 5797 | Loss: 89.878768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:13 | Steps: 5798 | Loss: 89.880005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:13 | Steps: 5800 | Loss: 89.884211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:13 | Steps: 5801 | Loss: 89.885027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:14 | Steps: 5802 | Loss: 89.886145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:14 | Steps: 5803 | Loss: 89.897183\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:14 | Steps: 5805 | Loss: 89.901988\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:14 | Steps: 5807 | Loss: 89.905802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:14 | Steps: 5809 | Loss: 89.902407\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:14 | Steps: 5810 | Loss: 89.905589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:14 | Steps: 5811 | Loss: 89.900751\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:15 | Steps: 5812 | Loss: 89.900772\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:15 | Steps: 5813 | Loss: 89.903461\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:15 | Steps: 5814 | Loss: 89.906644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:15 | Steps: 5816 | Loss: 89.909752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:15 | Steps: 5818 | Loss: 89.922460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:15 | Steps: 5820 | Loss: 89.929468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:16 | Steps: 5822 | Loss: 89.930271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:16 | Steps: 5824 | Loss: 89.923979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:16 | Steps: 5826 | Loss: 89.921678\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:16 | Steps: 5827 | Loss: 89.918378\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:16 | Steps: 5829 | Loss: 89.922193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:16 | Steps: 5831 | Loss: 89.915964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:16 | Steps: 5832 | Loss: 89.912896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:17 | Steps: 5834 | Loss: 89.914738\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:17 | Steps: 5836 | Loss: 89.910933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:17 | Steps: 5838 | Loss: 89.906947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:17 | Steps: 5840 | Loss: 89.901029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:17 | Steps: 5841 | Loss: 89.901325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:18 | Steps: 5843 | Loss: 89.901079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:18 | Steps: 5845 | Loss: 89.906465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:18 | Steps: 5847 | Loss: 89.904949\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:18 | Steps: 5849 | Loss: 89.904904\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:18 | Steps: 5850 | Loss: 89.908657\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:18 | Steps: 5852 | Loss: 89.915460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:19 | Steps: 5854 | Loss: 89.935961\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:19 | Steps: 5856 | Loss: 89.943214\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:19 | Steps: 5858 | Loss: 89.947508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:19 | Steps: 5859 | Loss: 89.946870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:19 | Steps: 5861 | Loss: 89.937029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:19 | Steps: 5862 | Loss: 89.932321\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:20 | Steps: 5864 | Loss: 89.928862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:20 | Steps: 5866 | Loss: 89.933231\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:20 | Steps: 5868 | Loss: 89.930641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:20 | Steps: 5870 | Loss: 89.929029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:20 | Steps: 5871 | Loss: 89.930683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:20 | Steps: 5873 | Loss: 89.932943\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:20 | Steps: 5874 | Loss: 89.935818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:21 | Steps: 5876 | Loss: 89.932180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:21 | Steps: 5878 | Loss: 89.927567\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:21 | Steps: 5880 | Loss: 89.934082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:21 | Steps: 5882 | Loss: 89.930969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:21 | Steps: 5884 | Loss: 89.925418\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:22 | Steps: 5886 | Loss: 89.923967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:22 | Steps: 5888 | Loss: 89.926110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:22 | Steps: 5889 | Loss: 89.929933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:22 | Steps: 5891 | Loss: 89.927338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:22 | Steps: 5893 | Loss: 89.916850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:22 | Steps: 5895 | Loss: 89.910025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:23 | Steps: 5896 | Loss: 89.906963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:23 | Steps: 5898 | Loss: 89.907195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:23 | Steps: 5900 | Loss: 89.909275\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:23 | Steps: 5902 | Loss: 89.910919\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:23 | Steps: 5904 | Loss: 89.916872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:24 | Steps: 5906 | Loss: 89.911534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:24 | Steps: 5907 | Loss: 89.911484\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:24 | Steps: 5909 | Loss: 89.910947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:24 | Steps: 5911 | Loss: 89.904612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:24 | Steps: 5913 | Loss: 89.898118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:24 | Steps: 5914 | Loss: 89.892714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:24 | Steps: 5916 | Loss: 89.894893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:25 | Steps: 5917 | Loss: 89.891150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:25 | Steps: 5919 | Loss: 89.887988\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:25 | Steps: 5920 | Loss: 89.899307\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:25 | Steps: 5922 | Loss: 89.905859\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:25 | Steps: 5923 | Loss: 89.901368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:25 | Steps: 5924 | Loss: 89.901924\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:25 | Steps: 5926 | Loss: 89.902179\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:26 | Steps: 5928 | Loss: 89.897664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:26 | Steps: 5929 | Loss: 89.893652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:26 | Steps: 5930 | Loss: 89.889727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:26 | Steps: 5932 | Loss: 89.886138\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:26 | Steps: 5933 | Loss: 89.886283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:26 | Steps: 5935 | Loss: 89.887352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:26 | Steps: 5936 | Loss: 89.887721\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:27 | Steps: 5938 | Loss: 89.892760\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:27 | Steps: 5939 | Loss: 89.891785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:27 | Steps: 5940 | Loss: 89.898917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:27 | Steps: 5942 | Loss: 89.910672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:27 | Steps: 5944 | Loss: 89.919720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:27 | Steps: 5945 | Loss: 89.922786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:28 | Steps: 5947 | Loss: 89.924060\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:28 | Steps: 5949 | Loss: 89.927846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:28 | Steps: 5950 | Loss: 89.927010\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:28 | Steps: 5952 | Loss: 89.928001\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:28 | Steps: 5954 | Loss: 89.932520\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:28 | Steps: 5955 | Loss: 89.940258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:28 | Steps: 5956 | Loss: 89.946127\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:29 | Steps: 5957 | Loss: 89.943985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:29 | Steps: 5959 | Loss: 89.943665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:29 | Steps: 5961 | Loss: 89.946244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:29 | Steps: 5963 | Loss: 89.951295\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:29 | Steps: 5964 | Loss: 89.951103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:29 | Steps: 5966 | Loss: 89.964059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:30 | Steps: 5968 | Loss: 89.963218\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:30 | Steps: 5970 | Loss: 89.959868\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:30 | Steps: 5972 | Loss: 89.962606\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:30 | Steps: 5974 | Loss: 89.961846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:30 | Steps: 5976 | Loss: 89.960046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:31 | Steps: 5978 | Loss: 89.952221\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:31 | Steps: 5980 | Loss: 89.952654\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:31 | Steps: 5981 | Loss: 89.956970\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:31 | Steps: 5983 | Loss: 89.953932\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:31 | Steps: 5984 | Loss: 89.961133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:31 | Steps: 5985 | Loss: 89.965627\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:32 | Steps: 5987 | Loss: 89.966518\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:32 | Steps: 5989 | Loss: 89.965412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:32 | Steps: 5990 | Loss: 89.964245\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:32 | Steps: 5992 | Loss: 89.957506\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:32 | Steps: 5993 | Loss: 89.960863\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:32 | Steps: 5995 | Loss: 89.958104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:32 | Steps: 5997 | Loss: 89.954909\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:33 | Steps: 5999 | Loss: 89.953059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:33 | Steps: 6001 | Loss: 89.947132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:33 | Steps: 6002 | Loss: 89.949051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:33 | Steps: 6004 | Loss: 89.960072\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:33 | Steps: 6006 | Loss: 89.962205\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:33 | Steps: 6008 | Loss: 89.961934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:34 | Steps: 6010 | Loss: 89.967573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:34 | Steps: 6011 | Loss: 89.969798\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:34 | Steps: 6012 | Loss: 89.975848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:34 | Steps: 6013 | Loss: 89.978230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:34 | Steps: 6014 | Loss: 89.988187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:34 | Steps: 6015 | Loss: 89.989746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:34 | Steps: 6017 | Loss: 89.991230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:34 | Steps: 6018 | Loss: 89.991017\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:35 | Steps: 6019 | Loss: 89.984823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:35 | Steps: 6021 | Loss: 89.978237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:35 | Steps: 6022 | Loss: 89.975957\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:35 | Steps: 6023 | Loss: 89.976375\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:35 | Steps: 6025 | Loss: 89.980188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:35 | Steps: 6027 | Loss: 89.975864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:35 | Steps: 6028 | Loss: 89.974190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:36 | Steps: 6030 | Loss: 89.975116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:36 | Steps: 6032 | Loss: 89.973727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:36 | Steps: 6034 | Loss: 89.976436\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:36 | Steps: 6035 | Loss: 89.977168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:36 | Steps: 6036 | Loss: 89.978833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:36 | Steps: 6038 | Loss: 89.973992\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:37 | Steps: 6040 | Loss: 89.973249\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:37 | Steps: 6042 | Loss: 89.977557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:37 | Steps: 6044 | Loss: 89.976950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:37 | Steps: 6045 | Loss: 89.976098\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:37 | Steps: 6047 | Loss: 89.972457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:37 | Steps: 6048 | Loss: 89.971139\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:38 | Steps: 6049 | Loss: 89.971837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:38 | Steps: 6050 | Loss: 89.973600\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:38 | Steps: 6052 | Loss: 89.976048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:38 | Steps: 6054 | Loss: 89.971243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:38 | Steps: 6056 | Loss: 89.971664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:38 | Steps: 6058 | Loss: 89.967146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:39 | Steps: 6060 | Loss: 89.971667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:39 | Steps: 6062 | Loss: 89.965497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:39 | Steps: 6064 | Loss: 89.966155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:39 | Steps: 6066 | Loss: 89.959548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:39 | Steps: 6068 | Loss: 89.956591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:40 | Steps: 6070 | Loss: 89.949790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:40 | Steps: 6072 | Loss: 89.945450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:40 | Steps: 6074 | Loss: 89.941716\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:40 | Steps: 6076 | Loss: 89.942476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:40 | Steps: 6078 | Loss: 89.942770\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:41 | Steps: 6080 | Loss: 89.945047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:41 | Steps: 6082 | Loss: 89.942365\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:41 | Steps: 6083 | Loss: 89.946709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:41 | Steps: 6084 | Loss: 89.952149\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:41 | Steps: 6085 | Loss: 89.953686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:41 | Steps: 6087 | Loss: 89.956281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:41 | Steps: 6089 | Loss: 89.958129\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:42 | Steps: 6091 | Loss: 89.960476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:42 | Steps: 6092 | Loss: 89.964243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:42 | Steps: 6094 | Loss: 89.962240\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:42 | Steps: 6096 | Loss: 89.958191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:42 | Steps: 6098 | Loss: 89.959167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:42 | Steps: 6100 | Loss: 89.953754\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:43 | Steps: 6102 | Loss: 89.956238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:43 | Steps: 6104 | Loss: 89.954961\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:43 | Steps: 6106 | Loss: 89.961986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:43 | Steps: 6108 | Loss: 89.960951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:43 | Steps: 6109 | Loss: 89.961609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:44 | Steps: 6111 | Loss: 89.967955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:44 | Steps: 6113 | Loss: 89.969546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:44 | Steps: 6114 | Loss: 89.971042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:44 | Steps: 6115 | Loss: 89.972508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:44 | Steps: 6117 | Loss: 89.978082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:44 | Steps: 6119 | Loss: 89.981638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:45 | Steps: 6121 | Loss: 89.981463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:45 | Steps: 6123 | Loss: 89.979614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:45 | Steps: 6124 | Loss: 89.973736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:45 | Steps: 6126 | Loss: 89.983821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:45 | Steps: 6127 | Loss: 89.990195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:45 | Steps: 6128 | Loss: 89.988300\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:45 | Steps: 6130 | Loss: 89.990038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:46 | Steps: 6131 | Loss: 89.989969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:46 | Steps: 6133 | Loss: 89.998325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:46 | Steps: 6134 | Loss: 90.003326\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:46 | Steps: 6136 | Loss: 90.015516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:46 | Steps: 6138 | Loss: 90.008802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:46 | Steps: 6139 | Loss: 90.014966\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:46 | Steps: 6140 | Loss: 90.013288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:47 | Steps: 6141 | Loss: 90.013193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:47 | Steps: 6143 | Loss: 90.011709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:47 | Steps: 6144 | Loss: 90.010752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:47 | Steps: 6145 | Loss: 90.009339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:47 | Steps: 6146 | Loss: 90.005386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:47 | Steps: 6147 | Loss: 90.005700\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:47 | Steps: 6149 | Loss: 90.004333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:48 | Steps: 6151 | Loss: 90.001067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:48 | Steps: 6152 | Loss: 90.002833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:48 | Steps: 6153 | Loss: 90.000761\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:48 | Steps: 6154 | Loss: 89.998026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:48 | Steps: 6155 | Loss: 89.996181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:48 | Steps: 6157 | Loss: 89.997897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:48 | Steps: 6158 | Loss: 90.000175\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:48 | Steps: 6159 | Loss: 90.001453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:49 | Steps: 6161 | Loss: 89.999982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:49 | Steps: 6163 | Loss: 89.998816\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:49 | Steps: 6164 | Loss: 89.997534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:49 | Steps: 6166 | Loss: 89.989865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:49 | Steps: 6168 | Loss: 89.986964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:49 | Steps: 6170 | Loss: 89.987274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:50 | Steps: 6171 | Loss: 89.992143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:50 | Steps: 6173 | Loss: 89.999836\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:50 | Steps: 6175 | Loss: 90.002406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:50 | Steps: 6177 | Loss: 90.002047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:50 | Steps: 6178 | Loss: 90.002898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:50 | Steps: 6180 | Loss: 89.994116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:51 | Steps: 6182 | Loss: 89.996082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:51 | Steps: 6183 | Loss: 89.992609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:51 | Steps: 6185 | Loss: 89.993857\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:51 | Steps: 6186 | Loss: 89.990699\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:51 | Steps: 6188 | Loss: 89.989998\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:51 | Steps: 6190 | Loss: 89.990881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:52 | Steps: 6192 | Loss: 89.988284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:52 | Steps: 6194 | Loss: 89.995747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:52 | Steps: 6196 | Loss: 89.993602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:52 | Steps: 6198 | Loss: 89.996317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:52 | Steps: 6199 | Loss: 89.995163\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:52 | Steps: 6201 | Loss: 89.998656\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:53 | Steps: 6203 | Loss: 89.996088\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:53 | Steps: 6205 | Loss: 89.993727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:53 | Steps: 6206 | Loss: 89.997508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:53 | Steps: 6207 | Loss: 89.999734\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:53 | Steps: 6208 | Loss: 90.000144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:53 | Steps: 6209 | Loss: 89.999665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:53 | Steps: 6210 | Loss: 90.007643\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:54 | Steps: 6212 | Loss: 90.008504\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:54 | Steps: 6214 | Loss: 90.006580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:54 | Steps: 6215 | Loss: 90.004927\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:54 | Steps: 6217 | Loss: 90.000392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:54 | Steps: 6219 | Loss: 89.991805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:54 | Steps: 6220 | Loss: 89.998805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:55 | Steps: 6222 | Loss: 90.005927\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:55 | Steps: 6224 | Loss: 90.005717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:55 | Steps: 6225 | Loss: 90.003299\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:55 | Steps: 6227 | Loss: 90.004559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:55 | Steps: 6228 | Loss: 90.003317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:55 | Steps: 6230 | Loss: 90.001323\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:55 | Steps: 6231 | Loss: 89.999916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:56 | Steps: 6233 | Loss: 89.998039\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:56 | Steps: 6234 | Loss: 89.999013\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:56 | Steps: 6235 | Loss: 89.997571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:56 | Steps: 6237 | Loss: 89.992460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:56 | Steps: 6238 | Loss: 89.992495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:56 | Steps: 6239 | Loss: 89.995920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:56 | Steps: 6241 | Loss: 89.998663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:57 | Steps: 6243 | Loss: 90.007962\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:57 | Steps: 6245 | Loss: 90.014189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:57 | Steps: 6246 | Loss: 90.011732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:57 | Steps: 6248 | Loss: 90.009702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:57 | Steps: 6249 | Loss: 90.006046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:57 | Steps: 6250 | Loss: 90.006729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:57 | Steps: 6251 | Loss: 90.005421\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:58 | Steps: 6252 | Loss: 90.007452\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:58 | Steps: 6254 | Loss: 90.007281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:58 | Steps: 6255 | Loss: 90.007320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:58 | Steps: 6256 | Loss: 90.005109\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:58 | Steps: 6257 | Loss: 90.002984\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:58 | Steps: 6259 | Loss: 90.011866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:58 | Steps: 6261 | Loss: 90.017483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:59 | Steps: 6262 | Loss: 90.014026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:59 | Steps: 6264 | Loss: 90.009132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:59 | Steps: 6266 | Loss: 90.006482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:59 | Steps: 6268 | Loss: 90.007332\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:59 | Steps: 6269 | Loss: 90.007099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:07:59 | Steps: 6271 | Loss: 90.014725\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:00 | Steps: 6273 | Loss: 90.015436\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:00 | Steps: 6274 | Loss: 90.022244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:00 | Steps: 6276 | Loss: 90.029016\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:00 | Steps: 6278 | Loss: 90.029843\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:00 | Steps: 6279 | Loss: 90.033766\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:00 | Steps: 6281 | Loss: 90.034092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:01 | Steps: 6283 | Loss: 90.031784\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:01 | Steps: 6285 | Loss: 90.043544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:01 | Steps: 6286 | Loss: 90.045085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:01 | Steps: 6288 | Loss: 90.046823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:01 | Steps: 6289 | Loss: 90.053346\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:01 | Steps: 6290 | Loss: 90.053906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:01 | Steps: 6291 | Loss: 90.049042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:02 | Steps: 6293 | Loss: 90.042820\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:02 | Steps: 6295 | Loss: 90.045511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:02 | Steps: 6297 | Loss: 90.042439\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:02 | Steps: 6298 | Loss: 90.046004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:02 | Steps: 6299 | Loss: 90.045777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:02 | Steps: 6301 | Loss: 90.052701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:03 | Steps: 6302 | Loss: 90.054372\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:03 | Steps: 6303 | Loss: 90.056250\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:03 | Steps: 6304 | Loss: 90.056313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:03 | Steps: 6306 | Loss: 90.063222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:03 | Steps: 6308 | Loss: 90.060392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:03 | Steps: 6309 | Loss: 90.063563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:03 | Steps: 6311 | Loss: 90.057073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:03 | Steps: 6312 | Loss: 90.055376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:04 | Steps: 6313 | Loss: 90.054466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:04 | Steps: 6314 | Loss: 90.052347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:04 | Steps: 6315 | Loss: 90.053014\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:04 | Steps: 6317 | Loss: 90.046838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:04 | Steps: 6319 | Loss: 90.044940\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:04 | Steps: 6320 | Loss: 90.041495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:05 | Steps: 6322 | Loss: 90.039711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:05 | Steps: 6323 | Loss: 90.041818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:05 | Steps: 6324 | Loss: 90.040237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:05 | Steps: 6325 | Loss: 90.039396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:05 | Steps: 6327 | Loss: 90.036164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:05 | Steps: 6328 | Loss: 90.037028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:05 | Steps: 6330 | Loss: 90.034174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:06 | Steps: 6332 | Loss: 90.038747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:06 | Steps: 6334 | Loss: 90.040790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:06 | Steps: 6335 | Loss: 90.038612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:06 | Steps: 6336 | Loss: 90.034782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:06 | Steps: 6337 | Loss: 90.034602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:06 | Steps: 6339 | Loss: 90.041525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:06 | Steps: 6341 | Loss: 90.048873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:07 | Steps: 6343 | Loss: 90.046641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:07 | Steps: 6345 | Loss: 90.040931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:07 | Steps: 6346 | Loss: 90.040367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:07 | Steps: 6347 | Loss: 90.038283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:07 | Steps: 6349 | Loss: 90.032713\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:07 | Steps: 6350 | Loss: 90.026819\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:07 | Steps: 6351 | Loss: 90.024063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:08 | Steps: 6353 | Loss: 90.022358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:08 | Steps: 6354 | Loss: 90.020933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:08 | Steps: 6356 | Loss: 90.019290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:08 | Steps: 6357 | Loss: 90.018975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:08 | Steps: 6358 | Loss: 90.018735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:08 | Steps: 6360 | Loss: 90.018055\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:09 | Steps: 6362 | Loss: 90.018626\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:09 | Steps: 6364 | Loss: 90.016588\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:09 | Steps: 6365 | Loss: 90.013676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:09 | Steps: 6366 | Loss: 90.011292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:09 | Steps: 6368 | Loss: 90.020821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:09 | Steps: 6369 | Loss: 90.026210\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:09 | Steps: 6371 | Loss: 90.024748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:10 | Steps: 6373 | Loss: 90.024100\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:10 | Steps: 6374 | Loss: 90.021172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:10 | Steps: 6376 | Loss: 90.026453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:10 | Steps: 6378 | Loss: 90.032224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:10 | Steps: 6380 | Loss: 90.035979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:10 | Steps: 6381 | Loss: 90.033547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:11 | Steps: 6382 | Loss: 90.033260\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:11 | Steps: 6384 | Loss: 90.029908\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:11 | Steps: 6385 | Loss: 90.025841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:11 | Steps: 6386 | Loss: 90.030946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:11 | Steps: 6388 | Loss: 90.036340\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:11 | Steps: 6389 | Loss: 90.033993\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:11 | Steps: 6391 | Loss: 90.030056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:12 | Steps: 6393 | Loss: 90.024689\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:12 | Steps: 6394 | Loss: 90.021279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:12 | Steps: 6396 | Loss: 90.018118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:12 | Steps: 6398 | Loss: 90.015579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:12 | Steps: 6400 | Loss: 90.015424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:13 | Steps: 6402 | Loss: 90.014669\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:13 | Steps: 6404 | Loss: 90.015617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:13 | Steps: 6405 | Loss: 90.025176\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:13 | Steps: 6407 | Loss: 90.025058\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:13 | Steps: 6409 | Loss: 90.022538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:13 | Steps: 6411 | Loss: 90.024381\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:14 | Steps: 6413 | Loss: 90.019544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:14 | Steps: 6414 | Loss: 90.019938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:14 | Steps: 6416 | Loss: 90.016299\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:14 | Steps: 6418 | Loss: 90.014507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:14 | Steps: 6419 | Loss: 90.017706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:14 | Steps: 6420 | Loss: 90.019345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:14 | Steps: 6422 | Loss: 90.026412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:15 | Steps: 6423 | Loss: 90.027978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:15 | Steps: 6424 | Loss: 90.029911\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:15 | Steps: 6426 | Loss: 90.035426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:15 | Steps: 6428 | Loss: 90.044357\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:15 | Steps: 6429 | Loss: 90.046012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:15 | Steps: 6430 | Loss: 90.046094\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:15 | Steps: 6432 | Loss: 90.048959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:16 | Steps: 6434 | Loss: 90.059336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:16 | Steps: 6435 | Loss: 90.060909\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:16 | Steps: 6436 | Loss: 90.061920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:16 | Steps: 6437 | Loss: 90.059964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:16 | Steps: 6439 | Loss: 90.053715\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:16 | Steps: 6441 | Loss: 90.068422\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:16 | Steps: 6442 | Loss: 90.068238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:17 | Steps: 6444 | Loss: 90.071488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:17 | Steps: 6446 | Loss: 90.073074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:17 | Steps: 6448 | Loss: 90.079551\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:17 | Steps: 6450 | Loss: 90.076636\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:17 | Steps: 6452 | Loss: 90.087635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:18 | Steps: 6454 | Loss: 90.088774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:18 | Steps: 6456 | Loss: 90.092810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:18 | Steps: 6458 | Loss: 90.088750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:18 | Steps: 6460 | Loss: 90.083501\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:18 | Steps: 6461 | Loss: 90.083585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:18 | Steps: 6462 | Loss: 90.079473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:19 | Steps: 6463 | Loss: 90.075282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:19 | Steps: 6465 | Loss: 90.074967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:19 | Steps: 6466 | Loss: 90.077172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:19 | Steps: 6468 | Loss: 90.071175\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:19 | Steps: 6470 | Loss: 90.080527\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:19 | Steps: 6472 | Loss: 90.087313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:20 | Steps: 6474 | Loss: 90.085458\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:20 | Steps: 6475 | Loss: 90.087635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:20 | Steps: 6476 | Loss: 90.088373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:20 | Steps: 6478 | Loss: 90.088876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:20 | Steps: 6480 | Loss: 90.084071\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:20 | Steps: 6481 | Loss: 90.082792\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:20 | Steps: 6482 | Loss: 90.084173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:21 | Steps: 6483 | Loss: 90.082973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:21 | Steps: 6485 | Loss: 90.084973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:21 | Steps: 6486 | Loss: 90.085943\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:21 | Steps: 6488 | Loss: 90.084017\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:21 | Steps: 6490 | Loss: 90.079826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:21 | Steps: 6491 | Loss: 90.078698\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:21 | Steps: 6492 | Loss: 90.077979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:22 | Steps: 6494 | Loss: 90.079661\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:22 | Steps: 6495 | Loss: 90.080785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:22 | Steps: 6496 | Loss: 90.080848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:22 | Steps: 6497 | Loss: 90.077281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:22 | Steps: 6498 | Loss: 90.074716\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:22 | Steps: 6499 | Loss: 90.075613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:22 | Steps: 6500 | Loss: 90.070441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:23 | Steps: 6502 | Loss: 90.060714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:23 | Steps: 6504 | Loss: 90.059850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:23 | Steps: 6506 | Loss: 90.060845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:23 | Steps: 6507 | Loss: 90.059782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:23 | Steps: 6509 | Loss: 90.061282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:23 | Steps: 6510 | Loss: 90.059159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:23 | Steps: 6511 | Loss: 90.060064\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:24 | Steps: 6513 | Loss: 90.062302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:24 | Steps: 6514 | Loss: 90.061376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:24 | Steps: 6516 | Loss: 90.058906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:24 | Steps: 6517 | Loss: 90.057192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:24 | Steps: 6519 | Loss: 90.055331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:24 | Steps: 6521 | Loss: 90.056302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:25 | Steps: 6522 | Loss: 90.053658\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:25 | Steps: 6524 | Loss: 90.057931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:25 | Steps: 6526 | Loss: 90.057286\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:25 | Steps: 6528 | Loss: 90.057938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:25 | Steps: 6530 | Loss: 90.055198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:25 | Steps: 6531 | Loss: 90.054950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:26 | Steps: 6533 | Loss: 90.055964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:26 | Steps: 6534 | Loss: 90.059252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:26 | Steps: 6535 | Loss: 90.063671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:26 | Steps: 6536 | Loss: 90.066126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:26 | Steps: 6538 | Loss: 90.073516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:26 | Steps: 6539 | Loss: 90.071607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:26 | Steps: 6540 | Loss: 90.068324\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:27 | Steps: 6542 | Loss: 90.063272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:27 | Steps: 6543 | Loss: 90.063232\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:27 | Steps: 6545 | Loss: 90.062579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:27 | Steps: 6546 | Loss: 90.063112\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:27 | Steps: 6547 | Loss: 90.066438\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:27 | Steps: 6548 | Loss: 90.067732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:27 | Steps: 6550 | Loss: 90.064567\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:28 | Steps: 6552 | Loss: 90.061613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:28 | Steps: 6553 | Loss: 90.058300\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:28 | Steps: 6554 | Loss: 90.057740\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:28 | Steps: 6556 | Loss: 90.051743\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:28 | Steps: 6558 | Loss: 90.050110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:28 | Steps: 6560 | Loss: 90.050529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:28 | Steps: 6561 | Loss: 90.049109\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:29 | Steps: 6563 | Loss: 90.045030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:29 | Steps: 6564 | Loss: 90.044246\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:29 | Steps: 6565 | Loss: 90.047561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:29 | Steps: 6566 | Loss: 90.049817\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:29 | Steps: 6568 | Loss: 90.052470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:29 | Steps: 6569 | Loss: 90.053179\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:29 | Steps: 6571 | Loss: 90.049478\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:30 | Steps: 6572 | Loss: 90.051150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:30 | Steps: 6573 | Loss: 90.054674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:30 | Steps: 6574 | Loss: 90.058532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:30 | Steps: 6575 | Loss: 90.060600\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:30 | Steps: 6576 | Loss: 90.061724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:30 | Steps: 6578 | Loss: 90.063832\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:30 | Steps: 6579 | Loss: 90.067558\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:30 | Steps: 6581 | Loss: 90.073270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:31 | Steps: 6582 | Loss: 90.077457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:31 | Steps: 6584 | Loss: 90.074425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:31 | Steps: 6585 | Loss: 90.071802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:31 | Steps: 6586 | Loss: 90.069155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:31 | Steps: 6587 | Loss: 90.068468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:31 | Steps: 6588 | Loss: 90.069632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:31 | Steps: 6590 | Loss: 90.067055\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:32 | Steps: 6592 | Loss: 90.065971\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:32 | Steps: 6594 | Loss: 90.066107\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:32 | Steps: 6595 | Loss: 90.070957\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:32 | Steps: 6596 | Loss: 90.073066\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:32 | Steps: 6598 | Loss: 90.086162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:32 | Steps: 6599 | Loss: 90.085373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:32 | Steps: 6600 | Loss: 90.085208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:33 | Steps: 6602 | Loss: 90.087672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:33 | Steps: 6604 | Loss: 90.089054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:33 | Steps: 6605 | Loss: 90.089581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:33 | Steps: 6606 | Loss: 90.089875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:33 | Steps: 6608 | Loss: 90.095550\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:33 | Steps: 6610 | Loss: 90.087734\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:34 | Steps: 6612 | Loss: 90.094788\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:34 | Steps: 6614 | Loss: 90.094135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:34 | Steps: 6615 | Loss: 90.092933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:34 | Steps: 6617 | Loss: 90.094467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:34 | Steps: 6618 | Loss: 90.095477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:34 | Steps: 6619 | Loss: 90.100056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:34 | Steps: 6620 | Loss: 90.105657\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:34 | Steps: 6621 | Loss: 90.108417\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:35 | Steps: 6623 | Loss: 90.114176\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:35 | Steps: 6625 | Loss: 90.110224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:35 | Steps: 6627 | Loss: 90.113011\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:35 | Steps: 6629 | Loss: 90.116089\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:35 | Steps: 6631 | Loss: 90.108483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6632 | Loss: 90.108534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6633 | Loss: 90.106400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6634 | Loss: 90.104383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6635 | Loss: 90.100424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6636 | Loss: 90.103251\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6638 | Loss: 90.098946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6639 | Loss: 90.099618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6640 | Loss: 90.100880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:36 | Steps: 6641 | Loss: 90.100973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:37 | Steps: 6643 | Loss: 90.100368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:37 | Steps: 6644 | Loss: 90.101310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:37 | Steps: 6645 | Loss: 90.098833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:37 | Steps: 6646 | Loss: 90.099507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:37 | Steps: 6648 | Loss: 90.099628\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:37 | Steps: 6650 | Loss: 90.101845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:37 | Steps: 6651 | Loss: 90.102192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:38 | Steps: 6652 | Loss: 90.100695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:38 | Steps: 6653 | Loss: 90.095578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:38 | Steps: 6655 | Loss: 90.100647\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:38 | Steps: 6656 | Loss: 90.099526\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:38 | Steps: 6658 | Loss: 90.111518\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:38 | Steps: 6660 | Loss: 90.111870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:39 | Steps: 6662 | Loss: 90.104979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:39 | Steps: 6663 | Loss: 90.106338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:39 | Steps: 6665 | Loss: 90.102470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:39 | Steps: 6667 | Loss: 90.100818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:39 | Steps: 6668 | Loss: 90.098923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:39 | Steps: 6669 | Loss: 90.098195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:39 | Steps: 6671 | Loss: 90.096704\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:40 | Steps: 6673 | Loss: 90.096711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:40 | Steps: 6675 | Loss: 90.098383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:40 | Steps: 6676 | Loss: 90.098638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:40 | Steps: 6677 | Loss: 90.097271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:40 | Steps: 6678 | Loss: 90.095544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:40 | Steps: 6680 | Loss: 90.098658\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:41 | Steps: 6682 | Loss: 90.092903\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:41 | Steps: 6683 | Loss: 90.097989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:41 | Steps: 6684 | Loss: 90.097922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:41 | Steps: 6685 | Loss: 90.097475\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:41 | Steps: 6687 | Loss: 90.093631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:41 | Steps: 6688 | Loss: 90.094690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:41 | Steps: 6689 | Loss: 90.095561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:41 | Steps: 6691 | Loss: 90.096671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:42 | Steps: 6692 | Loss: 90.101765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:42 | Steps: 6694 | Loss: 90.098454\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:42 | Steps: 6695 | Loss: 90.096191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:42 | Steps: 6697 | Loss: 90.093030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:42 | Steps: 6699 | Loss: 90.094409\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:42 | Steps: 6701 | Loss: 90.100473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:43 | Steps: 6702 | Loss: 90.099059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:43 | Steps: 6703 | Loss: 90.095889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:43 | Steps: 6704 | Loss: 90.093932\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:43 | Steps: 6705 | Loss: 90.095479\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:43 | Steps: 6707 | Loss: 90.095603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:43 | Steps: 6708 | Loss: 90.095523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:43 | Steps: 6709 | Loss: 90.093272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:43 | Steps: 6711 | Loss: 90.087506\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:44 | Steps: 6713 | Loss: 90.088164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:44 | Steps: 6714 | Loss: 90.085214\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:44 | Steps: 6716 | Loss: 90.088391\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:44 | Steps: 6717 | Loss: 90.088587\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:44 | Steps: 6719 | Loss: 90.081523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:44 | Steps: 6720 | Loss: 90.084475\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:45 | Steps: 6721 | Loss: 90.084266\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:45 | Steps: 6723 | Loss: 90.089103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:45 | Steps: 6725 | Loss: 90.090132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:45 | Steps: 6726 | Loss: 90.096757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:45 | Steps: 6728 | Loss: 90.097715\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:45 | Steps: 6730 | Loss: 90.099593\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:45 | Steps: 6731 | Loss: 90.099963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:46 | Steps: 6733 | Loss: 90.100889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:46 | Steps: 6734 | Loss: 90.100898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:46 | Steps: 6735 | Loss: 90.100808\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:46 | Steps: 6736 | Loss: 90.099166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:46 | Steps: 6737 | Loss: 90.099781\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:46 | Steps: 6738 | Loss: 90.096318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:46 | Steps: 6740 | Loss: 90.092567\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:46 | Steps: 6741 | Loss: 90.095026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:47 | Steps: 6743 | Loss: 90.096432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:47 | Steps: 6744 | Loss: 90.096086\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:47 | Steps: 6745 | Loss: 90.097498\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:47 | Steps: 6746 | Loss: 90.102227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:47 | Steps: 6747 | Loss: 90.110042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:47 | Steps: 6748 | Loss: 90.109160\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:47 | Steps: 6750 | Loss: 90.114917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:48 | Steps: 6751 | Loss: 90.115260\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:48 | Steps: 6753 | Loss: 90.119725\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:48 | Steps: 6754 | Loss: 90.119084\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:48 | Steps: 6755 | Loss: 90.121135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:48 | Steps: 6756 | Loss: 90.121503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:48 | Steps: 6758 | Loss: 90.122876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:48 | Steps: 6760 | Loss: 90.122654\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:49 | Steps: 6762 | Loss: 90.120905\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:49 | Steps: 6763 | Loss: 90.120029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:49 | Steps: 6764 | Loss: 90.120591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:49 | Steps: 6765 | Loss: 90.119495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:49 | Steps: 6767 | Loss: 90.128412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:49 | Steps: 6768 | Loss: 90.131256\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:49 | Steps: 6770 | Loss: 90.135920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:49 | Steps: 6771 | Loss: 90.138516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:50 | Steps: 6772 | Loss: 90.134985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:50 | Steps: 6773 | Loss: 90.140675\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:50 | Steps: 6774 | Loss: 90.139301\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:50 | Steps: 6776 | Loss: 90.137913\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:50 | Steps: 6777 | Loss: 90.134072\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:50 | Steps: 6778 | Loss: 90.131574\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:50 | Steps: 6780 | Loss: 90.132352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:51 | Steps: 6782 | Loss: 90.122178\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:51 | Steps: 6783 | Loss: 90.123353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:51 | Steps: 6784 | Loss: 90.119222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:51 | Steps: 6786 | Loss: 90.116347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:51 | Steps: 6787 | Loss: 90.124588\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:51 | Steps: 6788 | Loss: 90.124188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:51 | Steps: 6790 | Loss: 90.126595\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:52 | Steps: 6792 | Loss: 90.125597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:52 | Steps: 6794 | Loss: 90.124664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:52 | Steps: 6795 | Loss: 90.123056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:52 | Steps: 6797 | Loss: 90.126867\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:52 | Steps: 6798 | Loss: 90.126947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:52 | Steps: 6799 | Loss: 90.128871\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:52 | Steps: 6800 | Loss: 90.128678\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:53 | Steps: 6802 | Loss: 90.131535\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:53 | Steps: 6804 | Loss: 90.136468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:53 | Steps: 6805 | Loss: 90.138887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:53 | Steps: 6807 | Loss: 90.136199\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:53 | Steps: 6808 | Loss: 90.135464\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:53 | Steps: 6810 | Loss: 90.127456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:54 | Steps: 6811 | Loss: 90.122468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:54 | Steps: 6812 | Loss: 90.122759\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:54 | Steps: 6813 | Loss: 90.120320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:54 | Steps: 6814 | Loss: 90.118270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:54 | Steps: 6815 | Loss: 90.120309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:54 | Steps: 6817 | Loss: 90.123306\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:54 | Steps: 6818 | Loss: 90.122795\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:54 | Steps: 6820 | Loss: 90.123968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:55 | Steps: 6822 | Loss: 90.131613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:55 | Steps: 6824 | Loss: 90.131659\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:55 | Steps: 6825 | Loss: 90.133338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:55 | Steps: 6827 | Loss: 90.134533\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:55 | Steps: 6828 | Loss: 90.134279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:55 | Steps: 6829 | Loss: 90.133605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:56 | Steps: 6831 | Loss: 90.137213\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:56 | Steps: 6833 | Loss: 90.140477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:56 | Steps: 6834 | Loss: 90.138140\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:56 | Steps: 6836 | Loss: 90.135807\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:56 | Steps: 6837 | Loss: 90.133856\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:56 | Steps: 6838 | Loss: 90.134136\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:56 | Steps: 6840 | Loss: 90.129209\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:57 | Steps: 6841 | Loss: 90.129512\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:57 | Steps: 6842 | Loss: 90.131823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:57 | Steps: 6843 | Loss: 90.130603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:57 | Steps: 6845 | Loss: 90.133635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:57 | Steps: 6846 | Loss: 90.129416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:57 | Steps: 6848 | Loss: 90.127089\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:57 | Steps: 6849 | Loss: 90.126256\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:57 | Steps: 6850 | Loss: 90.127871\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:58 | Steps: 6852 | Loss: 90.127062\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:58 | Steps: 6854 | Loss: 90.126733\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:58 | Steps: 6855 | Loss: 90.125265\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:58 | Steps: 6856 | Loss: 90.121978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:58 | Steps: 6857 | Loss: 90.119796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:58 | Steps: 6858 | Loss: 90.116736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:58 | Steps: 6860 | Loss: 90.117376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:59 | Steps: 6862 | Loss: 90.118736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:59 | Steps: 6864 | Loss: 90.128925\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:59 | Steps: 6865 | Loss: 90.138946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:59 | Steps: 6866 | Loss: 90.137269\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:59 | Steps: 6867 | Loss: 90.137524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:59 | Steps: 6869 | Loss: 90.142062\n",
      "Epoch 0 |   Training | Elapsed Time: 0:08:59 | Steps: 6870 | Loss: 90.142781\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:00 | Steps: 6872 | Loss: 90.139193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:00 | Steps: 6874 | Loss: 90.135565\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:00 | Steps: 6876 | Loss: 90.136251\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:00 | Steps: 6877 | Loss: 90.136334\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:00 | Steps: 6878 | Loss: 90.138046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:00 | Steps: 6879 | Loss: 90.137887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:00 | Steps: 6880 | Loss: 90.144448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:01 | Steps: 6882 | Loss: 90.146266\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:01 | Steps: 6884 | Loss: 90.150838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:01 | Steps: 6886 | Loss: 90.157248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:01 | Steps: 6887 | Loss: 90.157750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:01 | Steps: 6888 | Loss: 90.157412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:01 | Steps: 6889 | Loss: 90.158458\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:01 | Steps: 6890 | Loss: 90.158324\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:02 | Steps: 6892 | Loss: 90.153324\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:02 | Steps: 6893 | Loss: 90.151642\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:02 | Steps: 6895 | Loss: 90.146921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:02 | Steps: 6897 | Loss: 90.147274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:02 | Steps: 6899 | Loss: 90.145406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:02 | Steps: 6900 | Loss: 90.152054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:03 | Steps: 6902 | Loss: 90.153963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:03 | Steps: 6903 | Loss: 90.154165\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:03 | Steps: 6905 | Loss: 90.155444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:03 | Steps: 6907 | Loss: 90.157206\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:03 | Steps: 6909 | Loss: 90.154839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:03 | Steps: 6910 | Loss: 90.154848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:04 | Steps: 6911 | Loss: 90.152847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:04 | Steps: 6913 | Loss: 90.167690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:04 | Steps: 6914 | Loss: 90.163851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:04 | Steps: 6916 | Loss: 90.161475\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:04 | Steps: 6917 | Loss: 90.160968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:04 | Steps: 6919 | Loss: 90.157425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:04 | Steps: 6920 | Loss: 90.155835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:05 | Steps: 6922 | Loss: 90.153860\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:05 | Steps: 6923 | Loss: 90.155644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:05 | Steps: 6924 | Loss: 90.153776\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:05 | Steps: 6925 | Loss: 90.152499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:05 | Steps: 6927 | Loss: 90.150770\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:05 | Steps: 6928 | Loss: 90.150989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:05 | Steps: 6930 | Loss: 90.153128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:06 | Steps: 6932 | Loss: 90.152953\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:06 | Steps: 6933 | Loss: 90.151944\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:06 | Steps: 6935 | Loss: 90.147147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:06 | Steps: 6936 | Loss: 90.150413\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:06 | Steps: 6937 | Loss: 90.160349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:06 | Steps: 6938 | Loss: 90.160938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:06 | Steps: 6940 | Loss: 90.165661\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:07 | Steps: 6941 | Loss: 90.165851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:07 | Steps: 6942 | Loss: 90.164079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:07 | Steps: 6944 | Loss: 90.165922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:07 | Steps: 6946 | Loss: 90.166253\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:07 | Steps: 6947 | Loss: 90.161608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:07 | Steps: 6948 | Loss: 90.158416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:07 | Steps: 6949 | Loss: 90.160514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:08 | Steps: 6951 | Loss: 90.157640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:08 | Steps: 6953 | Loss: 90.158754\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:08 | Steps: 6954 | Loss: 90.156903\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:08 | Steps: 6955 | Loss: 90.155935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:08 | Steps: 6957 | Loss: 90.153498\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:08 | Steps: 6958 | Loss: 90.154564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:08 | Steps: 6960 | Loss: 90.155514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:09 | Steps: 6962 | Loss: 90.154697\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:09 | Steps: 6963 | Loss: 90.152919\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:09 | Steps: 6964 | Loss: 90.152630\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:09 | Steps: 6965 | Loss: 90.158922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:09 | Steps: 6966 | Loss: 90.164412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:09 | Steps: 6967 | Loss: 90.168385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:09 | Steps: 6969 | Loss: 90.166929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:09 | Steps: 6970 | Loss: 90.168089\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:10 | Steps: 6971 | Loss: 90.169611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:10 | Steps: 6973 | Loss: 90.180015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:10 | Steps: 6974 | Loss: 90.185420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:10 | Steps: 6976 | Loss: 90.181059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:10 | Steps: 6978 | Loss: 90.176453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:10 | Steps: 6980 | Loss: 90.179479\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6981 | Loss: 90.182778\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6983 | Loss: 90.178742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6984 | Loss: 90.177599\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6985 | Loss: 90.175063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6986 | Loss: 90.177454\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6987 | Loss: 90.176073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6988 | Loss: 90.177930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6989 | Loss: 90.177229\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:11 | Steps: 6990 | Loss: 90.175057\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:12 | Steps: 6992 | Loss: 90.168657\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:12 | Steps: 6993 | Loss: 90.166818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:12 | Steps: 6995 | Loss: 90.167372\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:12 | Steps: 6996 | Loss: 90.173316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:12 | Steps: 6997 | Loss: 90.172595\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:12 | Steps: 6998 | Loss: 90.172673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:13 | Steps: 7000 | Loss: 90.169928\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:13 | Steps: 7002 | Loss: 90.168770\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:13 | Steps: 7003 | Loss: 90.168025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:13 | Steps: 7005 | Loss: 90.168390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:13 | Steps: 7006 | Loss: 90.167663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:13 | Steps: 7008 | Loss: 90.171700\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:14 | Steps: 7010 | Loss: 90.176800\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:14 | Steps: 7011 | Loss: 90.179109\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:14 | Steps: 7012 | Loss: 90.180901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:14 | Steps: 7013 | Loss: 90.180434\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:14 | Steps: 7015 | Loss: 90.181769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:14 | Steps: 7016 | Loss: 90.186393\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:14 | Steps: 7017 | Loss: 90.190525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:15 | Steps: 7019 | Loss: 90.186258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:15 | Steps: 7021 | Loss: 90.182599\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:15 | Steps: 7023 | Loss: 90.185316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:15 | Steps: 7024 | Loss: 90.186421\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:15 | Steps: 7025 | Loss: 90.186319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:15 | Steps: 7027 | Loss: 90.186973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:15 | Steps: 7028 | Loss: 90.191283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:16 | Steps: 7030 | Loss: 90.192216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:16 | Steps: 7031 | Loss: 90.198674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:16 | Steps: 7032 | Loss: 90.200928\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:16 | Steps: 7034 | Loss: 90.207388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:16 | Steps: 7035 | Loss: 90.207407\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:16 | Steps: 7036 | Loss: 90.211926\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:16 | Steps: 7037 | Loss: 90.214200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:17 | Steps: 7039 | Loss: 90.220369\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:17 | Steps: 7041 | Loss: 90.220500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:17 | Steps: 7043 | Loss: 90.226749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:17 | Steps: 7045 | Loss: 90.229029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:17 | Steps: 7046 | Loss: 90.232320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:17 | Steps: 7048 | Loss: 90.243596\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:18 | Steps: 7050 | Loss: 90.246110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:18 | Steps: 7051 | Loss: 90.245539\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:18 | Steps: 7053 | Loss: 90.241233\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:18 | Steps: 7055 | Loss: 90.240995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:18 | Steps: 7056 | Loss: 90.237965\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:18 | Steps: 7057 | Loss: 90.234410\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:18 | Steps: 7059 | Loss: 90.235955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:19 | Steps: 7061 | Loss: 90.238311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:19 | Steps: 7063 | Loss: 90.237959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:19 | Steps: 7064 | Loss: 90.236384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:19 | Steps: 7065 | Loss: 90.239460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:19 | Steps: 7066 | Loss: 90.234548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:19 | Steps: 7068 | Loss: 90.231888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:20 | Steps: 7069 | Loss: 90.233479\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:20 | Steps: 7071 | Loss: 90.234779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:20 | Steps: 7073 | Loss: 90.231058\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:20 | Steps: 7074 | Loss: 90.232211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:20 | Steps: 7076 | Loss: 90.236982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:20 | Steps: 7077 | Loss: 90.239434\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:20 | Steps: 7078 | Loss: 90.239528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:21 | Steps: 7079 | Loss: 90.238244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:21 | Steps: 7080 | Loss: 90.235629\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:21 | Steps: 7081 | Loss: 90.236596\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:21 | Steps: 7083 | Loss: 90.242790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:21 | Steps: 7084 | Loss: 90.242182\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:21 | Steps: 7085 | Loss: 90.241193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:21 | Steps: 7086 | Loss: 90.240569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:21 | Steps: 7087 | Loss: 90.237762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:22 | Steps: 7088 | Loss: 90.235426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:22 | Steps: 7089 | Loss: 90.234594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:22 | Steps: 7090 | Loss: 90.232651\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:22 | Steps: 7092 | Loss: 90.234561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:22 | Steps: 7094 | Loss: 90.233683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:22 | Steps: 7096 | Loss: 90.236496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:22 | Steps: 7097 | Loss: 90.237038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:23 | Steps: 7098 | Loss: 90.237576\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:23 | Steps: 7100 | Loss: 90.235390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:23 | Steps: 7102 | Loss: 90.234479\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:23 | Steps: 7104 | Loss: 90.237702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:23 | Steps: 7106 | Loss: 90.235995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:23 | Steps: 7107 | Loss: 90.236204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:24 | Steps: 7108 | Loss: 90.236022\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:24 | Steps: 7109 | Loss: 90.234573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:24 | Steps: 7111 | Loss: 90.236580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:24 | Steps: 7112 | Loss: 90.234930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:24 | Steps: 7113 | Loss: 90.237240\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:24 | Steps: 7114 | Loss: 90.239332\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:24 | Steps: 7115 | Loss: 90.240193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:24 | Steps: 7117 | Loss: 90.244433\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:25 | Steps: 7118 | Loss: 90.240024\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:25 | Steps: 7119 | Loss: 90.236444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:25 | Steps: 7120 | Loss: 90.235514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:25 | Steps: 7121 | Loss: 90.234194\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:25 | Steps: 7122 | Loss: 90.237215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:25 | Steps: 7123 | Loss: 90.240876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:25 | Steps: 7124 | Loss: 90.242425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:25 | Steps: 7125 | Loss: 90.243462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:26 | Steps: 7126 | Loss: 90.238908\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:26 | Steps: 7127 | Loss: 90.234741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:26 | Steps: 7129 | Loss: 90.231119\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:26 | Steps: 7130 | Loss: 90.230267\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:26 | Steps: 7131 | Loss: 90.227597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:26 | Steps: 7132 | Loss: 90.226021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:26 | Steps: 7133 | Loss: 90.227690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:26 | Steps: 7134 | Loss: 90.226069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:27 | Steps: 7135 | Loss: 90.224135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:27 | Steps: 7136 | Loss: 90.220693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:27 | Steps: 7137 | Loss: 90.226166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:27 | Steps: 7139 | Loss: 90.230880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:27 | Steps: 7140 | Loss: 90.226982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:27 | Steps: 7142 | Loss: 90.231721\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:27 | Steps: 7143 | Loss: 90.231076\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:28 | Steps: 7145 | Loss: 90.227542\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:28 | Steps: 7147 | Loss: 90.224192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:28 | Steps: 7148 | Loss: 90.224758\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:28 | Steps: 7149 | Loss: 90.231994\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:28 | Steps: 7150 | Loss: 90.230865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:28 | Steps: 7152 | Loss: 90.233785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:28 | Steps: 7153 | Loss: 90.236896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:29 | Steps: 7154 | Loss: 90.239384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:29 | Steps: 7155 | Loss: 90.240478\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:29 | Steps: 7156 | Loss: 90.246798\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:29 | Steps: 7157 | Loss: 90.244197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:29 | Steps: 7159 | Loss: 90.240731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:29 | Steps: 7160 | Loss: 90.241441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:29 | Steps: 7161 | Loss: 90.242455\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:29 | Steps: 7163 | Loss: 90.243380\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:30 | Steps: 7165 | Loss: 90.242351\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:30 | Steps: 7166 | Loss: 90.244191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:30 | Steps: 7168 | Loss: 90.250363\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:30 | Steps: 7170 | Loss: 90.253649\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:30 | Steps: 7171 | Loss: 90.255810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:30 | Steps: 7172 | Loss: 90.255851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:31 | Steps: 7173 | Loss: 90.254597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:31 | Steps: 7174 | Loss: 90.251110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:31 | Steps: 7175 | Loss: 90.248076\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:31 | Steps: 7176 | Loss: 90.245501\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:31 | Steps: 7178 | Loss: 90.257198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:31 | Steps: 7180 | Loss: 90.263865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:31 | Steps: 7181 | Loss: 90.265227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:31 | Steps: 7182 | Loss: 90.263510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:32 | Steps: 7184 | Loss: 90.268465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:32 | Steps: 7185 | Loss: 90.277276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:32 | Steps: 7186 | Loss: 90.279538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:32 | Steps: 7187 | Loss: 90.282719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:32 | Steps: 7189 | Loss: 90.284890\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:32 | Steps: 7190 | Loss: 90.286065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:32 | Steps: 7191 | Loss: 90.289145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:33 | Steps: 7193 | Loss: 90.292197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:33 | Steps: 7194 | Loss: 90.292558\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:33 | Steps: 7196 | Loss: 90.289557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:33 | Steps: 7197 | Loss: 90.291497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:33 | Steps: 7199 | Loss: 90.282441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:33 | Steps: 7200 | Loss: 90.284906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:33 | Steps: 7201 | Loss: 90.290760\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:33 | Steps: 7202 | Loss: 90.289129\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:34 | Steps: 7204 | Loss: 90.288423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:34 | Steps: 7206 | Loss: 90.297525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:34 | Steps: 7207 | Loss: 90.295469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:34 | Steps: 7209 | Loss: 90.293781\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:34 | Steps: 7210 | Loss: 90.293941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:34 | Steps: 7211 | Loss: 90.299338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:35 | Steps: 7213 | Loss: 90.302174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:35 | Steps: 7215 | Loss: 90.300960\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:35 | Steps: 7216 | Loss: 90.301113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:35 | Steps: 7218 | Loss: 90.301632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:35 | Steps: 7219 | Loss: 90.299579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:35 | Steps: 7220 | Loss: 90.302029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:35 | Steps: 7222 | Loss: 90.305278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:36 | Steps: 7223 | Loss: 90.302983\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:36 | Steps: 7224 | Loss: 90.302047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:36 | Steps: 7226 | Loss: 90.302652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:36 | Steps: 7227 | Loss: 90.301969\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:36 | Steps: 7229 | Loss: 90.306412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:36 | Steps: 7231 | Loss: 90.310329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:36 | Steps: 7232 | Loss: 90.310174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:37 | Steps: 7233 | Loss: 90.307273\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:37 | Steps: 7235 | Loss: 90.314046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:37 | Steps: 7237 | Loss: 90.310726\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:37 | Steps: 7238 | Loss: 90.311155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:37 | Steps: 7239 | Loss: 90.312223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:37 | Steps: 7240 | Loss: 90.311144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:37 | Steps: 7241 | Loss: 90.311841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:38 | Steps: 7242 | Loss: 90.314782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:38 | Steps: 7244 | Loss: 90.320386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:38 | Steps: 7246 | Loss: 90.319878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:38 | Steps: 7248 | Loss: 90.325493\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:38 | Steps: 7249 | Loss: 90.325572\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:38 | Steps: 7250 | Loss: 90.331332\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:38 | Steps: 7251 | Loss: 90.333615\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:39 | Steps: 7252 | Loss: 90.334428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:39 | Steps: 7254 | Loss: 90.337396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:39 | Steps: 7255 | Loss: 90.333431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:39 | Steps: 7256 | Loss: 90.332499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:39 | Steps: 7258 | Loss: 90.332865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:39 | Steps: 7260 | Loss: 90.331245\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:39 | Steps: 7261 | Loss: 90.330293\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:40 | Steps: 7262 | Loss: 90.331499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:40 | Steps: 7263 | Loss: 90.332570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:40 | Steps: 7265 | Loss: 90.335011\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:40 | Steps: 7266 | Loss: 90.332373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:40 | Steps: 7267 | Loss: 90.330448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:40 | Steps: 7268 | Loss: 90.328303\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:40 | Steps: 7269 | Loss: 90.326995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:41 | Steps: 7271 | Loss: 90.323816\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:41 | Steps: 7273 | Loss: 90.328446\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:41 | Steps: 7274 | Loss: 90.331620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:41 | Steps: 7275 | Loss: 90.334951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:41 | Steps: 7276 | Loss: 90.339415\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:41 | Steps: 7278 | Loss: 90.339099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:41 | Steps: 7279 | Loss: 90.340639\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:42 | Steps: 7280 | Loss: 90.340961\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:42 | Steps: 7281 | Loss: 90.339113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:42 | Steps: 7282 | Loss: 90.338081\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:42 | Steps: 7283 | Loss: 90.337529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:42 | Steps: 7285 | Loss: 90.337223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:42 | Steps: 7286 | Loss: 90.337607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:42 | Steps: 7287 | Loss: 90.333901\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:42 | Steps: 7288 | Loss: 90.334151\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:43 | Steps: 7290 | Loss: 90.336960\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:43 | Steps: 7292 | Loss: 90.338791\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:43 | Steps: 7294 | Loss: 90.344722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:43 | Steps: 7296 | Loss: 90.347659\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:43 | Steps: 7297 | Loss: 90.346135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:43 | Steps: 7298 | Loss: 90.344669\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:43 | Steps: 7299 | Loss: 90.347124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:44 | Steps: 7300 | Loss: 90.343611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:44 | Steps: 7301 | Loss: 90.345027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:44 | Steps: 7302 | Loss: 90.350761\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:44 | Steps: 7303 | Loss: 90.353809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:44 | Steps: 7304 | Loss: 90.351582\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:44 | Steps: 7305 | Loss: 90.351187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:44 | Steps: 7306 | Loss: 90.351196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:44 | Steps: 7307 | Loss: 90.356774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:45 | Steps: 7309 | Loss: 90.361281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:45 | Steps: 7311 | Loss: 90.366278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:45 | Steps: 7312 | Loss: 90.364902\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:45 | Steps: 7314 | Loss: 90.372911\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:45 | Steps: 7316 | Loss: 90.371496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:46 | Steps: 7317 | Loss: 90.372125\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:46 | Steps: 7319 | Loss: 90.370767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:46 | Steps: 7320 | Loss: 90.374404\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:46 | Steps: 7321 | Loss: 90.376089\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:46 | Steps: 7322 | Loss: 90.375285\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:46 | Steps: 7324 | Loss: 90.383123\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:46 | Steps: 7326 | Loss: 90.394817\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:47 | Steps: 7327 | Loss: 90.393870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:47 | Steps: 7328 | Loss: 90.398761\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:47 | Steps: 7329 | Loss: 90.402451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:47 | Steps: 7330 | Loss: 90.402945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:47 | Steps: 7331 | Loss: 90.400650\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:47 | Steps: 7332 | Loss: 90.399009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:47 | Steps: 7333 | Loss: 90.397986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:47 | Steps: 7335 | Loss: 90.398032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:48 | Steps: 7337 | Loss: 90.390638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:48 | Steps: 7339 | Loss: 90.386144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:48 | Steps: 7340 | Loss: 90.386331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:48 | Steps: 7342 | Loss: 90.390277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:48 | Steps: 7343 | Loss: 90.391578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:48 | Steps: 7344 | Loss: 90.391173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:49 | Steps: 7346 | Loss: 90.390846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:49 | Steps: 7348 | Loss: 90.392791\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:49 | Steps: 7349 | Loss: 90.390892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:49 | Steps: 7350 | Loss: 90.394034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:49 | Steps: 7351 | Loss: 90.392788\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:49 | Steps: 7352 | Loss: 90.392275\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:49 | Steps: 7353 | Loss: 90.401558\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:49 | Steps: 7354 | Loss: 90.406000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:50 | Steps: 7356 | Loss: 90.409996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:50 | Steps: 7357 | Loss: 90.408330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:50 | Steps: 7358 | Loss: 90.409745\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:50 | Steps: 7360 | Loss: 90.407831\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:50 | Steps: 7362 | Loss: 90.401798\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:50 | Steps: 7363 | Loss: 90.402536\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:50 | Steps: 7365 | Loss: 90.399658\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:51 | Steps: 7366 | Loss: 90.398315\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:51 | Steps: 7367 | Loss: 90.400283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:51 | Steps: 7369 | Loss: 90.410389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:51 | Steps: 7370 | Loss: 90.411777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:51 | Steps: 7371 | Loss: 90.412985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:51 | Steps: 7372 | Loss: 90.416647\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:51 | Steps: 7374 | Loss: 90.418728\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:52 | Steps: 7376 | Loss: 90.413628\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:52 | Steps: 7377 | Loss: 90.414986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:52 | Steps: 7378 | Loss: 90.420765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:52 | Steps: 7379 | Loss: 90.421528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:52 | Steps: 7381 | Loss: 90.421792\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:52 | Steps: 7383 | Loss: 90.425910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:52 | Steps: 7384 | Loss: 90.427381\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:53 | Steps: 7385 | Loss: 90.427546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:53 | Steps: 7387 | Loss: 90.423995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:53 | Steps: 7388 | Loss: 90.421919\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:53 | Steps: 7389 | Loss: 90.422196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:53 | Steps: 7390 | Loss: 90.418338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:53 | Steps: 7391 | Loss: 90.416608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:53 | Steps: 7392 | Loss: 90.416933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:53 | Steps: 7393 | Loss: 90.421880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7394 | Loss: 90.425175\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7395 | Loss: 90.427331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7396 | Loss: 90.422717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7397 | Loss: 90.419095\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7398 | Loss: 90.419195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7399 | Loss: 90.419616\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7400 | Loss: 90.419208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7401 | Loss: 90.418347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7402 | Loss: 90.416127\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:54 | Steps: 7403 | Loss: 90.416127\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:55 | Steps: 7404 | Loss: 90.417021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:55 | Steps: 7405 | Loss: 90.416184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:55 | Steps: 7406 | Loss: 90.420172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:55 | Steps: 7407 | Loss: 90.426327\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:55 | Steps: 7408 | Loss: 90.426976\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:55 | Steps: 7410 | Loss: 90.431725\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:55 | Steps: 7411 | Loss: 90.432974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:55 | Steps: 7412 | Loss: 90.432686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:56 | Steps: 7413 | Loss: 90.431141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:56 | Steps: 7414 | Loss: 90.427133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:56 | Steps: 7415 | Loss: 90.426126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:56 | Steps: 7416 | Loss: 90.426303\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:56 | Steps: 7417 | Loss: 90.426491\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:56 | Steps: 7418 | Loss: 90.422151\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:56 | Steps: 7419 | Loss: 90.422805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:56 | Steps: 7421 | Loss: 90.430384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:57 | Steps: 7423 | Loss: 90.426894\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:57 | Steps: 7424 | Loss: 90.425553\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:57 | Steps: 7426 | Loss: 90.428992\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:57 | Steps: 7428 | Loss: 90.427995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:57 | Steps: 7429 | Loss: 90.426542\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:57 | Steps: 7431 | Loss: 90.433874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:58 | Steps: 7433 | Loss: 90.442046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:58 | Steps: 7434 | Loss: 90.449188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:58 | Steps: 7435 | Loss: 90.448742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:58 | Steps: 7436 | Loss: 90.450420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:58 | Steps: 7437 | Loss: 90.453566\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:58 | Steps: 7439 | Loss: 90.459051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:58 | Steps: 7440 | Loss: 90.462510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:59 | Steps: 7441 | Loss: 90.464910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:59 | Steps: 7442 | Loss: 90.464012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:59 | Steps: 7443 | Loss: 90.467338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:59 | Steps: 7444 | Loss: 90.464451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:59 | Steps: 7445 | Loss: 90.464160\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:59 | Steps: 7447 | Loss: 90.465947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:09:59 | Steps: 7449 | Loss: 90.460429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:00 | Steps: 7450 | Loss: 90.463998\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:00 | Steps: 7451 | Loss: 90.466626\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:00 | Steps: 7452 | Loss: 90.472874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:00 | Steps: 7453 | Loss: 90.476026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:00 | Steps: 7454 | Loss: 90.480365\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:00 | Steps: 7455 | Loss: 90.475752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:00 | Steps: 7456 | Loss: 90.477603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:00 | Steps: 7457 | Loss: 90.477271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:01 | Steps: 7459 | Loss: 90.479457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:01 | Steps: 7460 | Loss: 90.478972\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:01 | Steps: 7461 | Loss: 90.480238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:01 | Steps: 7462 | Loss: 90.475371\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:01 | Steps: 7463 | Loss: 90.471347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:01 | Steps: 7465 | Loss: 90.465351\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:01 | Steps: 7467 | Loss: 90.470628\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:02 | Steps: 7468 | Loss: 90.471900\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:02 | Steps: 7469 | Loss: 90.471868\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:02 | Steps: 7470 | Loss: 90.472157\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:02 | Steps: 7471 | Loss: 90.477573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:02 | Steps: 7473 | Loss: 90.475105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:02 | Steps: 7474 | Loss: 90.472500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:02 | Steps: 7476 | Loss: 90.476428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:03 | Steps: 7477 | Loss: 90.477318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:03 | Steps: 7479 | Loss: 90.474724\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:03 | Steps: 7480 | Loss: 90.473676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:03 | Steps: 7482 | Loss: 90.475579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:03 | Steps: 7483 | Loss: 90.479815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:03 | Steps: 7485 | Loss: 90.485177\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:03 | Steps: 7486 | Loss: 90.488258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:04 | Steps: 7488 | Loss: 90.488803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:04 | Steps: 7489 | Loss: 90.487807\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:04 | Steps: 7491 | Loss: 90.486446\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:04 | Steps: 7493 | Loss: 90.491667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:04 | Steps: 7494 | Loss: 90.489416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:04 | Steps: 7495 | Loss: 90.489186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:05 | Steps: 7497 | Loss: 90.495804\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:05 | Steps: 7499 | Loss: 90.496509\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:05 | Steps: 7500 | Loss: 90.497872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:05 | Steps: 7502 | Loss: 90.494777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:05 | Steps: 7503 | Loss: 90.490541\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:05 | Steps: 7504 | Loss: 90.488950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:05 | Steps: 7505 | Loss: 90.487149\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:06 | Steps: 7507 | Loss: 90.484426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:06 | Steps: 7508 | Loss: 90.485025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:06 | Steps: 7509 | Loss: 90.483219\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:06 | Steps: 7510 | Loss: 90.482535\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:06 | Steps: 7511 | Loss: 90.484506\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:06 | Steps: 7513 | Loss: 90.483623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:06 | Steps: 7514 | Loss: 90.485263\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:07 | Steps: 7516 | Loss: 90.482157\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:07 | Steps: 7518 | Loss: 90.480096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:07 | Steps: 7519 | Loss: 90.482262\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:07 | Steps: 7521 | Loss: 90.480879\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:07 | Steps: 7522 | Loss: 90.483043\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:07 | Steps: 7524 | Loss: 90.480316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:07 | Steps: 7525 | Loss: 90.480650\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:08 | Steps: 7526 | Loss: 90.483597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:08 | Steps: 7528 | Loss: 90.481282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:08 | Steps: 7530 | Loss: 90.480412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:08 | Steps: 7532 | Loss: 90.487571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:08 | Steps: 7533 | Loss: 90.487955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:08 | Steps: 7534 | Loss: 90.487268\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:09 | Steps: 7536 | Loss: 90.484223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:09 | Steps: 7537 | Loss: 90.482036\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:09 | Steps: 7538 | Loss: 90.480802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:09 | Steps: 7540 | Loss: 90.477976\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:09 | Steps: 7541 | Loss: 90.484153\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:09 | Steps: 7542 | Loss: 90.486563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:09 | Steps: 7543 | Loss: 90.484384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:09 | Steps: 7544 | Loss: 90.481586\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:10 | Steps: 7545 | Loss: 90.478854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:10 | Steps: 7546 | Loss: 90.477317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:10 | Steps: 7547 | Loss: 90.477923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:10 | Steps: 7548 | Loss: 90.479449\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:10 | Steps: 7549 | Loss: 90.479531\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:10 | Steps: 7550 | Loss: 90.480769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:10 | Steps: 7551 | Loss: 90.481383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:10 | Steps: 7552 | Loss: 90.477459\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:11 | Steps: 7554 | Loss: 90.474470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:11 | Steps: 7555 | Loss: 90.471950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:11 | Steps: 7557 | Loss: 90.476415\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:11 | Steps: 7559 | Loss: 90.472401\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:11 | Steps: 7560 | Loss: 90.473000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:11 | Steps: 7561 | Loss: 90.472785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:11 | Steps: 7562 | Loss: 90.471916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:11 | Steps: 7563 | Loss: 90.470220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:12 | Steps: 7564 | Loss: 90.472143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:12 | Steps: 7565 | Loss: 90.469063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:12 | Steps: 7566 | Loss: 90.474468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:12 | Steps: 7568 | Loss: 90.476104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:12 | Steps: 7570 | Loss: 90.487220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:12 | Steps: 7571 | Loss: 90.498649\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:12 | Steps: 7572 | Loss: 90.509940\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:13 | Steps: 7573 | Loss: 90.510617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:13 | Steps: 7574 | Loss: 90.514434\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:13 | Steps: 7575 | Loss: 90.514477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:13 | Steps: 7576 | Loss: 90.516192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:13 | Steps: 7578 | Loss: 90.523396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:13 | Steps: 7580 | Loss: 90.521127\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:13 | Steps: 7581 | Loss: 90.524259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7582 | Loss: 90.523803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7583 | Loss: 90.522292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7584 | Loss: 90.526850\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7585 | Loss: 90.526780\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7586 | Loss: 90.531568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7588 | Loss: 90.534382\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7589 | Loss: 90.539348\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7590 | Loss: 90.541740\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:14 | Steps: 7591 | Loss: 90.542575\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:15 | Steps: 7592 | Loss: 90.548413\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:15 | Steps: 7594 | Loss: 90.550466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:15 | Steps: 7596 | Loss: 90.553701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:15 | Steps: 7597 | Loss: 90.557116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:15 | Steps: 7598 | Loss: 90.559145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:15 | Steps: 7599 | Loss: 90.567292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:15 | Steps: 7600 | Loss: 90.566007\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:16 | Steps: 7601 | Loss: 90.568140\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:16 | Steps: 7602 | Loss: 90.565970\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:16 | Steps: 7603 | Loss: 90.564742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:16 | Steps: 7604 | Loss: 90.565000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:16 | Steps: 7606 | Loss: 90.565636\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:16 | Steps: 7608 | Loss: 90.571858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:16 | Steps: 7609 | Loss: 90.571892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:16 | Steps: 7610 | Loss: 90.570292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:17 | Steps: 7612 | Loss: 90.573051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:17 | Steps: 7613 | Loss: 90.575185\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:17 | Steps: 7614 | Loss: 90.577055\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:17 | Steps: 7615 | Loss: 90.575738\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:17 | Steps: 7616 | Loss: 90.574356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:17 | Steps: 7617 | Loss: 90.570608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:17 | Steps: 7619 | Loss: 90.571609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:18 | Steps: 7621 | Loss: 90.572497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:18 | Steps: 7622 | Loss: 90.571688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:18 | Steps: 7623 | Loss: 90.569896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:18 | Steps: 7624 | Loss: 90.568857\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:18 | Steps: 7625 | Loss: 90.568451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:18 | Steps: 7626 | Loss: 90.568080\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:18 | Steps: 7628 | Loss: 90.561051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:19 | Steps: 7629 | Loss: 90.556478\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:19 | Steps: 7630 | Loss: 90.556837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:19 | Steps: 7631 | Loss: 90.554351\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:19 | Steps: 7633 | Loss: 90.553014\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:19 | Steps: 7635 | Loss: 90.552407\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:19 | Steps: 7636 | Loss: 90.556101\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:19 | Steps: 7637 | Loss: 90.554374\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:20 | Steps: 7638 | Loss: 90.556037\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:20 | Steps: 7639 | Loss: 90.555858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:20 | Steps: 7641 | Loss: 90.558351\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:20 | Steps: 7643 | Loss: 90.556978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:20 | Steps: 7644 | Loss: 90.557451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:20 | Steps: 7646 | Loss: 90.556675\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:20 | Steps: 7647 | Loss: 90.558336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:21 | Steps: 7648 | Loss: 90.560990\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:21 | Steps: 7650 | Loss: 90.567884\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:21 | Steps: 7652 | Loss: 90.570981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:21 | Steps: 7654 | Loss: 90.571720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:21 | Steps: 7656 | Loss: 90.569377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:22 | Steps: 7657 | Loss: 90.568729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:22 | Steps: 7658 | Loss: 90.567737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:22 | Steps: 7659 | Loss: 90.568117\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:22 | Steps: 7660 | Loss: 90.567953\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:22 | Steps: 7662 | Loss: 90.566578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:22 | Steps: 7663 | Loss: 90.568702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:22 | Steps: 7664 | Loss: 90.570574\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:22 | Steps: 7665 | Loss: 90.571815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:23 | Steps: 7667 | Loss: 90.570631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:23 | Steps: 7668 | Loss: 90.568526\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:23 | Steps: 7669 | Loss: 90.571399\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:23 | Steps: 7670 | Loss: 90.573347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:23 | Steps: 7671 | Loss: 90.573319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:23 | Steps: 7672 | Loss: 90.576018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:23 | Steps: 7673 | Loss: 90.575728\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:23 | Steps: 7675 | Loss: 90.578179\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:24 | Steps: 7676 | Loss: 90.579811\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:24 | Steps: 7677 | Loss: 90.584114\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:24 | Steps: 7679 | Loss: 90.590087\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:24 | Steps: 7680 | Loss: 90.589505\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:24 | Steps: 7681 | Loss: 90.591118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:24 | Steps: 7682 | Loss: 90.589325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:24 | Steps: 7684 | Loss: 90.587422\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:25 | Steps: 7686 | Loss: 90.588364\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:25 | Steps: 7687 | Loss: 90.591785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:25 | Steps: 7688 | Loss: 90.588046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:25 | Steps: 7689 | Loss: 90.586909\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:25 | Steps: 7690 | Loss: 90.586394\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:25 | Steps: 7691 | Loss: 90.585032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:25 | Steps: 7692 | Loss: 90.583571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:25 | Steps: 7693 | Loss: 90.583007\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:26 | Steps: 7694 | Loss: 90.581350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:26 | Steps: 7696 | Loss: 90.578751\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:26 | Steps: 7698 | Loss: 90.584574\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:26 | Steps: 7700 | Loss: 90.580207\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:26 | Steps: 7701 | Loss: 90.581909\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:26 | Steps: 7702 | Loss: 90.580222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:27 | Steps: 7704 | Loss: 90.586636\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:27 | Steps: 7705 | Loss: 90.588840\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:27 | Steps: 7706 | Loss: 90.591155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:27 | Steps: 7707 | Loss: 90.590716\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:27 | Steps: 7709 | Loss: 90.589271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:27 | Steps: 7710 | Loss: 90.587143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:27 | Steps: 7711 | Loss: 90.588426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:27 | Steps: 7712 | Loss: 90.589338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:28 | Steps: 7713 | Loss: 90.593466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:28 | Steps: 7715 | Loss: 90.600796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:28 | Steps: 7717 | Loss: 90.605476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:28 | Steps: 7718 | Loss: 90.609398\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:28 | Steps: 7719 | Loss: 90.612946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:28 | Steps: 7720 | Loss: 90.615722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:28 | Steps: 7721 | Loss: 90.618285\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:29 | Steps: 7722 | Loss: 90.624191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:29 | Steps: 7723 | Loss: 90.623360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:29 | Steps: 7724 | Loss: 90.623105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:29 | Steps: 7726 | Loss: 90.626465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:29 | Steps: 7728 | Loss: 90.624176\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:29 | Steps: 7729 | Loss: 90.631230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:29 | Steps: 7730 | Loss: 90.629826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:29 | Steps: 7731 | Loss: 90.627847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:30 | Steps: 7732 | Loss: 90.629834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:30 | Steps: 7733 | Loss: 90.631145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:30 | Steps: 7734 | Loss: 90.638285\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:30 | Steps: 7736 | Loss: 90.642703\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:30 | Steps: 7737 | Loss: 90.647936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:30 | Steps: 7738 | Loss: 90.653359\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:30 | Steps: 7740 | Loss: 90.648478\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:31 | Steps: 7741 | Loss: 90.649306\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:31 | Steps: 7742 | Loss: 90.649061\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:31 | Steps: 7743 | Loss: 90.647958\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:31 | Steps: 7744 | Loss: 90.647715\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:31 | Steps: 7746 | Loss: 90.644414\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:31 | Steps: 7747 | Loss: 90.640557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:31 | Steps: 7749 | Loss: 90.637043\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:32 | Steps: 7750 | Loss: 90.639405\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:32 | Steps: 7751 | Loss: 90.638467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:32 | Steps: 7752 | Loss: 90.640196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:32 | Steps: 7753 | Loss: 90.644396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:32 | Steps: 7754 | Loss: 90.641180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:32 | Steps: 7755 | Loss: 90.640363\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:32 | Steps: 7756 | Loss: 90.642974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:32 | Steps: 7757 | Loss: 90.646184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:33 | Steps: 7759 | Loss: 90.645054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:33 | Steps: 7760 | Loss: 90.643640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:33 | Steps: 7762 | Loss: 90.644251\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:33 | Steps: 7763 | Loss: 90.645152\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:33 | Steps: 7764 | Loss: 90.647576\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:33 | Steps: 7765 | Loss: 90.647748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:33 | Steps: 7766 | Loss: 90.649706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:33 | Steps: 7767 | Loss: 90.650277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:34 | Steps: 7768 | Loss: 90.650013\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:34 | Steps: 7769 | Loss: 90.648780\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:34 | Steps: 7770 | Loss: 90.647500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:34 | Steps: 7771 | Loss: 90.645810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:34 | Steps: 7773 | Loss: 90.651153\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:34 | Steps: 7774 | Loss: 90.652306\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:34 | Steps: 7775 | Loss: 90.655663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:34 | Steps: 7776 | Loss: 90.653469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:35 | Steps: 7777 | Loss: 90.651281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:35 | Steps: 7778 | Loss: 90.653987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:35 | Steps: 7779 | Loss: 90.649534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:35 | Steps: 7781 | Loss: 90.644707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:35 | Steps: 7783 | Loss: 90.645572\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:35 | Steps: 7784 | Loss: 90.644668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:35 | Steps: 7785 | Loss: 90.646183\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:36 | Steps: 7786 | Loss: 90.647292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:36 | Steps: 7787 | Loss: 90.648428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:36 | Steps: 7788 | Loss: 90.655272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:36 | Steps: 7789 | Loss: 90.654408\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:36 | Steps: 7790 | Loss: 90.655698\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:36 | Steps: 7791 | Loss: 90.655750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:36 | Steps: 7793 | Loss: 90.656996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:37 | Steps: 7795 | Loss: 90.654986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:37 | Steps: 7796 | Loss: 90.658443\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:37 | Steps: 7797 | Loss: 90.663383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:37 | Steps: 7798 | Loss: 90.663082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:37 | Steps: 7799 | Loss: 90.662067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:37 | Steps: 7800 | Loss: 90.662557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:37 | Steps: 7801 | Loss: 90.658011\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:37 | Steps: 7803 | Loss: 90.658413\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:38 | Steps: 7805 | Loss: 90.661298\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:38 | Steps: 7806 | Loss: 90.667503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:38 | Steps: 7807 | Loss: 90.668533\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:38 | Steps: 7808 | Loss: 90.667150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:38 | Steps: 7809 | Loss: 90.665144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:38 | Steps: 7810 | Loss: 90.664322\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:38 | Steps: 7811 | Loss: 90.664259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:39 | Steps: 7813 | Loss: 90.657806\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:39 | Steps: 7815 | Loss: 90.666383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:39 | Steps: 7816 | Loss: 90.662800\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:39 | Steps: 7817 | Loss: 90.659709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:39 | Steps: 7818 | Loss: 90.654930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:39 | Steps: 7819 | Loss: 90.654400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:39 | Steps: 7820 | Loss: 90.653633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:39 | Steps: 7821 | Loss: 90.654689\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:40 | Steps: 7823 | Loss: 90.653012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:40 | Steps: 7825 | Loss: 90.649102\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:40 | Steps: 7826 | Loss: 90.647491\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:40 | Steps: 7827 | Loss: 90.648262\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:40 | Steps: 7828 | Loss: 90.648358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:40 | Steps: 7829 | Loss: 90.645633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:40 | Steps: 7830 | Loss: 90.645890\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:40 | Steps: 7831 | Loss: 90.646310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:41 | Steps: 7832 | Loss: 90.647846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:41 | Steps: 7833 | Loss: 90.650358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:41 | Steps: 7835 | Loss: 90.648011\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:41 | Steps: 7837 | Loss: 90.659288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:41 | Steps: 7838 | Loss: 90.659859\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:41 | Steps: 7840 | Loss: 90.663417\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:42 | Steps: 7841 | Loss: 90.666049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:42 | Steps: 7843 | Loss: 90.670582\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:42 | Steps: 7844 | Loss: 90.669366\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:42 | Steps: 7845 | Loss: 90.665417\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:42 | Steps: 7847 | Loss: 90.661136\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:42 | Steps: 7848 | Loss: 90.659773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:42 | Steps: 7849 | Loss: 90.659951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:43 | Steps: 7850 | Loss: 90.659915\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:43 | Steps: 7851 | Loss: 90.660668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:43 | Steps: 7852 | Loss: 90.664023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:43 | Steps: 7853 | Loss: 90.665630\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:43 | Steps: 7855 | Loss: 90.669918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:43 | Steps: 7856 | Loss: 90.670015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:43 | Steps: 7857 | Loss: 90.672210\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:43 | Steps: 7858 | Loss: 90.676064\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:44 | Steps: 7859 | Loss: 90.681404\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:44 | Steps: 7860 | Loss: 90.683427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:44 | Steps: 7861 | Loss: 90.685715\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:44 | Steps: 7862 | Loss: 90.683656\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:44 | Steps: 7863 | Loss: 90.682068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:44 | Steps: 7864 | Loss: 90.684540\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:44 | Steps: 7865 | Loss: 90.689092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:44 | Steps: 7867 | Loss: 90.689882\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7868 | Loss: 90.688774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7869 | Loss: 90.691004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7870 | Loss: 90.697348\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7871 | Loss: 90.700866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7872 | Loss: 90.704979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7873 | Loss: 90.705970\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7874 | Loss: 90.705641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7875 | Loss: 90.702416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:45 | Steps: 7876 | Loss: 90.702146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:46 | Steps: 7877 | Loss: 90.707041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:46 | Steps: 7878 | Loss: 90.707640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:46 | Steps: 7880 | Loss: 90.713944\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:46 | Steps: 7882 | Loss: 90.712639\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:46 | Steps: 7884 | Loss: 90.715313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:46 | Steps: 7885 | Loss: 90.716885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:47 | Steps: 7886 | Loss: 90.713838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:47 | Steps: 7887 | Loss: 90.717807\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:47 | Steps: 7889 | Loss: 90.714252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:47 | Steps: 7890 | Loss: 90.717195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:47 | Steps: 7891 | Loss: 90.721607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:47 | Steps: 7892 | Loss: 90.724019\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:47 | Steps: 7894 | Loss: 90.724047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:48 | Steps: 7896 | Loss: 90.724816\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:48 | Steps: 7897 | Loss: 90.726032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:48 | Steps: 7898 | Loss: 90.730656\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:48 | Steps: 7899 | Loss: 90.732319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:48 | Steps: 7900 | Loss: 90.735120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:48 | Steps: 7901 | Loss: 90.737625\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:48 | Steps: 7902 | Loss: 90.744305\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:49 | Steps: 7904 | Loss: 90.742755\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:49 | Steps: 7905 | Loss: 90.741566\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:49 | Steps: 7906 | Loss: 90.747244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:49 | Steps: 7907 | Loss: 90.745073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:49 | Steps: 7909 | Loss: 90.747776\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:49 | Steps: 7911 | Loss: 90.749466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:49 | Steps: 7912 | Loss: 90.748593\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:50 | Steps: 7913 | Loss: 90.747739\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:50 | Steps: 7914 | Loss: 90.749258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:50 | Steps: 7915 | Loss: 90.749674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:50 | Steps: 7916 | Loss: 90.755987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:50 | Steps: 7917 | Loss: 90.753466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:50 | Steps: 7918 | Loss: 90.758096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:50 | Steps: 7919 | Loss: 90.761136\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:50 | Steps: 7920 | Loss: 90.764848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:51 | Steps: 7921 | Loss: 90.767849\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:51 | Steps: 7923 | Loss: 90.770134\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:51 | Steps: 7925 | Loss: 90.767873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:51 | Steps: 7926 | Loss: 90.767451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:51 | Steps: 7927 | Loss: 90.770714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:51 | Steps: 7928 | Loss: 90.774675\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:52 | Steps: 7929 | Loss: 90.773333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:52 | Steps: 7930 | Loss: 90.772536\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:52 | Steps: 7931 | Loss: 90.771674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:52 | Steps: 7932 | Loss: 90.774386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:52 | Steps: 7933 | Loss: 90.772411\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:52 | Steps: 7934 | Loss: 90.769117\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7935 | Loss: 90.768879\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7936 | Loss: 90.774047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7937 | Loss: 90.778544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7938 | Loss: 90.780650\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7939 | Loss: 90.776976\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7940 | Loss: 90.777547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7941 | Loss: 90.779090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7942 | Loss: 90.778716\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:53 | Steps: 7943 | Loss: 90.782308\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:54 | Steps: 7944 | Loss: 90.781281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:54 | Steps: 7945 | Loss: 90.780623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:54 | Steps: 7946 | Loss: 90.779162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:54 | Steps: 7947 | Loss: 90.780695\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:54 | Steps: 7948 | Loss: 90.781622\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:54 | Steps: 7949 | Loss: 90.782732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:54 | Steps: 7950 | Loss: 90.783902\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:54 | Steps: 7951 | Loss: 90.783834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:55 | Steps: 7952 | Loss: 90.785345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:55 | Steps: 7953 | Loss: 90.785642\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:55 | Steps: 7954 | Loss: 90.785336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:55 | Steps: 7955 | Loss: 90.794786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:55 | Steps: 7956 | Loss: 90.797390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:55 | Steps: 7957 | Loss: 90.798401\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:55 | Steps: 7958 | Loss: 90.801510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:56 | Steps: 7959 | Loss: 90.801061\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:56 | Steps: 7960 | Loss: 90.800618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:56 | Steps: 7961 | Loss: 90.798917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:56 | Steps: 7962 | Loss: 90.799483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:56 | Steps: 7963 | Loss: 90.807221\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:56 | Steps: 7964 | Loss: 90.808381\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:56 | Steps: 7965 | Loss: 90.810287\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:56 | Steps: 7966 | Loss: 90.810703\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7967 | Loss: 90.809053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7968 | Loss: 90.807270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7969 | Loss: 90.805161\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7970 | Loss: 90.803132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7971 | Loss: 90.804881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7972 | Loss: 90.807336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7973 | Loss: 90.811462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7974 | Loss: 90.819292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:57 | Steps: 7975 | Loss: 90.826783\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:58 | Steps: 7976 | Loss: 90.830432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:58 | Steps: 7977 | Loss: 90.834286\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:58 | Steps: 7978 | Loss: 90.839779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:58 | Steps: 7979 | Loss: 90.843278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:58 | Steps: 7980 | Loss: 90.845147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:58 | Steps: 7981 | Loss: 90.846918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:58 | Steps: 7983 | Loss: 90.850594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:59 | Steps: 7984 | Loss: 90.852460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:59 | Steps: 7985 | Loss: 90.852018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:59 | Steps: 7986 | Loss: 90.852812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:59 | Steps: 7988 | Loss: 90.860749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:59 | Steps: 7989 | Loss: 90.861208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:59 | Steps: 7990 | Loss: 90.863226\n",
      "Epoch 0 |   Training | Elapsed Time: 0:10:59 | Steps: 7991 | Loss: 90.865386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:00 | Steps: 7993 | Loss: 90.859673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:00 | Steps: 7994 | Loss: 90.863250\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:00 | Steps: 7995 | Loss: 90.862354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:00 | Steps: 7996 | Loss: 90.860019\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:00 | Steps: 7997 | Loss: 90.861257\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:00 | Steps: 7999 | Loss: 90.860336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:00 | Steps: 8000 | Loss: 90.856170\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:01 | Steps: 8001 | Loss: 90.857118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:01 | Steps: 8002 | Loss: 90.855392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:01 | Steps: 8003 | Loss: 90.854749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:01 | Steps: 8004 | Loss: 90.855415\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:01 | Steps: 8005 | Loss: 90.852544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:01 | Steps: 8006 | Loss: 90.853320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:01 | Steps: 8007 | Loss: 90.853272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:01 | Steps: 8008 | Loss: 90.852760\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 8010 | Loss: 90.852140\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 8011 | Loss: 90.852847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 8012 | Loss: 90.853414\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 8013 | Loss: 90.853751\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 8014 | Loss: 90.857999\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 8015 | Loss: 90.860360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 8017 | Loss: 90.856843\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:03 | Steps: 8018 | Loss: 90.855936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:03 | Steps: 8019 | Loss: 90.851260\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:03 | Steps: 8020 | Loss: 90.854399\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:03 | Steps: 8021 | Loss: 90.856947\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:03 | Steps: 8023 | Loss: 90.863572\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:03 | Steps: 8024 | Loss: 90.867450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:03 | Steps: 8025 | Loss: 90.870330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:04 | Steps: 8026 | Loss: 90.868319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:04 | Steps: 8027 | Loss: 90.867242\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:04 | Steps: 8028 | Loss: 90.868102\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:04 | Steps: 8029 | Loss: 90.864548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:04 | Steps: 8030 | Loss: 90.860808\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:04 | Steps: 8031 | Loss: 90.860609\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:04 | Steps: 8032 | Loss: 90.859933\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:04 | Steps: 8033 | Loss: 90.862437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:05 | Steps: 8034 | Loss: 90.863350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:05 | Steps: 8035 | Loss: 90.864166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:05 | Steps: 8036 | Loss: 90.862928\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:05 | Steps: 8037 | Loss: 90.860995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:05 | Steps: 8038 | Loss: 90.859487\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:05 | Steps: 8039 | Loss: 90.858912\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:05 | Steps: 8040 | Loss: 90.858458\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:06 | Steps: 8041 | Loss: 90.857192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:06 | Steps: 8042 | Loss: 90.858643\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:06 | Steps: 8043 | Loss: 90.856183\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:06 | Steps: 8044 | Loss: 90.856748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:06 | Steps: 8045 | Loss: 90.854717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:06 | Steps: 8046 | Loss: 90.857772\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:06 | Steps: 8047 | Loss: 90.864199\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:06 | Steps: 8048 | Loss: 90.865271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:07 | Steps: 8049 | Loss: 90.867686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:07 | Steps: 8050 | Loss: 90.867385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:07 | Steps: 8051 | Loss: 90.866585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:07 | Steps: 8052 | Loss: 90.867250\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:07 | Steps: 8053 | Loss: 90.870312\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:07 | Steps: 8054 | Loss: 90.871889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:07 | Steps: 8055 | Loss: 90.870818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:08 | Steps: 8056 | Loss: 90.867335\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:08 | Steps: 8057 | Loss: 90.866133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:08 | Steps: 8058 | Loss: 90.864597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:08 | Steps: 8059 | Loss: 90.862289\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:08 | Steps: 8060 | Loss: 90.862848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:08 | Steps: 8061 | Loss: 90.864429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:09 | Steps: 8062 | Loss: 90.860795\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:09 | Steps: 8063 | Loss: 90.860746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:09 | Steps: 8064 | Loss: 90.859209\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:09 | Steps: 8065 | Loss: 90.859594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:09 | Steps: 8066 | Loss: 90.858056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:09 | Steps: 8067 | Loss: 90.857640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:09 | Steps: 8068 | Loss: 90.856684\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:09 | Steps: 8069 | Loss: 90.854793\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:10 | Steps: 8070 | Loss: 90.857320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:10 | Steps: 8071 | Loss: 90.863547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:10 | Steps: 8072 | Loss: 90.865803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:10 | Steps: 8073 | Loss: 90.865943\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:10 | Steps: 8074 | Loss: 90.865594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:10 | Steps: 8075 | Loss: 90.865168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:10 | Steps: 8076 | Loss: 90.866424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:11 | Steps: 8077 | Loss: 90.870922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:11 | Steps: 8078 | Loss: 90.872466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:11 | Steps: 8079 | Loss: 90.871848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:11 | Steps: 8080 | Loss: 90.872114\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:11 | Steps: 8081 | Loss: 90.870502\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:11 | Steps: 8082 | Loss: 90.870193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:11 | Steps: 8083 | Loss: 90.873500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:11 | Steps: 8084 | Loss: 90.877967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:12 | Steps: 8085 | Loss: 90.882208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:12 | Steps: 8086 | Loss: 90.883273\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:12 | Steps: 8087 | Loss: 90.886612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:12 | Steps: 8088 | Loss: 90.889673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:12 | Steps: 8089 | Loss: 90.894466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:12 | Steps: 8090 | Loss: 90.895626\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:12 | Steps: 8091 | Loss: 90.902882\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:12 | Steps: 8092 | Loss: 90.907590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:13 | Steps: 8094 | Loss: 90.909145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:13 | Steps: 8095 | Loss: 90.906665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:13 | Steps: 8096 | Loss: 90.904873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:13 | Steps: 8097 | Loss: 90.905449\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:13 | Steps: 8098 | Loss: 90.903129\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:13 | Steps: 8099 | Loss: 90.901737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:13 | Steps: 8100 | Loss: 90.902666\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:14 | Steps: 8102 | Loss: 90.911359\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:14 | Steps: 8103 | Loss: 90.914771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:14 | Steps: 8104 | Loss: 90.918361\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:14 | Steps: 8105 | Loss: 90.920998\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:14 | Steps: 8106 | Loss: 90.918071\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:14 | Steps: 8107 | Loss: 90.918754\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:14 | Steps: 8108 | Loss: 90.921776\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:15 | Steps: 8110 | Loss: 90.928802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:15 | Steps: 8111 | Loss: 90.927004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:15 | Steps: 8112 | Loss: 90.925244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:15 | Steps: 8113 | Loss: 90.924000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:15 | Steps: 8115 | Loss: 90.918370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:15 | Steps: 8116 | Loss: 90.914970\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:15 | Steps: 8117 | Loss: 90.911441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:15 | Steps: 8118 | Loss: 90.908928\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:16 | Steps: 8119 | Loss: 90.906482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:16 | Steps: 8121 | Loss: 90.913051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:16 | Steps: 8122 | Loss: 90.910187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:16 | Steps: 8123 | Loss: 90.907632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:16 | Steps: 8124 | Loss: 90.907139\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:16 | Steps: 8125 | Loss: 90.907512\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:16 | Steps: 8126 | Loss: 90.907948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:17 | Steps: 8127 | Loss: 90.909657\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:17 | Steps: 8128 | Loss: 90.909825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:17 | Steps: 8129 | Loss: 90.908248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:17 | Steps: 8131 | Loss: 90.907534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:17 | Steps: 8132 | Loss: 90.910390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:17 | Steps: 8133 | Loss: 90.913989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:17 | Steps: 8134 | Loss: 90.914230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:18 | Steps: 8136 | Loss: 90.912296\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:18 | Steps: 8137 | Loss: 90.911241\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:18 | Steps: 8138 | Loss: 90.913368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:18 | Steps: 8139 | Loss: 90.914247\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:18 | Steps: 8140 | Loss: 90.921426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:18 | Steps: 8141 | Loss: 90.922042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:18 | Steps: 8142 | Loss: 90.925638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:18 | Steps: 8143 | Loss: 90.925909\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8144 | Loss: 90.926621\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8145 | Loss: 90.929103\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8146 | Loss: 90.929751\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8147 | Loss: 90.926605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8148 | Loss: 90.924904\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8149 | Loss: 90.923251\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8150 | Loss: 90.924162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8151 | Loss: 90.926618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:19 | Steps: 8152 | Loss: 90.927015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:20 | Steps: 8153 | Loss: 90.928387\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:20 | Steps: 8154 | Loss: 90.930048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:20 | Steps: 8155 | Loss: 90.928544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:20 | Steps: 8156 | Loss: 90.927016\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:20 | Steps: 8158 | Loss: 90.931034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:20 | Steps: 8159 | Loss: 90.933741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:20 | Steps: 8160 | Loss: 90.934315\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:21 | Steps: 8161 | Loss: 90.933128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:21 | Steps: 8162 | Loss: 90.933283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:21 | Steps: 8163 | Loss: 90.931253\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:21 | Steps: 8164 | Loss: 90.927977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:21 | Steps: 8165 | Loss: 90.929810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:21 | Steps: 8166 | Loss: 90.926916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:21 | Steps: 8167 | Loss: 90.928025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:21 | Steps: 8168 | Loss: 90.925741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:22 | Steps: 8170 | Loss: 90.925633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:22 | Steps: 8171 | Loss: 90.926537\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:22 | Steps: 8172 | Loss: 90.926603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:22 | Steps: 8173 | Loss: 90.926431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:22 | Steps: 8175 | Loss: 90.933903\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:22 | Steps: 8177 | Loss: 90.931874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:23 | Steps: 8178 | Loss: 90.928211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:23 | Steps: 8179 | Loss: 90.931228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:23 | Steps: 8180 | Loss: 90.933412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:23 | Steps: 8182 | Loss: 90.934961\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:23 | Steps: 8183 | Loss: 90.931773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:23 | Steps: 8184 | Loss: 90.932607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:23 | Steps: 8185 | Loss: 90.934043\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:23 | Steps: 8186 | Loss: 90.934107\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:24 | Steps: 8187 | Loss: 90.935345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:24 | Steps: 8188 | Loss: 90.934285\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:24 | Steps: 8189 | Loss: 90.934389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:24 | Steps: 8190 | Loss: 90.932626\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:24 | Steps: 8191 | Loss: 90.933429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:24 | Steps: 8192 | Loss: 90.929883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:24 | Steps: 8193 | Loss: 90.925888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:24 | Steps: 8195 | Loss: 90.931562\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:25 | Steps: 8196 | Loss: 90.931374\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:25 | Steps: 8197 | Loss: 90.931549\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:25 | Steps: 8198 | Loss: 90.929291\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:25 | Steps: 8199 | Loss: 90.926813\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:25 | Steps: 8200 | Loss: 90.931233\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:25 | Steps: 8202 | Loss: 90.933876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:25 | Steps: 8203 | Loss: 90.938216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:25 | Steps: 8204 | Loss: 90.937977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:26 | Steps: 8205 | Loss: 90.941934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:26 | Steps: 8206 | Loss: 90.944858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:26 | Steps: 8207 | Loss: 90.946033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:26 | Steps: 8208 | Loss: 90.945353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:26 | Steps: 8209 | Loss: 90.944764\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:26 | Steps: 8211 | Loss: 90.949799\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:26 | Steps: 8212 | Loss: 90.949654\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8213 | Loss: 90.950867\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8214 | Loss: 90.948858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8215 | Loss: 90.952897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8216 | Loss: 90.957070\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8217 | Loss: 90.962025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8218 | Loss: 90.965291\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8219 | Loss: 90.966132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8220 | Loss: 90.968828\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:27 | Steps: 8221 | Loss: 90.970396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:28 | Steps: 8222 | Loss: 90.974937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:28 | Steps: 8223 | Loss: 90.973702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:28 | Steps: 8224 | Loss: 90.974673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:28 | Steps: 8225 | Loss: 90.975496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:28 | Steps: 8226 | Loss: 90.974350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:28 | Steps: 8227 | Loss: 90.978529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:28 | Steps: 8228 | Loss: 90.977872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:29 | Steps: 8230 | Loss: 90.977869\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:29 | Steps: 8231 | Loss: 90.979614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:29 | Steps: 8232 | Loss: 90.978841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:29 | Steps: 8233 | Loss: 90.985920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:29 | Steps: 8234 | Loss: 90.988426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:29 | Steps: 8236 | Loss: 90.995322\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:29 | Steps: 8237 | Loss: 90.998225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:29 | Steps: 8238 | Loss: 90.998347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:30 | Steps: 8239 | Loss: 91.001548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:30 | Steps: 8240 | Loss: 90.998677\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:30 | Steps: 8241 | Loss: 91.001146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:30 | Steps: 8242 | Loss: 90.997204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:30 | Steps: 8243 | Loss: 90.994310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:30 | Steps: 8244 | Loss: 90.997231\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:30 | Steps: 8246 | Loss: 90.996341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:30 | Steps: 8247 | Loss: 90.997765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:31 | Steps: 8249 | Loss: 91.003463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:31 | Steps: 8251 | Loss: 90.996607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:31 | Steps: 8252 | Loss: 90.995649\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:31 | Steps: 8253 | Loss: 90.995730\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:31 | Steps: 8254 | Loss: 90.994511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:31 | Steps: 8255 | Loss: 90.997570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:32 | Steps: 8257 | Loss: 90.995212\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:32 | Steps: 8258 | Loss: 90.993915\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:32 | Steps: 8259 | Loss: 90.993524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:32 | Steps: 8260 | Loss: 90.993883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:32 | Steps: 8261 | Loss: 90.994358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:32 | Steps: 8263 | Loss: 90.998071\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:32 | Steps: 8264 | Loss: 90.999271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:33 | Steps: 8266 | Loss: 90.993903\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:33 | Steps: 8267 | Loss: 90.993215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:33 | Steps: 8269 | Loss: 90.997119\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:33 | Steps: 8270 | Loss: 90.997920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:33 | Steps: 8271 | Loss: 91.000029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:33 | Steps: 8272 | Loss: 91.002223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:33 | Steps: 8273 | Loss: 91.005186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:34 | Steps: 8275 | Loss: 91.005226\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:34 | Steps: 8276 | Loss: 91.006108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:34 | Steps: 8277 | Loss: 91.004989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:34 | Steps: 8279 | Loss: 91.003959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:34 | Steps: 8280 | Loss: 91.003784\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:34 | Steps: 8281 | Loss: 91.003730\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:35 | Steps: 8282 | Loss: 91.004837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:35 | Steps: 8283 | Loss: 91.004617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:35 | Steps: 8284 | Loss: 91.002728\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:35 | Steps: 8285 | Loss: 91.006160\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:35 | Steps: 8286 | Loss: 91.008928\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:35 | Steps: 8287 | Loss: 91.009108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:35 | Steps: 8289 | Loss: 91.005608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:36 | Steps: 8290 | Loss: 91.007230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:36 | Steps: 8291 | Loss: 91.006469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:36 | Steps: 8292 | Loss: 91.007747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:36 | Steps: 8293 | Loss: 91.008139\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:36 | Steps: 8294 | Loss: 91.008834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:36 | Steps: 8295 | Loss: 91.012092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:36 | Steps: 8296 | Loss: 91.013422\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8298 | Loss: 91.020294\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8299 | Loss: 91.018142\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8300 | Loss: 91.017742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8301 | Loss: 91.015532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8302 | Loss: 91.014692\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8303 | Loss: 91.012045\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8304 | Loss: 91.011201\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8305 | Loss: 91.006339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:37 | Steps: 8306 | Loss: 91.008975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:38 | Steps: 8307 | Loss: 91.011255\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:38 | Steps: 8308 | Loss: 91.008821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:38 | Steps: 8309 | Loss: 91.008907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:38 | Steps: 8310 | Loss: 91.008804\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:38 | Steps: 8311 | Loss: 91.007931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:38 | Steps: 8312 | Loss: 91.008346\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:38 | Steps: 8313 | Loss: 91.006661\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:38 | Steps: 8314 | Loss: 91.006328\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:39 | Steps: 8315 | Loss: 91.004233\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:39 | Steps: 8316 | Loss: 91.003488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:39 | Steps: 8317 | Loss: 91.001164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:39 | Steps: 8318 | Loss: 91.001989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:39 | Steps: 8319 | Loss: 91.003122\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:39 | Steps: 8320 | Loss: 91.004403\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:39 | Steps: 8321 | Loss: 91.006470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:39 | Steps: 8323 | Loss: 91.007603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:40 | Steps: 8324 | Loss: 91.013182\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:40 | Steps: 8325 | Loss: 91.018693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:40 | Steps: 8326 | Loss: 91.017090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:40 | Steps: 8327 | Loss: 91.017018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:40 | Steps: 8328 | Loss: 91.020164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:40 | Steps: 8330 | Loss: 91.022054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:40 | Steps: 8331 | Loss: 91.027341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:40 | Steps: 8332 | Loss: 91.037889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:41 | Steps: 8333 | Loss: 91.037255\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:41 | Steps: 8334 | Loss: 91.038093\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:41 | Steps: 8335 | Loss: 91.042481\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:41 | Steps: 8336 | Loss: 91.046225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:41 | Steps: 8338 | Loss: 91.046218\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:41 | Steps: 8339 | Loss: 91.043886\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:42 | Steps: 8340 | Loss: 91.044783\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:42 | Steps: 8341 | Loss: 91.048800\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:42 | Steps: 8342 | Loss: 91.048099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:42 | Steps: 8343 | Loss: 91.049732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:42 | Steps: 8344 | Loss: 91.051118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:42 | Steps: 8345 | Loss: 91.052313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:42 | Steps: 8347 | Loss: 91.050902\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:43 | Steps: 8348 | Loss: 91.053053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:43 | Steps: 8349 | Loss: 91.050052\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:43 | Steps: 8350 | Loss: 91.048769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:43 | Steps: 8351 | Loss: 91.049979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:43 | Steps: 8352 | Loss: 91.060341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:43 | Steps: 8353 | Loss: 91.060703\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:43 | Steps: 8354 | Loss: 91.063546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:43 | Steps: 8355 | Loss: 91.065520\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:44 | Steps: 8356 | Loss: 91.069645\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:44 | Steps: 8357 | Loss: 91.076589\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:44 | Steps: 8358 | Loss: 91.080348\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:44 | Steps: 8360 | Loss: 91.075833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:44 | Steps: 8361 | Loss: 91.074253\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:44 | Steps: 8362 | Loss: 91.071438\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:44 | Steps: 8364 | Loss: 91.069713\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:45 | Steps: 8365 | Loss: 91.067289\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:45 | Steps: 8366 | Loss: 91.068493\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:45 | Steps: 8367 | Loss: 91.064084\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:45 | Steps: 8368 | Loss: 91.061348\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:45 | Steps: 8369 | Loss: 91.060123\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:45 | Steps: 8370 | Loss: 91.059120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:45 | Steps: 8371 | Loss: 91.063311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:45 | Steps: 8372 | Loss: 91.063827\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:46 | Steps: 8373 | Loss: 91.065470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:46 | Steps: 8374 | Loss: 91.068430\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:46 | Steps: 8375 | Loss: 91.069529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:46 | Steps: 8376 | Loss: 91.067579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:46 | Steps: 8377 | Loss: 91.067955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:46 | Steps: 8378 | Loss: 91.071008\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:46 | Steps: 8380 | Loss: 91.065919\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:47 | Steps: 8381 | Loss: 91.067722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:47 | Steps: 8382 | Loss: 91.067236\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:47 | Steps: 8383 | Loss: 91.070765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:47 | Steps: 8385 | Loss: 91.072563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:47 | Steps: 8386 | Loss: 91.069313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:47 | Steps: 8387 | Loss: 91.069370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:47 | Steps: 8388 | Loss: 91.070494\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:48 | Steps: 8389 | Loss: 91.072920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:48 | Steps: 8390 | Loss: 91.076265\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:48 | Steps: 8391 | Loss: 91.075568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:48 | Steps: 8392 | Loss: 91.076202\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:48 | Steps: 8394 | Loss: 91.077982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:48 | Steps: 8395 | Loss: 91.081330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:48 | Steps: 8396 | Loss: 91.082466\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:48 | Steps: 8397 | Loss: 91.083700\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:49 | Steps: 8398 | Loss: 91.080499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:49 | Steps: 8399 | Loss: 91.083865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:49 | Steps: 8401 | Loss: 91.089108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:49 | Steps: 8402 | Loss: 91.089809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:49 | Steps: 8403 | Loss: 91.089985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:49 | Steps: 8404 | Loss: 91.090594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:49 | Steps: 8405 | Loss: 91.093492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:50 | Steps: 8407 | Loss: 91.091177\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:50 | Steps: 8408 | Loss: 91.089374\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:50 | Steps: 8409 | Loss: 91.089495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:50 | Steps: 8410 | Loss: 91.087709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:50 | Steps: 8412 | Loss: 91.085831\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:50 | Steps: 8413 | Loss: 91.090236\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:50 | Steps: 8414 | Loss: 91.091906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:51 | Steps: 8416 | Loss: 91.089428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:51 | Steps: 8418 | Loss: 91.089264\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:51 | Steps: 8419 | Loss: 91.089492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:51 | Steps: 8420 | Loss: 91.091135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:51 | Steps: 8421 | Loss: 91.091800\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:51 | Steps: 8422 | Loss: 91.092044\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:52 | Steps: 8424 | Loss: 91.092440\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:52 | Steps: 8425 | Loss: 91.092224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:52 | Steps: 8426 | Loss: 91.095886\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:52 | Steps: 8427 | Loss: 91.098872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:52 | Steps: 8429 | Loss: 91.098599\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:52 | Steps: 8430 | Loss: 91.097207\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:52 | Steps: 8431 | Loss: 91.097473\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8432 | Loss: 91.097552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8433 | Loss: 91.096278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8434 | Loss: 91.094027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8435 | Loss: 91.095376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8436 | Loss: 91.099483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8437 | Loss: 91.106005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8438 | Loss: 91.106833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8439 | Loss: 91.106999\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:53 | Steps: 8440 | Loss: 91.107343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:54 | Steps: 8442 | Loss: 91.114224\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:54 | Steps: 8443 | Loss: 91.117425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:54 | Steps: 8444 | Loss: 91.121910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:54 | Steps: 8445 | Loss: 91.126858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:54 | Steps: 8446 | Loss: 91.126188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:54 | Steps: 8447 | Loss: 91.125368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:54 | Steps: 8448 | Loss: 91.124052\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:55 | Steps: 8449 | Loss: 91.123812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:55 | Steps: 8450 | Loss: 91.124623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:55 | Steps: 8451 | Loss: 91.123720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:55 | Steps: 8452 | Loss: 91.123563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:55 | Steps: 8453 | Loss: 91.122497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:55 | Steps: 8454 | Loss: 91.124796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:55 | Steps: 8455 | Loss: 91.125794\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:55 | Steps: 8456 | Loss: 91.123208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:56 | Steps: 8457 | Loss: 91.123309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:56 | Steps: 8458 | Loss: 91.124750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:56 | Steps: 8459 | Loss: 91.129640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:56 | Steps: 8460 | Loss: 91.129211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:56 | Steps: 8462 | Loss: 91.125353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:56 | Steps: 8463 | Loss: 91.127848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:56 | Steps: 8464 | Loss: 91.125561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:56 | Steps: 8465 | Loss: 91.121602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:57 | Steps: 8466 | Loss: 91.120672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:57 | Steps: 8467 | Loss: 91.123894\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:57 | Steps: 8468 | Loss: 91.125766\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:57 | Steps: 8469 | Loss: 91.129472\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:57 | Steps: 8470 | Loss: 91.131232\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:57 | Steps: 8471 | Loss: 91.129195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:57 | Steps: 8472 | Loss: 91.125937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:57 | Steps: 8473 | Loss: 91.122590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:58 | Steps: 8474 | Loss: 91.121866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:58 | Steps: 8475 | Loss: 91.124584\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:58 | Steps: 8476 | Loss: 91.126249\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:58 | Steps: 8477 | Loss: 91.127290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:58 | Steps: 8479 | Loss: 91.127021\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:58 | Steps: 8480 | Loss: 91.126574\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:58 | Steps: 8481 | Loss: 91.128952\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:59 | Steps: 8482 | Loss: 91.129866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:59 | Steps: 8483 | Loss: 91.132526\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:59 | Steps: 8484 | Loss: 91.131387\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:59 | Steps: 8485 | Loss: 91.129590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:59 | Steps: 8486 | Loss: 91.130519\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:59 | Steps: 8487 | Loss: 91.130231\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:59 | Steps: 8489 | Loss: 91.133258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:11:59 | Steps: 8490 | Loss: 91.132380\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:00 | Steps: 8491 | Loss: 91.128605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:00 | Steps: 8492 | Loss: 91.133511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:00 | Steps: 8493 | Loss: 91.131330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:00 | Steps: 8494 | Loss: 91.132481\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:00 | Steps: 8495 | Loss: 91.131318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:00 | Steps: 8496 | Loss: 91.133300\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:00 | Steps: 8497 | Loss: 91.134659\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:00 | Steps: 8498 | Loss: 91.131239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:01 | Steps: 8499 | Loss: 91.130370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:01 | Steps: 8500 | Loss: 91.130230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:01 | Steps: 8501 | Loss: 91.136502\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:01 | Steps: 8502 | Loss: 91.137309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:01 | Steps: 8503 | Loss: 91.139613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:01 | Steps: 8504 | Loss: 91.139822\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:01 | Steps: 8506 | Loss: 91.143905\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:02 | Steps: 8507 | Loss: 91.141971\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:02 | Steps: 8508 | Loss: 91.142837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:02 | Steps: 8509 | Loss: 91.142213\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:02 | Steps: 8510 | Loss: 91.142984\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:02 | Steps: 8512 | Loss: 91.143784\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:02 | Steps: 8513 | Loss: 91.147838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:02 | Steps: 8514 | Loss: 91.150499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:03 | Steps: 8515 | Loss: 91.150336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:03 | Steps: 8517 | Loss: 91.151177\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:03 | Steps: 8518 | Loss: 91.147516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:03 | Steps: 8519 | Loss: 91.146763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:03 | Steps: 8520 | Loss: 91.151570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:03 | Steps: 8522 | Loss: 91.148741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:03 | Steps: 8523 | Loss: 91.149002\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:04 | Steps: 8524 | Loss: 91.149596\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:04 | Steps: 8525 | Loss: 91.152215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:04 | Steps: 8526 | Loss: 91.152460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:04 | Steps: 8528 | Loss: 91.151765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:04 | Steps: 8529 | Loss: 91.150275\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:04 | Steps: 8530 | Loss: 91.149180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:04 | Steps: 8531 | Loss: 91.148158\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:05 | Steps: 8532 | Loss: 91.148288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:05 | Steps: 8533 | Loss: 91.148744\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:05 | Steps: 8534 | Loss: 91.149516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:05 | Steps: 8535 | Loss: 91.147805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:05 | Steps: 8537 | Loss: 91.149010\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:05 | Steps: 8538 | Loss: 91.147967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:05 | Steps: 8539 | Loss: 91.148128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:06 | Steps: 8540 | Loss: 91.146693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:06 | Steps: 8542 | Loss: 91.151015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:06 | Steps: 8543 | Loss: 91.151929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:06 | Steps: 8544 | Loss: 91.153067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:06 | Steps: 8545 | Loss: 91.155132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:06 | Steps: 8546 | Loss: 91.154390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:07 | Steps: 8548 | Loss: 91.163198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:07 | Steps: 8549 | Loss: 91.160538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:07 | Steps: 8550 | Loss: 91.158914\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:07 | Steps: 8551 | Loss: 91.157113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:07 | Steps: 8552 | Loss: 91.157033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:07 | Steps: 8553 | Loss: 91.159174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:07 | Steps: 8554 | Loss: 91.158270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:07 | Steps: 8555 | Loss: 91.165050\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:08 | Steps: 8556 | Loss: 91.165987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:08 | Steps: 8557 | Loss: 91.167389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:08 | Steps: 8558 | Loss: 91.170744\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:08 | Steps: 8559 | Loss: 91.172104\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:08 | Steps: 8560 | Loss: 91.177528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:08 | Steps: 8562 | Loss: 91.177685\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:08 | Steps: 8563 | Loss: 91.174611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:08 | Steps: 8564 | Loss: 91.174366\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:09 | Steps: 8565 | Loss: 91.172838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:09 | Steps: 8567 | Loss: 91.171895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:09 | Steps: 8568 | Loss: 91.174126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:09 | Steps: 8569 | Loss: 91.175258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:09 | Steps: 8570 | Loss: 91.176776\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:09 | Steps: 8571 | Loss: 91.182376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:09 | Steps: 8572 | Loss: 91.189015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:09 | Steps: 8573 | Loss: 91.191169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:10 | Steps: 8574 | Loss: 91.192243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:10 | Steps: 8575 | Loss: 91.189759\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:10 | Steps: 8576 | Loss: 91.188683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:10 | Steps: 8577 | Loss: 91.187923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:10 | Steps: 8578 | Loss: 91.186020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:10 | Steps: 8579 | Loss: 91.184955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:10 | Steps: 8580 | Loss: 91.182406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:10 | Steps: 8581 | Loss: 91.178297\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:11 | Steps: 8583 | Loss: 91.172737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:11 | Steps: 8584 | Loss: 91.170371\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:11 | Steps: 8585 | Loss: 91.172612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:11 | Steps: 8586 | Loss: 91.173011\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:11 | Steps: 8588 | Loss: 91.173758\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:11 | Steps: 8589 | Loss: 91.175005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:12 | Steps: 8590 | Loss: 91.175206\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:12 | Steps: 8591 | Loss: 91.176281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:12 | Steps: 8592 | Loss: 91.175587\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:12 | Steps: 8593 | Loss: 91.177700\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:12 | Steps: 8594 | Loss: 91.179862\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:12 | Steps: 8595 | Loss: 91.184118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:12 | Steps: 8596 | Loss: 91.183520\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:12 | Steps: 8597 | Loss: 91.184779\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:13 | Steps: 8598 | Loss: 91.182664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:13 | Steps: 8599 | Loss: 91.182698\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:13 | Steps: 8600 | Loss: 91.182250\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:13 | Steps: 8601 | Loss: 91.181290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:13 | Steps: 8602 | Loss: 91.179938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:13 | Steps: 8603 | Loss: 91.182538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:13 | Steps: 8604 | Loss: 91.183321\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:13 | Steps: 8605 | Loss: 91.184900\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8606 | Loss: 91.188775\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8607 | Loss: 91.189156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8608 | Loss: 91.191835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8609 | Loss: 91.192365\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8610 | Loss: 91.187736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8611 | Loss: 91.185429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8612 | Loss: 91.186427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8613 | Loss: 91.186067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:14 | Steps: 8614 | Loss: 91.184734\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:15 | Steps: 8615 | Loss: 91.185782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:15 | Steps: 8616 | Loss: 91.189325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:15 | Steps: 8617 | Loss: 91.195702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:15 | Steps: 8618 | Loss: 91.197340\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:15 | Steps: 8620 | Loss: 91.197777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:15 | Steps: 8621 | Loss: 91.197762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:16 | Steps: 8623 | Loss: 91.200117\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:16 | Steps: 8624 | Loss: 91.202907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:16 | Steps: 8625 | Loss: 91.200244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:16 | Steps: 8627 | Loss: 91.198817\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:16 | Steps: 8628 | Loss: 91.198978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:16 | Steps: 8629 | Loss: 91.198269\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:16 | Steps: 8630 | Loss: 91.199634\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:17 | Steps: 8632 | Loss: 91.200973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:17 | Steps: 8633 | Loss: 91.203370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:17 | Steps: 8634 | Loss: 91.206370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:17 | Steps: 8635 | Loss: 91.202733\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:17 | Steps: 8637 | Loss: 91.201072\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:17 | Steps: 8638 | Loss: 91.201405\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:18 | Steps: 8639 | Loss: 91.198303\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:18 | Steps: 8640 | Loss: 91.196821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:18 | Steps: 8641 | Loss: 91.201551\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:18 | Steps: 8642 | Loss: 91.203452\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:18 | Steps: 8643 | Loss: 91.204295\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:18 | Steps: 8644 | Loss: 91.206587\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:19 | Steps: 8645 | Loss: 91.207851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:19 | Steps: 8646 | Loss: 91.209617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:19 | Steps: 8647 | Loss: 91.208035\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:19 | Steps: 8648 | Loss: 91.207133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:19 | Steps: 8650 | Loss: 91.212592\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:19 | Steps: 8651 | Loss: 91.211006\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:19 | Steps: 8652 | Loss: 91.214679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:20 | Steps: 8653 | Loss: 91.217048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:20 | Steps: 8654 | Loss: 91.218670\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:20 | Steps: 8655 | Loss: 91.217543\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:20 | Steps: 8656 | Loss: 91.216061\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:20 | Steps: 8657 | Loss: 91.219818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:20 | Steps: 8658 | Loss: 91.222396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:20 | Steps: 8659 | Loss: 91.230220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:20 | Steps: 8660 | Loss: 91.244322\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:21 | Steps: 8661 | Loss: 91.246495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:21 | Steps: 8662 | Loss: 91.249291\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:21 | Steps: 8663 | Loss: 91.252232\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:21 | Steps: 8664 | Loss: 91.262683\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:21 | Steps: 8665 | Loss: 91.265188\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:21 | Steps: 8666 | Loss: 91.265098\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:21 | Steps: 8667 | Loss: 91.265079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:21 | Steps: 8668 | Loss: 91.265958\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:22 | Steps: 8669 | Loss: 91.267610\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:22 | Steps: 8670 | Loss: 91.267557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:22 | Steps: 8671 | Loss: 91.271510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:22 | Steps: 8672 | Loss: 91.270374\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:22 | Steps: 8673 | Loss: 91.277132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:22 | Steps: 8674 | Loss: 91.280413\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:22 | Steps: 8675 | Loss: 91.284144\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:22 | Steps: 8676 | Loss: 91.288507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:23 | Steps: 8677 | Loss: 91.287074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:23 | Steps: 8679 | Loss: 91.288855\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:23 | Steps: 8680 | Loss: 91.296531\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:23 | Steps: 8681 | Loss: 91.295285\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:23 | Steps: 8682 | Loss: 91.296338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:23 | Steps: 8683 | Loss: 91.297215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:24 | Steps: 8684 | Loss: 91.299455\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:24 | Steps: 8685 | Loss: 91.304098\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:24 | Steps: 8686 | Loss: 91.311728\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:24 | Steps: 8687 | Loss: 91.313063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:24 | Steps: 8688 | Loss: 91.315970\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:24 | Steps: 8689 | Loss: 91.321733\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:24 | Steps: 8690 | Loss: 91.324389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:25 | Steps: 8691 | Loss: 91.326977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:25 | Steps: 8693 | Loss: 91.327264\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:25 | Steps: 8694 | Loss: 91.325252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:25 | Steps: 8695 | Loss: 91.322839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:25 | Steps: 8696 | Loss: 91.321274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:25 | Steps: 8697 | Loss: 91.321585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:25 | Steps: 8698 | Loss: 91.320926\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:26 | Steps: 8699 | Loss: 91.317772\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:26 | Steps: 8700 | Loss: 91.319865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:26 | Steps: 8701 | Loss: 91.328269\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:26 | Steps: 8702 | Loss: 91.326377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:26 | Steps: 8704 | Loss: 91.321169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:26 | Steps: 8705 | Loss: 91.321029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:26 | Steps: 8706 | Loss: 91.320334\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:27 | Steps: 8707 | Loss: 91.322493\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:27 | Steps: 8708 | Loss: 91.323659\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:27 | Steps: 8709 | Loss: 91.324346\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:27 | Steps: 8710 | Loss: 91.327255\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:27 | Steps: 8711 | Loss: 91.327691\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:27 | Steps: 8712 | Loss: 91.328717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:27 | Steps: 8713 | Loss: 91.331484\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:28 | Steps: 8714 | Loss: 91.336760\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:28 | Steps: 8715 | Loss: 91.337987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:28 | Steps: 8716 | Loss: 91.343306\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:28 | Steps: 8717 | Loss: 91.341164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:28 | Steps: 8718 | Loss: 91.342722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:28 | Steps: 8719 | Loss: 91.347522\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:28 | Steps: 8720 | Loss: 91.351505\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:29 | Steps: 8721 | Loss: 91.351922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:29 | Steps: 8722 | Loss: 91.350579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:29 | Steps: 8723 | Loss: 91.348822\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:29 | Steps: 8724 | Loss: 91.348723\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:29 | Steps: 8725 | Loss: 91.351347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:29 | Steps: 8726 | Loss: 91.348014\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:29 | Steps: 8727 | Loss: 91.346127\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:30 | Steps: 8728 | Loss: 91.345671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:30 | Steps: 8729 | Loss: 91.347914\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:30 | Steps: 8730 | Loss: 91.347752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:30 | Steps: 8731 | Loss: 91.347548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:30 | Steps: 8732 | Loss: 91.346967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:30 | Steps: 8733 | Loss: 91.347476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:30 | Steps: 8734 | Loss: 91.346521\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:31 | Steps: 8735 | Loss: 91.346333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:31 | Steps: 8736 | Loss: 91.349212\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:31 | Steps: 8737 | Loss: 91.352917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:31 | Steps: 8738 | Loss: 91.353507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:31 | Steps: 8739 | Loss: 91.353341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:31 | Steps: 8740 | Loss: 91.355797\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:31 | Steps: 8741 | Loss: 91.354045\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:32 | Steps: 8742 | Loss: 91.351306\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:32 | Steps: 8743 | Loss: 91.352111\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:32 | Steps: 8745 | Loss: 91.352423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:32 | Steps: 8746 | Loss: 91.348806\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:32 | Steps: 8747 | Loss: 91.347590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:32 | Steps: 8748 | Loss: 91.347320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:32 | Steps: 8749 | Loss: 91.350563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:33 | Steps: 8750 | Loss: 91.351322\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:33 | Steps: 8751 | Loss: 91.352225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:33 | Steps: 8752 | Loss: 91.351113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:33 | Steps: 8753 | Loss: 91.350737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:33 | Steps: 8755 | Loss: 91.349865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:33 | Steps: 8756 | Loss: 91.349061\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:34 | Steps: 8758 | Loss: 91.352464\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:34 | Steps: 8759 | Loss: 91.350756\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:34 | Steps: 8760 | Loss: 91.351728\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:34 | Steps: 8761 | Loss: 91.352317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:34 | Steps: 8762 | Loss: 91.350435\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:34 | Steps: 8763 | Loss: 91.349476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:34 | Steps: 8764 | Loss: 91.351143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:34 | Steps: 8765 | Loss: 91.351967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:35 | Steps: 8766 | Loss: 91.357746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:35 | Steps: 8767 | Loss: 91.358742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:35 | Steps: 8768 | Loss: 91.359181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:35 | Steps: 8769 | Loss: 91.358727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:35 | Steps: 8771 | Loss: 91.366957\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:35 | Steps: 8772 | Loss: 91.371524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:35 | Steps: 8773 | Loss: 91.372417\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:36 | Steps: 8774 | Loss: 91.374587\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:36 | Steps: 8776 | Loss: 91.375158\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:36 | Steps: 8777 | Loss: 91.373845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:36 | Steps: 8778 | Loss: 91.377448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:36 | Steps: 8779 | Loss: 91.377179\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:36 | Steps: 8780 | Loss: 91.380824\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:36 | Steps: 8781 | Loss: 91.381032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:37 | Steps: 8782 | Loss: 91.384238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:37 | Steps: 8783 | Loss: 91.385669\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:37 | Steps: 8784 | Loss: 91.389286\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:37 | Steps: 8786 | Loss: 91.395048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:37 | Steps: 8787 | Loss: 91.392924\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:37 | Steps: 8788 | Loss: 91.389913\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:38 | Steps: 8789 | Loss: 91.389077\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:38 | Steps: 8791 | Loss: 91.390248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:38 | Steps: 8792 | Loss: 91.395830\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:38 | Steps: 8793 | Loss: 91.399967\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:38 | Steps: 8794 | Loss: 91.397406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:38 | Steps: 8795 | Loss: 91.396993\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:38 | Steps: 8796 | Loss: 91.400594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:39 | Steps: 8797 | Loss: 91.400230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:39 | Steps: 8798 | Loss: 91.402935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:39 | Steps: 8799 | Loss: 91.401822\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:39 | Steps: 8800 | Loss: 91.399127\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:39 | Steps: 8801 | Loss: 91.397573\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:39 | Steps: 8802 | Loss: 91.396747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:39 | Steps: 8803 | Loss: 91.394231\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:39 | Steps: 8804 | Loss: 91.393841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:40 | Steps: 8805 | Loss: 91.396027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:40 | Steps: 8806 | Loss: 91.398352\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:40 | Steps: 8807 | Loss: 91.400870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:40 | Steps: 8808 | Loss: 91.401830\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:40 | Steps: 8809 | Loss: 91.404512\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:40 | Steps: 8810 | Loss: 91.405922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:40 | Steps: 8811 | Loss: 91.405133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:40 | Steps: 8812 | Loss: 91.404905\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:41 | Steps: 8813 | Loss: 91.404066\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:41 | Steps: 8814 | Loss: 91.407652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:41 | Steps: 8815 | Loss: 91.408025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:41 | Steps: 8816 | Loss: 91.411026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:41 | Steps: 8817 | Loss: 91.413076\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:41 | Steps: 8818 | Loss: 91.414692\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:41 | Steps: 8820 | Loss: 91.417912\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:42 | Steps: 8821 | Loss: 91.415815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:42 | Steps: 8822 | Loss: 91.412607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:42 | Steps: 8823 | Loss: 91.411301\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:42 | Steps: 8824 | Loss: 91.412717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:42 | Steps: 8825 | Loss: 91.415266\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:42 | Steps: 8826 | Loss: 91.418791\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:42 | Steps: 8827 | Loss: 91.421401\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:43 | Steps: 8829 | Loss: 91.423164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:43 | Steps: 8830 | Loss: 91.422452\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:43 | Steps: 8831 | Loss: 91.420307\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:43 | Steps: 8832 | Loss: 91.425166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:43 | Steps: 8833 | Loss: 91.423059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:43 | Steps: 8834 | Loss: 91.425310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:43 | Steps: 8835 | Loss: 91.428289\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:43 | Steps: 8836 | Loss: 91.429628\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:44 | Steps: 8837 | Loss: 91.429261\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:44 | Steps: 8838 | Loss: 91.428298\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:44 | Steps: 8840 | Loss: 91.424034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:44 | Steps: 8841 | Loss: 91.422121\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:44 | Steps: 8842 | Loss: 91.422968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:44 | Steps: 8843 | Loss: 91.421411\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:44 | Steps: 8844 | Loss: 91.418532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:45 | Steps: 8845 | Loss: 91.419342\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:45 | Steps: 8846 | Loss: 91.420551\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:45 | Steps: 8847 | Loss: 91.423655\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:45 | Steps: 8848 | Loss: 91.424003\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:45 | Steps: 8849 | Loss: 91.422876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:45 | Steps: 8850 | Loss: 91.420452\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:45 | Steps: 8852 | Loss: 91.415310\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:46 | Steps: 8853 | Loss: 91.422063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:46 | Steps: 8854 | Loss: 91.422846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:46 | Steps: 8855 | Loss: 91.425782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:46 | Steps: 8856 | Loss: 91.424365\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:46 | Steps: 8857 | Loss: 91.425009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:46 | Steps: 8858 | Loss: 91.427192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:46 | Steps: 8859 | Loss: 91.426333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:46 | Steps: 8860 | Loss: 91.429034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:47 | Steps: 8861 | Loss: 91.429833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:47 | Steps: 8862 | Loss: 91.430149\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:47 | Steps: 8863 | Loss: 91.432842\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:47 | Steps: 8864 | Loss: 91.432203\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:47 | Steps: 8865 | Loss: 91.434795\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:47 | Steps: 8866 | Loss: 91.438255\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:47 | Steps: 8867 | Loss: 91.436510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:48 | Steps: 8869 | Loss: 91.436590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:48 | Steps: 8870 | Loss: 91.437536\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:48 | Steps: 8871 | Loss: 91.439064\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:48 | Steps: 8872 | Loss: 91.441028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:48 | Steps: 8873 | Loss: 91.446135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:48 | Steps: 8874 | Loss: 91.444448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:48 | Steps: 8875 | Loss: 91.447426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:48 | Steps: 8876 | Loss: 91.450552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:49 | Steps: 8877 | Loss: 91.451383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:49 | Steps: 8878 | Loss: 91.450772\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:49 | Steps: 8879 | Loss: 91.449594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:49 | Steps: 8880 | Loss: 91.449177\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:49 | Steps: 8881 | Loss: 91.447833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:49 | Steps: 8882 | Loss: 91.452603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:49 | Steps: 8883 | Loss: 91.451474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:49 | Steps: 8884 | Loss: 91.455336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:50 | Steps: 8885 | Loss: 91.457632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:50 | Steps: 8886 | Loss: 91.458625\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:50 | Steps: 8887 | Loss: 91.461753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:50 | Steps: 8889 | Loss: 91.460572\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:50 | Steps: 8890 | Loss: 91.462816\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:50 | Steps: 8891 | Loss: 91.463073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:50 | Steps: 8892 | Loss: 91.464372\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:51 | Steps: 8893 | Loss: 91.464071\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:51 | Steps: 8894 | Loss: 91.462345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:51 | Steps: 8895 | Loss: 91.460943\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:51 | Steps: 8896 | Loss: 91.460032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:51 | Steps: 8897 | Loss: 91.457172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:51 | Steps: 8898 | Loss: 91.454432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:51 | Steps: 8899 | Loss: 91.454289\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:51 | Steps: 8900 | Loss: 91.452739\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:52 | Steps: 8901 | Loss: 91.452325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:52 | Steps: 8902 | Loss: 91.450513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:52 | Steps: 8903 | Loss: 91.446687\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:52 | Steps: 8904 | Loss: 91.444952\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:52 | Steps: 8906 | Loss: 91.444253\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:52 | Steps: 8907 | Loss: 91.442866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:52 | Steps: 8908 | Loss: 91.443483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:53 | Steps: 8909 | Loss: 91.444805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:53 | Steps: 8910 | Loss: 91.449551\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:53 | Steps: 8911 | Loss: 91.451112\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:53 | Steps: 8912 | Loss: 91.452252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:53 | Steps: 8913 | Loss: 91.456279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:53 | Steps: 8914 | Loss: 91.459540\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:53 | Steps: 8915 | Loss: 91.462618\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:53 | Steps: 8916 | Loss: 91.460120\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:54 | Steps: 8917 | Loss: 91.458661\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:54 | Steps: 8918 | Loss: 91.459343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:54 | Steps: 8919 | Loss: 91.462217\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:54 | Steps: 8920 | Loss: 91.463100\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:54 | Steps: 8921 | Loss: 91.462191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:54 | Steps: 8923 | Loss: 91.463981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:54 | Steps: 8924 | Loss: 91.462999\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:55 | Steps: 8925 | Loss: 91.460662\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:55 | Steps: 8927 | Loss: 91.460181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:55 | Steps: 8928 | Loss: 91.462480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:55 | Steps: 8929 | Loss: 91.461229\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:55 | Steps: 8931 | Loss: 91.464941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8933 | Loss: 91.468246\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8934 | Loss: 91.468395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8935 | Loss: 91.467446\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8936 | Loss: 91.466726\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8937 | Loss: 91.469431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8938 | Loss: 91.470735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8939 | Loss: 91.469447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8940 | Loss: 91.469292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:56 | Steps: 8941 | Loss: 91.468874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:57 | Steps: 8942 | Loss: 91.471881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:57 | Steps: 8943 | Loss: 91.475623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:57 | Steps: 8944 | Loss: 91.473531\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:57 | Steps: 8945 | Loss: 91.471540\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:57 | Steps: 8946 | Loss: 91.470186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:57 | Steps: 8947 | Loss: 91.468674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:57 | Steps: 8948 | Loss: 91.465257\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:58 | Steps: 8949 | Loss: 91.469955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:58 | Steps: 8950 | Loss: 91.467235\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:58 | Steps: 8951 | Loss: 91.465016\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:58 | Steps: 8952 | Loss: 91.467139\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:58 | Steps: 8954 | Loss: 91.469991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:58 | Steps: 8955 | Loss: 91.469427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:58 | Steps: 8956 | Loss: 91.467488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:58 | Steps: 8957 | Loss: 91.469634\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:59 | Steps: 8959 | Loss: 91.468960\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:59 | Steps: 8960 | Loss: 91.468670\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:59 | Steps: 8961 | Loss: 91.469243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:59 | Steps: 8962 | Loss: 91.469682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:59 | Steps: 8964 | Loss: 91.469686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:12:59 | Steps: 8965 | Loss: 91.473062\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:00 | Steps: 8966 | Loss: 91.478706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:00 | Steps: 8967 | Loss: 91.480837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:00 | Steps: 8968 | Loss: 91.484954\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:00 | Steps: 8969 | Loss: 91.495367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:00 | Steps: 8970 | Loss: 91.501046\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:00 | Steps: 8971 | Loss: 91.504196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:00 | Steps: 8972 | Loss: 91.504916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:00 | Steps: 8973 | Loss: 91.506534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:01 | Steps: 8974 | Loss: 91.507023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:01 | Steps: 8975 | Loss: 91.506699\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:01 | Steps: 8976 | Loss: 91.507738\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:01 | Steps: 8977 | Loss: 91.505838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:01 | Steps: 8978 | Loss: 91.507168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:01 | Steps: 8979 | Loss: 91.507282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:01 | Steps: 8980 | Loss: 91.508686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:01 | Steps: 8981 | Loss: 91.514066\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:02 | Steps: 8982 | Loss: 91.521649\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:02 | Steps: 8983 | Loss: 91.526338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:02 | Steps: 8984 | Loss: 91.525895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:02 | Steps: 8985 | Loss: 91.524868\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:02 | Steps: 8986 | Loss: 91.522364\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:02 | Steps: 8988 | Loss: 91.523431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:02 | Steps: 8989 | Loss: 91.525124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:03 | Steps: 8990 | Loss: 91.528861\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:03 | Steps: 8991 | Loss: 91.536887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:03 | Steps: 8992 | Loss: 91.541070\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:03 | Steps: 8993 | Loss: 91.541872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:03 | Steps: 8994 | Loss: 91.544624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:03 | Steps: 8996 | Loss: 91.542698\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:03 | Steps: 8997 | Loss: 91.541916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:04 | Steps: 8998 | Loss: 91.542079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:04 | Steps: 8999 | Loss: 91.540271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:04 | Steps: 9000 | Loss: 91.535996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:04 | Steps: 9001 | Loss: 91.536722\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:04 | Steps: 9002 | Loss: 91.536311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:04 | Steps: 9003 | Loss: 91.534932\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:04 | Steps: 9004 | Loss: 91.536369\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:05 | Steps: 9005 | Loss: 91.540544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:05 | Steps: 9007 | Loss: 91.537272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:05 | Steps: 9008 | Loss: 91.534861\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:05 | Steps: 9009 | Loss: 91.532073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:05 | Steps: 9010 | Loss: 91.531452\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:05 | Steps: 9011 | Loss: 91.530531\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:05 | Steps: 9012 | Loss: 91.530128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:06 | Steps: 9013 | Loss: 91.529557\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:06 | Steps: 9014 | Loss: 91.532930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:06 | Steps: 9015 | Loss: 91.533513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:06 | Steps: 9016 | Loss: 91.532375\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:06 | Steps: 9017 | Loss: 91.532999\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:06 | Steps: 9018 | Loss: 91.533830\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:06 | Steps: 9019 | Loss: 91.533643\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:06 | Steps: 9020 | Loss: 91.535444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:07 | Steps: 9022 | Loss: 91.534558\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:07 | Steps: 9023 | Loss: 91.532922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:07 | Steps: 9024 | Loss: 91.533287\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:07 | Steps: 9025 | Loss: 91.534034\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:07 | Steps: 9026 | Loss: 91.534736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:07 | Steps: 9027 | Loss: 91.539676\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:07 | Steps: 9028 | Loss: 91.542318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:08 | Steps: 9029 | Loss: 91.539887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:08 | Steps: 9030 | Loss: 91.540339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:08 | Steps: 9031 | Loss: 91.542235\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:08 | Steps: 9032 | Loss: 91.540326\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:08 | Steps: 9033 | Loss: 91.539581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:08 | Steps: 9034 | Loss: 91.541348\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:08 | Steps: 9035 | Loss: 91.543393\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:09 | Steps: 9037 | Loss: 91.546977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:09 | Steps: 9038 | Loss: 91.548184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:09 | Steps: 9039 | Loss: 91.545863\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:09 | Steps: 9040 | Loss: 91.549281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:09 | Steps: 9042 | Loss: 91.550478\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:09 | Steps: 9043 | Loss: 91.552956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:09 | Steps: 9044 | Loss: 91.553532\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:10 | Steps: 9045 | Loss: 91.555663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:10 | Steps: 9046 | Loss: 91.560528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:10 | Steps: 9047 | Loss: 91.559976\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:10 | Steps: 9048 | Loss: 91.557635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:10 | Steps: 9049 | Loss: 91.556186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:10 | Steps: 9050 | Loss: 91.554636\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:10 | Steps: 9051 | Loss: 91.550665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:10 | Steps: 9052 | Loss: 91.546041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:11 | Steps: 9053 | Loss: 91.549216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:11 | Steps: 9054 | Loss: 91.551916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:11 | Steps: 9055 | Loss: 91.550785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:11 | Steps: 9056 | Loss: 91.549240\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:11 | Steps: 9057 | Loss: 91.550118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:11 | Steps: 9059 | Loss: 91.550759\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:12 | Steps: 9060 | Loss: 91.550027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:12 | Steps: 9061 | Loss: 91.549150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:12 | Steps: 9062 | Loss: 91.548756\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:12 | Steps: 9063 | Loss: 91.548469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:12 | Steps: 9064 | Loss: 91.547456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:12 | Steps: 9065 | Loss: 91.550020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:12 | Steps: 9066 | Loss: 91.550751\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:13 | Steps: 9067 | Loss: 91.552396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:13 | Steps: 9068 | Loss: 91.553437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:13 | Steps: 9069 | Loss: 91.551456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:13 | Steps: 9070 | Loss: 91.553559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:13 | Steps: 9071 | Loss: 91.557182\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:13 | Steps: 9072 | Loss: 91.556971\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:13 | Steps: 9073 | Loss: 91.557906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:13 | Steps: 9074 | Loss: 91.558719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:14 | Steps: 9075 | Loss: 91.562487\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:14 | Steps: 9076 | Loss: 91.563383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:14 | Steps: 9077 | Loss: 91.562717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:14 | Steps: 9078 | Loss: 91.564312\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:14 | Steps: 9079 | Loss: 91.564818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:14 | Steps: 9080 | Loss: 91.566977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:14 | Steps: 9081 | Loss: 91.572435\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:15 | Steps: 9082 | Loss: 91.573178\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:15 | Steps: 9083 | Loss: 91.578719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:15 | Steps: 9084 | Loss: 91.576610\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:15 | Steps: 9085 | Loss: 91.574590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:15 | Steps: 9086 | Loss: 91.574414\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:15 | Steps: 9087 | Loss: 91.579801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:15 | Steps: 9088 | Loss: 91.577968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:15 | Steps: 9089 | Loss: 91.577836\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:16 | Steps: 9090 | Loss: 91.581628\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:16 | Steps: 9091 | Loss: 91.582917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:16 | Steps: 9092 | Loss: 91.580119\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:16 | Steps: 9093 | Loss: 91.575831\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:16 | Steps: 9094 | Loss: 91.578363\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:16 | Steps: 9095 | Loss: 91.578329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:16 | Steps: 9096 | Loss: 91.578971\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:17 | Steps: 9097 | Loss: 91.576325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:17 | Steps: 9098 | Loss: 91.572671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:17 | Steps: 9099 | Loss: 91.570207\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:17 | Steps: 9100 | Loss: 91.569496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:17 | Steps: 9101 | Loss: 91.572360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:17 | Steps: 9102 | Loss: 91.568500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:18 | Steps: 9103 | Loss: 91.565070\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:18 | Steps: 9104 | Loss: 91.566232\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:18 | Steps: 9105 | Loss: 91.567757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:18 | Steps: 9106 | Loss: 91.569198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:18 | Steps: 9107 | Loss: 91.570490\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:19 | Steps: 9108 | Loss: 91.570815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:19 | Steps: 9109 | Loss: 91.571284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:19 | Steps: 9110 | Loss: 91.572635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:19 | Steps: 9111 | Loss: 91.573462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:19 | Steps: 9112 | Loss: 91.573480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:20 | Steps: 9113 | Loss: 91.571680\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:20 | Steps: 9114 | Loss: 91.572008\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:20 | Steps: 9115 | Loss: 91.570302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:20 | Steps: 9116 | Loss: 91.575106\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:20 | Steps: 9117 | Loss: 91.575265\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:20 | Steps: 9118 | Loss: 91.574147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:21 | Steps: 9119 | Loss: 91.571771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:21 | Steps: 9120 | Loss: 91.569912\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:21 | Steps: 9121 | Loss: 91.569987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:21 | Steps: 9122 | Loss: 91.571149\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:21 | Steps: 9123 | Loss: 91.570948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:21 | Steps: 9124 | Loss: 91.572509\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:21 | Steps: 9125 | Loss: 91.579948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:22 | Steps: 9126 | Loss: 91.584989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:22 | Steps: 9127 | Loss: 91.586854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:22 | Steps: 9128 | Loss: 91.588157\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:22 | Steps: 9129 | Loss: 91.587302\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:22 | Steps: 9130 | Loss: 91.591508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:22 | Steps: 9131 | Loss: 91.596894\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:23 | Steps: 9132 | Loss: 91.600453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:23 | Steps: 9133 | Loss: 91.600320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:23 | Steps: 9134 | Loss: 91.601274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:23 | Steps: 9135 | Loss: 91.601979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:23 | Steps: 9136 | Loss: 91.603646\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:23 | Steps: 9137 | Loss: 91.605129\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:24 | Steps: 9138 | Loss: 91.608482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:24 | Steps: 9139 | Loss: 91.609105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:24 | Steps: 9140 | Loss: 91.608375\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:24 | Steps: 9141 | Loss: 91.606663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:24 | Steps: 9142 | Loss: 91.603228\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:24 | Steps: 9143 | Loss: 91.606373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:25 | Steps: 9144 | Loss: 91.606625\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:25 | Steps: 9145 | Loss: 91.605796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:25 | Steps: 9146 | Loss: 91.607921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:25 | Steps: 9147 | Loss: 91.610132\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:25 | Steps: 9148 | Loss: 91.611361\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:25 | Steps: 9149 | Loss: 91.610367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:26 | Steps: 9150 | Loss: 91.608773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:26 | Steps: 9151 | Loss: 91.607396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:26 | Steps: 9152 | Loss: 91.606998\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:26 | Steps: 9153 | Loss: 91.606858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:26 | Steps: 9154 | Loss: 91.606876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:27 | Steps: 9155 | Loss: 91.605123\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:27 | Steps: 9156 | Loss: 91.610330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:27 | Steps: 9157 | Loss: 91.614966\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:27 | Steps: 9158 | Loss: 91.613527\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:27 | Steps: 9159 | Loss: 91.611644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:27 | Steps: 9160 | Loss: 91.615367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:27 | Steps: 9161 | Loss: 91.619830\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:28 | Steps: 9162 | Loss: 91.621556\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:28 | Steps: 9163 | Loss: 91.621176\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:28 | Steps: 9164 | Loss: 91.623538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:28 | Steps: 9165 | Loss: 91.622465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:28 | Steps: 9166 | Loss: 91.632785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:29 | Steps: 9167 | Loss: 91.633671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:29 | Steps: 9168 | Loss: 91.632218\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:29 | Steps: 9169 | Loss: 91.631007\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:29 | Steps: 9170 | Loss: 91.631392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:29 | Steps: 9171 | Loss: 91.634552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:30 | Steps: 9172 | Loss: 91.635875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:30 | Steps: 9173 | Loss: 91.634926\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:30 | Steps: 9174 | Loss: 91.636151\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:30 | Steps: 9175 | Loss: 91.637558\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:30 | Steps: 9176 | Loss: 91.640235\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:30 | Steps: 9177 | Loss: 91.640429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:31 | Steps: 9178 | Loss: 91.646419\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:31 | Steps: 9179 | Loss: 91.645048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:31 | Steps: 9180 | Loss: 91.643329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:31 | Steps: 9181 | Loss: 91.645942\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:31 | Steps: 9182 | Loss: 91.647013\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:31 | Steps: 9183 | Loss: 91.649908\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:32 | Steps: 9184 | Loss: 91.653359\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:32 | Steps: 9185 | Loss: 91.655412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:32 | Steps: 9186 | Loss: 91.653880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:32 | Steps: 9187 | Loss: 91.654786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:32 | Steps: 9188 | Loss: 91.655745\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:32 | Steps: 9189 | Loss: 91.657502\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:32 | Steps: 9190 | Loss: 91.658377\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:33 | Steps: 9191 | Loss: 91.659934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:33 | Steps: 9192 | Loss: 91.657833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:33 | Steps: 9193 | Loss: 91.655001\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:33 | Steps: 9194 | Loss: 91.651569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:33 | Steps: 9195 | Loss: 91.647966\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:33 | Steps: 9197 | Loss: 91.643599\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:33 | Steps: 9198 | Loss: 91.645392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:34 | Steps: 9199 | Loss: 91.646910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:34 | Steps: 9200 | Loss: 91.648424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:34 | Steps: 9201 | Loss: 91.650100\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:34 | Steps: 9202 | Loss: 91.652225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:34 | Steps: 9203 | Loss: 91.655897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:34 | Steps: 9205 | Loss: 91.655619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:35 | Steps: 9206 | Loss: 91.656211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:35 | Steps: 9207 | Loss: 91.657268\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:35 | Steps: 9208 | Loss: 91.658786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:35 | Steps: 9209 | Loss: 91.665238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:35 | Steps: 9210 | Loss: 91.665526\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:35 | Steps: 9211 | Loss: 91.665799\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:35 | Steps: 9212 | Loss: 91.663870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:35 | Steps: 9213 | Loss: 91.662269\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:36 | Steps: 9214 | Loss: 91.665250\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:36 | Steps: 9215 | Loss: 91.666583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:36 | Steps: 9216 | Loss: 91.667731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:36 | Steps: 9217 | Loss: 91.666382\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:36 | Steps: 9218 | Loss: 91.667467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:36 | Steps: 9219 | Loss: 91.669568\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:36 | Steps: 9220 | Loss: 91.669086\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:36 | Steps: 9221 | Loss: 91.670635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:37 | Steps: 9222 | Loss: 91.668515\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:37 | Steps: 9223 | Loss: 91.667514\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:37 | Steps: 9224 | Loss: 91.665200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:37 | Steps: 9225 | Loss: 91.663334\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:37 | Steps: 9226 | Loss: 91.667882\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:37 | Steps: 9227 | Loss: 91.669440\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:37 | Steps: 9228 | Loss: 91.670325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:37 | Steps: 9229 | Loss: 91.670690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:38 | Steps: 9230 | Loss: 91.672027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:38 | Steps: 9231 | Loss: 91.673201\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:38 | Steps: 9232 | Loss: 91.669290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:38 | Steps: 9233 | Loss: 91.668979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:38 | Steps: 9234 | Loss: 91.672801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:38 | Steps: 9236 | Loss: 91.673089\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:39 | Steps: 9237 | Loss: 91.674789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:39 | Steps: 9238 | Loss: 91.676990\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:39 | Steps: 9239 | Loss: 91.676048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:39 | Steps: 9240 | Loss: 91.674834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:39 | Steps: 9241 | Loss: 91.675451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:39 | Steps: 9242 | Loss: 91.675507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:39 | Steps: 9243 | Loss: 91.676743\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:39 | Steps: 9244 | Loss: 91.677937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:40 | Steps: 9245 | Loss: 91.677112\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:40 | Steps: 9247 | Loss: 91.681587\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:40 | Steps: 9248 | Loss: 91.684299\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:40 | Steps: 9249 | Loss: 91.684784\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:40 | Steps: 9250 | Loss: 91.697222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:40 | Steps: 9251 | Loss: 91.699997\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:40 | Steps: 9252 | Loss: 91.697623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:41 | Steps: 9253 | Loss: 91.698333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:41 | Steps: 9254 | Loss: 91.698856\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:41 | Steps: 9255 | Loss: 91.702611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:41 | Steps: 9256 | Loss: 91.705035\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:41 | Steps: 9258 | Loss: 91.702757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:41 | Steps: 9259 | Loss: 91.703385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:41 | Steps: 9260 | Loss: 91.703160\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:42 | Steps: 9262 | Loss: 91.702249\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:42 | Steps: 9263 | Loss: 91.706945\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:42 | Steps: 9264 | Loss: 91.708009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:42 | Steps: 9265 | Loss: 91.710775\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:42 | Steps: 9267 | Loss: 91.717758\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:42 | Steps: 9268 | Loss: 91.716607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:43 | Steps: 9269 | Loss: 91.722025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:43 | Steps: 9270 | Loss: 91.726558\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:43 | Steps: 9271 | Loss: 91.724946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:43 | Steps: 9272 | Loss: 91.723623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:43 | Steps: 9273 | Loss: 91.723393\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:43 | Steps: 9275 | Loss: 91.731311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:43 | Steps: 9276 | Loss: 91.738482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:44 | Steps: 9277 | Loss: 91.739216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:44 | Steps: 9279 | Loss: 91.741083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:44 | Steps: 9280 | Loss: 91.741373\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:44 | Steps: 9281 | Loss: 91.739110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:44 | Steps: 9282 | Loss: 91.735914\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:44 | Steps: 9283 | Loss: 91.732887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:44 | Steps: 9284 | Loss: 91.730880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:45 | Steps: 9285 | Loss: 91.732917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:45 | Steps: 9286 | Loss: 91.731742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:45 | Steps: 9287 | Loss: 91.726940\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:45 | Steps: 9288 | Loss: 91.725137\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:45 | Steps: 9289 | Loss: 91.724439\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:45 | Steps: 9290 | Loss: 91.723801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:46 | Steps: 9291 | Loss: 91.724935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:46 | Steps: 9292 | Loss: 91.725433\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:46 | Steps: 9293 | Loss: 91.726385\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:46 | Steps: 9294 | Loss: 91.727004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:46 | Steps: 9295 | Loss: 91.726907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:46 | Steps: 9296 | Loss: 91.730442\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:46 | Steps: 9297 | Loss: 91.730343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:47 | Steps: 9298 | Loss: 91.730438\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:47 | Steps: 9299 | Loss: 91.730693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:47 | Steps: 9300 | Loss: 91.727742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:47 | Steps: 9301 | Loss: 91.727826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:47 | Steps: 9302 | Loss: 91.728670\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:47 | Steps: 9303 | Loss: 91.728851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:48 | Steps: 9304 | Loss: 91.730959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:48 | Steps: 9306 | Loss: 91.731763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:48 | Steps: 9307 | Loss: 91.731349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:48 | Steps: 9308 | Loss: 91.731652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:48 | Steps: 9309 | Loss: 91.731563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:48 | Steps: 9310 | Loss: 91.731454\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:48 | Steps: 9311 | Loss: 91.732482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:49 | Steps: 9312 | Loss: 91.736507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:49 | Steps: 9313 | Loss: 91.739284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:49 | Steps: 9314 | Loss: 91.740759\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:49 | Steps: 9315 | Loss: 91.742149\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:49 | Steps: 9317 | Loss: 91.743239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:49 | Steps: 9318 | Loss: 91.741303\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:49 | Steps: 9319 | Loss: 91.738748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:50 | Steps: 9320 | Loss: 91.744074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:50 | Steps: 9322 | Loss: 91.740764\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:50 | Steps: 9323 | Loss: 91.744190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:50 | Steps: 9324 | Loss: 91.745660\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:50 | Steps: 9325 | Loss: 91.743172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:50 | Steps: 9326 | Loss: 91.743015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:50 | Steps: 9327 | Loss: 91.742288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:51 | Steps: 9328 | Loss: 91.737949\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:51 | Steps: 9329 | Loss: 91.738897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:51 | Steps: 9330 | Loss: 91.738953\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:51 | Steps: 9331 | Loss: 91.737180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:51 | Steps: 9332 | Loss: 91.736647\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:51 | Steps: 9333 | Loss: 91.736317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:51 | Steps: 9334 | Loss: 91.737510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:51 | Steps: 9335 | Loss: 91.737938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:52 | Steps: 9336 | Loss: 91.737845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:52 | Steps: 9337 | Loss: 91.740689\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:52 | Steps: 9338 | Loss: 91.739634\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:52 | Steps: 9339 | Loss: 91.740414\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:52 | Steps: 9340 | Loss: 91.743785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:52 | Steps: 9341 | Loss: 91.743375\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:52 | Steps: 9342 | Loss: 91.742668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:53 | Steps: 9344 | Loss: 91.743598\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:53 | Steps: 9345 | Loss: 91.746482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:53 | Steps: 9346 | Loss: 91.747017\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:53 | Steps: 9348 | Loss: 91.752455\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:53 | Steps: 9349 | Loss: 91.756672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:53 | Steps: 9350 | Loss: 91.759888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:53 | Steps: 9351 | Loss: 91.762992\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:54 | Steps: 9352 | Loss: 91.763535\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:54 | Steps: 9353 | Loss: 91.763167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:54 | Steps: 9354 | Loss: 91.767190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:54 | Steps: 9355 | Loss: 91.765821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:54 | Steps: 9356 | Loss: 91.765437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:54 | Steps: 9357 | Loss: 91.764898\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:54 | Steps: 9358 | Loss: 91.767610\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:55 | Steps: 9359 | Loss: 91.773128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:55 | Steps: 9360 | Loss: 91.771806\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:55 | Steps: 9361 | Loss: 91.772264\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:55 | Steps: 9362 | Loss: 91.776550\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:55 | Steps: 9363 | Loss: 91.777300\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:55 | Steps: 9364 | Loss: 91.776244\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:55 | Steps: 9365 | Loss: 91.775035\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:55 | Steps: 9366 | Loss: 91.773619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:56 | Steps: 9367 | Loss: 91.771243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:56 | Steps: 9368 | Loss: 91.773561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:56 | Steps: 9369 | Loss: 91.774674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:56 | Steps: 9370 | Loss: 91.775590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:56 | Steps: 9371 | Loss: 91.771988\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:56 | Steps: 9372 | Loss: 91.769760\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:56 | Steps: 9373 | Loss: 91.769336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:56 | Steps: 9374 | Loss: 91.768288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:57 | Steps: 9375 | Loss: 91.769178\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:57 | Steps: 9376 | Loss: 91.770325\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:57 | Steps: 9377 | Loss: 91.770263\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:57 | Steps: 9378 | Loss: 91.776159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:57 | Steps: 9379 | Loss: 91.777033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:57 | Steps: 9380 | Loss: 91.777172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:57 | Steps: 9381 | Loss: 91.776427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:57 | Steps: 9382 | Loss: 91.775412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:58 | Steps: 9383 | Loss: 91.774684\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:58 | Steps: 9384 | Loss: 91.776420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:58 | Steps: 9385 | Loss: 91.776583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:58 | Steps: 9386 | Loss: 91.779150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:58 | Steps: 9387 | Loss: 91.780007\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:58 | Steps: 9388 | Loss: 91.782048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:58 | Steps: 9389 | Loss: 91.783697\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:58 | Steps: 9390 | Loss: 91.782329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:59 | Steps: 9391 | Loss: 91.781196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:59 | Steps: 9392 | Loss: 91.783376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:59 | Steps: 9393 | Loss: 91.783477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:59 | Steps: 9394 | Loss: 91.785161\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:59 | Steps: 9395 | Loss: 91.787226\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:59 | Steps: 9396 | Loss: 91.786436\n",
      "Epoch 0 |   Training | Elapsed Time: 0:13:59 | Steps: 9397 | Loss: 91.787065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:00 | Steps: 9398 | Loss: 91.789003\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:00 | Steps: 9399 | Loss: 91.793196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:00 | Steps: 9400 | Loss: 91.790940\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:00 | Steps: 9401 | Loss: 91.788940\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:00 | Steps: 9402 | Loss: 91.792948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:00 | Steps: 9403 | Loss: 91.792594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:00 | Steps: 9404 | Loss: 91.793893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:00 | Steps: 9405 | Loss: 91.795575\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:01 | Steps: 9406 | Loss: 91.796376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:01 | Steps: 9407 | Loss: 91.795038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:01 | Steps: 9408 | Loss: 91.792603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:01 | Steps: 9409 | Loss: 91.787937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:01 | Steps: 9410 | Loss: 91.792602\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:01 | Steps: 9411 | Loss: 91.793519\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:01 | Steps: 9412 | Loss: 91.797245\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:01 | Steps: 9413 | Loss: 91.799357\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:02 | Steps: 9414 | Loss: 91.798476\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:02 | Steps: 9415 | Loss: 91.798060\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:02 | Steps: 9416 | Loss: 91.797554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:02 | Steps: 9417 | Loss: 91.796083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:02 | Steps: 9418 | Loss: 91.796033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:02 | Steps: 9419 | Loss: 91.796020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:02 | Steps: 9420 | Loss: 91.795329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:02 | Steps: 9421 | Loss: 91.799456\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:03 | Steps: 9422 | Loss: 91.798605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:03 | Steps: 9423 | Loss: 91.801201\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:03 | Steps: 9424 | Loss: 91.801769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:03 | Steps: 9425 | Loss: 91.799522\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:03 | Steps: 9426 | Loss: 91.801761\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:03 | Steps: 9427 | Loss: 91.803819\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:03 | Steps: 9428 | Loss: 91.802809\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:04 | Steps: 9429 | Loss: 91.805536\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:04 | Steps: 9430 | Loss: 91.807154\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:04 | Steps: 9431 | Loss: 91.805851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:04 | Steps: 9432 | Loss: 91.809830\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:04 | Steps: 9433 | Loss: 91.816099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:04 | Steps: 9434 | Loss: 91.816882\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:04 | Steps: 9435 | Loss: 91.820087\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:04 | Steps: 9436 | Loss: 91.821087\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:05 | Steps: 9437 | Loss: 91.823409\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:05 | Steps: 9438 | Loss: 91.829818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:05 | Steps: 9439 | Loss: 91.827693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:05 | Steps: 9440 | Loss: 91.828859\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:05 | Steps: 9441 | Loss: 91.827640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:05 | Steps: 9442 | Loss: 91.828054\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:05 | Steps: 9443 | Loss: 91.825958\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:05 | Steps: 9444 | Loss: 91.826068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:06 | Steps: 9445 | Loss: 91.827681\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:06 | Steps: 9446 | Loss: 91.829133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:06 | Steps: 9447 | Loss: 91.832018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:06 | Steps: 9448 | Loss: 91.833825\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:06 | Steps: 9450 | Loss: 91.833340\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:06 | Steps: 9451 | Loss: 91.833186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:06 | Steps: 9452 | Loss: 91.833010\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:07 | Steps: 9453 | Loss: 91.832124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:07 | Steps: 9454 | Loss: 91.830361\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:07 | Steps: 9455 | Loss: 91.839142\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:07 | Steps: 9456 | Loss: 91.835525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:07 | Steps: 9457 | Loss: 91.837258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:07 | Steps: 9458 | Loss: 91.838142\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:07 | Steps: 9459 | Loss: 91.839664\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:08 | Steps: 9460 | Loss: 91.841835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:08 | Steps: 9461 | Loss: 91.839488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:08 | Steps: 9462 | Loss: 91.836872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:08 | Steps: 9463 | Loss: 91.836051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:08 | Steps: 9464 | Loss: 91.835459\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:08 | Steps: 9465 | Loss: 91.835492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:08 | Steps: 9466 | Loss: 91.837804\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:08 | Steps: 9467 | Loss: 91.836856\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:09 | Steps: 9468 | Loss: 91.838317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:09 | Steps: 9469 | Loss: 91.841477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:09 | Steps: 9470 | Loss: 91.843351\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:09 | Steps: 9471 | Loss: 91.846143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:09 | Steps: 9472 | Loss: 91.844088\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:09 | Steps: 9473 | Loss: 91.842941\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:09 | Steps: 9474 | Loss: 91.844320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:09 | Steps: 9475 | Loss: 91.843995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:10 | Steps: 9476 | Loss: 91.842607\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:10 | Steps: 9477 | Loss: 91.842858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:10 | Steps: 9478 | Loss: 91.845921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:10 | Steps: 9479 | Loss: 91.847904\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:10 | Steps: 9480 | Loss: 91.849400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:10 | Steps: 9481 | Loss: 91.853789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:10 | Steps: 9482 | Loss: 91.853200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:11 | Steps: 9484 | Loss: 91.854186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:11 | Steps: 9485 | Loss: 91.854849\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:11 | Steps: 9486 | Loss: 91.854686\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:11 | Steps: 9487 | Loss: 91.857509\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:11 | Steps: 9488 | Loss: 91.860541\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:11 | Steps: 9489 | Loss: 91.859987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:11 | Steps: 9490 | Loss: 91.860392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:11 | Steps: 9491 | Loss: 91.855982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:12 | Steps: 9492 | Loss: 91.857084\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:12 | Steps: 9493 | Loss: 91.857349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:12 | Steps: 9494 | Loss: 91.859605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:12 | Steps: 9495 | Loss: 91.859951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:12 | Steps: 9496 | Loss: 91.858644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:12 | Steps: 9497 | Loss: 91.860049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:13 | Steps: 9498 | Loss: 91.860345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:13 | Steps: 9499 | Loss: 91.862719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:13 | Steps: 9500 | Loss: 91.869181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:13 | Steps: 9501 | Loss: 91.870150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:13 | Steps: 9502 | Loss: 91.867902\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:13 | Steps: 9503 | Loss: 91.870196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:14 | Steps: 9504 | Loss: 91.871731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:14 | Steps: 9505 | Loss: 91.872727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:14 | Steps: 9506 | Loss: 91.882795\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:14 | Steps: 9507 | Loss: 91.888762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:14 | Steps: 9508 | Loss: 91.890274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:14 | Steps: 9509 | Loss: 91.892711\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:14 | Steps: 9510 | Loss: 91.892441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:15 | Steps: 9511 | Loss: 91.892262\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:15 | Steps: 9512 | Loss: 91.890037\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:15 | Steps: 9513 | Loss: 91.890975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:15 | Steps: 9514 | Loss: 91.890370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:15 | Steps: 9515 | Loss: 91.894591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:15 | Steps: 9516 | Loss: 91.895574\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:16 | Steps: 9517 | Loss: 91.897167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:16 | Steps: 9518 | Loss: 91.903510\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:16 | Steps: 9519 | Loss: 91.906097\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:16 | Steps: 9520 | Loss: 91.905020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:16 | Steps: 9521 | Loss: 91.909644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:16 | Steps: 9522 | Loss: 91.910545\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:16 | Steps: 9523 | Loss: 91.913147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:16 | Steps: 9524 | Loss: 91.916309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:17 | Steps: 9525 | Loss: 91.915297\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:17 | Steps: 9526 | Loss: 91.915942\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:17 | Steps: 9527 | Loss: 91.916954\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:17 | Steps: 9529 | Loss: 91.914524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:17 | Steps: 9530 | Loss: 91.912685\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:17 | Steps: 9531 | Loss: 91.912033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:17 | Steps: 9532 | Loss: 91.912950\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:18 | Steps: 9533 | Loss: 91.913097\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:18 | Steps: 9534 | Loss: 91.915584\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:18 | Steps: 9535 | Loss: 91.917962\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:18 | Steps: 9536 | Loss: 91.919836\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:18 | Steps: 9537 | Loss: 91.923757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:18 | Steps: 9538 | Loss: 91.925774\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:19 | Steps: 9539 | Loss: 91.925326\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:19 | Steps: 9540 | Loss: 91.923062\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:19 | Steps: 9541 | Loss: 91.924280\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:19 | Steps: 9542 | Loss: 91.925983\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:19 | Steps: 9543 | Loss: 91.925250\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:19 | Steps: 9544 | Loss: 91.922128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:19 | Steps: 9545 | Loss: 91.922345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:20 | Steps: 9546 | Loss: 91.921432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:20 | Steps: 9547 | Loss: 91.921292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:20 | Steps: 9548 | Loss: 91.922866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:20 | Steps: 9549 | Loss: 91.926851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:20 | Steps: 9550 | Loss: 91.928390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:20 | Steps: 9551 | Loss: 91.928701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:20 | Steps: 9552 | Loss: 91.927014\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:21 | Steps: 9553 | Loss: 91.925248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:21 | Steps: 9554 | Loss: 91.929804\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:21 | Steps: 9555 | Loss: 91.928169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:21 | Steps: 9556 | Loss: 91.930562\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:21 | Steps: 9557 | Loss: 91.934455\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:21 | Steps: 9558 | Loss: 91.934304\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:21 | Steps: 9559 | Loss: 91.932951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:21 | Steps: 9560 | Loss: 91.927958\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:22 | Steps: 9561 | Loss: 91.926918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:22 | Steps: 9562 | Loss: 91.931594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:22 | Steps: 9563 | Loss: 91.933246\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:22 | Steps: 9564 | Loss: 91.935511\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:22 | Steps: 9565 | Loss: 91.939555\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:22 | Steps: 9566 | Loss: 91.939843\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:22 | Steps: 9567 | Loss: 91.940569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:22 | Steps: 9568 | Loss: 91.941044\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:23 | Steps: 9569 | Loss: 91.939198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:23 | Steps: 9570 | Loss: 91.939848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:23 | Steps: 9571 | Loss: 91.939230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:23 | Steps: 9572 | Loss: 91.936626\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:23 | Steps: 9573 | Loss: 91.938988\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:23 | Steps: 9574 | Loss: 91.937651\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:23 | Steps: 9575 | Loss: 91.934028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:24 | Steps: 9576 | Loss: 91.936978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:24 | Steps: 9577 | Loss: 91.937575\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:24 | Steps: 9578 | Loss: 91.937801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:24 | Steps: 9579 | Loss: 91.941029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:24 | Steps: 9580 | Loss: 91.939736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:24 | Steps: 9581 | Loss: 91.940204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:25 | Steps: 9582 | Loss: 91.939964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:25 | Steps: 9583 | Loss: 91.939496\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:25 | Steps: 9584 | Loss: 91.941509\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:25 | Steps: 9585 | Loss: 91.948176\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:25 | Steps: 9586 | Loss: 91.952065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:25 | Steps: 9587 | Loss: 91.957169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:25 | Steps: 9588 | Loss: 91.962362\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:26 | Steps: 9589 | Loss: 91.960925\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:26 | Steps: 9590 | Loss: 91.963308\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:26 | Steps: 9591 | Loss: 91.964470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:26 | Steps: 9592 | Loss: 91.964952\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:26 | Steps: 9593 | Loss: 91.964524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:26 | Steps: 9594 | Loss: 91.968024\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:27 | Steps: 9595 | Loss: 91.971457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:27 | Steps: 9596 | Loss: 91.974223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:27 | Steps: 9597 | Loss: 91.975519\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:27 | Steps: 9598 | Loss: 91.973887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:27 | Steps: 9599 | Loss: 91.974210\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:27 | Steps: 9600 | Loss: 91.975349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:28 | Steps: 9601 | Loss: 91.975610\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:28 | Steps: 9602 | Loss: 91.977230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:28 | Steps: 9603 | Loss: 91.977897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:28 | Steps: 9604 | Loss: 91.976865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:28 | Steps: 9605 | Loss: 91.974386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:28 | Steps: 9606 | Loss: 91.974387\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:28 | Steps: 9607 | Loss: 91.972161\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:28 | Steps: 9608 | Loss: 91.970955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:29 | Steps: 9609 | Loss: 91.975304\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:29 | Steps: 9610 | Loss: 91.978672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:29 | Steps: 9611 | Loss: 91.976844\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:29 | Steps: 9612 | Loss: 91.974107\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:29 | Steps: 9613 | Loss: 91.970052\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:29 | Steps: 9614 | Loss: 91.966544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:29 | Steps: 9615 | Loss: 91.963802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:30 | Steps: 9616 | Loss: 91.962020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:30 | Steps: 9617 | Loss: 91.964667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:30 | Steps: 9618 | Loss: 91.966437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:30 | Steps: 9619 | Loss: 91.969541\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:30 | Steps: 9620 | Loss: 91.969105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:30 | Steps: 9621 | Loss: 91.969840\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:30 | Steps: 9622 | Loss: 91.971533\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:30 | Steps: 9623 | Loss: 91.974402\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:31 | Steps: 9624 | Loss: 91.975125\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:31 | Steps: 9625 | Loss: 91.974964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:31 | Steps: 9626 | Loss: 91.975364\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:31 | Steps: 9628 | Loss: 91.973626\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:31 | Steps: 9629 | Loss: 91.972492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:31 | Steps: 9630 | Loss: 91.974907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:31 | Steps: 9631 | Loss: 91.977525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:32 | Steps: 9632 | Loss: 91.975991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:32 | Steps: 9633 | Loss: 91.974881\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:32 | Steps: 9634 | Loss: 91.975748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:32 | Steps: 9635 | Loss: 91.976880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:32 | Steps: 9636 | Loss: 91.976768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:32 | Steps: 9637 | Loss: 91.976865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:32 | Steps: 9638 | Loss: 91.975620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:33 | Steps: 9639 | Loss: 91.980135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:33 | Steps: 9640 | Loss: 91.983520\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:33 | Steps: 9641 | Loss: 91.984885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:33 | Steps: 9642 | Loss: 91.991033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:33 | Steps: 9643 | Loss: 91.992450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:33 | Steps: 9644 | Loss: 91.993413\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:33 | Steps: 9645 | Loss: 91.992732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:34 | Steps: 9647 | Loss: 91.992735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:34 | Steps: 9648 | Loss: 91.995223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:34 | Steps: 9649 | Loss: 91.994441\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:34 | Steps: 9650 | Loss: 91.992341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:34 | Steps: 9651 | Loss: 91.987684\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:34 | Steps: 9652 | Loss: 91.989799\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:34 | Steps: 9653 | Loss: 91.987810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:35 | Steps: 9654 | Loss: 91.987270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:35 | Steps: 9655 | Loss: 91.987780\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:35 | Steps: 9656 | Loss: 91.989223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:35 | Steps: 9657 | Loss: 91.989173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:35 | Steps: 9658 | Loss: 91.986444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:35 | Steps: 9659 | Loss: 91.988248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:35 | Steps: 9660 | Loss: 91.990371\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:36 | Steps: 9661 | Loss: 91.991741\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:36 | Steps: 9662 | Loss: 91.997403\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:36 | Steps: 9663 | Loss: 91.995837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:36 | Steps: 9664 | Loss: 91.996786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:36 | Steps: 9665 | Loss: 91.997428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:36 | Steps: 9666 | Loss: 91.998870\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:36 | Steps: 9667 | Loss: 91.999755\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:36 | Steps: 9668 | Loss: 92.001236\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:37 | Steps: 9669 | Loss: 91.999995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:37 | Steps: 9670 | Loss: 91.999911\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:37 | Steps: 9671 | Loss: 91.999085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:37 | Steps: 9672 | Loss: 91.998251\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:37 | Steps: 9673 | Loss: 92.000959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:37 | Steps: 9674 | Loss: 92.002494\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:37 | Steps: 9675 | Loss: 92.006756\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:38 | Steps: 9676 | Loss: 92.012643\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:38 | Steps: 9677 | Loss: 92.015396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:38 | Steps: 9678 | Loss: 92.020707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:38 | Steps: 9679 | Loss: 92.018218\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:38 | Steps: 9680 | Loss: 92.017350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:38 | Steps: 9681 | Loss: 92.017546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:38 | Steps: 9682 | Loss: 92.019220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:38 | Steps: 9683 | Loss: 92.021005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:39 | Steps: 9684 | Loss: 92.028215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:39 | Steps: 9685 | Loss: 92.034212\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:39 | Steps: 9686 | Loss: 92.031767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:39 | Steps: 9687 | Loss: 92.036778\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:39 | Steps: 9688 | Loss: 92.037592\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:39 | Steps: 9689 | Loss: 92.037020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:39 | Steps: 9690 | Loss: 92.035763\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:40 | Steps: 9691 | Loss: 92.033146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:40 | Steps: 9692 | Loss: 92.032770\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:40 | Steps: 9693 | Loss: 92.033360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:40 | Steps: 9694 | Loss: 92.038085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:40 | Steps: 9695 | Loss: 92.034382\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:40 | Steps: 9696 | Loss: 92.033907\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:40 | Steps: 9697 | Loss: 92.033641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:41 | Steps: 9698 | Loss: 92.035341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:41 | Steps: 9699 | Loss: 92.035155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:41 | Steps: 9700 | Loss: 92.037841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:41 | Steps: 9701 | Loss: 92.039672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:41 | Steps: 9702 | Loss: 92.043232\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:41 | Steps: 9703 | Loss: 92.045277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:41 | Steps: 9704 | Loss: 92.045448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:42 | Steps: 9705 | Loss: 92.047353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:42 | Steps: 9706 | Loss: 92.046900\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:42 | Steps: 9707 | Loss: 92.047540\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:42 | Steps: 9708 | Loss: 92.044239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:42 | Steps: 9709 | Loss: 92.040678\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:42 | Steps: 9710 | Loss: 92.040208\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:42 | Steps: 9711 | Loss: 92.044414\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:42 | Steps: 9712 | Loss: 92.047311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:43 | Steps: 9713 | Loss: 92.049316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:43 | Steps: 9714 | Loss: 92.052525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:43 | Steps: 9715 | Loss: 92.053765\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:43 | Steps: 9716 | Loss: 92.055187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:43 | Steps: 9717 | Loss: 92.056936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:43 | Steps: 9718 | Loss: 92.055569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:43 | Steps: 9719 | Loss: 92.053154\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:44 | Steps: 9720 | Loss: 92.055162\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:44 | Steps: 9721 | Loss: 92.055474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:44 | Steps: 9722 | Loss: 92.054794\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:44 | Steps: 9723 | Loss: 92.054459\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:44 | Steps: 9724 | Loss: 92.056842\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:44 | Steps: 9725 | Loss: 92.061841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:44 | Steps: 9726 | Loss: 92.061636\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:44 | Steps: 9727 | Loss: 92.060731\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:45 | Steps: 9728 | Loss: 92.060001\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:45 | Steps: 9729 | Loss: 92.062786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:45 | Steps: 9730 | Loss: 92.064946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:45 | Steps: 9731 | Loss: 92.062396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:45 | Steps: 9732 | Loss: 92.062357\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:45 | Steps: 9733 | Loss: 92.061935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:45 | Steps: 9734 | Loss: 92.062879\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:46 | Steps: 9735 | Loss: 92.061821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:46 | Steps: 9736 | Loss: 92.060425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:46 | Steps: 9737 | Loss: 92.059762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:46 | Steps: 9738 | Loss: 92.057977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:46 | Steps: 9739 | Loss: 92.059400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:46 | Steps: 9740 | Loss: 92.061477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:46 | Steps: 9741 | Loss: 92.060665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:46 | Steps: 9742 | Loss: 92.063767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:47 | Steps: 9743 | Loss: 92.072802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:47 | Steps: 9744 | Loss: 92.075222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:47 | Steps: 9745 | Loss: 92.075336\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:47 | Steps: 9746 | Loss: 92.081108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:47 | Steps: 9747 | Loss: 92.081315\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:47 | Steps: 9748 | Loss: 92.083084\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:47 | Steps: 9749 | Loss: 92.084546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:47 | Steps: 9750 | Loss: 92.085887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:48 | Steps: 9751 | Loss: 92.089075\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:48 | Steps: 9752 | Loss: 92.092431\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:48 | Steps: 9753 | Loss: 92.097920\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:48 | Steps: 9754 | Loss: 92.095446\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:48 | Steps: 9755 | Loss: 92.096141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:48 | Steps: 9756 | Loss: 92.096633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:48 | Steps: 9757 | Loss: 92.099562\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:49 | Steps: 9758 | Loss: 92.102337\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:49 | Steps: 9759 | Loss: 92.104009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:49 | Steps: 9760 | Loss: 92.101871\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:49 | Steps: 9761 | Loss: 92.103645\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:49 | Steps: 9762 | Loss: 92.103734\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:49 | Steps: 9763 | Loss: 92.104017\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:49 | Steps: 9764 | Loss: 92.105554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:49 | Steps: 9765 | Loss: 92.104612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:50 | Steps: 9766 | Loss: 92.105026\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:50 | Steps: 9767 | Loss: 92.101864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:50 | Steps: 9768 | Loss: 92.101164\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:50 | Steps: 9769 | Loss: 92.100384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:50 | Steps: 9770 | Loss: 92.103516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:50 | Steps: 9771 | Loss: 92.101458\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:50 | Steps: 9772 | Loss: 92.099645\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:51 | Steps: 9773 | Loss: 92.102147\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:51 | Steps: 9774 | Loss: 92.101459\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:51 | Steps: 9775 | Loss: 92.102652\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:51 | Steps: 9776 | Loss: 92.108074\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:51 | Steps: 9777 | Loss: 92.107338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:51 | Steps: 9778 | Loss: 92.107124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:51 | Steps: 9779 | Loss: 92.106404\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:52 | Steps: 9780 | Loss: 92.110151\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:52 | Steps: 9781 | Loss: 92.109938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:52 | Steps: 9782 | Loss: 92.108846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:52 | Steps: 9783 | Loss: 92.108472\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:52 | Steps: 9784 | Loss: 92.109667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:52 | Steps: 9785 | Loss: 92.109237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:52 | Steps: 9786 | Loss: 92.112923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:52 | Steps: 9787 | Loss: 92.114453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:53 | Steps: 9788 | Loss: 92.119338\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:53 | Steps: 9789 | Loss: 92.122369\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:53 | Steps: 9790 | Loss: 92.120673\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:53 | Steps: 9791 | Loss: 92.119981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:53 | Steps: 9792 | Loss: 92.122116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:53 | Steps: 9793 | Loss: 92.123314\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:53 | Steps: 9794 | Loss: 92.125782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:54 | Steps: 9795 | Loss: 92.129973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:54 | Steps: 9796 | Loss: 92.129069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:54 | Steps: 9797 | Loss: 92.128267\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:54 | Steps: 9798 | Loss: 92.126814\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:54 | Steps: 9799 | Loss: 92.125427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:54 | Steps: 9800 | Loss: 92.129492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:54 | Steps: 9801 | Loss: 92.131096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:54 | Steps: 9802 | Loss: 92.133346\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:55 | Steps: 9803 | Loss: 92.133801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:55 | Steps: 9804 | Loss: 92.132296\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:55 | Steps: 9805 | Loss: 92.130855\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:55 | Steps: 9806 | Loss: 92.131777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:55 | Steps: 9807 | Loss: 92.131494\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:55 | Steps: 9808 | Loss: 92.131059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:55 | Steps: 9809 | Loss: 92.136610\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:56 | Steps: 9810 | Loss: 92.137799\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:56 | Steps: 9811 | Loss: 92.137277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:56 | Steps: 9812 | Loss: 92.136959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:56 | Steps: 9813 | Loss: 92.136921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:56 | Steps: 9814 | Loss: 92.136341\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:56 | Steps: 9815 | Loss: 92.136767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:56 | Steps: 9816 | Loss: 92.139276\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:57 | Steps: 9817 | Loss: 92.141738\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:57 | Steps: 9818 | Loss: 92.147537\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:57 | Steps: 9819 | Loss: 92.147890\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:57 | Steps: 9820 | Loss: 92.149665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:57 | Steps: 9821 | Loss: 92.154428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:57 | Steps: 9822 | Loss: 92.156973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:57 | Steps: 9823 | Loss: 92.156889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:57 | Steps: 9824 | Loss: 92.159139\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:58 | Steps: 9825 | Loss: 92.160392\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:58 | Steps: 9826 | Loss: 92.160848\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:58 | Steps: 9827 | Loss: 92.159810\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:58 | Steps: 9828 | Loss: 92.156485\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:58 | Steps: 9829 | Loss: 92.156133\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:58 | Steps: 9830 | Loss: 92.156937\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:58 | Steps: 9831 | Loss: 92.155874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:58 | Steps: 9832 | Loss: 92.157349\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:59 | Steps: 9833 | Loss: 92.159890\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:59 | Steps: 9834 | Loss: 92.159709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:59 | Steps: 9835 | Loss: 92.157477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:59 | Steps: 9836 | Loss: 92.160049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:59 | Steps: 9837 | Loss: 92.159287\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:59 | Steps: 9838 | Loss: 92.157350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:14:59 | Steps: 9839 | Loss: 92.159257\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:00 | Steps: 9840 | Loss: 92.156124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:00 | Steps: 9841 | Loss: 92.157388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:00 | Steps: 9842 | Loss: 92.159659\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:00 | Steps: 9843 | Loss: 92.161753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:00 | Steps: 9844 | Loss: 92.162041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:00 | Steps: 9845 | Loss: 92.163362\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:00 | Steps: 9846 | Loss: 92.162949\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:01 | Steps: 9847 | Loss: 92.163746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:01 | Steps: 9848 | Loss: 92.166424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:01 | Steps: 9849 | Loss: 92.164923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:01 | Steps: 9850 | Loss: 92.165127\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:01 | Steps: 9851 | Loss: 92.165769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:01 | Steps: 9852 | Loss: 92.165976\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:01 | Steps: 9853 | Loss: 92.165016\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:01 | Steps: 9854 | Loss: 92.164772\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:02 | Steps: 9855 | Loss: 92.164168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:02 | Steps: 9856 | Loss: 92.164462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:02 | Steps: 9857 | Loss: 92.163946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:02 | Steps: 9858 | Loss: 92.165277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:02 | Steps: 9859 | Loss: 92.165854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:02 | Steps: 9860 | Loss: 92.167380\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:02 | Steps: 9861 | Loss: 92.169259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:03 | Steps: 9862 | Loss: 92.177364\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:03 | Steps: 9863 | Loss: 92.180637\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:03 | Steps: 9864 | Loss: 92.180119\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:03 | Steps: 9865 | Loss: 92.182023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:03 | Steps: 9866 | Loss: 92.180121\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:03 | Steps: 9867 | Loss: 92.180734\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:03 | Steps: 9868 | Loss: 92.179334\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:03 | Steps: 9869 | Loss: 92.180130\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:04 | Steps: 9870 | Loss: 92.181888\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:04 | Steps: 9871 | Loss: 92.181703\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:04 | Steps: 9872 | Loss: 92.182727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:04 | Steps: 9873 | Loss: 92.184506\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:04 | Steps: 9874 | Loss: 92.187665\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:04 | Steps: 9875 | Loss: 92.188539\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:04 | Steps: 9876 | Loss: 92.192150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:05 | Steps: 9877 | Loss: 92.193094\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:05 | Steps: 9878 | Loss: 92.194355\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:05 | Steps: 9879 | Loss: 92.194913\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:05 | Steps: 9880 | Loss: 92.192954\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:05 | Steps: 9881 | Loss: 92.191564\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:05 | Steps: 9882 | Loss: 92.189146\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:05 | Steps: 9883 | Loss: 92.189313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:06 | Steps: 9884 | Loss: 92.189027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:06 | Steps: 9885 | Loss: 92.191167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:06 | Steps: 9886 | Loss: 92.190585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:06 | Steps: 9887 | Loss: 92.189895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:06 | Steps: 9888 | Loss: 92.187123\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:06 | Steps: 9889 | Loss: 92.183942\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:06 | Steps: 9890 | Loss: 92.183271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:07 | Steps: 9891 | Loss: 92.181199\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:07 | Steps: 9892 | Loss: 92.177305\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:07 | Steps: 9893 | Loss: 92.176284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:07 | Steps: 9894 | Loss: 92.175130\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:07 | Steps: 9895 | Loss: 92.174149\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:07 | Steps: 9896 | Loss: 92.174737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:07 | Steps: 9897 | Loss: 92.176721\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:07 | Steps: 9898 | Loss: 92.177335\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:08 | Steps: 9899 | Loss: 92.180886\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:08 | Steps: 9900 | Loss: 92.184219\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:08 | Steps: 9901 | Loss: 92.186156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:08 | Steps: 9902 | Loss: 92.186575\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:08 | Steps: 9903 | Loss: 92.183756\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:08 | Steps: 9904 | Loss: 92.184635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:08 | Steps: 9905 | Loss: 92.183167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:09 | Steps: 9906 | Loss: 92.181534\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:09 | Steps: 9907 | Loss: 92.183469\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:09 | Steps: 9908 | Loss: 92.185197\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:09 | Steps: 9909 | Loss: 92.185210\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:09 | Steps: 9910 | Loss: 92.188367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:09 | Steps: 9911 | Loss: 92.187972\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:09 | Steps: 9912 | Loss: 92.185720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:10 | Steps: 9913 | Loss: 92.185184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:10 | Steps: 9914 | Loss: 92.188715\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:10 | Steps: 9915 | Loss: 92.188506\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:10 | Steps: 9916 | Loss: 92.190267\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:10 | Steps: 9917 | Loss: 92.191416\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:10 | Steps: 9918 | Loss: 92.193714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:10 | Steps: 9919 | Loss: 92.193500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:11 | Steps: 9920 | Loss: 92.193450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:11 | Steps: 9921 | Loss: 92.189559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:11 | Steps: 9922 | Loss: 92.193331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:11 | Steps: 9923 | Loss: 92.192177\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:11 | Steps: 9924 | Loss: 92.192465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:11 | Steps: 9925 | Loss: 92.192767\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:11 | Steps: 9926 | Loss: 92.192090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:11 | Steps: 9927 | Loss: 92.192331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:12 | Steps: 9928 | Loss: 92.192858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:12 | Steps: 9929 | Loss: 92.194818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:12 | Steps: 9930 | Loss: 92.193065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:12 | Steps: 9931 | Loss: 92.195805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:12 | Steps: 9932 | Loss: 92.195533\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:12 | Steps: 9933 | Loss: 92.196347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:12 | Steps: 9934 | Loss: 92.198270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:13 | Steps: 9936 | Loss: 92.209662\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:13 | Steps: 9937 | Loss: 92.209167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:13 | Steps: 9938 | Loss: 92.213471\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:13 | Steps: 9939 | Loss: 92.213917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:13 | Steps: 9940 | Loss: 92.214883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:13 | Steps: 9941 | Loss: 92.213985\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:14 | Steps: 9942 | Loss: 92.214904\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:14 | Steps: 9943 | Loss: 92.215220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:14 | Steps: 9944 | Loss: 92.217358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:14 | Steps: 9945 | Loss: 92.221053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:14 | Steps: 9946 | Loss: 92.220963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:14 | Steps: 9947 | Loss: 92.219876\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:14 | Steps: 9948 | Loss: 92.219529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:14 | Steps: 9949 | Loss: 92.221007\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:15 | Steps: 9950 | Loss: 92.226749\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:15 | Steps: 9951 | Loss: 92.227042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:15 | Steps: 9952 | Loss: 92.228079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:15 | Steps: 9953 | Loss: 92.227038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:15 | Steps: 9954 | Loss: 92.225168\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:15 | Steps: 9955 | Loss: 92.223272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:15 | Steps: 9956 | Loss: 92.224540\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:16 | Steps: 9957 | Loss: 92.221635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:16 | Steps: 9958 | Loss: 92.218846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:16 | Steps: 9959 | Loss: 92.217853\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:16 | Steps: 9960 | Loss: 92.218910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:16 | Steps: 9961 | Loss: 92.222613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:16 | Steps: 9962 | Loss: 92.222605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:16 | Steps: 9963 | Loss: 92.225875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:16 | Steps: 9964 | Loss: 92.228195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:17 | Steps: 9965 | Loss: 92.231663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:17 | Steps: 9966 | Loss: 92.230856\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:17 | Steps: 9967 | Loss: 92.231036\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:17 | Steps: 9968 | Loss: 92.229814\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:17 | Steps: 9969 | Loss: 92.232298\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:17 | Steps: 9970 | Loss: 92.234050\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:17 | Steps: 9971 | Loss: 92.233346\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:18 | Steps: 9972 | Loss: 92.232584\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:18 | Steps: 9973 | Loss: 92.233653\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:18 | Steps: 9974 | Loss: 92.233875\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:18 | Steps: 9975 | Loss: 92.235030\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:18 | Steps: 9976 | Loss: 92.238612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:18 | Steps: 9977 | Loss: 92.237167\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:18 | Steps: 9978 | Loss: 92.235805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:19 | Steps: 9979 | Loss: 92.237438\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:19 | Steps: 9980 | Loss: 92.237145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:19 | Steps: 9981 | Loss: 92.238272\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:19 | Steps: 9982 | Loss: 92.238918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:19 | Steps: 9983 | Loss: 92.237009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:19 | Steps: 9984 | Loss: 92.236815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:19 | Steps: 9985 | Loss: 92.245839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:20 | Steps: 9986 | Loss: 92.245548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:20 | Steps: 9987 | Loss: 92.245864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:20 | Steps: 9988 | Loss: 92.245234\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:20 | Steps: 9989 | Loss: 92.248426\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:20 | Steps: 9990 | Loss: 92.252748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:20 | Steps: 9991 | Loss: 92.253519\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:20 | Steps: 9992 | Loss: 92.256121\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:21 | Steps: 9993 | Loss: 92.257938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:21 | Steps: 9994 | Loss: 92.259835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:21 | Steps: 9995 | Loss: 92.258249\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:21 | Steps: 9996 | Loss: 92.258635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:21 | Steps: 9997 | Loss: 92.260688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:21 | Steps: 9998 | Loss: 92.261250\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:21 | Steps: 9999 | Loss: 92.266114\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:21 | Steps: 10000 | Loss: 92.270236\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:22 | Steps: 10001 | Loss: 92.272274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:22 | Steps: 10002 | Loss: 92.276527\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:22 | Steps: 10003 | Loss: 92.281081\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:22 | Steps: 10004 | Loss: 92.280415\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:22 | Steps: 10005 | Loss: 92.283583\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:22 | Steps: 10006 | Loss: 92.283492\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:22 | Steps: 10007 | Loss: 92.282462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:23 | Steps: 10008 | Loss: 92.284090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:23 | Steps: 10009 | Loss: 92.288585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:23 | Steps: 10010 | Loss: 92.291159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:23 | Steps: 10011 | Loss: 92.295868\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:23 | Steps: 10012 | Loss: 92.296762\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:23 | Steps: 10013 | Loss: 92.294554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:23 | Steps: 10014 | Loss: 92.292174\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:24 | Steps: 10015 | Loss: 92.291657\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:24 | Steps: 10016 | Loss: 92.292961\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:24 | Steps: 10017 | Loss: 92.292283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:24 | Steps: 10018 | Loss: 92.290141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:24 | Steps: 10019 | Loss: 92.291339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:24 | Steps: 10020 | Loss: 92.292330\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:24 | Steps: 10021 | Loss: 92.291139\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:25 | Steps: 10022 | Loss: 92.293523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:25 | Steps: 10023 | Loss: 92.297216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:25 | Steps: 10024 | Loss: 92.299746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:25 | Steps: 10025 | Loss: 92.299050\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:25 | Steps: 10026 | Loss: 92.297464\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:25 | Steps: 10027 | Loss: 92.298222\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:26 | Steps: 10028 | Loss: 92.298044\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:26 | Steps: 10029 | Loss: 92.300212\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:26 | Steps: 10030 | Loss: 92.303669\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:26 | Steps: 10031 | Loss: 92.308578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:26 | Steps: 10032 | Loss: 92.308115\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:26 | Steps: 10033 | Loss: 92.310477\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:26 | Steps: 10034 | Loss: 92.309971\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:27 | Steps: 10035 | Loss: 92.313053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:27 | Steps: 10036 | Loss: 92.318507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:27 | Steps: 10037 | Loss: 92.318268\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:27 | Steps: 10038 | Loss: 92.316658\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:27 | Steps: 10039 | Loss: 92.321110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:27 | Steps: 10040 | Loss: 92.325093\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:27 | Steps: 10041 | Loss: 92.324987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:28 | Steps: 10042 | Loss: 92.324784\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:28 | Steps: 10043 | Loss: 92.324674\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:28 | Steps: 10044 | Loss: 92.324099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:28 | Steps: 10045 | Loss: 92.325448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:28 | Steps: 10046 | Loss: 92.326097\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:28 | Steps: 10047 | Loss: 92.327319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:28 | Steps: 10048 | Loss: 92.328497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:29 | Steps: 10049 | Loss: 92.328988\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:29 | Steps: 10050 | Loss: 92.327929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:29 | Steps: 10051 | Loss: 92.330290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:29 | Steps: 10052 | Loss: 92.336216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:29 | Steps: 10053 | Loss: 92.334579\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:29 | Steps: 10054 | Loss: 92.335331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:30 | Steps: 10055 | Loss: 92.341655\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:30 | Steps: 10056 | Loss: 92.343682\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:30 | Steps: 10057 | Loss: 92.344083\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:30 | Steps: 10058 | Loss: 92.342905\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:30 | Steps: 10059 | Loss: 92.343744\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:30 | Steps: 10060 | Loss: 92.344977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:30 | Steps: 10061 | Loss: 92.347317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:31 | Steps: 10062 | Loss: 92.347913\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:31 | Steps: 10063 | Loss: 92.345857\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:31 | Steps: 10064 | Loss: 92.347237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:31 | Steps: 10065 | Loss: 92.347490\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:31 | Steps: 10066 | Loss: 92.347841\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:31 | Steps: 10067 | Loss: 92.349383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:31 | Steps: 10068 | Loss: 92.350708\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:32 | Steps: 10069 | Loss: 92.351099\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:32 | Steps: 10070 | Loss: 92.349467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:32 | Steps: 10071 | Loss: 92.352917\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:32 | Steps: 10072 | Loss: 92.352447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:32 | Steps: 10073 | Loss: 92.352195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:32 | Steps: 10074 | Loss: 92.352975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:32 | Steps: 10075 | Loss: 92.354838\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:33 | Steps: 10076 | Loss: 92.358644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:33 | Steps: 10077 | Loss: 92.361247\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:33 | Steps: 10078 | Loss: 92.361752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:33 | Steps: 10079 | Loss: 92.360429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:33 | Steps: 10080 | Loss: 92.362792\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:33 | Steps: 10081 | Loss: 92.365714\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:34 | Steps: 10082 | Loss: 92.367626\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:34 | Steps: 10083 | Loss: 92.368152\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:34 | Steps: 10084 | Loss: 92.366432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:34 | Steps: 10085 | Loss: 92.365979\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:34 | Steps: 10086 | Loss: 92.367320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:34 | Steps: 10087 | Loss: 92.368016\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:34 | Steps: 10088 | Loss: 92.368223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:35 | Steps: 10089 | Loss: 92.379085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:35 | Steps: 10090 | Loss: 92.380186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:35 | Steps: 10091 | Loss: 92.384274\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:35 | Steps: 10092 | Loss: 92.384559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:35 | Steps: 10093 | Loss: 92.383390\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:35 | Steps: 10094 | Loss: 92.383131\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:35 | Steps: 10095 | Loss: 92.388008\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:36 | Steps: 10096 | Loss: 92.387781\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:36 | Steps: 10097 | Loss: 92.388011\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:36 | Steps: 10098 | Loss: 92.388180\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:36 | Steps: 10099 | Loss: 92.388388\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:36 | Steps: 10100 | Loss: 92.388386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:36 | Steps: 10101 | Loss: 92.392946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:36 | Steps: 10102 | Loss: 92.397424\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:37 | Steps: 10103 | Loss: 92.400691\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:37 | Steps: 10104 | Loss: 92.405747\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:37 | Steps: 10105 | Loss: 92.408314\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:37 | Steps: 10106 | Loss: 92.410230\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:37 | Steps: 10107 | Loss: 92.413773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:37 | Steps: 10108 | Loss: 92.413181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:38 | Steps: 10109 | Loss: 92.415370\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:38 | Steps: 10110 | Loss: 92.416268\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:38 | Steps: 10111 | Loss: 92.418200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:38 | Steps: 10112 | Loss: 92.420334\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:38 | Steps: 10113 | Loss: 92.421757\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:38 | Steps: 10114 | Loss: 92.419113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:38 | Steps: 10115 | Loss: 92.416729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:39 | Steps: 10116 | Loss: 92.417922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:39 | Steps: 10117 | Loss: 92.417513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:39 | Steps: 10118 | Loss: 92.416501\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:39 | Steps: 10119 | Loss: 92.417329\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:39 | Steps: 10120 | Loss: 92.419743\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:39 | Steps: 10121 | Loss: 92.418281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:40 | Steps: 10122 | Loss: 92.418892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:40 | Steps: 10123 | Loss: 92.420320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:40 | Steps: 10124 | Loss: 92.421834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:40 | Steps: 10125 | Loss: 92.420563\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:40 | Steps: 10126 | Loss: 92.422105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:40 | Steps: 10127 | Loss: 92.422258\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:40 | Steps: 10128 | Loss: 92.420343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:40 | Steps: 10129 | Loss: 92.420014\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:41 | Steps: 10130 | Loss: 92.421062\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:41 | Steps: 10131 | Loss: 92.420707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:41 | Steps: 10132 | Loss: 92.422353\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:41 | Steps: 10133 | Loss: 92.425796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:41 | Steps: 10134 | Loss: 92.426429\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:41 | Steps: 10135 | Loss: 92.426319\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:42 | Steps: 10136 | Loss: 92.427666\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:42 | Steps: 10137 | Loss: 92.430368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:42 | Steps: 10138 | Loss: 92.431896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:42 | Steps: 10139 | Loss: 92.434053\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:42 | Steps: 10140 | Loss: 92.436361\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:42 | Steps: 10141 | Loss: 92.438024\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:42 | Steps: 10142 | Loss: 92.441628\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:43 | Steps: 10143 | Loss: 92.438460\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:43 | Steps: 10144 | Loss: 92.434909\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:43 | Steps: 10145 | Loss: 92.438847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:43 | Steps: 10146 | Loss: 92.442998\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:43 | Steps: 10147 | Loss: 92.442880\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:43 | Steps: 10148 | Loss: 92.445283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:43 | Steps: 10149 | Loss: 92.445935\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:44 | Steps: 10150 | Loss: 92.446444\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:44 | Steps: 10151 | Loss: 92.448685\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:44 | Steps: 10152 | Loss: 92.446991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:44 | Steps: 10153 | Loss: 92.448639\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:44 | Steps: 10154 | Loss: 92.454245\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:44 | Steps: 10155 | Loss: 92.455141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:45 | Steps: 10156 | Loss: 92.455736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:45 | Steps: 10157 | Loss: 92.456427\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:45 | Steps: 10158 | Loss: 92.456783\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:45 | Steps: 10159 | Loss: 92.463667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:45 | Steps: 10160 | Loss: 92.464578\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:45 | Steps: 10161 | Loss: 92.466127\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:45 | Steps: 10162 | Loss: 92.471462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:45 | Steps: 10163 | Loss: 92.475580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:46 | Steps: 10164 | Loss: 92.499447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:46 | Steps: 10165 | Loss: 92.497896\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:46 | Steps: 10166 | Loss: 92.498149\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:46 | Steps: 10167 | Loss: 92.495866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:46 | Steps: 10168 | Loss: 92.495785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:46 | Steps: 10169 | Loss: 92.499040\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:46 | Steps: 10170 | Loss: 92.496922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:47 | Steps: 10171 | Loss: 92.496051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:47 | Steps: 10172 | Loss: 92.496279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:47 | Steps: 10173 | Loss: 92.496265\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:47 | Steps: 10174 | Loss: 92.497292\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:47 | Steps: 10175 | Loss: 92.498354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:47 | Steps: 10176 | Loss: 92.501949\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:47 | Steps: 10177 | Loss: 92.502784\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:48 | Steps: 10178 | Loss: 92.504518\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:48 | Steps: 10179 | Loss: 92.507008\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:48 | Steps: 10180 | Loss: 92.514479\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:48 | Steps: 10181 | Loss: 92.522038\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:48 | Steps: 10182 | Loss: 92.522058\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:48 | Steps: 10183 | Loss: 92.521918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:48 | Steps: 10184 | Loss: 92.523049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:49 | Steps: 10185 | Loss: 92.523525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:49 | Steps: 10186 | Loss: 92.526010\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:49 | Steps: 10187 | Loss: 92.529069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:49 | Steps: 10188 | Loss: 92.528874\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:49 | Steps: 10189 | Loss: 92.527964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:49 | Steps: 10190 | Loss: 92.525453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:50 | Steps: 10191 | Loss: 92.527317\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:50 | Steps: 10192 | Loss: 92.525989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:50 | Steps: 10193 | Loss: 92.528018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:50 | Steps: 10194 | Loss: 92.529299\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:50 | Steps: 10195 | Loss: 92.529864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:50 | Steps: 10196 | Loss: 92.531443\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:50 | Steps: 10197 | Loss: 92.532383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:50 | Steps: 10198 | Loss: 92.531729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:51 | Steps: 10199 | Loss: 92.535084\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:51 | Steps: 10200 | Loss: 92.536449\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:51 | Steps: 10201 | Loss: 92.540275\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:51 | Steps: 10202 | Loss: 92.540745\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:51 | Steps: 10203 | Loss: 92.544635\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:51 | Steps: 10204 | Loss: 92.543580\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:51 | Steps: 10205 | Loss: 92.544136\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:52 | Steps: 10206 | Loss: 92.543621\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:52 | Steps: 10207 | Loss: 92.547847\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:52 | Steps: 10208 | Loss: 92.550434\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:52 | Steps: 10209 | Loss: 92.554984\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:52 | Steps: 10210 | Loss: 92.554936\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:52 | Steps: 10211 | Loss: 92.553733\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:53 | Steps: 10212 | Loss: 92.554093\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:53 | Steps: 10213 | Loss: 92.558620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:53 | Steps: 10214 | Loss: 92.555993\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:53 | Steps: 10215 | Loss: 92.555716\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:53 | Steps: 10216 | Loss: 92.556195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:53 | Steps: 10217 | Loss: 92.554459\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:53 | Steps: 10218 | Loss: 92.555502\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:54 | Steps: 10219 | Loss: 92.553703\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:54 | Steps: 10220 | Loss: 92.551910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:54 | Steps: 10221 | Loss: 92.552079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:54 | Steps: 10222 | Loss: 92.551500\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:54 | Steps: 10223 | Loss: 92.552278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:54 | Steps: 10224 | Loss: 92.554205\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:54 | Steps: 10225 | Loss: 92.555214\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:55 | Steps: 10226 | Loss: 92.556773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:55 | Steps: 10227 | Loss: 92.557251\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:55 | Steps: 10228 | Loss: 92.555671\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:55 | Steps: 10229 | Loss: 92.556846\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:55 | Steps: 10230 | Loss: 92.559264\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:55 | Steps: 10231 | Loss: 92.557482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:55 | Steps: 10232 | Loss: 92.562962\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:56 | Steps: 10233 | Loss: 92.561632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:56 | Steps: 10234 | Loss: 92.564148\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:56 | Steps: 10235 | Loss: 92.565184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:56 | Steps: 10236 | Loss: 92.564837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:56 | Steps: 10237 | Loss: 92.566521\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:56 | Steps: 10238 | Loss: 92.568255\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:56 | Steps: 10239 | Loss: 92.565215\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:57 | Steps: 10240 | Loss: 92.564140\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:57 | Steps: 10241 | Loss: 92.564323\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:57 | Steps: 10242 | Loss: 92.565803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:57 | Steps: 10243 | Loss: 92.565499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:57 | Steps: 10244 | Loss: 92.565281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:57 | Steps: 10245 | Loss: 92.566308\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:57 | Steps: 10246 | Loss: 92.568343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:58 | Steps: 10247 | Loss: 92.569109\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:58 | Steps: 10248 | Loss: 92.573742\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:58 | Steps: 10249 | Loss: 92.573829\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:58 | Steps: 10250 | Loss: 92.576065\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:58 | Steps: 10251 | Loss: 92.575948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:58 | Steps: 10252 | Loss: 92.576565\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:58 | Steps: 10253 | Loss: 92.577614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:59 | Steps: 10254 | Loss: 92.577608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:59 | Steps: 10255 | Loss: 92.578729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:59 | Steps: 10256 | Loss: 92.582613\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:59 | Steps: 10257 | Loss: 92.587192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:59 | Steps: 10258 | Loss: 92.591982\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:59 | Steps: 10259 | Loss: 92.592245\n",
      "Epoch 0 |   Training | Elapsed Time: 0:15:59 | Steps: 10260 | Loss: 92.595769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:00 | Steps: 10261 | Loss: 92.594584\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:00 | Steps: 10262 | Loss: 92.594569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:00 | Steps: 10263 | Loss: 92.597821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:00 | Steps: 10264 | Loss: 92.597277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:00 | Steps: 10265 | Loss: 92.593975\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:00 | Steps: 10266 | Loss: 92.595746\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:00 | Steps: 10267 | Loss: 92.596504\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:01 | Steps: 10268 | Loss: 92.596995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:01 | Steps: 10269 | Loss: 92.598243\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:01 | Steps: 10270 | Loss: 92.598073\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:01 | Steps: 10271 | Loss: 92.595787\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:01 | Steps: 10272 | Loss: 92.597529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:01 | Steps: 10273 | Loss: 92.598082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:02 | Steps: 10274 | Loss: 92.598296\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:02 | Steps: 10275 | Loss: 92.599764\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:02 | Steps: 10276 | Loss: 92.599641\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:02 | Steps: 10277 | Loss: 92.599538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:02 | Steps: 10278 | Loss: 92.601698\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:02 | Steps: 10279 | Loss: 92.607480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:02 | Steps: 10280 | Loss: 92.610102\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:03 | Steps: 10281 | Loss: 92.607956\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:03 | Steps: 10282 | Loss: 92.609181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:03 | Steps: 10283 | Loss: 92.609107\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:03 | Steps: 10284 | Loss: 92.607995\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:03 | Steps: 10285 | Loss: 92.609570\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:03 | Steps: 10286 | Loss: 92.609221\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:03 | Steps: 10287 | Loss: 92.612420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:04 | Steps: 10288 | Loss: 92.613247\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:04 | Steps: 10289 | Loss: 92.611343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:04 | Steps: 10290 | Loss: 92.611506\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:04 | Steps: 10291 | Loss: 92.612360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:04 | Steps: 10292 | Loss: 92.616748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:04 | Steps: 10293 | Loss: 92.616627\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:04 | Steps: 10294 | Loss: 92.616463\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:05 | Steps: 10295 | Loss: 92.619921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:05 | Steps: 10296 | Loss: 92.622151\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:05 | Steps: 10297 | Loss: 92.618866\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:05 | Steps: 10298 | Loss: 92.618170\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:05 | Steps: 10299 | Loss: 92.616760\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:05 | Steps: 10300 | Loss: 92.617028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:05 | Steps: 10301 | Loss: 92.615689\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:06 | Steps: 10302 | Loss: 92.612347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:06 | Steps: 10303 | Loss: 92.610009\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:06 | Steps: 10304 | Loss: 92.609175\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:06 | Steps: 10305 | Loss: 92.614418\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:06 | Steps: 10306 | Loss: 92.613833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:06 | Steps: 10307 | Loss: 92.612324\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:07 | Steps: 10308 | Loss: 92.612368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:07 | Steps: 10309 | Loss: 92.613141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:07 | Steps: 10310 | Loss: 92.612288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:07 | Steps: 10311 | Loss: 92.613059\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:07 | Steps: 10312 | Loss: 92.612166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:07 | Steps: 10313 | Loss: 92.610604\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:07 | Steps: 10314 | Loss: 92.610337\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:08 | Steps: 10315 | Loss: 92.611439\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:08 | Steps: 10316 | Loss: 92.610436\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:08 | Steps: 10317 | Loss: 92.609963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:08 | Steps: 10318 | Loss: 92.611729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:08 | Steps: 10319 | Loss: 92.613076\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:08 | Steps: 10320 | Loss: 92.613507\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:08 | Steps: 10321 | Loss: 92.619493\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:09 | Steps: 10322 | Loss: 92.619282\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:09 | Steps: 10323 | Loss: 92.617885\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:09 | Steps: 10324 | Loss: 92.620331\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:09 | Steps: 10325 | Loss: 92.619893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:09 | Steps: 10326 | Loss: 92.617262\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:09 | Steps: 10327 | Loss: 92.616354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:09 | Steps: 10328 | Loss: 92.616646\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:10 | Steps: 10329 | Loss: 92.620337\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:10 | Steps: 10330 | Loss: 92.621805\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:10 | Steps: 10331 | Loss: 92.621138\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:10 | Steps: 10332 | Loss: 92.619360\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:10 | Steps: 10333 | Loss: 92.623560\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:10 | Steps: 10334 | Loss: 92.628395\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:10 | Steps: 10335 | Loss: 92.632356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:11 | Steps: 10336 | Loss: 92.633227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:11 | Steps: 10337 | Loss: 92.635624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:11 | Steps: 10338 | Loss: 92.634773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:11 | Steps: 10339 | Loss: 92.635498\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:11 | Steps: 10340 | Loss: 92.637834\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:11 | Steps: 10341 | Loss: 92.641582\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:11 | Steps: 10342 | Loss: 92.646835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:12 | Steps: 10343 | Loss: 92.651028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:12 | Steps: 10344 | Loss: 92.656271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:12 | Steps: 10345 | Loss: 92.659890\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:12 | Steps: 10346 | Loss: 92.663934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:12 | Steps: 10347 | Loss: 92.663209\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:12 | Steps: 10348 | Loss: 92.666633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:12 | Steps: 10349 | Loss: 92.666356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:13 | Steps: 10350 | Loss: 92.668946\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:13 | Steps: 10351 | Loss: 92.670504\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:13 | Steps: 10352 | Loss: 92.673212\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:13 | Steps: 10353 | Loss: 92.670028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:13 | Steps: 10354 | Loss: 92.667533\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:13 | Steps: 10355 | Loss: 92.668484\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:13 | Steps: 10356 | Loss: 92.666170\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:14 | Steps: 10357 | Loss: 92.666350\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:14 | Steps: 10358 | Loss: 92.667094\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:14 | Steps: 10359 | Loss: 92.668971\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:14 | Steps: 10360 | Loss: 92.669078\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:14 | Steps: 10361 | Loss: 92.669748\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:14 | Steps: 10362 | Loss: 92.667638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:14 | Steps: 10363 | Loss: 92.670732\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:15 | Steps: 10364 | Loss: 92.678387\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:15 | Steps: 10365 | Loss: 92.682685\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:15 | Steps: 10366 | Loss: 92.684358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:15 | Steps: 10367 | Loss: 92.688734\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:15 | Steps: 10368 | Loss: 92.688394\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:15 | Steps: 10369 | Loss: 92.689782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:16 | Steps: 10370 | Loss: 92.689571\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:16 | Steps: 10371 | Loss: 92.688768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:16 | Steps: 10372 | Loss: 92.690403\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:16 | Steps: 10373 | Loss: 92.693343\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:16 | Steps: 10374 | Loss: 92.694291\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:16 | Steps: 10375 | Loss: 92.697706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:16 | Steps: 10376 | Loss: 92.696851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:17 | Steps: 10377 | Loss: 92.699048\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:17 | Steps: 10378 | Loss: 92.698311\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:17 | Steps: 10379 | Loss: 92.699751\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:17 | Steps: 10380 | Loss: 92.700041\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:17 | Steps: 10381 | Loss: 92.700822\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:17 | Steps: 10382 | Loss: 92.701363\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:18 | Steps: 10383 | Loss: 92.700480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:18 | Steps: 10384 | Loss: 92.702996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:18 | Steps: 10385 | Loss: 92.704872\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:18 | Steps: 10386 | Loss: 92.710454\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:18 | Steps: 10387 | Loss: 92.711223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:18 | Steps: 10388 | Loss: 92.711561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:18 | Steps: 10389 | Loss: 92.715396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:19 | Steps: 10390 | Loss: 92.721394\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:19 | Steps: 10391 | Loss: 92.720436\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:19 | Steps: 10392 | Loss: 92.718968\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:19 | Steps: 10393 | Loss: 92.722604\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:19 | Steps: 10394 | Loss: 92.720513\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:19 | Steps: 10395 | Loss: 92.719183\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:19 | Steps: 10396 | Loss: 92.719181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:20 | Steps: 10397 | Loss: 92.722333\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:20 | Steps: 10398 | Loss: 92.722800\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:20 | Steps: 10399 | Loss: 92.723468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:20 | Steps: 10400 | Loss: 92.725928\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:20 | Steps: 10401 | Loss: 92.728576\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:20 | Steps: 10402 | Loss: 92.730999\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:20 | Steps: 10403 | Loss: 92.732216\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:21 | Steps: 10404 | Loss: 92.731803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:21 | Steps: 10405 | Loss: 92.731729\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:21 | Steps: 10406 | Loss: 92.728063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:21 | Steps: 10407 | Loss: 92.727085\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:21 | Steps: 10408 | Loss: 92.728963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:21 | Steps: 10409 | Loss: 92.731521\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:21 | Steps: 10410 | Loss: 92.735934\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:22 | Steps: 10411 | Loss: 92.736693\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:22 | Steps: 10412 | Loss: 92.735991\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:22 | Steps: 10413 | Loss: 92.738029\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:22 | Steps: 10414 | Loss: 92.740213\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:22 | Steps: 10415 | Loss: 92.743530\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:22 | Steps: 10416 | Loss: 92.746951\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:22 | Steps: 10417 | Loss: 92.746425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:23 | Steps: 10418 | Loss: 92.745678\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:23 | Steps: 10419 | Loss: 92.747537\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:23 | Steps: 10420 | Loss: 92.751356\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:23 | Steps: 10421 | Loss: 92.752705\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:23 | Steps: 10422 | Loss: 92.751706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:23 | Steps: 10423 | Loss: 92.749802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:24 | Steps: 10424 | Loss: 92.751965\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:24 | Steps: 10425 | Loss: 92.752309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:24 | Steps: 10426 | Loss: 92.754396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:24 | Steps: 10427 | Loss: 92.754923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:24 | Steps: 10428 | Loss: 92.755687\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:24 | Steps: 10429 | Loss: 92.756252\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:24 | Steps: 10430 | Loss: 92.759771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:25 | Steps: 10431 | Loss: 92.760529\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:25 | Steps: 10432 | Loss: 92.761066\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:25 | Steps: 10433 | Loss: 92.761854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:25 | Steps: 10434 | Loss: 92.763011\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:25 | Steps: 10435 | Loss: 92.764976\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:25 | Steps: 10436 | Loss: 92.766284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:25 | Steps: 10437 | Loss: 92.766380\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:26 | Steps: 10438 | Loss: 92.765897\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:26 | Steps: 10439 | Loss: 92.763639\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:26 | Steps: 10440 | Loss: 92.763277\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:26 | Steps: 10441 | Loss: 92.762877\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:26 | Steps: 10442 | Loss: 92.762948\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:26 | Steps: 10443 | Loss: 92.767013\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:27 | Steps: 10444 | Loss: 92.770090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:27 | Steps: 10445 | Loss: 92.770755\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:27 | Steps: 10446 | Loss: 92.773955\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:27 | Steps: 10447 | Loss: 92.773667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:27 | Steps: 10448 | Loss: 92.776032\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:27 | Steps: 10449 | Loss: 92.778039\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:27 | Steps: 10450 | Loss: 92.780680\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:28 | Steps: 10451 | Loss: 92.787793\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:28 | Steps: 10452 | Loss: 92.790125\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:28 | Steps: 10453 | Loss: 92.789412\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:28 | Steps: 10454 | Loss: 92.789291\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:28 | Steps: 10455 | Loss: 92.793572\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:28 | Steps: 10456 | Loss: 92.793471\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:28 | Steps: 10457 | Loss: 92.798520\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:29 | Steps: 10458 | Loss: 92.797502\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:29 | Steps: 10459 | Loss: 92.795623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:29 | Steps: 10460 | Loss: 92.794117\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:29 | Steps: 10461 | Loss: 92.793488\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:29 | Steps: 10462 | Loss: 92.793015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:29 | Steps: 10463 | Loss: 92.795482\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:30 | Steps: 10464 | Loss: 92.795717\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:30 | Steps: 10465 | Loss: 92.798889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:30 | Steps: 10466 | Loss: 92.800451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:30 | Steps: 10467 | Loss: 92.799128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:30 | Steps: 10468 | Loss: 92.799835\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:30 | Steps: 10469 | Loss: 92.802679\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:30 | Steps: 10470 | Loss: 92.805284\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:31 | Steps: 10471 | Loss: 92.806095\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:31 | Steps: 10472 | Loss: 92.807314\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:31 | Steps: 10473 | Loss: 92.813192\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:31 | Steps: 10474 | Loss: 92.812617\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:31 | Steps: 10475 | Loss: 92.810814\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:31 | Steps: 10476 | Loss: 92.810873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:32 | Steps: 10477 | Loss: 92.811108\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:32 | Steps: 10478 | Loss: 92.810227\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:32 | Steps: 10479 | Loss: 92.809977\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:32 | Steps: 10480 | Loss: 92.814868\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:32 | Steps: 10481 | Loss: 92.815758\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:32 | Steps: 10482 | Loss: 92.816001\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:32 | Steps: 10483 | Loss: 92.816366\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:33 | Steps: 10484 | Loss: 92.818973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:33 | Steps: 10485 | Loss: 92.823986\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:33 | Steps: 10486 | Loss: 92.830027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:33 | Steps: 10487 | Loss: 92.829102\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:33 | Steps: 10488 | Loss: 92.828346\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:33 | Steps: 10489 | Loss: 92.829138\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:34 | Steps: 10490 | Loss: 92.833364\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:34 | Steps: 10491 | Loss: 92.834474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:34 | Steps: 10492 | Loss: 92.834105\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:34 | Steps: 10493 | Loss: 92.831420\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:34 | Steps: 10494 | Loss: 92.832183\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:34 | Steps: 10495 | Loss: 92.832367\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:34 | Steps: 10496 | Loss: 92.830783\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:35 | Steps: 10497 | Loss: 92.831299\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:35 | Steps: 10498 | Loss: 92.833270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:35 | Steps: 10499 | Loss: 92.833322\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:35 | Steps: 10500 | Loss: 92.834753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:35 | Steps: 10501 | Loss: 92.835483\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:35 | Steps: 10502 | Loss: 92.837443\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:35 | Steps: 10503 | Loss: 92.837565\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:36 | Steps: 10504 | Loss: 92.838161\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:36 | Steps: 10505 | Loss: 92.836598\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:36 | Steps: 10506 | Loss: 92.838814\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:36 | Steps: 10507 | Loss: 92.836812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:36 | Steps: 10508 | Loss: 92.837260\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:36 | Steps: 10509 | Loss: 92.838383\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:36 | Steps: 10510 | Loss: 92.839396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:37 | Steps: 10511 | Loss: 92.841097\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:37 | Steps: 10512 | Loss: 92.840775\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:37 | Steps: 10513 | Loss: 92.841318\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:37 | Steps: 10514 | Loss: 92.842177\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:37 | Steps: 10515 | Loss: 92.841141\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:37 | Steps: 10516 | Loss: 92.841056\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:38 | Steps: 10517 | Loss: 92.842110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:38 | Steps: 10518 | Loss: 92.844092\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:38 | Steps: 10519 | Loss: 92.847278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:38 | Steps: 10520 | Loss: 92.850124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:38 | Steps: 10521 | Loss: 92.849681\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:38 | Steps: 10522 | Loss: 92.848561\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:38 | Steps: 10523 | Loss: 92.850803\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:39 | Steps: 10524 | Loss: 92.850470\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:39 | Steps: 10525 | Loss: 92.848173\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:39 | Steps: 10526 | Loss: 92.846931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:39 | Steps: 10527 | Loss: 92.844837\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:39 | Steps: 10528 | Loss: 92.846000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:39 | Steps: 10529 | Loss: 92.848191\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:40 | Steps: 10530 | Loss: 92.847709\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:40 | Steps: 10531 | Loss: 92.851110\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:40 | Steps: 10532 | Loss: 92.853475\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:40 | Steps: 10533 | Loss: 92.852631\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:40 | Steps: 10534 | Loss: 92.853063\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:40 | Steps: 10535 | Loss: 92.852313\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:40 | Steps: 10536 | Loss: 92.852232\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:41 | Steps: 10537 | Loss: 92.852989\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:41 | Steps: 10538 | Loss: 92.853594\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:41 | Steps: 10539 | Loss: 92.857220\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:41 | Steps: 10540 | Loss: 92.857961\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:41 | Steps: 10541 | Loss: 92.854391\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:41 | Steps: 10542 | Loss: 92.857472\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:41 | Steps: 10543 | Loss: 92.857321\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:42 | Steps: 10544 | Loss: 92.858619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:42 | Steps: 10545 | Loss: 92.863289\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:42 | Steps: 10546 | Loss: 92.862526\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:42 | Steps: 10547 | Loss: 92.864364\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:42 | Steps: 10548 | Loss: 92.874033\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:42 | Steps: 10549 | Loss: 92.880086\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:43 | Steps: 10550 | Loss: 92.884516\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:43 | Steps: 10551 | Loss: 92.886235\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:43 | Steps: 10552 | Loss: 92.886498\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:43 | Steps: 10553 | Loss: 92.893238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:43 | Steps: 10554 | Loss: 92.896116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:43 | Steps: 10555 | Loss: 92.895927\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:43 | Steps: 10556 | Loss: 92.895873\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:44 | Steps: 10557 | Loss: 92.895150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:44 | Steps: 10558 | Loss: 92.896005\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:44 | Steps: 10559 | Loss: 92.897750\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:44 | Steps: 10560 | Loss: 92.898768\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:44 | Steps: 10561 | Loss: 92.900528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:44 | Steps: 10562 | Loss: 92.900271\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:45 | Steps: 10563 | Loss: 92.901826\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:45 | Steps: 10564 | Loss: 92.901720\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:45 | Steps: 10565 | Loss: 92.903440\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:45 | Steps: 10566 | Loss: 92.904938\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:45 | Steps: 10567 | Loss: 92.905297\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:45 | Steps: 10568 | Loss: 92.903590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:45 | Steps: 10569 | Loss: 92.905978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:46 | Steps: 10570 | Loss: 92.905417\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:46 | Steps: 10571 | Loss: 92.905091\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:46 | Steps: 10572 | Loss: 92.907052\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:46 | Steps: 10573 | Loss: 92.908677\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:46 | Steps: 10574 | Loss: 92.908887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:46 | Steps: 10575 | Loss: 92.910323\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:47 | Steps: 10576 | Loss: 92.908632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:47 | Steps: 10577 | Loss: 92.909812\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:47 | Steps: 10578 | Loss: 92.913503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:47 | Steps: 10579 | Loss: 92.912816\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:47 | Steps: 10580 | Loss: 92.916019\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:47 | Steps: 10581 | Loss: 92.918548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:47 | Steps: 10582 | Loss: 92.917298\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:48 | Steps: 10583 | Loss: 92.920278\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:48 | Steps: 10584 | Loss: 92.919451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:48 | Steps: 10585 | Loss: 92.920796\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:48 | Steps: 10586 | Loss: 92.919406\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:48 | Steps: 10587 | Loss: 92.918199\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:48 | Steps: 10588 | Loss: 92.917121\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:49 | Steps: 10589 | Loss: 92.919705\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:49 | Steps: 10590 | Loss: 92.922189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:49 | Steps: 10591 | Loss: 92.925096\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:49 | Steps: 10592 | Loss: 92.927559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:49 | Steps: 10593 | Loss: 92.926203\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:49 | Steps: 10594 | Loss: 92.927632\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:50 | Steps: 10595 | Loss: 92.929601\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:50 | Steps: 10596 | Loss: 92.928769\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:50 | Steps: 10597 | Loss: 92.931166\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:50 | Steps: 10598 | Loss: 92.932672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:50 | Steps: 10599 | Loss: 92.933974\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:51 | Steps: 10600 | Loss: 92.933175\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:51 | Steps: 10601 | Loss: 92.933795\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:51 | Steps: 10602 | Loss: 92.935386\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:51 | Steps: 10603 | Loss: 92.935212\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:51 | Steps: 10604 | Loss: 92.933944\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:51 | Steps: 10605 | Loss: 92.933851\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:52 | Steps: 10606 | Loss: 92.939417\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:52 | Steps: 10607 | Loss: 92.941795\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:52 | Steps: 10608 | Loss: 92.942821\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:52 | Steps: 10609 | Loss: 92.947559\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:52 | Steps: 10610 | Loss: 92.947786\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:52 | Steps: 10611 | Loss: 92.950419\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:53 | Steps: 10612 | Loss: 92.953200\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:53 | Steps: 10613 | Loss: 92.954376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:53 | Steps: 10614 | Loss: 92.954067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:53 | Steps: 10615 | Loss: 92.954283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:53 | Steps: 10616 | Loss: 92.955845\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:53 | Steps: 10617 | Loss: 92.954893\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:54 | Steps: 10618 | Loss: 92.954569\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:54 | Steps: 10619 | Loss: 92.954128\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:54 | Steps: 10620 | Loss: 92.955916\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:54 | Steps: 10621 | Loss: 92.957068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:54 | Steps: 10622 | Loss: 92.958122\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:54 | Steps: 10623 | Loss: 92.958620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:55 | Steps: 10624 | Loss: 92.958611\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:55 | Steps: 10625 | Loss: 92.957047\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:55 | Steps: 10626 | Loss: 92.956334\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:55 | Steps: 10627 | Loss: 92.957267\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:55 | Steps: 10628 | Loss: 92.963023\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:55 | Steps: 10629 | Loss: 92.973135\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:56 | Steps: 10630 | Loss: 92.977095\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:56 | Steps: 10631 | Loss: 92.977156\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:56 | Steps: 10632 | Loss: 92.977547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:56 | Steps: 10633 | Loss: 92.978049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:56 | Steps: 10634 | Loss: 92.976906\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:56 | Steps: 10635 | Loss: 92.978524\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:56 | Steps: 10636 | Loss: 92.978818\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:57 | Steps: 10637 | Loss: 92.978342\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:57 | Steps: 10638 | Loss: 92.976497\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:57 | Steps: 10639 | Loss: 92.978067\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:57 | Steps: 10640 | Loss: 92.979069\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:57 | Steps: 10641 | Loss: 92.977297\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:57 | Steps: 10642 | Loss: 92.976447\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:58 | Steps: 10643 | Loss: 92.979379\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:58 | Steps: 10644 | Loss: 92.980275\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:58 | Steps: 10645 | Loss: 92.984143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:58 | Steps: 10646 | Loss: 92.986263\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:58 | Steps: 10647 | Loss: 92.988687\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:58 | Steps: 10648 | Loss: 92.990293\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:58 | Steps: 10649 | Loss: 92.990389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:59 | Steps: 10650 | Loss: 92.991677\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:59 | Steps: 10651 | Loss: 92.994193\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:59 | Steps: 10652 | Loss: 92.995163\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:59 | Steps: 10653 | Loss: 92.995028\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:59 | Steps: 10654 | Loss: 92.995257\n",
      "Epoch 0 |   Training | Elapsed Time: 0:16:59 | Steps: 10655 | Loss: 92.999078\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:00 | Steps: 10656 | Loss: 93.000669\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:00 | Steps: 10657 | Loss: 93.006581\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:00 | Steps: 10658 | Loss: 93.008315\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:00 | Steps: 10659 | Loss: 93.010574\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:00 | Steps: 10660 | Loss: 93.012020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:00 | Steps: 10661 | Loss: 93.013931\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:00 | Steps: 10662 | Loss: 93.014126\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:01 | Steps: 10663 | Loss: 93.014309\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:01 | Steps: 10664 | Loss: 93.011546\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:01 | Steps: 10665 | Loss: 93.012165\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:01 | Steps: 10666 | Loss: 93.013738\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:01 | Steps: 10667 | Loss: 93.013752\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:01 | Steps: 10668 | Loss: 93.014269\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:02 | Steps: 10669 | Loss: 93.014922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:02 | Steps: 10670 | Loss: 93.016262\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:02 | Steps: 10671 | Loss: 93.014283\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:02 | Steps: 10672 | Loss: 93.014503\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:02 | Steps: 10673 | Loss: 93.013808\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:02 | Steps: 10674 | Loss: 93.014622\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:02 | Steps: 10675 | Loss: 93.015654\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:03 | Steps: 10676 | Loss: 93.016918\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:03 | Steps: 10677 | Loss: 93.013939\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:03 | Steps: 10678 | Loss: 93.012218\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:03 | Steps: 10679 | Loss: 93.013195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:03 | Steps: 10680 | Loss: 93.018539\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:03 | Steps: 10681 | Loss: 93.020965\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:04 | Steps: 10682 | Loss: 93.022531\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:04 | Steps: 10683 | Loss: 93.022785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:04 | Steps: 10684 | Loss: 93.022777\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:04 | Steps: 10685 | Loss: 93.026879\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:04 | Steps: 10686 | Loss: 93.026400\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:04 | Steps: 10687 | Loss: 93.029677\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:05 | Steps: 10688 | Loss: 93.031759\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:05 | Steps: 10689 | Loss: 93.032764\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:05 | Steps: 10690 | Loss: 93.039079\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:05 | Steps: 10691 | Loss: 93.037458\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:05 | Steps: 10692 | Loss: 93.035087\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:05 | Steps: 10693 | Loss: 93.038419\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:05 | Steps: 10694 | Loss: 93.039266\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:06 | Steps: 10695 | Loss: 93.040113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:06 | Steps: 10696 | Loss: 93.041921\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:06 | Steps: 10697 | Loss: 93.040864\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:06 | Steps: 10698 | Loss: 93.045644\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:06 | Steps: 10699 | Loss: 93.052095\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:06 | Steps: 10700 | Loss: 93.054068\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:07 | Steps: 10701 | Loss: 93.055237\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:07 | Steps: 10702 | Loss: 93.055184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:07 | Steps: 10703 | Loss: 93.052462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:07 | Steps: 10704 | Loss: 93.054694\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:07 | Steps: 10705 | Loss: 93.054465\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:07 | Steps: 10706 | Loss: 93.059987\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:07 | Steps: 10707 | Loss: 93.060404\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:08 | Steps: 10708 | Loss: 93.060668\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:08 | Steps: 10709 | Loss: 93.061719\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:08 | Steps: 10710 | Loss: 93.070218\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:08 | Steps: 10711 | Loss: 93.075981\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:08 | Steps: 10712 | Loss: 93.079238\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:08 | Steps: 10713 | Loss: 93.078785\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:09 | Steps: 10714 | Loss: 93.081753\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:09 | Steps: 10715 | Loss: 93.082273\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:09 | Steps: 10716 | Loss: 93.084316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:09 | Steps: 10717 | Loss: 93.084415\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:09 | Steps: 10718 | Loss: 93.085663\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:09 | Steps: 10719 | Loss: 93.087155\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:10 | Steps: 10720 | Loss: 93.086815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:10 | Steps: 10721 | Loss: 93.088677\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:10 | Steps: 10722 | Loss: 93.088892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:10 | Steps: 10723 | Loss: 93.088910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:10 | Steps: 10724 | Loss: 93.088359\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:10 | Steps: 10725 | Loss: 93.095453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:10 | Steps: 10726 | Loss: 93.095964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:11 | Steps: 10727 | Loss: 93.095612\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:11 | Steps: 10728 | Loss: 93.099688\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:11 | Steps: 10729 | Loss: 93.098667\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:11 | Steps: 10730 | Loss: 93.100003\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:11 | Steps: 10731 | Loss: 93.102432\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:11 | Steps: 10732 | Loss: 93.108814\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:12 | Steps: 10733 | Loss: 93.110210\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:12 | Steps: 10734 | Loss: 93.115290\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:12 | Steps: 10735 | Loss: 93.115892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:12 | Steps: 10736 | Loss: 93.116802\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:12 | Steps: 10737 | Loss: 93.118576\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:12 | Steps: 10738 | Loss: 93.118536\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:13 | Steps: 10739 | Loss: 93.117509\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:13 | Steps: 10740 | Loss: 93.120450\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:13 | Steps: 10741 | Loss: 93.121332\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:13 | Steps: 10742 | Loss: 93.121980\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:13 | Steps: 10743 | Loss: 93.120223\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:13 | Steps: 10744 | Loss: 93.122547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:14 | Steps: 10745 | Loss: 93.123368\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:14 | Steps: 10746 | Loss: 93.124379\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:14 | Steps: 10747 | Loss: 93.126172\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:14 | Steps: 10748 | Loss: 93.126480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:14 | Steps: 10749 | Loss: 93.129548\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:14 | Steps: 10750 | Loss: 93.132929\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:15 | Steps: 10751 | Loss: 93.133887\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:15 | Steps: 10752 | Loss: 93.135121\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:15 | Steps: 10753 | Loss: 93.136143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:15 | Steps: 10754 | Loss: 93.137020\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:15 | Steps: 10755 | Loss: 93.142425\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:15 | Steps: 10756 | Loss: 93.146145\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:16 | Steps: 10757 | Loss: 93.145910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:16 | Steps: 10758 | Loss: 93.144552\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:16 | Steps: 10759 | Loss: 93.146211\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:16 | Steps: 10760 | Loss: 93.149566\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:16 | Steps: 10761 | Loss: 93.150045\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:16 | Steps: 10762 | Loss: 93.154708\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:16 | Steps: 10763 | Loss: 93.155944\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:17 | Steps: 10764 | Loss: 93.154940\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:17 | Steps: 10765 | Loss: 93.154702\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:17 | Steps: 10766 | Loss: 93.156697\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:17 | Steps: 10767 | Loss: 93.158355\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:17 | Steps: 10768 | Loss: 93.162793\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:18 | Steps: 10769 | Loss: 93.162621\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:18 | Steps: 10770 | Loss: 93.162049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:18 | Steps: 10771 | Loss: 93.164544\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:18 | Steps: 10772 | Loss: 93.164636\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:18 | Steps: 10773 | Loss: 93.165647\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:18 | Steps: 10774 | Loss: 93.167542\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:19 | Steps: 10775 | Loss: 93.168619\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:19 | Steps: 10776 | Loss: 93.169057\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:19 | Steps: 10777 | Loss: 93.173528\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:19 | Steps: 10778 | Loss: 93.174543\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:19 | Steps: 10779 | Loss: 93.175171\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:19 | Steps: 10780 | Loss: 93.176181\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:20 | Steps: 10781 | Loss: 93.175457\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:20 | Steps: 10782 | Loss: 93.177354\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:20 | Steps: 10783 | Loss: 93.175712\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:20 | Steps: 10784 | Loss: 93.177701\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:20 | Steps: 10785 | Loss: 93.183736\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:20 | Steps: 10786 | Loss: 93.186017\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:20 | Steps: 10787 | Loss: 93.188189\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:21 | Steps: 10788 | Loss: 93.191451\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:21 | Steps: 10789 | Loss: 93.195704\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:21 | Steps: 10790 | Loss: 93.196576\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:21 | Steps: 10791 | Loss: 93.196467\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:21 | Steps: 10792 | Loss: 93.195384\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:21 | Steps: 10793 | Loss: 93.195773\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:22 | Steps: 10794 | Loss: 93.199654\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:22 | Steps: 10795 | Loss: 93.200187\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:22 | Steps: 10796 | Loss: 93.199525\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:22 | Steps: 10797 | Loss: 93.202169\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:22 | Steps: 10798 | Loss: 93.201082\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:22 | Steps: 10799 | Loss: 93.201858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:23 | Steps: 10800 | Loss: 93.202396\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:23 | Steps: 10801 | Loss: 93.201358\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:23 | Steps: 10802 | Loss: 93.204624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:23 | Steps: 10803 | Loss: 93.203138\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:23 | Steps: 10804 | Loss: 93.204461\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:24 | Steps: 10805 | Loss: 93.204448\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:24 | Steps: 10806 | Loss: 93.204585\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:24 | Steps: 10807 | Loss: 93.204194\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:24 | Steps: 10808 | Loss: 93.205320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:24 | Steps: 10809 | Loss: 93.205196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:24 | Steps: 10810 | Loss: 93.204707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:25 | Steps: 10811 | Loss: 93.206247\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:25 | Steps: 10812 | Loss: 93.206195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:25 | Steps: 10813 | Loss: 93.206239\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:25 | Steps: 10814 | Loss: 93.208892\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:25 | Steps: 10815 | Loss: 93.208590\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:25 | Steps: 10816 | Loss: 93.209430\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:26 | Steps: 10817 | Loss: 93.215018\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:26 | Steps: 10818 | Loss: 93.215004\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:26 | Steps: 10819 | Loss: 93.215685\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:26 | Steps: 10820 | Loss: 93.218620\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:26 | Steps: 10821 | Loss: 93.219721\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:26 | Steps: 10822 | Loss: 93.221234\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:27 | Steps: 10823 | Loss: 93.225097\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:27 | Steps: 10824 | Loss: 93.226376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:27 | Steps: 10825 | Loss: 93.228675\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:27 | Steps: 10826 | Loss: 93.230927\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:27 | Steps: 10827 | Loss: 93.236288\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:28 | Steps: 10828 | Loss: 93.235782\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:28 | Steps: 10829 | Loss: 93.236076\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:28 | Steps: 10830 | Loss: 93.235434\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:28 | Steps: 10831 | Loss: 93.237551\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:28 | Steps: 10832 | Loss: 93.239190\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:28 | Steps: 10833 | Loss: 93.241266\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:29 | Steps: 10834 | Loss: 93.243270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:29 | Steps: 10835 | Loss: 93.247672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:29 | Steps: 10836 | Loss: 93.248493\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:29 | Steps: 10837 | Loss: 93.250889\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:29 | Steps: 10838 | Loss: 93.250996\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:29 | Steps: 10839 | Loss: 93.249706\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:30 | Steps: 10840 | Loss: 93.250737\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:30 | Steps: 10841 | Loss: 93.250198\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:30 | Steps: 10842 | Loss: 93.251316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:30 | Steps: 10843 | Loss: 93.252027\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:30 | Steps: 10844 | Loss: 93.253530\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:30 | Steps: 10845 | Loss: 93.255195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:31 | Steps: 10846 | Loss: 93.257895\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:31 | Steps: 10847 | Loss: 93.259624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:31 | Steps: 10848 | Loss: 93.262623\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:31 | Steps: 10849 | Loss: 93.262813\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:31 | Steps: 10850 | Loss: 93.267994\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:31 | Steps: 10851 | Loss: 93.270684\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:32 | Steps: 10852 | Loss: 93.272116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:32 | Steps: 10853 | Loss: 93.271727\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:32 | Steps: 10854 | Loss: 93.270058\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:32 | Steps: 10855 | Loss: 93.272735\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:32 | Steps: 10856 | Loss: 93.272855\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:32 | Steps: 10857 | Loss: 93.273770\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:33 | Steps: 10858 | Loss: 93.275633\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:33 | Steps: 10859 | Loss: 93.275640\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:33 | Steps: 10860 | Loss: 93.274672\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:33 | Steps: 10861 | Loss: 93.277437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:33 | Steps: 10862 | Loss: 93.280357\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:33 | Steps: 10863 | Loss: 93.284091\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:34 | Steps: 10864 | Loss: 93.289515\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:34 | Steps: 10865 | Loss: 93.292248\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:34 | Steps: 10866 | Loss: 93.292334\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:34 | Steps: 10867 | Loss: 93.293692\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:34 | Steps: 10868 | Loss: 93.294554\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:34 | Steps: 10869 | Loss: 93.294480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:35 | Steps: 10870 | Loss: 93.295376\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:35 | Steps: 10871 | Loss: 93.296024\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:35 | Steps: 10872 | Loss: 93.297854\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:35 | Steps: 10873 | Loss: 93.299148\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:35 | Steps: 10874 | Loss: 93.304839\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:35 | Steps: 10875 | Loss: 93.308182\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:36 | Steps: 10876 | Loss: 93.311808\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:36 | Steps: 10877 | Loss: 93.314480\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:36 | Steps: 10878 | Loss: 93.318738\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:36 | Steps: 10879 | Loss: 93.318118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:36 | Steps: 10880 | Loss: 93.321225\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:36 | Steps: 10881 | Loss: 93.321051\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:37 | Steps: 10882 | Loss: 93.320801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:37 | Steps: 10883 | Loss: 93.320499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:37 | Steps: 10884 | Loss: 93.322538\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:37 | Steps: 10885 | Loss: 93.322523\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:37 | Steps: 10886 | Loss: 93.323998\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:37 | Steps: 10887 | Loss: 93.325090\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:38 | Steps: 10888 | Loss: 93.327013\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:38 | Steps: 10889 | Loss: 93.330791\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:38 | Steps: 10890 | Loss: 93.328468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:38 | Steps: 10891 | Loss: 93.330710\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:38 | Steps: 10892 | Loss: 93.331339\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:38 | Steps: 10893 | Loss: 93.333113\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:39 | Steps: 10894 | Loss: 93.333423\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:39 | Steps: 10895 | Loss: 93.333259\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:39 | Steps: 10896 | Loss: 93.339365\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:39 | Steps: 10897 | Loss: 93.342910\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:39 | Steps: 10898 | Loss: 93.342088\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:39 | Steps: 10899 | Loss: 93.345207\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:40 | Steps: 10900 | Loss: 93.346281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:40 | Steps: 10901 | Loss: 93.346625\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:40 | Steps: 10902 | Loss: 93.347245\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:40 | Steps: 10903 | Loss: 93.347049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:40 | Steps: 10904 | Loss: 93.349347\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:41 | Steps: 10905 | Loss: 93.348772\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:41 | Steps: 10906 | Loss: 93.347829\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:41 | Steps: 10907 | Loss: 93.351494\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:41 | Steps: 10908 | Loss: 93.350973\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:41 | Steps: 10909 | Loss: 93.353597\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:41 | Steps: 10910 | Loss: 93.355624\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:42 | Steps: 10911 | Loss: 93.358657\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:42 | Steps: 10912 | Loss: 93.357328\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:42 | Steps: 10913 | Loss: 93.359690\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:42 | Steps: 10914 | Loss: 93.361015\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:42 | Steps: 10915 | Loss: 93.361923\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:42 | Steps: 10916 | Loss: 93.361495\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:43 | Steps: 10917 | Loss: 93.364012\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:43 | Steps: 10918 | Loss: 93.364911\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:43 | Steps: 10919 | Loss: 93.366255\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:43 | Steps: 10920 | Loss: 93.371061\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:43 | Steps: 10921 | Loss: 93.370036\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:44 | Steps: 10922 | Loss: 93.375859\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:44 | Steps: 10923 | Loss: 93.377138\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:44 | Steps: 10924 | Loss: 93.377912\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:44 | Steps: 10925 | Loss: 93.377508\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:44 | Steps: 10926 | Loss: 93.382308\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:44 | Steps: 10927 | Loss: 93.384235\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:45 | Steps: 10928 | Loss: 93.389600\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:45 | Steps: 10929 | Loss: 93.394389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:45 | Steps: 10930 | Loss: 93.393801\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:45 | Steps: 10931 | Loss: 93.394823\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:45 | Steps: 10932 | Loss: 93.394637\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:46 | Steps: 10933 | Loss: 93.395608\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:46 | Steps: 10934 | Loss: 93.395878\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:46 | Steps: 10935 | Loss: 93.396761\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:46 | Steps: 10936 | Loss: 93.397978\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:46 | Steps: 10937 | Loss: 93.398883\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:46 | Steps: 10938 | Loss: 93.400790\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:47 | Steps: 10939 | Loss: 93.402072\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:47 | Steps: 10940 | Loss: 93.402605\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:47 | Steps: 10941 | Loss: 93.404131\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:47 | Steps: 10942 | Loss: 93.401930\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:47 | Steps: 10943 | Loss: 93.400279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:48 | Steps: 10944 | Loss: 93.399499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:48 | Steps: 10945 | Loss: 93.402795\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:48 | Steps: 10946 | Loss: 93.407462\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:48 | Steps: 10947 | Loss: 93.412964\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:48 | Steps: 10948 | Loss: 93.414150\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:48 | Steps: 10949 | Loss: 93.416327\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:49 | Steps: 10950 | Loss: 93.417296\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:49 | Steps: 10951 | Loss: 93.417468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:49 | Steps: 10952 | Loss: 93.423397\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:49 | Steps: 10953 | Loss: 93.427042\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:49 | Steps: 10954 | Loss: 93.428095\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:50 | Steps: 10955 | Loss: 93.429159\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:50 | Steps: 10956 | Loss: 93.433437\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:50 | Steps: 10957 | Loss: 93.436428\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:50 | Steps: 10958 | Loss: 93.436474\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:50 | Steps: 10959 | Loss: 93.440707\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:50 | Steps: 10960 | Loss: 93.440572\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:51 | Steps: 10961 | Loss: 93.442049\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:51 | Steps: 10962 | Loss: 93.444116\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:51 | Steps: 10963 | Loss: 93.444789\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:51 | Steps: 10964 | Loss: 93.443858\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:51 | Steps: 10965 | Loss: 93.447815\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:52 | Steps: 10966 | Loss: 93.450124\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:52 | Steps: 10967 | Loss: 93.451195\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:52 | Steps: 10968 | Loss: 93.450684\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:52 | Steps: 10969 | Loss: 93.459771\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:52 | Steps: 10970 | Loss: 93.462499\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:53 | Steps: 10971 | Loss: 93.461270\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:53 | Steps: 10972 | Loss: 93.460863\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:53 | Steps: 10973 | Loss: 93.461699\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:53 | Steps: 10974 | Loss: 93.459922\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:53 | Steps: 10975 | Loss: 93.460415\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:53 | Steps: 10976 | Loss: 93.460638\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:54 | Steps: 10977 | Loss: 93.465316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:54 | Steps: 10978 | Loss: 93.465183\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:54 | Steps: 10979 | Loss: 93.468320\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:54 | Steps: 10980 | Loss: 93.470025\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:54 | Steps: 10981 | Loss: 93.470595\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:55 | Steps: 10982 | Loss: 93.472959\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:55 | Steps: 10983 | Loss: 93.474865\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:55 | Steps: 10984 | Loss: 93.476614\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:55 | Steps: 10985 | Loss: 93.476453\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:55 | Steps: 10986 | Loss: 93.476076\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:55 | Steps: 10987 | Loss: 93.474924\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:56 | Steps: 10988 | Loss: 93.475359\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:56 | Steps: 10989 | Loss: 93.475196\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:56 | Steps: 10990 | Loss: 93.473389\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:56 | Steps: 10991 | Loss: 93.473723\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:56 | Steps: 10992 | Loss: 93.476118\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:57 | Steps: 10993 | Loss: 93.479143\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:57 | Steps: 10994 | Loss: 93.481186\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:57 | Steps: 10995 | Loss: 93.482345\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:57 | Steps: 10996 | Loss: 93.484811\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:57 | Steps: 10997 | Loss: 93.482547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:58 | Steps: 10998 | Loss: 93.486691\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:58 | Steps: 10999 | Loss: 93.486184\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:58 | Steps: 11000 | Loss: 93.489468\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:58 | Steps: 11001 | Loss: 93.488171\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:58 | Steps: 11002 | Loss: 93.489472\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:58 | Steps: 11003 | Loss: 93.490204\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:59 | Steps: 11004 | Loss: 93.491316\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:59 | Steps: 11005 | Loss: 93.491587\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:59 | Steps: 11006 | Loss: 93.495833\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:59 | Steps: 11007 | Loss: 93.496603\n",
      "Epoch 0 |   Training | Elapsed Time: 0:17:59 | Steps: 11008 | Loss: 93.499209\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:00 | Steps: 11009 | Loss: 93.505372\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:00 | Steps: 11010 | Loss: 93.504249\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:00 | Steps: 11011 | Loss: 93.504591\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:00 | Steps: 11012 | Loss: 93.506050\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:00 | Steps: 11013 | Loss: 93.509279\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:00 | Steps: 11014 | Loss: 93.511281\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:01 | Steps: 11015 | Loss: 93.512915\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:01 | Steps: 11016 | Loss: 93.520547\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:01 | Steps: 11017 | Loss: 93.519963\n",
      "Epoch 0 |   Training | Elapsed Time: 0:18:01 | Steps: 11017 | Loss: 93.519963\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 245.273712 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 114.579401 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 7 | Loss: 97.216135 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 9 | Loss: 87.404984 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 11 | Loss: 80.375465 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 13 | Loss: 74.888992 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 15 | Loss: 73.002133 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 17 | Loss: 68.149523 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 19 | Loss: 67.594606 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 22 | Loss: 64.452768 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 25 | Loss: 61.475191 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 27 | Loss: 61.257711 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 30 | Loss: 61.660626 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 33 | Loss: 59.740208 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 36 | Loss: 58.356257 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:07 | Steps: 39 | Loss: 58.810056 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:07 | Steps: 40 | Loss: 58.663643 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:07 | Steps: 42 | Loss: 57.788262 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:07 | Steps: 44 | Loss: 59.505978 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:08 | Steps: 46 | Loss: 58.871028 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:08 | Steps: 48 | Loss: 57.756158 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:08 | Steps: 49 | Loss: 58.631697 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:08 | Steps: 52 | Loss: 58.252702 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:08 | Steps: 54 | Loss: 57.741411 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:08 | Steps: 56 | Loss: 57.012137 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:08 | Steps: 58 | Loss: 56.305613 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:09 | Steps: 61 | Loss: 55.186996 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:09 | Steps: 63 | Loss: 55.190398 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:09 | Steps: 65 | Loss: 55.122746 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:09 | Steps: 67 | Loss: 54.842118 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:09 | Steps: 69 | Loss: 54.902509 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:09 | Steps: 71 | Loss: 54.216597 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:10 | Steps: 72 | Loss: 54.030922 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:10 | Steps: 74 | Loss: 54.144402 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:10 | Steps: 76 | Loss: 53.796410 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:10 | Steps: 77 | Loss: 53.794904 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:10 | Steps: 79 | Loss: 53.365389 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:11 | Steps: 81 | Loss: 53.036217 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:11 | Steps: 84 | Loss: 52.788731 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:11 | Steps: 86 | Loss: 52.535336 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:11 | Steps: 89 | Loss: 53.505039 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:11 | Steps: 92 | Loss: 54.541718 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:11 | Steps: 94 | Loss: 55.858507 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:11 | Steps: 97 | Loss: 56.054971 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:11 | Steps: 99 | Loss: 56.442789 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:12 | Steps: 102 | Loss: 55.815973 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:12 | Steps: 105 | Loss: 55.949225 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:12 | Steps: 108 | Loss: 55.788637 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:12 | Steps: 110 | Loss: 55.773333 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:12 | Steps: 112 | Loss: 55.220267 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:12 | Steps: 114 | Loss: 55.499202 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:12 | Steps: 117 | Loss: 55.615641 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:12 | Steps: 118 | Loss: 55.513594 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:13 | Steps: 120 | Loss: 55.517629 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:13 | Steps: 123 | Loss: 55.245833 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:13 | Steps: 125 | Loss: 55.012616 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:13 | Steps: 127 | Loss: 54.860521 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:13 | Steps: 130 | Loss: 54.700570 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:13 | Steps: 133 | Loss: 54.820832 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:13 | Steps: 136 | Loss: 54.924274 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 137 | Loss: 54.877884 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 140 | Loss: 54.976933 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 142 | Loss: 54.921237 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 145 | Loss: 54.795988 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 147 | Loss: 54.769046 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 149 | Loss: 55.349592 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 152 | Loss: 55.185982 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 154 | Loss: 55.131825 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:15 | Steps: 157 | Loss: 54.912791 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:15 | Steps: 160 | Loss: 54.825961 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:15 | Steps: 162 | Loss: 54.943753 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:15 | Steps: 164 | Loss: 55.118492 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:15 | Steps: 167 | Loss: 55.430303 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:15 | Steps: 169 | Loss: 55.949179 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:15 | Steps: 170 | Loss: 55.791154 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:16 | Steps: 172 | Loss: 55.547138 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:16 | Steps: 174 | Loss: 55.527782 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:16 | Steps: 176 | Loss: 55.565491 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:16 | Steps: 178 | Loss: 55.394214 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:16 | Steps: 181 | Loss: 55.542787 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:16 | Steps: 184 | Loss: 55.789019 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:16 | Steps: 187 | Loss: 55.920393 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:16 | Steps: 190 | Loss: 55.648404 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:17 | Steps: 192 | Loss: 55.417525 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:17 | Steps: 194 | Loss: 55.570318 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:17 | Steps: 198 | Loss: 55.534754 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:17 | Steps: 201 | Loss: 55.646908 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:17 | Steps: 203 | Loss: 55.754620 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:17 | Steps: 205 | Loss: 55.556957 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:17 | Steps: 208 | Loss: 55.490735 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:17 | Steps: 211 | Loss: 55.466323 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:18 | Steps: 213 | Loss: 55.233099 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:18 | Steps: 215 | Loss: 55.292592 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:18 | Steps: 218 | Loss: 55.450476 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:18 | Steps: 220 | Loss: 55.353125 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:18 | Steps: 222 | Loss: 55.340259 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:18 | Steps: 225 | Loss: 55.307285 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:18 | Steps: 228 | Loss: 55.470167 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 230 | Loss: 55.384781 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 233 | Loss: 55.288064 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 235 | Loss: 55.150088 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 237 | Loss: 55.220242 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 239 | Loss: 55.260013 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 242 | Loss: 55.196155 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 244 | Loss: 55.131308 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 246 | Loss: 55.151855 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:19 | Steps: 249 | Loss: 55.066358 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:20 | Steps: 251 | Loss: 54.979896 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:20 | Steps: 254 | Loss: 55.200781 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:20 | Steps: 255 | Loss: 55.126384 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:20 | Steps: 259 | Loss: 55.386206 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:20 | Steps: 262 | Loss: 55.433882 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:20 | Steps: 263 | Loss: 55.410066 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:20 | Steps: 265 | Loss: 55.282752 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:20 | Steps: 267 | Loss: 55.276989 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:21 | Steps: 269 | Loss: 55.180949 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:21 | Steps: 272 | Loss: 55.096814 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:21 | Steps: 274 | Loss: 54.924130 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:21 | Steps: 276 | Loss: 54.901205 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:21 | Steps: 279 | Loss: 54.871596 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:21 | Steps: 281 | Loss: 54.885247 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:21 | Steps: 283 | Loss: 54.979196 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:21 | Steps: 286 | Loss: 55.056321 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:22 | Steps: 287 | Loss: 54.998910 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:22 | Steps: 291 | Loss: 54.890918 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:22 | Steps: 293 | Loss: 54.951775 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:22 | Steps: 295 | Loss: 54.871069 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:22 | Steps: 298 | Loss: 54.935726 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:22 | Steps: 300 | Loss: 55.015727 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:22 | Steps: 303 | Loss: 54.993157 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:22 | Steps: 306 | Loss: 55.064718 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:23 | Steps: 307 | Loss: 55.279442 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:23 | Steps: 309 | Loss: 55.263692 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:23 | Steps: 311 | Loss: 55.147679 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:23 | Steps: 314 | Loss: 55.089986 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:23 | Steps: 317 | Loss: 55.123472 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:23 | Steps: 321 | Loss: 54.972706 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:23 | Steps: 323 | Loss: 54.930858 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:24 | Steps: 326 | Loss: 55.114789 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:24 | Steps: 329 | Loss: 55.136607 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:24 | Steps: 333 | Loss: 55.120524 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:24 | Steps: 335 | Loss: 55.096339 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:24 | Steps: 337 | Loss: 55.138923 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:24 | Steps: 340 | Loss: 55.073494 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:24 | Steps: 341 | Loss: 55.017914 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:25 | Steps: 343 | Loss: 54.995364 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:25 | Steps: 345 | Loss: 55.155709 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:25 | Steps: 347 | Loss: 55.071100 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:25 | Steps: 349 | Loss: 55.242257 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:25 | Steps: 351 | Loss: 55.163597 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:25 | Steps: 355 | Loss: 55.155017 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:25 | Steps: 357 | Loss: 55.063388 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:25 | Steps: 359 | Loss: 54.971021 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:26 | Steps: 361 | Loss: 54.940340 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:26 | Steps: 364 | Loss: 54.919659 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:26 | Steps: 366 | Loss: 54.867978 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:26 | Steps: 369 | Loss: 54.935207 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:26 | Steps: 371 | Loss: 54.973805 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:26 | Steps: 373 | Loss: 55.327128 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:26 | Steps: 376 | Loss: 55.353007 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:26 | Steps: 378 | Loss: 55.416156 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:27 | Steps: 379 | Loss: 55.415462 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:27 | Steps: 382 | Loss: 55.528479 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:27 | Steps: 385 | Loss: 55.480827 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:27 | Steps: 387 | Loss: 55.423646 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:27 | Steps: 389 | Loss: 55.389352 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:27 | Steps: 391 | Loss: 55.494347 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:27 | Steps: 393 | Loss: 55.451532 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:27 | Steps: 396 | Loss: 55.355673 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:28 | Steps: 398 | Loss: 55.429469 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:28 | Steps: 399 | Loss: 55.512518 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:28 | Steps: 401 | Loss: 55.726227 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:28 | Steps: 404 | Loss: 55.675980 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:28 | Steps: 407 | Loss: 55.691246 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:28 | Steps: 409 | Loss: 55.620840 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:28 | Steps: 411 | Loss: 55.568640 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:28 | Steps: 414 | Loss: 55.720925 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:29 | Steps: 416 | Loss: 55.659384 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:29 | Steps: 418 | Loss: 55.635725 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:29 | Steps: 420 | Loss: 55.623212 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:29 | Steps: 423 | Loss: 55.597185 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:29 | Steps: 426 | Loss: 55.706148 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:29 | Steps: 428 | Loss: 55.709400 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:29 | Steps: 430 | Loss: 55.713100 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:29 | Steps: 432 | Loss: 55.809789 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:30 | Steps: 435 | Loss: 55.884096 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:30 | Steps: 437 | Loss: 55.886831 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:30 | Steps: 440 | Loss: 55.899771 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:30 | Steps: 442 | Loss: 55.909726 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:30 | Steps: 445 | Loss: 56.034159 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:30 | Steps: 447 | Loss: 56.147900 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:30 | Steps: 449 | Loss: 56.127139 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:30 | Steps: 451 | Loss: 56.082313 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:31 | Steps: 453 | Loss: 56.239984 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:31 | Steps: 455 | Loss: 56.307721 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:31 | Steps: 457 | Loss: 56.343546 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:31 | Steps: 459 | Loss: 56.371401 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:31 | Steps: 461 | Loss: 56.384197 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:31 | Steps: 463 | Loss: 56.392717 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:31 | Steps: 465 | Loss: 56.398205 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:31 | Steps: 468 | Loss: 56.362144 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:32 | Steps: 471 | Loss: 56.346124 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:32 | Steps: 474 | Loss: 56.468116 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:32 | Steps: 477 | Loss: 56.444649 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:32 | Steps: 479 | Loss: 56.454762 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:32 | Steps: 481 | Loss: 56.383171 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:32 | Steps: 484 | Loss: 56.375155 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:32 | Steps: 487 | Loss: 56.398670 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:33 | Steps: 489 | Loss: 56.471022 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:33 | Steps: 491 | Loss: 56.508965 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:33 | Steps: 493 | Loss: 56.523234 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:33 | Steps: 495 | Loss: 56.602058 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:33 | Steps: 497 | Loss: 56.660112 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:33 | Steps: 499 | Loss: 56.698483 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:33 | Steps: 501 | Loss: 56.757266 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:33 | Steps: 504 | Loss: 56.762475 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:34 | Steps: 506 | Loss: 56.764801 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:34 | Steps: 508 | Loss: 56.789089 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:34 | Steps: 510 | Loss: 56.812339 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:34 | Steps: 513 | Loss: 56.957751 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:34 | Steps: 516 | Loss: 56.938011 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:34 | Steps: 518 | Loss: 56.941812 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:34 | Steps: 520 | Loss: 57.083873 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:34 | Steps: 523 | Loss: 57.284673 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:35 | Steps: 525 | Loss: 57.257365 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:35 | Steps: 527 | Loss: 57.323822 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:35 | Steps: 530 | Loss: 57.293148 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:35 | Steps: 532 | Loss: 57.257290 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:35 | Steps: 535 | Loss: 57.279002 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:35 | Steps: 537 | Loss: 57.219631 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:35 | Steps: 539 | Loss: 57.207216 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:36 | Steps: 541 | Loss: 57.166187 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:36 | Steps: 544 | Loss: 57.209823 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:36 | Steps: 546 | Loss: 57.237866 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:36 | Steps: 549 | Loss: 57.308194 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:36 | Steps: 550 | Loss: 57.326086 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:36 | Steps: 552 | Loss: 57.409064 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:36 | Steps: 555 | Loss: 57.570463 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:37 | Steps: 556 | Loss: 57.571023 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:37 | Steps: 558 | Loss: 57.710792 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:37 | Steps: 560 | Loss: 57.665031 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:37 | Steps: 563 | Loss: 57.745946 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:37 | Steps: 565 | Loss: 57.768063 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:37 | Steps: 567 | Loss: 57.769599 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:37 | Steps: 570 | Loss: 57.900214 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:38 | Steps: 572 | Loss: 57.869418 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:38 | Steps: 575 | Loss: 57.925091 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:38 | Steps: 576 | Loss: 57.942652 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:38 | Steps: 578 | Loss: 57.960103 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:38 | Steps: 581 | Loss: 58.000555 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:38 | Steps: 584 | Loss: 58.135429 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:38 | Steps: 586 | Loss: 58.165846 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:38 | Steps: 588 | Loss: 58.239571 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:39 | Steps: 590 | Loss: 58.368050 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:39 | Steps: 592 | Loss: 58.344409 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:39 | Steps: 595 | Loss: 58.302366 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:39 | Steps: 598 | Loss: 58.286485 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:39 | Steps: 601 | Loss: 58.240892 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:39 | Steps: 603 | Loss: 58.243214 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:40 | Steps: 607 | Loss: 58.270813 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:40 | Steps: 609 | Loss: 58.334693 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:40 | Steps: 611 | Loss: 58.427330 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:40 | Steps: 613 | Loss: 58.497155 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:40 | Steps: 615 | Loss: 58.598190 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:40 | Steps: 617 | Loss: 58.717319 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:40 | Steps: 619 | Loss: 58.741407 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:41 | Steps: 622 | Loss: 58.705980 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:41 | Steps: 624 | Loss: 58.718627 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:41 | Steps: 626 | Loss: 58.748898 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:41 | Steps: 628 | Loss: 58.757411 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:41 | Steps: 630 | Loss: 58.763101 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:41 | Steps: 633 | Loss: 58.823721 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:41 | Steps: 635 | Loss: 58.949566 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:42 | Steps: 638 | Loss: 58.912685 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:42 | Steps: 640 | Loss: 58.913505 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:42 | Steps: 643 | Loss: 58.922233 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:42 | Steps: 645 | Loss: 58.927554 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:42 | Steps: 647 | Loss: 59.015360 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:42 | Steps: 650 | Loss: 59.076320 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:42 | Steps: 652 | Loss: 59.081075 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:43 | Steps: 654 | Loss: 59.123419 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:43 | Steps: 656 | Loss: 59.119150 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:43 | Steps: 659 | Loss: 59.102574 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:43 | Steps: 661 | Loss: 59.107869 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:43 | Steps: 663 | Loss: 59.080603 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:43 | Steps: 665 | Loss: 59.168828 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:43 | Steps: 667 | Loss: 59.217779 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:44 | Steps: 669 | Loss: 59.343067 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:44 | Steps: 671 | Loss: 59.341610 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:44 | Steps: 673 | Loss: 59.433216 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:44 | Steps: 675 | Loss: 59.440078 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:44 | Steps: 678 | Loss: 59.511521 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:44 | Steps: 681 | Loss: 59.709366 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:44 | Steps: 682 | Loss: 59.720605 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:45 | Steps: 684 | Loss: 59.731526 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:45 | Steps: 686 | Loss: 59.873533 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:45 | Steps: 689 | Loss: 59.949455 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:45 | Steps: 691 | Loss: 60.019713 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:45 | Steps: 694 | Loss: 60.053867 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:45 | Steps: 696 | Loss: 60.129522 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:45 | Steps: 698 | Loss: 60.095222 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:46 | Steps: 700 | Loss: 60.148041 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:46 | Steps: 702 | Loss: 60.171965 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:46 | Steps: 704 | Loss: 60.194452 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:46 | Steps: 706 | Loss: 60.148786 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:46 | Steps: 708 | Loss: 60.145695 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:46 | Steps: 710 | Loss: 60.214075 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:46 | Steps: 712 | Loss: 60.221264 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:46 | Steps: 715 | Loss: 60.245820 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:47 | Steps: 717 | Loss: 60.314915 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:47 | Steps: 719 | Loss: 60.456267 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:47 | Steps: 721 | Loss: 60.483556 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:47 | Steps: 724 | Loss: 60.577498 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:47 | Steps: 727 | Loss: 60.595562 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:48 | Steps: 729 | Loss: 60.585324 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:48 | Steps: 731 | Loss: 60.644994 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:48 | Steps: 732 | Loss: 60.631911 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:48 | Steps: 734 | Loss: 60.626855 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:48 | Steps: 736 | Loss: 60.631953 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:48 | Steps: 738 | Loss: 60.664611 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:49 | Steps: 740 | Loss: 60.734804 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:49 | Steps: 742 | Loss: 60.711365 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:49 | Steps: 745 | Loss: 60.780438 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:49 | Steps: 747 | Loss: 60.765363 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:49 | Steps: 750 | Loss: 60.807919 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:50 | Steps: 752 | Loss: 60.870943 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:50 | Steps: 754 | Loss: 60.949118 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:50 | Steps: 757 | Loss: 61.024083 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:50 | Steps: 759 | Loss: 61.042126 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:50 | Steps: 761 | Loss: 61.076515 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:51 | Steps: 763 | Loss: 61.079209 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:51 | Steps: 765 | Loss: 61.146656 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:51 | Steps: 767 | Loss: 61.111907 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:51 | Steps: 769 | Loss: 61.147318 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:51 | Steps: 772 | Loss: 61.202234 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:52 | Steps: 774 | Loss: 61.226512 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:52 | Steps: 777 | Loss: 61.219743 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:52 | Steps: 779 | Loss: 61.176126 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:52 | Steps: 781 | Loss: 61.215634 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:52 | Steps: 784 | Loss: 61.253735 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:53 | Steps: 786 | Loss: 61.245636 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:53 | Steps: 789 | Loss: 61.266676 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:53 | Steps: 791 | Loss: 61.369279 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:53 | Steps: 793 | Loss: 61.432220 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:53 | Steps: 795 | Loss: 61.489371 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:53 | Steps: 797 | Loss: 61.521436 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:54 | Steps: 799 | Loss: 61.551043 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:54 | Steps: 802 | Loss: 61.582784 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:54 | Steps: 804 | Loss: 61.585914 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:54 | Steps: 806 | Loss: 61.621911 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:54 | Steps: 808 | Loss: 61.617772 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:55 | Steps: 810 | Loss: 61.615324 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:55 | Steps: 812 | Loss: 61.634810 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:55 | Steps: 814 | Loss: 61.673327 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:55 | Steps: 817 | Loss: 61.635342 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:55 | Steps: 819 | Loss: 61.686518 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:55 | Steps: 821 | Loss: 61.716611 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:56 | Steps: 823 | Loss: 61.716181 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:56 | Steps: 825 | Loss: 61.723450 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:56 | Steps: 826 | Loss: 61.728090 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:56 | Steps: 829 | Loss: 61.747282 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:56 | Steps: 830 | Loss: 61.783034 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:56 | Steps: 832 | Loss: 61.926494 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:57 | Steps: 834 | Loss: 61.911579 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:57 | Steps: 836 | Loss: 61.928668 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:57 | Steps: 838 | Loss: 61.918227 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:57 | Steps: 840 | Loss: 61.918105 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:57 | Steps: 842 | Loss: 61.905141 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:57 | Steps: 844 | Loss: 61.923657 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:57 | Steps: 846 | Loss: 61.916264 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:58 | Steps: 849 | Loss: 61.908774 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:58 | Steps: 851 | Loss: 61.936781 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:58 | Steps: 853 | Loss: 62.071609 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:58 | Steps: 854 | Loss: 62.055469 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:58 | Steps: 856 | Loss: 62.061294 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:58 | Steps: 858 | Loss: 62.122401 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:58 | Steps: 860 | Loss: 62.150045 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:59 | Steps: 863 | Loss: 62.157825 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:59 | Steps: 865 | Loss: 62.201244 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:59 | Steps: 866 | Loss: 62.219389 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:59 | Steps: 869 | Loss: 62.272105 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:59 | Steps: 871 | Loss: 62.305201 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:59 | Steps: 874 | Loss: 62.368163 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:00 | Steps: 877 | Loss: 62.392672 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:00 | Steps: 878 | Loss: 62.393821 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:00 | Steps: 880 | Loss: 62.520529 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:00 | Steps: 882 | Loss: 62.573849 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:00 | Steps: 884 | Loss: 62.567441 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:00 | Steps: 886 | Loss: 62.548487 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:00 | Steps: 888 | Loss: 62.498711 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:01 | Steps: 891 | Loss: 62.491408 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:01 | Steps: 894 | Loss: 62.526408 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:01 | Steps: 896 | Loss: 62.524908 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:02 | Steps: 898 | Loss: 62.701596 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:02 | Steps: 901 | Loss: 62.730401 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:02 | Steps: 903 | Loss: 62.737670 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:02 | Steps: 906 | Loss: 62.870163 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:02 | Steps: 908 | Loss: 62.881043 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:02 | Steps: 910 | Loss: 62.895016 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:03 | Steps: 912 | Loss: 62.942908 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:03 | Steps: 914 | Loss: 62.967239 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:03 | Steps: 916 | Loss: 62.983573 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:03 | Steps: 918 | Loss: 63.018099 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:03 | Steps: 920 | Loss: 63.046955 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:03 | Steps: 922 | Loss: 63.060811 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:03 | Steps: 924 | Loss: 63.080433 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:04 | Steps: 927 | Loss: 63.086055 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:04 | Steps: 929 | Loss: 63.076121 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:04 | Steps: 931 | Loss: 63.116628 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:04 | Steps: 934 | Loss: 63.194801 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:04 | Steps: 936 | Loss: 63.198257 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:04 | Steps: 938 | Loss: 63.205344 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:05 | Steps: 940 | Loss: 63.182071 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:05 | Steps: 942 | Loss: 63.215140 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:05 | Steps: 944 | Loss: 63.233269 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:05 | Steps: 946 | Loss: 63.296982 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:05 | Steps: 948 | Loss: 63.366675 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:06 | Steps: 951 | Loss: 63.407312 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:06 | Steps: 953 | Loss: 63.418800 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:06 | Steps: 955 | Loss: 63.402587 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:06 | Steps: 956 | Loss: 63.390985 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:06 | Steps: 958 | Loss: 63.477213 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:06 | Steps: 960 | Loss: 63.525290 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:07 | Steps: 962 | Loss: 63.573980 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:07 | Steps: 964 | Loss: 63.581528 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:07 | Steps: 965 | Loss: 63.566845 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:07 | Steps: 967 | Loss: 63.581700 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:07 | Steps: 969 | Loss: 63.596996 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:07 | Steps: 971 | Loss: 63.652813 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:07 | Steps: 973 | Loss: 63.625440 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:08 | Steps: 975 | Loss: 63.732711 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:08 | Steps: 977 | Loss: 63.736866 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:08 | Steps: 979 | Loss: 63.746830 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:08 | Steps: 981 | Loss: 63.725226 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:08 | Steps: 983 | Loss: 63.751708 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:09 | Steps: 985 | Loss: 63.787222 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:09 | Steps: 987 | Loss: 63.805620 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:09 | Steps: 989 | Loss: 63.862910 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:09 | Steps: 991 | Loss: 63.909728 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:09 | Steps: 994 | Loss: 63.902245 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:09 | Steps: 995 | Loss: 63.884056 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:10 | Steps: 997 | Loss: 63.922034 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:10 | Steps: 999 | Loss: 64.005994 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:10 | Steps: 1002 | Loss: 64.003360 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:10 | Steps: 1004 | Loss: 64.006745 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:10 | Steps: 1007 | Loss: 64.043163 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:11 | Steps: 1010 | Loss: 64.057699 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:11 | Steps: 1011 | Loss: 64.054796 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:11 | Steps: 1014 | Loss: 64.058298 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:11 | Steps: 1016 | Loss: 64.075511 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:11 | Steps: 1017 | Loss: 64.077446 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:11 | Steps: 1019 | Loss: 64.085149 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:11 | Steps: 1022 | Loss: 64.088556 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:12 | Steps: 1024 | Loss: 64.108435 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:12 | Steps: 1026 | Loss: 64.147356 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:12 | Steps: 1028 | Loss: 64.197778 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:12 | Steps: 1031 | Loss: 64.315727 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:12 | Steps: 1033 | Loss: 64.322781 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:12 | Steps: 1035 | Loss: 64.341692 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:12 | Steps: 1036 | Loss: 64.332252 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:13 | Steps: 1038 | Loss: 64.365583 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:13 | Steps: 1041 | Loss: 64.376724 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:13 | Steps: 1043 | Loss: 64.410418 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:13 | Steps: 1045 | Loss: 64.485505 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:13 | Steps: 1048 | Loss: 64.475122 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:14 | Steps: 1051 | Loss: 64.523241 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:14 | Steps: 1052 | Loss: 64.494657 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:14 | Steps: 1055 | Loss: 64.505773 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:14 | Steps: 1058 | Loss: 64.492225 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:14 | Steps: 1060 | Loss: 64.489643 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:14 | Steps: 1062 | Loss: 64.500942 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:14 | Steps: 1064 | Loss: 64.503552 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:15 | Steps: 1065 | Loss: 64.531532 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:15 | Steps: 1068 | Loss: 64.552273 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:15 | Steps: 1070 | Loss: 64.541099 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:15 | Steps: 1073 | Loss: 64.599585 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:15 | Steps: 1075 | Loss: 64.649573 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:15 | Steps: 1076 | Loss: 64.666152 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:16 | Steps: 1078 | Loss: 64.687687 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:16 | Steps: 1080 | Loss: 64.689857 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:16 | Steps: 1083 | Loss: 64.707563 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:16 | Steps: 1086 | Loss: 64.834038 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:16 | Steps: 1087 | Loss: 64.855241 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:16 | Steps: 1089 | Loss: 64.854962 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:17 | Steps: 1093 | Loss: 64.859255 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:17 | Steps: 1096 | Loss: 64.892063 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:17 | Steps: 1099 | Loss: 64.912557 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:17 | Steps: 1100 | Loss: 64.930729 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:17 | Steps: 1102 | Loss: 64.938643 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:18 | Steps: 1104 | Loss: 64.937536 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:18 | Steps: 1106 | Loss: 64.988587 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:18 | Steps: 1109 | Loss: 65.008925 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:18 | Steps: 1110 | Loss: 64.995867 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:18 | Steps: 1112 | Loss: 65.003664 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:18 | Steps: 1114 | Loss: 65.040603 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:18 | Steps: 1116 | Loss: 65.085987 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:19 | Steps: 1119 | Loss: 65.167570 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:19 | Steps: 1121 | Loss: 65.198701 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:19 | Steps: 1123 | Loss: 65.240612 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:19 | Steps: 1125 | Loss: 65.270680 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:19 | Steps: 1128 | Loss: 65.281814 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:20 | Steps: 1130 | Loss: 65.312700 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:20 | Steps: 1132 | Loss: 65.287249 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:20 | Steps: 1135 | Loss: 65.355453 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:20 | Steps: 1137 | Loss: 65.335968 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:20 | Steps: 1139 | Loss: 65.397621 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:20 | Steps: 1141 | Loss: 65.399704 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:20 | Steps: 1143 | Loss: 65.406587 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:20 | Steps: 1145 | Loss: 65.437210 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:21 | Steps: 1146 | Loss: 65.424213 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:21 | Steps: 1149 | Loss: 65.446241 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:21 | Steps: 1151 | Loss: 65.475661 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:21 | Steps: 1154 | Loss: 65.482423 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:21 | Steps: 1156 | Loss: 65.504063 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:21 | Steps: 1158 | Loss: 65.559676 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:22 | Steps: 1161 | Loss: 65.567332 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:22 | Steps: 1163 | Loss: 65.635157 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:22 | Steps: 1164 | Loss: 65.656626 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:22 | Steps: 1166 | Loss: 65.674456 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:22 | Steps: 1169 | Loss: 65.700283 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:22 | Steps: 1171 | Loss: 65.713460 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:22 | Steps: 1174 | Loss: 65.715457 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:23 | Steps: 1175 | Loss: 65.731944 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:23 | Steps: 1177 | Loss: 65.796913 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:23 | Steps: 1179 | Loss: 65.837224 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:23 | Steps: 1182 | Loss: 65.838829 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:23 | Steps: 1184 | Loss: 65.850910 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:23 | Steps: 1186 | Loss: 65.849029 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:24 | Steps: 1189 | Loss: 65.911813 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:24 | Steps: 1191 | Loss: 65.945381 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:24 | Steps: 1193 | Loss: 65.946270 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:24 | Steps: 1196 | Loss: 66.033306 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:24 | Steps: 1198 | Loss: 66.061880 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:24 | Steps: 1200 | Loss: 66.064569 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 1202 | Loss: 66.092388 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 1204 | Loss: 66.124316 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 1205 | Loss: 66.135748 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 1206 | Loss: 66.148401 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 1208 | Loss: 66.173288 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 1210 | Loss: 66.180478 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 1212 | Loss: 66.244091 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 1214 | Loss: 66.244869 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:26 | Steps: 1216 | Loss: 66.240625 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:26 | Steps: 1217 | Loss: 66.248006 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:26 | Steps: 1219 | Loss: 66.237732 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:26 | Steps: 1221 | Loss: 66.278779 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:26 | Steps: 1223 | Loss: 66.281773 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:26 | Steps: 1226 | Loss: 66.273168 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:27 | Steps: 1229 | Loss: 66.277466 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:27 | Steps: 1231 | Loss: 66.324096 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:27 | Steps: 1233 | Loss: 66.346093 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:27 | Steps: 1235 | Loss: 66.370660 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:27 | Steps: 1237 | Loss: 66.378688 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:27 | Steps: 1239 | Loss: 66.446453 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:28 | Steps: 1241 | Loss: 66.470894 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:28 | Steps: 1243 | Loss: 66.516211 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:28 | Steps: 1246 | Loss: 66.543264 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:28 | Steps: 1248 | Loss: 66.546805 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:28 | Steps: 1250 | Loss: 66.545995 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:28 | Steps: 1252 | Loss: 66.559121 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:29 | Steps: 1254 | Loss: 66.632694 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:29 | Steps: 1257 | Loss: 66.661413 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:29 | Steps: 1259 | Loss: 66.660782 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:29 | Steps: 1261 | Loss: 66.646427 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:29 | Steps: 1263 | Loss: 66.668901 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:29 | Steps: 1265 | Loss: 66.684018 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:30 | Steps: 1267 | Loss: 66.702643 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:30 | Steps: 1270 | Loss: 66.680530 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:30 | Steps: 1273 | Loss: 66.702561 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:30 | Steps: 1274 | Loss: 66.719790 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:30 | Steps: 1276 | Loss: 66.730840 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:30 | Steps: 1278 | Loss: 66.731405 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:31 | Steps: 1279 | Loss: 66.746228 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:31 | Steps: 1281 | Loss: 66.778799 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:31 | Steps: 1283 | Loss: 66.790962 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:31 | Steps: 1285 | Loss: 66.831703 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:31 | Steps: 1287 | Loss: 66.832147 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:32 | Steps: 1290 | Loss: 66.820617 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:32 | Steps: 1292 | Loss: 66.879416 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:32 | Steps: 1294 | Loss: 66.905727 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:32 | Steps: 1296 | Loss: 66.959777 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:32 | Steps: 1298 | Loss: 66.945578 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:32 | Steps: 1300 | Loss: 66.942522 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:33 | Steps: 1302 | Loss: 66.962278 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:33 | Steps: 1305 | Loss: 67.000411 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:33 | Steps: 1308 | Loss: 67.012201 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:33 | Steps: 1310 | Loss: 67.004532 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:33 | Steps: 1312 | Loss: 66.995654 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:33 | Steps: 1313 | Loss: 66.985513 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:33 | Steps: 1315 | Loss: 67.001583 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:34 | Steps: 1318 | Loss: 67.030226 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:34 | Steps: 1320 | Loss: 67.014579 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:34 | Steps: 1322 | Loss: 67.050086 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:34 | Steps: 1325 | Loss: 67.109724 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:34 | Steps: 1326 | Loss: 67.129209 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:35 | Steps: 1328 | Loss: 67.150548 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:35 | Steps: 1331 | Loss: 67.179227 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:35 | Steps: 1333 | Loss: 67.206588 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:35 | Steps: 1336 | Loss: 67.205282 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:35 | Steps: 1338 | Loss: 67.199220 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:35 | Steps: 1341 | Loss: 67.260298 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:36 | Steps: 1343 | Loss: 67.279055 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:36 | Steps: 1346 | Loss: 67.278253 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:36 | Steps: 1348 | Loss: 67.296111 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:36 | Steps: 1350 | Loss: 67.373277 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:36 | Steps: 1353 | Loss: 67.390224 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:37 | Steps: 1356 | Loss: 67.380022 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:37 | Steps: 1359 | Loss: 67.422312 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:37 | Steps: 1361 | Loss: 67.463784 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:37 | Steps: 1363 | Loss: 67.491069 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:37 | Steps: 1365 | Loss: 67.539664 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:37 | Steps: 1367 | Loss: 67.558137 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:37 | Steps: 1368 | Loss: 67.564042 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:38 | Steps: 1371 | Loss: 67.575567 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:38 | Steps: 1374 | Loss: 67.602984 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:38 | Steps: 1376 | Loss: 67.627534 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:38 | Steps: 1379 | Loss: 67.604559 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:38 | Steps: 1381 | Loss: 67.633219 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:39 | Steps: 1383 | Loss: 67.645049 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:39 | Steps: 1385 | Loss: 67.667787 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:39 | Steps: 1387 | Loss: 67.685879 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:39 | Steps: 1390 | Loss: 67.722122 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:39 | Steps: 1392 | Loss: 67.719820 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:40 | Steps: 1394 | Loss: 67.729917 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:40 | Steps: 1396 | Loss: 67.740939 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:40 | Steps: 1398 | Loss: 67.749162 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:40 | Steps: 1401 | Loss: 67.732914 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:40 | Steps: 1403 | Loss: 67.777002 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:40 | Steps: 1405 | Loss: 67.794439 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:41 | Steps: 1408 | Loss: 67.833994 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:41 | Steps: 1411 | Loss: 67.850034 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:41 | Steps: 1413 | Loss: 67.860466 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:41 | Steps: 1415 | Loss: 67.855332 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:41 | Steps: 1416 | Loss: 67.871173 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:42 | Steps: 1419 | Loss: 67.907079 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:42 | Steps: 1422 | Loss: 67.930302 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:42 | Steps: 1424 | Loss: 67.942149 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:42 | Steps: 1426 | Loss: 67.933866 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:42 | Steps: 1428 | Loss: 67.915812 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:42 | Steps: 1430 | Loss: 67.954293 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:43 | Steps: 1432 | Loss: 67.959793 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:43 | Steps: 1434 | Loss: 67.963070 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:43 | Steps: 1437 | Loss: 67.969843 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:43 | Steps: 1439 | Loss: 68.006944 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:43 | Steps: 1441 | Loss: 68.040193 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:43 | Steps: 1443 | Loss: 68.064975 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:44 | Steps: 1446 | Loss: 68.129595 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:44 | Steps: 1448 | Loss: 68.167329 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:44 | Steps: 1449 | Loss: 68.169105 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:44 | Steps: 1451 | Loss: 68.186546 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:44 | Steps: 1453 | Loss: 68.224711 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:44 | Steps: 1455 | Loss: 68.225261 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:45 | Steps: 1457 | Loss: 68.258905 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:45 | Steps: 1459 | Loss: 68.285368 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:45 | Steps: 1461 | Loss: 68.294759 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:45 | Steps: 1463 | Loss: 68.292961 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:45 | Steps: 1465 | Loss: 68.276446 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:45 | Steps: 1467 | Loss: 68.291052 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:46 | Steps: 1469 | Loss: 68.295864 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:46 | Steps: 1471 | Loss: 68.339200 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:46 | Steps: 1473 | Loss: 68.390565 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:46 | Steps: 1475 | Loss: 68.411878 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:46 | Steps: 1477 | Loss: 68.419130 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:46 | Steps: 1479 | Loss: 68.411141 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:47 | Steps: 1481 | Loss: 68.453231 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:47 | Steps: 1483 | Loss: 68.461108 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:47 | Steps: 1485 | Loss: 68.479935 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:47 | Steps: 1487 | Loss: 68.514494 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:47 | Steps: 1489 | Loss: 68.521915 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:47 | Steps: 1491 | Loss: 68.520771 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:47 | Steps: 1493 | Loss: 68.553453 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:47 | Steps: 1494 | Loss: 68.575663 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:48 | Steps: 1496 | Loss: 68.634024 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:48 | Steps: 1498 | Loss: 68.679245 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:48 | Steps: 1500 | Loss: 68.706562 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:48 | Steps: 1502 | Loss: 68.737884 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:48 | Steps: 1504 | Loss: 68.733976 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:48 | Steps: 1505 | Loss: 68.753550 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:49 | Steps: 1507 | Loss: 68.761669 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:49 | Steps: 1509 | Loss: 68.774485 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:49 | Steps: 1511 | Loss: 68.792911 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:49 | Steps: 1512 | Loss: 68.787425 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:49 | Steps: 1514 | Loss: 68.794474 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:49 | Steps: 1516 | Loss: 68.818717 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:49 | Steps: 1518 | Loss: 68.831885 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:50 | Steps: 1520 | Loss: 68.844044 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:50 | Steps: 1522 | Loss: 68.868870 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:50 | Steps: 1525 | Loss: 68.891254 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:50 | Steps: 1527 | Loss: 68.930800 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:50 | Steps: 1529 | Loss: 68.938050 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:50 | Steps: 1531 | Loss: 68.952655 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:51 | Steps: 1533 | Loss: 68.960386 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:51 | Steps: 1535 | Loss: 68.988445 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:51 | Steps: 1537 | Loss: 68.984909 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:51 | Steps: 1539 | Loss: 68.976247 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:51 | Steps: 1542 | Loss: 68.986975 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:51 | Steps: 1544 | Loss: 69.033166 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:52 | Steps: 1545 | Loss: 69.057297 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:52 | Steps: 1547 | Loss: 69.065041 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:52 | Steps: 1549 | Loss: 69.071266 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:52 | Steps: 1552 | Loss: 69.064237 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:52 | Steps: 1555 | Loss: 69.110314 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:53 | Steps: 1557 | Loss: 69.077025 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:53 | Steps: 1559 | Loss: 69.115884 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:53 | Steps: 1561 | Loss: 69.096813 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:53 | Steps: 1564 | Loss: 69.157082 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:53 | Steps: 1566 | Loss: 69.175540 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:53 | Steps: 1568 | Loss: 69.209356 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:54 | Steps: 1571 | Loss: 69.214784 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:54 | Steps: 1573 | Loss: 69.228995 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:54 | Steps: 1575 | Loss: 69.248229 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:54 | Steps: 1578 | Loss: 69.309684 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:54 | Steps: 1579 | Loss: 69.321682 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:54 | Steps: 1582 | Loss: 69.315891 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:55 | Steps: 1585 | Loss: 69.338244 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:55 | Steps: 1587 | Loss: 69.343227 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:55 | Steps: 1590 | Loss: 69.379904 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:55 | Steps: 1592 | Loss: 69.377657 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:55 | Steps: 1593 | Loss: 69.383129 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:55 | Steps: 1595 | Loss: 69.413496 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:56 | Steps: 1597 | Loss: 69.501710 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:56 | Steps: 1599 | Loss: 69.507471 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:56 | Steps: 1601 | Loss: 69.507077 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:56 | Steps: 1602 | Loss: 69.551573 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:56 | Steps: 1604 | Loss: 69.575696 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:56 | Steps: 1606 | Loss: 69.621002 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:57 | Steps: 1609 | Loss: 69.667168 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:57 | Steps: 1611 | Loss: 69.666789 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:57 | Steps: 1613 | Loss: 69.661950 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:57 | Steps: 1615 | Loss: 69.671992 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:57 | Steps: 1617 | Loss: 69.691061 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:57 | Steps: 1618 | Loss: 69.690851 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:58 | Steps: 1620 | Loss: 69.697008 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:58 | Steps: 1622 | Loss: 69.709146 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:58 | Steps: 1624 | Loss: 69.719318 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:58 | Steps: 1627 | Loss: 69.754876 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:58 | Steps: 1629 | Loss: 69.755517 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:58 | Steps: 1631 | Loss: 69.786887 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:59 | Steps: 1634 | Loss: 69.770322 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:59 | Steps: 1636 | Loss: 69.789120 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:59 | Steps: 1638 | Loss: 69.807401 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:59 | Steps: 1640 | Loss: 69.810204 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:01:59 | Steps: 1642 | Loss: 69.847185 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:00 | Steps: 1645 | Loss: 69.895349 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:00 | Steps: 1648 | Loss: 69.949047 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:00 | Steps: 1650 | Loss: 69.980316 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:00 | Steps: 1652 | Loss: 70.009464 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:00 | Steps: 1655 | Loss: 70.011289 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:01 | Steps: 1657 | Loss: 70.002811 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:01 | Steps: 1659 | Loss: 70.017427 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:01 | Steps: 1662 | Loss: 70.023126 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:01 | Steps: 1663 | Loss: 70.031261 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:01 | Steps: 1666 | Loss: 70.074120 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:02 | Steps: 1669 | Loss: 70.104303 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:02 | Steps: 1671 | Loss: 70.104253 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:02 | Steps: 1674 | Loss: 70.133001 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:02 | Steps: 1677 | Loss: 70.188267 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:02 | Steps: 1679 | Loss: 70.230430 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:03 | Steps: 1681 | Loss: 70.259127 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:03 | Steps: 1683 | Loss: 70.278704 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:03 | Steps: 1686 | Loss: 70.299299 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:03 | Steps: 1688 | Loss: 70.322043 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:03 | Steps: 1691 | Loss: 70.340075 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:03 | Steps: 1693 | Loss: 70.360516 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:04 | Steps: 1695 | Loss: 70.363156 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:04 | Steps: 1697 | Loss: 70.355479 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:04 | Steps: 1699 | Loss: 70.362164 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:04 | Steps: 1701 | Loss: 70.368351 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:04 | Steps: 1703 | Loss: 70.428557 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:05 | Steps: 1705 | Loss: 70.457412 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:05 | Steps: 1708 | Loss: 70.466264 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:05 | Steps: 1710 | Loss: 70.461385 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:05 | Steps: 1713 | Loss: 70.470559 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:05 | Steps: 1715 | Loss: 70.521078 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:06 | Steps: 1717 | Loss: 70.530012 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:06 | Steps: 1720 | Loss: 70.587951 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:06 | Steps: 1722 | Loss: 70.608221 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:06 | Steps: 1723 | Loss: 70.605947 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:06 | Steps: 1725 | Loss: 70.637592 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:06 | Steps: 1727 | Loss: 70.671909 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:07 | Steps: 1729 | Loss: 70.685007 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:07 | Steps: 1731 | Loss: 70.710537 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:07 | Steps: 1733 | Loss: 70.737897 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:07 | Steps: 1734 | Loss: 70.753982 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:07 | Steps: 1736 | Loss: 70.787772 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:07 | Steps: 1739 | Loss: 70.795787 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:08 | Steps: 1741 | Loss: 70.809074 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:08 | Steps: 1744 | Loss: 70.815470 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:08 | Steps: 1745 | Loss: 70.818598 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:08 | Steps: 1747 | Loss: 70.832627 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:08 | Steps: 1750 | Loss: 70.842161 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:08 | Steps: 1752 | Loss: 70.882699 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:09 | Steps: 1753 | Loss: 70.883980 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:09 | Steps: 1755 | Loss: 70.877356 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:09 | Steps: 1757 | Loss: 70.890624 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:09 | Steps: 1759 | Loss: 70.898926 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:09 | Steps: 1762 | Loss: 70.914372 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:09 | Steps: 1764 | Loss: 70.930783 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:09 | Steps: 1765 | Loss: 70.934928 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:10 | Steps: 1767 | Loss: 70.962236 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:10 | Steps: 1769 | Loss: 70.990509 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:10 | Steps: 1771 | Loss: 71.004061 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:10 | Steps: 1773 | Loss: 71.025098 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:10 | Steps: 1775 | Loss: 71.041612 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:11 | Steps: 1777 | Loss: 71.084387 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:11 | Steps: 1779 | Loss: 71.119482 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:11 | Steps: 1781 | Loss: 71.142155 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:11 | Steps: 1784 | Loss: 71.155195 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:11 | Steps: 1786 | Loss: 71.141709 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:12 | Steps: 1788 | Loss: 71.191188 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:12 | Steps: 1790 | Loss: 71.194827 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:12 | Steps: 1791 | Loss: 71.193568 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:12 | Steps: 1793 | Loss: 71.212222 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:12 | Steps: 1795 | Loss: 71.262117 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:12 | Steps: 1797 | Loss: 71.259139 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:12 | Steps: 1799 | Loss: 71.262731 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:13 | Steps: 1801 | Loss: 71.313254 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:13 | Steps: 1804 | Loss: 71.351035 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:13 | Steps: 1806 | Loss: 71.347189 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:13 | Steps: 1808 | Loss: 71.366737 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:13 | Steps: 1810 | Loss: 71.387467 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:14 | Steps: 1812 | Loss: 71.432791 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:14 | Steps: 1814 | Loss: 71.447416 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:14 | Steps: 1817 | Loss: 71.480595 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:14 | Steps: 1819 | Loss: 71.497995 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:15 | Steps: 1821 | Loss: 71.491260 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:15 | Steps: 1823 | Loss: 71.532032 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:15 | Steps: 1825 | Loss: 71.556790 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:15 | Steps: 1827 | Loss: 71.563390 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:15 | Steps: 1829 | Loss: 71.577654 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:15 | Steps: 1831 | Loss: 71.589343 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:16 | Steps: 1832 | Loss: 71.606524 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:16 | Steps: 1833 | Loss: 71.624468 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:16 | Steps: 1835 | Loss: 71.626979 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:16 | Steps: 1836 | Loss: 71.617328 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:16 | Steps: 1838 | Loss: 71.615429 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:16 | Steps: 1841 | Loss: 71.664856 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:17 | Steps: 1844 | Loss: 71.694101 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:17 | Steps: 1846 | Loss: 71.703542 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:17 | Steps: 1848 | Loss: 71.727978 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:17 | Steps: 1850 | Loss: 71.776093 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:17 | Steps: 1853 | Loss: 71.788534 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:18 | Steps: 1855 | Loss: 71.799650 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:18 | Steps: 1857 | Loss: 71.825580 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:18 | Steps: 1860 | Loss: 71.857300 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:18 | Steps: 1862 | Loss: 71.861288 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:18 | Steps: 1864 | Loss: 71.889109 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:19 | Steps: 1866 | Loss: 71.923034 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:19 | Steps: 1868 | Loss: 71.931340 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:19 | Steps: 1870 | Loss: 71.961005 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:19 | Steps: 1872 | Loss: 71.956510 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:19 | Steps: 1874 | Loss: 71.969118 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:19 | Steps: 1876 | Loss: 71.999297 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:20 | Steps: 1877 | Loss: 72.007214 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:20 | Steps: 1879 | Loss: 72.029636 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:20 | Steps: 1881 | Loss: 72.023660 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:20 | Steps: 1883 | Loss: 72.079340 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:20 | Steps: 1884 | Loss: 72.093838 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:20 | Steps: 1886 | Loss: 72.112556 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:21 | Steps: 1888 | Loss: 72.147388 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:21 | Steps: 1890 | Loss: 72.164316 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:21 | Steps: 1892 | Loss: 72.184886 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:21 | Steps: 1894 | Loss: 72.172393 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:21 | Steps: 1897 | Loss: 72.199972 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:22 | Steps: 1899 | Loss: 72.212058 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:22 | Steps: 1901 | Loss: 72.225263 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:22 | Steps: 1904 | Loss: 72.221460 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:22 | Steps: 1906 | Loss: 72.262957 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:22 | Steps: 1908 | Loss: 72.283407 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:22 | Steps: 1910 | Loss: 72.288658 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:23 | Steps: 1912 | Loss: 72.309662 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:23 | Steps: 1914 | Loss: 72.303740 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:23 | Steps: 1915 | Loss: 72.317903 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:23 | Steps: 1917 | Loss: 72.370033 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:23 | Steps: 1919 | Loss: 72.391281 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:23 | Steps: 1921 | Loss: 72.399146 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:24 | Steps: 1923 | Loss: 72.412933 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:24 | Steps: 1925 | Loss: 72.432609 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:24 | Steps: 1928 | Loss: 72.483494 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:24 | Steps: 1930 | Loss: 72.479036 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:24 | Steps: 1932 | Loss: 72.500813 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:25 | Steps: 1935 | Loss: 72.502479 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:25 | Steps: 1936 | Loss: 72.518381 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:25 | Steps: 1938 | Loss: 72.536029 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:25 | Steps: 1940 | Loss: 72.575120 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:25 | Steps: 1942 | Loss: 72.577271 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:25 | Steps: 1944 | Loss: 72.575997 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:26 | Steps: 1946 | Loss: 72.569566 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:26 | Steps: 1948 | Loss: 72.608591 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:26 | Steps: 1949 | Loss: 72.616212 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:26 | Steps: 1951 | Loss: 72.642412 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:26 | Steps: 1953 | Loss: 72.663234 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:26 | Steps: 1955 | Loss: 72.678768 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:27 | Steps: 1957 | Loss: 72.694112 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:27 | Steps: 1960 | Loss: 72.744932 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:27 | Steps: 1962 | Loss: 72.745964 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:27 | Steps: 1964 | Loss: 72.761707 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:27 | Steps: 1965 | Loss: 72.780292 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:28 | Steps: 1967 | Loss: 72.789726 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:28 | Steps: 1969 | Loss: 72.811378 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:28 | Steps: 1970 | Loss: 72.824878 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:28 | Steps: 1972 | Loss: 72.821136 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:28 | Steps: 1973 | Loss: 72.821786 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:28 | Steps: 1975 | Loss: 72.823484 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:29 | Steps: 1977 | Loss: 72.822824 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:29 | Steps: 1979 | Loss: 72.823821 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:29 | Steps: 1982 | Loss: 72.819326 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:29 | Steps: 1984 | Loss: 72.845240 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:29 | Steps: 1986 | Loss: 72.847257 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:30 | Steps: 1988 | Loss: 72.859934 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:30 | Steps: 1989 | Loss: 72.869513 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:30 | Steps: 1990 | Loss: 72.877977 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:30 | Steps: 1992 | Loss: 72.919453 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:30 | Steps: 1993 | Loss: 72.944289 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:30 | Steps: 1994 | Loss: 72.954883 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:31 | Steps: 1996 | Loss: 72.983943 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:31 | Steps: 1998 | Loss: 73.001268 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:31 | Steps: 2000 | Loss: 73.027434 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:31 | Steps: 2002 | Loss: 73.045790 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:32 | Steps: 2004 | Loss: 73.077161 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:32 | Steps: 2005 | Loss: 73.093476 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:32 | Steps: 2006 | Loss: 73.099326 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:32 | Steps: 2008 | Loss: 73.128935 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:32 | Steps: 2009 | Loss: 73.131529 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:32 | Steps: 2010 | Loss: 73.127431 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:32 | Steps: 2011 | Loss: 73.145472 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:32 | Steps: 2013 | Loss: 73.153710 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:33 | Steps: 2015 | Loss: 73.151555 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:33 | Steps: 2016 | Loss: 73.189263 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:33 | Steps: 2018 | Loss: 73.205149 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:33 | Steps: 2019 | Loss: 73.218431 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:33 | Steps: 2021 | Loss: 73.251112 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:33 | Steps: 2022 | Loss: 73.269475 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:34 | Steps: 2024 | Loss: 73.275335 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:34 | Steps: 2025 | Loss: 73.298564 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:34 | Steps: 2027 | Loss: 73.313773 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:34 | Steps: 2029 | Loss: 73.335798 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:34 | Steps: 2031 | Loss: 73.348467 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:35 | Steps: 2033 | Loss: 73.336034 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:35 | Steps: 2035 | Loss: 73.340496 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:35 | Steps: 2037 | Loss: 73.348818 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:35 | Steps: 2039 | Loss: 73.357396 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:35 | Steps: 2041 | Loss: 73.358218 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:36 | Steps: 2042 | Loss: 73.358697 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:36 | Steps: 2044 | Loss: 73.391497 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:36 | Steps: 2045 | Loss: 73.399844 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:36 | Steps: 2046 | Loss: 73.412461 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:36 | Steps: 2048 | Loss: 73.420884 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:36 | Steps: 2049 | Loss: 73.421044 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:36 | Steps: 2051 | Loss: 73.452498 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:37 | Steps: 2053 | Loss: 73.480691 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:37 | Steps: 2054 | Loss: 73.503971 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:37 | Steps: 2057 | Loss: 73.525929 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:37 | Steps: 2059 | Loss: 73.529509 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:37 | Steps: 2060 | Loss: 73.548852 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:37 | Steps: 2062 | Loss: 73.586993 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:38 | Steps: 2064 | Loss: 73.599403 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:38 | Steps: 2066 | Loss: 73.612286 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:38 | Steps: 2068 | Loss: 73.614828 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:38 | Steps: 2070 | Loss: 73.637535 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:39 | Steps: 2072 | Loss: 73.657398 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:39 | Steps: 2074 | Loss: 73.665117 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:39 | Steps: 2075 | Loss: 73.664069 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:39 | Steps: 2077 | Loss: 73.682178 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:39 | Steps: 2079 | Loss: 73.702413 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:39 | Steps: 2081 | Loss: 73.729522 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:40 | Steps: 2083 | Loss: 73.724242 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:40 | Steps: 2085 | Loss: 73.742277 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:40 | Steps: 2087 | Loss: 73.777024 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:40 | Steps: 2089 | Loss: 73.788036 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:40 | Steps: 2091 | Loss: 73.816363 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:41 | Steps: 2093 | Loss: 73.837120 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:41 | Steps: 2094 | Loss: 73.856263 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:41 | Steps: 2095 | Loss: 73.857656 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:41 | Steps: 2097 | Loss: 73.886393 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:41 | Steps: 2098 | Loss: 73.895699 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:41 | Steps: 2099 | Loss: 73.892345 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:41 | Steps: 2101 | Loss: 73.918966 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:41 | Steps: 2102 | Loss: 73.930820 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:42 | Steps: 2103 | Loss: 73.933647 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:42 | Steps: 2104 | Loss: 73.946679 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:42 | Steps: 2106 | Loss: 73.957405 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:42 | Steps: 2108 | Loss: 73.952365 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:42 | Steps: 2110 | Loss: 73.978198 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:42 | Steps: 2112 | Loss: 74.005486 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:43 | Steps: 2114 | Loss: 74.022228 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:43 | Steps: 2116 | Loss: 74.034050 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:43 | Steps: 2118 | Loss: 74.069269 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:43 | Steps: 2120 | Loss: 74.092306 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:43 | Steps: 2122 | Loss: 74.111670 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:44 | Steps: 2124 | Loss: 74.133218 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:44 | Steps: 2125 | Loss: 74.134705 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:44 | Steps: 2127 | Loss: 74.143287 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:44 | Steps: 2129 | Loss: 74.143235 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:44 | Steps: 2131 | Loss: 74.152162 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:45 | Steps: 2133 | Loss: 74.187928 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:45 | Steps: 2135 | Loss: 74.197813 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:45 | Steps: 2137 | Loss: 74.214640 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:45 | Steps: 2139 | Loss: 74.208123 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:45 | Steps: 2141 | Loss: 74.215884 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:46 | Steps: 2143 | Loss: 74.248529 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:46 | Steps: 2145 | Loss: 74.262044 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:46 | Steps: 2147 | Loss: 74.255409 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:46 | Steps: 2149 | Loss: 74.266277 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:46 | Steps: 2151 | Loss: 74.292027 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:47 | Steps: 2153 | Loss: 74.330550 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:47 | Steps: 2155 | Loss: 74.359008 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:47 | Steps: 2157 | Loss: 74.395919 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:47 | Steps: 2159 | Loss: 74.405827 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:47 | Steps: 2161 | Loss: 74.435103 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:47 | Steps: 2162 | Loss: 74.443796 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:48 | Steps: 2164 | Loss: 74.445361 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:48 | Steps: 2166 | Loss: 74.471079 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:48 | Steps: 2168 | Loss: 74.501477 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:48 | Steps: 2170 | Loss: 74.540230 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:48 | Steps: 2172 | Loss: 74.557224 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:49 | Steps: 2174 | Loss: 74.564138 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:49 | Steps: 2176 | Loss: 74.572607 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:49 | Steps: 2179 | Loss: 74.646755 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:50 | Steps: 2181 | Loss: 74.665977 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:50 | Steps: 2183 | Loss: 74.689727 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:51 | Steps: 2185 | Loss: 74.724108 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:51 | Steps: 2187 | Loss: 74.735446 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:51 | Steps: 2188 | Loss: 74.748565 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:51 | Steps: 2189 | Loss: 74.767378 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:52 | Steps: 2191 | Loss: 74.783604 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:52 | Steps: 2193 | Loss: 74.836400 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:52 | Steps: 2195 | Loss: 74.839987 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:52 | Steps: 2197 | Loss: 74.841207 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:53 | Steps: 2199 | Loss: 74.868949 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:53 | Steps: 2201 | Loss: 74.877416 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:53 | Steps: 2202 | Loss: 74.874324 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:54 | Steps: 2204 | Loss: 74.875193 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:54 | Steps: 2206 | Loss: 74.886283 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:54 | Steps: 2208 | Loss: 74.899624 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:55 | Steps: 2210 | Loss: 74.925155 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:55 | Steps: 2212 | Loss: 74.946202 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:55 | Steps: 2214 | Loss: 74.967600 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:56 | Steps: 2216 | Loss: 74.985963 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:56 | Steps: 2218 | Loss: 74.987071 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:56 | Steps: 2219 | Loss: 75.002588 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:56 | Steps: 2221 | Loss: 75.011576 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:57 | Steps: 2223 | Loss: 75.038924 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:57 | Steps: 2225 | Loss: 75.059649 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:57 | Steps: 2226 | Loss: 75.073721 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:57 | Steps: 2227 | Loss: 75.082227 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:58 | Steps: 2229 | Loss: 75.098124 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:58 | Steps: 2231 | Loss: 75.105662 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:58 | Steps: 2233 | Loss: 75.119989 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:58 | Steps: 2234 | Loss: 75.134538 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:59 | Steps: 2236 | Loss: 75.166934 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:59 | Steps: 2237 | Loss: 75.183226 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:59 | Steps: 2238 | Loss: 75.209035 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:59 | Steps: 2239 | Loss: 75.239570 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:02:59 | Steps: 2241 | Loss: 75.277893 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:00 | Steps: 2242 | Loss: 75.315514 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:00 | Steps: 2243 | Loss: 75.321745 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:00 | Steps: 2245 | Loss: 75.333876 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:00 | Steps: 2247 | Loss: 75.373682 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:00 | Steps: 2249 | Loss: 75.403398 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:00 | Steps: 2250 | Loss: 75.414582 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:01 | Steps: 2251 | Loss: 75.439128 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:01 | Steps: 2253 | Loss: 75.468001 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:02 | Steps: 2255 | Loss: 75.494203 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:02 | Steps: 2257 | Loss: 75.487885 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:02 | Steps: 2259 | Loss: 75.500871 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:03 | Steps: 2261 | Loss: 75.533682 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:03 | Steps: 2263 | Loss: 75.539133 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:03 | Steps: 2264 | Loss: 75.539888 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:03 | Steps: 2266 | Loss: 75.553405 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:04 | Steps: 2268 | Loss: 75.563937 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:04 | Steps: 2270 | Loss: 75.570924 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:04 | Steps: 2272 | Loss: 75.586719 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:04 | Steps: 2274 | Loss: 75.605271 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:05 | Steps: 2276 | Loss: 75.635176 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:05 | Steps: 2278 | Loss: 75.675901 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:05 | Steps: 2280 | Loss: 75.679206 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:05 | Steps: 2282 | Loss: 75.698335 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:06 | Steps: 2284 | Loss: 75.701210 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:06 | Steps: 2286 | Loss: 75.712872 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:06 | Steps: 2288 | Loss: 75.711453 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:07 | Steps: 2290 | Loss: 75.727328 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:07 | Steps: 2291 | Loss: 75.741421 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:07 | Steps: 2292 | Loss: 75.749535 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:07 | Steps: 2293 | Loss: 75.739011 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:08 | Steps: 2294 | Loss: 75.737176 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:08 | Steps: 2295 | Loss: 75.752988 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:08 | Steps: 2297 | Loss: 75.771566 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:09 | Steps: 2299 | Loss: 75.808708 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:09 | Steps: 2301 | Loss: 75.826776 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:09 | Steps: 2303 | Loss: 75.843427 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:09 | Steps: 2304 | Loss: 75.861828 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:10 | Steps: 2306 | Loss: 75.869463 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:10 | Steps: 2308 | Loss: 75.908263 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:10 | Steps: 2310 | Loss: 75.935033 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:10 | Steps: 2312 | Loss: 75.944758 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:10 | Steps: 2314 | Loss: 75.944810 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:11 | Steps: 2316 | Loss: 75.943669 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:11 | Steps: 2317 | Loss: 75.946354 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:11 | Steps: 2319 | Loss: 75.955883 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:11 | Steps: 2321 | Loss: 75.961875 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:12 | Steps: 2322 | Loss: 75.984674 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:12 | Steps: 2323 | Loss: 76.011649 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:12 | Steps: 2324 | Loss: 76.023117 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:12 | Steps: 2326 | Loss: 76.056570 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:12 | Steps: 2328 | Loss: 76.085507 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:12 | Steps: 2330 | Loss: 76.102432 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:13 | Steps: 2332 | Loss: 76.118912 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:13 | Steps: 2333 | Loss: 76.133901 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:13 | Steps: 2335 | Loss: 76.169234 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:13 | Steps: 2336 | Loss: 76.162952 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:13 | Steps: 2338 | Loss: 76.190665 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:14 | Steps: 2339 | Loss: 76.207351 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:14 | Steps: 2341 | Loss: 76.226542 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:14 | Steps: 2342 | Loss: 76.234337 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:14 | Steps: 2344 | Loss: 76.239185 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:14 | Steps: 2345 | Loss: 76.251400 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:14 | Steps: 2346 | Loss: 76.245817 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:15 | Steps: 2348 | Loss: 76.245281 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:15 | Steps: 2350 | Loss: 76.271792 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:15 | Steps: 2351 | Loss: 76.277912 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:15 | Steps: 2353 | Loss: 76.302025 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:15 | Steps: 2355 | Loss: 76.332978 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:15 | Steps: 2357 | Loss: 76.370778 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:16 | Steps: 2359 | Loss: 76.377513 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:16 | Steps: 2361 | Loss: 76.409932 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:16 | Steps: 2363 | Loss: 76.415050 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:16 | Steps: 2365 | Loss: 76.420627 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:17 | Steps: 2367 | Loss: 76.441550 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:17 | Steps: 2369 | Loss: 76.449979 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:17 | Steps: 2371 | Loss: 76.469091 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:17 | Steps: 2373 | Loss: 76.479164 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:18 | Steps: 2375 | Loss: 76.527773 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:18 | Steps: 2376 | Loss: 76.550977 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:18 | Steps: 2378 | Loss: 76.580970 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:18 | Steps: 2379 | Loss: 76.589359 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:18 | Steps: 2381 | Loss: 76.607338 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:18 | Steps: 2382 | Loss: 76.608287 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:19 | Steps: 2383 | Loss: 76.614982 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:19 | Steps: 2385 | Loss: 76.643045 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:19 | Steps: 2386 | Loss: 76.645876 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:19 | Steps: 2387 | Loss: 76.655400 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:19 | Steps: 2388 | Loss: 76.658927 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:19 | Steps: 2389 | Loss: 76.662265 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:19 | Steps: 2390 | Loss: 76.659349 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:20 | Steps: 2392 | Loss: 76.658017 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:20 | Steps: 2394 | Loss: 76.683541 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:20 | Steps: 2396 | Loss: 76.689106 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:20 | Steps: 2397 | Loss: 76.699412 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:20 | Steps: 2399 | Loss: 76.736471 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:21 | Steps: 2401 | Loss: 76.753117 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:21 | Steps: 2402 | Loss: 76.768348 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:21 | Steps: 2403 | Loss: 76.789957 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:21 | Steps: 2405 | Loss: 76.807528 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:22 | Steps: 2407 | Loss: 76.846340 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:22 | Steps: 2408 | Loss: 76.852622 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:22 | Steps: 2409 | Loss: 76.852850 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:22 | Steps: 2410 | Loss: 76.869098 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:22 | Steps: 2412 | Loss: 76.895671 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:22 | Steps: 2413 | Loss: 76.910839 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:22 | Steps: 2414 | Loss: 76.916455 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:23 | Steps: 2416 | Loss: 76.926221 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:23 | Steps: 2418 | Loss: 76.939504 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:23 | Steps: 2419 | Loss: 76.943565 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:23 | Steps: 2420 | Loss: 76.947794 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:23 | Steps: 2422 | Loss: 76.968019 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:23 | Steps: 2423 | Loss: 76.972462 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:24 | Steps: 2425 | Loss: 76.977127 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:24 | Steps: 2426 | Loss: 76.994616 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:24 | Steps: 2427 | Loss: 77.000154 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:24 | Steps: 2428 | Loss: 77.013308 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:24 | Steps: 2430 | Loss: 77.028563 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:25 | Steps: 2432 | Loss: 77.055801 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:25 | Steps: 2434 | Loss: 77.084420 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:25 | Steps: 2435 | Loss: 77.094596 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:25 | Steps: 2436 | Loss: 77.098585 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:25 | Steps: 2438 | Loss: 77.120981 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:25 | Steps: 2439 | Loss: 77.150443 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:26 | Steps: 2441 | Loss: 77.162264 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:26 | Steps: 2443 | Loss: 77.208045 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:26 | Steps: 2444 | Loss: 77.212375 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:26 | Steps: 2445 | Loss: 77.225659 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:27 | Steps: 2447 | Loss: 77.241194 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:27 | Steps: 2449 | Loss: 77.298021 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:27 | Steps: 2450 | Loss: 77.309929 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:27 | Steps: 2452 | Loss: 77.315587 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:27 | Steps: 2454 | Loss: 77.344830 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:28 | Steps: 2456 | Loss: 77.349568 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:28 | Steps: 2458 | Loss: 77.375108 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:28 | Steps: 2460 | Loss: 77.365378 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:28 | Steps: 2462 | Loss: 77.376060 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:28 | Steps: 2464 | Loss: 77.414911 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:29 | Steps: 2466 | Loss: 77.438044 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:29 | Steps: 2468 | Loss: 77.455672 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:29 | Steps: 2469 | Loss: 77.460248 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:29 | Steps: 2470 | Loss: 77.471989 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:29 | Steps: 2471 | Loss: 77.487189 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:29 | Steps: 2472 | Loss: 77.491043 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:30 | Steps: 2474 | Loss: 77.499497 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:30 | Steps: 2475 | Loss: 77.526741 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:30 | Steps: 2476 | Loss: 77.532128 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:30 | Steps: 2477 | Loss: 77.563454 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:30 | Steps: 2479 | Loss: 77.607382 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:30 | Steps: 2480 | Loss: 77.623345 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:31 | Steps: 2481 | Loss: 77.629556 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:31 | Steps: 2483 | Loss: 77.637457 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:31 | Steps: 2485 | Loss: 77.660870 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:31 | Steps: 2487 | Loss: 77.668203 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:32 | Steps: 2489 | Loss: 77.690442 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:32 | Steps: 2490 | Loss: 77.699199 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:32 | Steps: 2492 | Loss: 77.710581 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:32 | Steps: 2493 | Loss: 77.718797 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:32 | Steps: 2494 | Loss: 77.723402 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:32 | Steps: 2495 | Loss: 77.732702 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:32 | Steps: 2496 | Loss: 77.734637 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:33 | Steps: 2498 | Loss: 77.764680 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:33 | Steps: 2499 | Loss: 77.770699 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:33 | Steps: 2500 | Loss: 77.772101 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:33 | Steps: 2501 | Loss: 77.771759 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:33 | Steps: 2503 | Loss: 77.781305 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:34 | Steps: 2505 | Loss: 77.788147 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:34 | Steps: 2506 | Loss: 77.909151 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:34 | Steps: 2507 | Loss: 77.910662 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:34 | Steps: 2508 | Loss: 77.923875 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:34 | Steps: 2510 | Loss: 77.953777 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:35 | Steps: 2511 | Loss: 77.972670 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:35 | Steps: 2512 | Loss: 77.981910 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:35 | Steps: 2513 | Loss: 77.995909 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:35 | Steps: 2515 | Loss: 78.021711 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:35 | Steps: 2516 | Loss: 78.028309 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:35 | Steps: 2518 | Loss: 78.025252 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:35 | Steps: 2520 | Loss: 78.048408 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:36 | Steps: 2521 | Loss: 78.054428 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:36 | Steps: 2522 | Loss: 78.063668 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:36 | Steps: 2523 | Loss: 78.080365 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:36 | Steps: 2524 | Loss: 78.082798 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:36 | Steps: 2526 | Loss: 78.128640 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:36 | Steps: 2528 | Loss: 78.176044 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:37 | Steps: 2530 | Loss: 78.207637 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:37 | Steps: 2532 | Loss: 78.265784 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:38 | Steps: 2534 | Loss: 78.294492 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:38 | Steps: 2536 | Loss: 78.330049 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:38 | Steps: 2537 | Loss: 78.334480 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:39 | Steps: 2539 | Loss: 78.354364 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:39 | Steps: 2540 | Loss: 78.360137 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:39 | Steps: 2542 | Loss: 78.375895 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:39 | Steps: 2544 | Loss: 78.391633 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:40 | Steps: 2546 | Loss: 78.417881 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:40 | Steps: 2548 | Loss: 78.424321 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:40 | Steps: 2550 | Loss: 78.462554 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:40 | Steps: 2552 | Loss: 78.494656 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:40 | Steps: 2553 | Loss: 78.504076 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:41 | Steps: 2555 | Loss: 78.529342 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:41 | Steps: 2556 | Loss: 78.542986 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:41 | Steps: 2557 | Loss: 78.553290 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:41 | Steps: 2559 | Loss: 78.592577 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:41 | Steps: 2560 | Loss: 78.597179 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:41 | Steps: 2561 | Loss: 78.603933 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:42 | Steps: 2563 | Loss: 78.616235 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:42 | Steps: 2565 | Loss: 78.627693 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:42 | Steps: 2567 | Loss: 78.641963 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:42 | Steps: 2568 | Loss: 78.629072 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:43 | Steps: 2569 | Loss: 78.623236 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:43 | Steps: 2570 | Loss: 78.622207 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:43 | Steps: 2572 | Loss: 78.649196 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:43 | Steps: 2574 | Loss: 78.660498 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:44 | Steps: 2576 | Loss: 78.663540 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:44 | Steps: 2577 | Loss: 78.678855 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:44 | Steps: 2578 | Loss: 78.680050 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:44 | Steps: 2580 | Loss: 78.693068 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:44 | Steps: 2582 | Loss: 78.691492 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:44 | Steps: 2584 | Loss: 78.715090 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:45 | Steps: 2586 | Loss: 78.727586 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:45 | Steps: 2587 | Loss: 78.740249 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:45 | Steps: 2589 | Loss: 78.760066 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:45 | Steps: 2590 | Loss: 78.776996 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:45 | Steps: 2592 | Loss: 78.796941 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:45 | Steps: 2593 | Loss: 78.807879 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:46 | Steps: 2594 | Loss: 78.813504 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:46 | Steps: 2595 | Loss: 78.826378 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:46 | Steps: 2596 | Loss: 78.830323 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:46 | Steps: 2598 | Loss: 78.858650 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:46 | Steps: 2599 | Loss: 78.862546 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:46 | Steps: 2601 | Loss: 78.867919 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:47 | Steps: 2602 | Loss: 78.867799 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:47 | Steps: 2603 | Loss: 78.873239 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:47 | Steps: 2605 | Loss: 78.898557 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:47 | Steps: 2607 | Loss: 78.929805 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:47 | Steps: 2609 | Loss: 78.993758 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:48 | Steps: 2611 | Loss: 78.998250 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:48 | Steps: 2612 | Loss: 79.005256 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:48 | Steps: 2613 | Loss: 79.023726 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:48 | Steps: 2614 | Loss: 79.033151 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:48 | Steps: 2617 | Loss: 79.037497 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:48 | Steps: 2618 | Loss: 79.043784 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:48 | Steps: 2619 | Loss: 79.060539 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:49 | Steps: 2621 | Loss: 79.078374 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:49 | Steps: 2622 | Loss: 79.079811 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:49 | Steps: 2623 | Loss: 79.078826 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:49 | Steps: 2625 | Loss: 79.102809 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:49 | Steps: 2626 | Loss: 79.105063 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:50 | Steps: 2628 | Loss: 79.112414 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:50 | Steps: 2630 | Loss: 79.128493 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:50 | Steps: 2631 | Loss: 79.138017 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:50 | Steps: 2632 | Loss: 79.147790 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:50 | Steps: 2634 | Loss: 79.176918 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:50 | Steps: 2635 | Loss: 79.184574 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:51 | Steps: 2637 | Loss: 79.200872 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:51 | Steps: 2638 | Loss: 79.212111 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:51 | Steps: 2639 | Loss: 79.232693 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:51 | Steps: 2640 | Loss: 79.235186 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:51 | Steps: 2642 | Loss: 79.282293 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:51 | Steps: 2643 | Loss: 79.297095 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:51 | Steps: 2644 | Loss: 79.312713 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:52 | Steps: 2646 | Loss: 79.347721 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:52 | Steps: 2648 | Loss: 79.356162 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:52 | Steps: 2650 | Loss: 79.383797 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:52 | Steps: 2651 | Loss: 79.392334 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:53 | Steps: 2653 | Loss: 79.430761 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:53 | Steps: 2654 | Loss: 79.433539 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:53 | Steps: 2655 | Loss: 79.456045 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:53 | Steps: 2656 | Loss: 79.456467 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:53 | Steps: 2657 | Loss: 79.463049 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:53 | Steps: 2659 | Loss: 79.476970 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:53 | Steps: 2660 | Loss: 79.493371 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:54 | Steps: 2662 | Loss: 79.507695 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:54 | Steps: 2664 | Loss: 79.543326 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:54 | Steps: 2666 | Loss: 79.586357 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:54 | Steps: 2668 | Loss: 79.598045 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:54 | Steps: 2669 | Loss: 79.605054 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:55 | Steps: 2671 | Loss: 79.619838 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:55 | Steps: 2673 | Loss: 79.629292 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:55 | Steps: 2675 | Loss: 79.663330 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:55 | Steps: 2677 | Loss: 79.673841 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:56 | Steps: 2679 | Loss: 79.693969 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:56 | Steps: 2680 | Loss: 79.697728 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:56 | Steps: 2681 | Loss: 79.700653 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:56 | Steps: 2683 | Loss: 79.733954 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:57 | Steps: 2684 | Loss: 79.739332 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:57 | Steps: 2686 | Loss: 79.759030 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:57 | Steps: 2687 | Loss: 79.752575 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:57 | Steps: 2688 | Loss: 79.760245 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:57 | Steps: 2689 | Loss: 79.775467 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:57 | Steps: 2690 | Loss: 79.828078 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:58 | Steps: 2692 | Loss: 79.837574 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:58 | Steps: 2694 | Loss: 79.863904 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:58 | Steps: 2696 | Loss: 79.878992 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:58 | Steps: 2698 | Loss: 79.914680 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:59 | Steps: 2699 | Loss: 79.921057 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:59 | Steps: 2701 | Loss: 79.927789 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:59 | Steps: 2703 | Loss: 79.938085 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:59 | Steps: 2705 | Loss: 79.944504 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:59 | Steps: 2706 | Loss: 79.944221 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:03:59 | Steps: 2707 | Loss: 79.965256 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:00 | Steps: 2709 | Loss: 79.996037 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:00 | Steps: 2710 | Loss: 80.020341 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:00 | Steps: 2712 | Loss: 80.030875 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:01 | Steps: 2714 | Loss: 80.039085 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:01 | Steps: 2716 | Loss: 80.071731 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:01 | Steps: 2717 | Loss: 80.078155 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:01 | Steps: 2720 | Loss: 80.101859 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:02 | Steps: 2721 | Loss: 80.110739 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:02 | Steps: 2722 | Loss: 80.125205 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:02 | Steps: 2725 | Loss: 80.153999 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:02 | Steps: 2726 | Loss: 80.159174 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:02 | Steps: 2728 | Loss: 80.171279 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:02 | Steps: 2729 | Loss: 80.173076 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:03 | Steps: 2731 | Loss: 80.204746 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:03 | Steps: 2733 | Loss: 80.234901 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:03 | Steps: 2734 | Loss: 80.248668 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:03 | Steps: 2735 | Loss: 80.250718 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:03 | Steps: 2737 | Loss: 80.261668 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:04 | Steps: 2739 | Loss: 80.297302 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:04 | Steps: 2741 | Loss: 80.320722 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:04 | Steps: 2742 | Loss: 80.325289 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:04 | Steps: 2744 | Loss: 80.345407 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:04 | Steps: 2745 | Loss: 80.356904 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:04 | Steps: 2746 | Loss: 80.373154 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:04 | Steps: 2747 | Loss: 80.376038 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:05 | Steps: 2748 | Loss: 80.374360 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:05 | Steps: 2749 | Loss: 80.382262 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:05 | Steps: 2750 | Loss: 80.392762 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:05 | Steps: 2751 | Loss: 80.423533 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:05 | Steps: 2752 | Loss: 80.437031 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:05 | Steps: 2753 | Loss: 80.457176 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:05 | Steps: 2755 | Loss: 80.490686 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:06 | Steps: 2757 | Loss: 80.531505 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:06 | Steps: 2759 | Loss: 80.546447 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:06 | Steps: 2761 | Loss: 80.580236 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:06 | Steps: 2762 | Loss: 80.591871 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:06 | Steps: 2763 | Loss: 80.610899 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:06 | Steps: 2764 | Loss: 80.623987 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:07 | Steps: 2765 | Loss: 80.655460 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:07 | Steps: 2766 | Loss: 80.676681 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:07 | Steps: 2768 | Loss: 80.693823 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:07 | Steps: 2770 | Loss: 80.701336 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:07 | Steps: 2772 | Loss: 80.700067 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:08 | Steps: 2774 | Loss: 80.721373 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:08 | Steps: 2776 | Loss: 80.740233 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:08 | Steps: 2777 | Loss: 80.748500 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:08 | Steps: 2778 | Loss: 80.759979 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:08 | Steps: 2780 | Loss: 80.785264 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:08 | Steps: 2781 | Loss: 80.805274 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:09 | Steps: 2783 | Loss: 80.815447 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:09 | Steps: 2785 | Loss: 80.837794 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:09 | Steps: 2787 | Loss: 80.868212 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:09 | Steps: 2788 | Loss: 80.869568 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:09 | Steps: 2789 | Loss: 80.879862 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:09 | Steps: 2790 | Loss: 80.904598 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:09 | Steps: 2791 | Loss: 80.906452 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:10 | Steps: 2792 | Loss: 80.915331 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:10 | Steps: 2793 | Loss: 80.933899 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:10 | Steps: 2794 | Loss: 80.937369 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:10 | Steps: 2795 | Loss: 80.946657 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:10 | Steps: 2797 | Loss: 80.968620 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:10 | Steps: 2798 | Loss: 80.969218 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:11 | Steps: 2800 | Loss: 80.994605 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:11 | Steps: 2801 | Loss: 81.052711 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:11 | Steps: 2802 | Loss: 81.073192 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:11 | Steps: 2804 | Loss: 81.095814 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:11 | Steps: 2805 | Loss: 81.101269 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:11 | Steps: 2807 | Loss: 81.131567 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:12 | Steps: 2808 | Loss: 81.129349 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:12 | Steps: 2810 | Loss: 81.148444 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:12 | Steps: 2812 | Loss: 81.167430 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:12 | Steps: 2813 | Loss: 81.179905 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:12 | Steps: 2814 | Loss: 81.180521 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:13 | Steps: 2816 | Loss: 81.210817 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:13 | Steps: 2818 | Loss: 81.230806 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:13 | Steps: 2819 | Loss: 81.250215 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:13 | Steps: 2820 | Loss: 81.269318 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:13 | Steps: 2821 | Loss: 81.273464 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:13 | Steps: 2823 | Loss: 81.323401 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:13 | Steps: 2824 | Loss: 81.332430 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:14 | Steps: 2826 | Loss: 81.367354 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:14 | Steps: 2827 | Loss: 81.381922 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:14 | Steps: 2829 | Loss: 81.411688 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:14 | Steps: 2830 | Loss: 81.440431 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:14 | Steps: 2832 | Loss: 81.445769 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:15 | Steps: 2834 | Loss: 81.481220 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:15 | Steps: 2836 | Loss: 81.490461 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:15 | Steps: 2837 | Loss: 81.505509 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:15 | Steps: 2839 | Loss: 81.521990 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:15 | Steps: 2840 | Loss: 81.533855 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:15 | Steps: 2841 | Loss: 81.545948 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:16 | Steps: 2842 | Loss: 81.566135 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:16 | Steps: 2843 | Loss: 81.579873 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:16 | Steps: 2844 | Loss: 81.591457 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:16 | Steps: 2845 | Loss: 81.603394 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:16 | Steps: 2847 | Loss: 81.642910 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:16 | Steps: 2848 | Loss: 81.655002 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:16 | Steps: 2849 | Loss: 81.660502 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:17 | Steps: 2850 | Loss: 81.671507 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:17 | Steps: 2852 | Loss: 81.702611 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:17 | Steps: 2853 | Loss: 81.735309 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:17 | Steps: 2854 | Loss: 81.771561 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:17 | Steps: 2855 | Loss: 81.788366 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:17 | Steps: 2856 | Loss: 81.798614 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:17 | Steps: 2857 | Loss: 81.816918 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:18 | Steps: 2859 | Loss: 81.838315 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:18 | Steps: 2860 | Loss: 81.846945 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:18 | Steps: 2861 | Loss: 81.879694 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:18 | Steps: 2862 | Loss: 81.937300 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:18 | Steps: 2863 | Loss: 81.954799 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:18 | Steps: 2865 | Loss: 81.980890 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:19 | Steps: 2867 | Loss: 81.997800 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:19 | Steps: 2869 | Loss: 82.019962 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:19 | Steps: 2870 | Loss: 82.043078 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:19 | Steps: 2872 | Loss: 82.056486 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:19 | Steps: 2873 | Loss: 82.087084 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:20 | Steps: 2875 | Loss: 82.160803 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:20 | Steps: 2876 | Loss: 82.173666 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:20 | Steps: 2878 | Loss: 82.196714 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:20 | Steps: 2879 | Loss: 82.211102 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:20 | Steps: 2880 | Loss: 82.232348 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:20 | Steps: 2881 | Loss: 82.243932 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:21 | Steps: 2882 | Loss: 82.258187 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:21 | Steps: 2883 | Loss: 82.272247 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:21 | Steps: 2884 | Loss: 82.274416 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:21 | Steps: 2886 | Loss: 82.297715 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:21 | Steps: 2888 | Loss: 82.356150 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:21 | Steps: 2889 | Loss: 82.365040 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:22 | Steps: 2891 | Loss: 82.391303 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:22 | Steps: 2893 | Loss: 82.447059 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:22 | Steps: 2895 | Loss: 82.455795 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:22 | Steps: 2896 | Loss: 82.459761 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:22 | Steps: 2897 | Loss: 82.473720 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:22 | Steps: 2898 | Loss: 82.478247 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:23 | Steps: 2899 | Loss: 82.503366 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:23 | Steps: 2900 | Loss: 82.523114 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:23 | Steps: 2901 | Loss: 82.527934 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:23 | Steps: 2903 | Loss: 82.544391 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:23 | Steps: 2904 | Loss: 82.547083 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:23 | Steps: 2905 | Loss: 82.557865 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:24 | Steps: 2906 | Loss: 82.557335 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:24 | Steps: 2908 | Loss: 82.585760 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:24 | Steps: 2910 | Loss: 82.634731 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:24 | Steps: 2912 | Loss: 82.667852 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:25 | Steps: 2914 | Loss: 82.714419 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:25 | Steps: 2916 | Loss: 82.725034 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:25 | Steps: 2917 | Loss: 82.745064 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:25 | Steps: 2918 | Loss: 82.770471 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:25 | Steps: 2919 | Loss: 82.791682 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:25 | Steps: 2920 | Loss: 82.816634 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:26 | Steps: 2921 | Loss: 82.829414 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:26 | Steps: 2923 | Loss: 82.862725 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:26 | Steps: 2925 | Loss: 82.890215 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:26 | Steps: 2927 | Loss: 82.940132 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:27 | Steps: 2928 | Loss: 82.956659 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:27 | Steps: 2930 | Loss: 82.981390 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:27 | Steps: 2931 | Loss: 82.991249 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:27 | Steps: 2932 | Loss: 83.004545 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:28 | Steps: 2934 | Loss: 83.035587 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:28 | Steps: 2937 | Loss: 83.092444 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:28 | Steps: 2939 | Loss: 83.139032 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:28 | Steps: 2940 | Loss: 83.162830 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:29 | Steps: 2941 | Loss: 83.171128 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:29 | Steps: 2942 | Loss: 83.194071 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:29 | Steps: 2944 | Loss: 83.221949 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:29 | Steps: 2945 | Loss: 83.225533 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:29 | Steps: 2946 | Loss: 83.255833 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:29 | Steps: 2947 | Loss: 83.279169 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:29 | Steps: 2949 | Loss: 83.300354 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:30 | Steps: 2950 | Loss: 83.309689 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:30 | Steps: 2951 | Loss: 83.323455 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:30 | Steps: 2953 | Loss: 83.355737 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:30 | Steps: 2955 | Loss: 83.402267 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:31 | Steps: 2957 | Loss: 83.440299 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:31 | Steps: 2958 | Loss: 83.456158 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:31 | Steps: 2959 | Loss: 83.474179 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:31 | Steps: 2961 | Loss: 83.510325 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:31 | Steps: 2963 | Loss: 83.535472 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:32 | Steps: 2964 | Loss: 83.559849 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:32 | Steps: 2965 | Loss: 83.564511 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:32 | Steps: 2967 | Loss: 83.583296 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:32 | Steps: 2969 | Loss: 83.632416 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:32 | Steps: 2970 | Loss: 83.656517 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:32 | Steps: 2971 | Loss: 83.667960 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:33 | Steps: 2972 | Loss: 83.693405 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:33 | Steps: 2974 | Loss: 83.713520 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:33 | Steps: 2975 | Loss: 83.745445 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:33 | Steps: 2976 | Loss: 83.755567 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:33 | Steps: 2977 | Loss: 83.767863 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:33 | Steps: 2979 | Loss: 83.804047 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:34 | Steps: 2980 | Loss: 83.822749 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:34 | Steps: 2981 | Loss: 83.837812 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:34 | Steps: 2983 | Loss: 83.851429 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:34 | Steps: 2984 | Loss: 83.867523 | Dataset: sw/dev.csv\n",
      "Epoch 0 | Validation | Elapsed Time: 0:04:34 | Steps: 2985 | Loss: 83.892487 | Dataset: sw/dev.csv\n",
      "I Saved new best validating model with loss 83.892487 to: ckpt_dir/best_dev-11017\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 45.872841\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 3 | Loss: 46.883804\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 6 | Loss: 70.229870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 8 | Loss: 62.506753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 10 | Loss: 57.022170\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 13 | Loss: 50.174679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:03 | Steps: 15 | Loss: 47.987270\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:03 | Steps: 17 | Loss: 46.004506\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:03 | Steps: 19 | Loss: 44.762908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:03 | Steps: 21 | Loss: 43.623176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:03 | Steps: 23 | Loss: 42.432798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:03 | Steps: 26 | Loss: 42.234789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:03 | Steps: 28 | Loss: 41.240344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:03 | Steps: 31 | Loss: 40.784576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 34 | Loss: 39.863106\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 36 | Loss: 40.617736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 38 | Loss: 39.916642\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 41 | Loss: 41.817339\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 43 | Loss: 41.848935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 46 | Loss: 41.145527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 48 | Loss: 41.804963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 50 | Loss: 41.134659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:05 | Steps: 53 | Loss: 40.317306\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:05 | Steps: 56 | Loss: 39.663476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:05 | Steps: 58 | Loss: 39.411603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:05 | Steps: 61 | Loss: 38.820573\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:05 | Steps: 63 | Loss: 38.434422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:05 | Steps: 65 | Loss: 37.955237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:05 | Steps: 67 | Loss: 39.002707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:05 | Steps: 69 | Loss: 39.146713\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 72 | Loss: 39.071853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 74 | Loss: 38.724718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 76 | Loss: 38.233233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 79 | Loss: 37.952840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 82 | Loss: 38.903719\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 85 | Loss: 39.378588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 87 | Loss: 39.683381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 90 | Loss: 39.571399\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:06 | Steps: 92 | Loss: 39.237369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:07 | Steps: 94 | Loss: 38.950064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:07 | Steps: 96 | Loss: 38.718650\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:07 | Steps: 99 | Loss: 38.388260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:07 | Steps: 101 | Loss: 38.395810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:07 | Steps: 103 | Loss: 38.432466\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:07 | Steps: 105 | Loss: 38.272837\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:07 | Steps: 108 | Loss: 38.471241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:07 | Steps: 111 | Loss: 38.352357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:08 | Steps: 113 | Loss: 38.449727\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:08 | Steps: 115 | Loss: 38.257372\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:08 | Steps: 117 | Loss: 37.945933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:08 | Steps: 120 | Loss: 37.676692\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:08 | Steps: 123 | Loss: 37.527416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:08 | Steps: 126 | Loss: 37.960519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:08 | Steps: 129 | Loss: 37.956033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:09 | Steps: 132 | Loss: 37.682165\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:09 | Steps: 134 | Loss: 37.452427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:09 | Steps: 136 | Loss: 37.236608\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:09 | Steps: 138 | Loss: 37.100703\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:09 | Steps: 140 | Loss: 37.067889\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:09 | Steps: 142 | Loss: 36.918661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:09 | Steps: 144 | Loss: 37.110675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:09 | Steps: 147 | Loss: 36.945039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 150 | Loss: 37.376659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 152 | Loss: 37.379000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 155 | Loss: 37.299052\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 158 | Loss: 37.100368\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 161 | Loss: 36.900040\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 164 | Loss: 36.662728\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 166 | Loss: 36.827220\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 168 | Loss: 36.745838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:11 | Steps: 170 | Loss: 36.703095\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:11 | Steps: 173 | Loss: 36.574098\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:11 | Steps: 176 | Loss: 37.304262\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:11 | Steps: 179 | Loss: 37.282153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:11 | Steps: 182 | Loss: 37.210946\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:11 | Steps: 184 | Loss: 37.143733\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:11 | Steps: 186 | Loss: 37.219665\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:12 | Steps: 188 | Loss: 37.290475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:12 | Steps: 190 | Loss: 37.257443\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:12 | Steps: 192 | Loss: 37.293682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:12 | Steps: 195 | Loss: 37.244004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:12 | Steps: 197 | Loss: 37.314662\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:12 | Steps: 200 | Loss: 37.411364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:12 | Steps: 202 | Loss: 37.445222\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:12 | Steps: 204 | Loss: 37.355936\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:13 | Steps: 207 | Loss: 37.274597\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:13 | Steps: 210 | Loss: 37.112876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:13 | Steps: 213 | Loss: 37.135004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:13 | Steps: 215 | Loss: 37.240237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:13 | Steps: 217 | Loss: 37.370749\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:13 | Steps: 220 | Loss: 37.476431\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:13 | Steps: 222 | Loss: 37.500149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:13 | Steps: 224 | Loss: 37.655627\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 226 | Loss: 37.714277\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 228 | Loss: 37.843349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 230 | Loss: 37.908339\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 232 | Loss: 37.854516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 234 | Loss: 37.740821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 236 | Loss: 37.679696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 238 | Loss: 37.635012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 240 | Loss: 37.565606\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:14 | Steps: 242 | Loss: 37.825101\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 245 | Loss: 37.848516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 247 | Loss: 37.782910\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 249 | Loss: 37.855598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 251 | Loss: 37.949468\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 253 | Loss: 37.918137\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 255 | Loss: 37.941701\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 257 | Loss: 38.206470\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 259 | Loss: 38.324037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:15 | Steps: 261 | Loss: 38.421349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:16 | Steps: 264 | Loss: 38.523038\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:16 | Steps: 267 | Loss: 38.577761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:16 | Steps: 270 | Loss: 38.515372\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:16 | Steps: 272 | Loss: 38.387142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:16 | Steps: 274 | Loss: 38.335601\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:16 | Steps: 276 | Loss: 38.281562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:16 | Steps: 278 | Loss: 38.414705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:16 | Steps: 280 | Loss: 38.323228\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:17 | Steps: 283 | Loss: 38.345928\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:17 | Steps: 285 | Loss: 38.418671\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:17 | Steps: 287 | Loss: 38.408665\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:17 | Steps: 289 | Loss: 38.565693\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:17 | Steps: 291 | Loss: 38.833964\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:17 | Steps: 293 | Loss: 38.902830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:17 | Steps: 295 | Loss: 38.958828\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:17 | Steps: 298 | Loss: 38.999153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 301 | Loss: 38.935674\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 303 | Loss: 38.901288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 305 | Loss: 38.817346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 307 | Loss: 38.797238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 309 | Loss: 38.712079\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 311 | Loss: 38.624543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 313 | Loss: 38.707456\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 315 | Loss: 38.704837\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:18 | Steps: 317 | Loss: 38.668164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:19 | Steps: 319 | Loss: 38.814762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:19 | Steps: 321 | Loss: 38.804743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:19 | Steps: 324 | Loss: 38.774978\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:19 | Steps: 326 | Loss: 38.746366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:19 | Steps: 328 | Loss: 38.919541\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:19 | Steps: 330 | Loss: 39.303083\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:19 | Steps: 332 | Loss: 39.241950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:19 | Steps: 334 | Loss: 39.334450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:20 | Steps: 336 | Loss: 39.511911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:20 | Steps: 338 | Loss: 39.484224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:20 | Steps: 341 | Loss: 39.488628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:20 | Steps: 344 | Loss: 39.408535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:20 | Steps: 346 | Loss: 39.338833\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:20 | Steps: 348 | Loss: 39.326296\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:20 | Steps: 350 | Loss: 39.394878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:20 | Steps: 352 | Loss: 39.439609\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 354 | Loss: 39.611743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 355 | Loss: 39.711247\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 357 | Loss: 39.663790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 359 | Loss: 39.701615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 361 | Loss: 39.736593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 363 | Loss: 39.736307\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 365 | Loss: 39.697469\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 367 | Loss: 39.811491\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:21 | Steps: 370 | Loss: 39.911056\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:22 | Steps: 373 | Loss: 39.973577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:22 | Steps: 375 | Loss: 39.965921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:22 | Steps: 377 | Loss: 39.931722\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:22 | Steps: 379 | Loss: 39.926993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:22 | Steps: 381 | Loss: 39.870196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:22 | Steps: 383 | Loss: 39.792097\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:22 | Steps: 385 | Loss: 39.767778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:22 | Steps: 387 | Loss: 39.712838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:23 | Steps: 390 | Loss: 39.666316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:23 | Steps: 392 | Loss: 39.748015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:23 | Steps: 394 | Loss: 39.756453\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:23 | Steps: 396 | Loss: 39.724286\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 39.745874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:23 | Steps: 400 | Loss: 39.840019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:23 | Steps: 402 | Loss: 39.826876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:23 | Steps: 404 | Loss: 39.792045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:24 | Steps: 406 | Loss: 39.916542\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:24 | Steps: 408 | Loss: 39.951963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:24 | Steps: 410 | Loss: 40.086074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:24 | Steps: 412 | Loss: 40.088111\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:24 | Steps: 414 | Loss: 40.139295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:24 | Steps: 416 | Loss: 40.130695\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:24 | Steps: 418 | Loss: 40.093507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:24 | Steps: 420 | Loss: 40.088265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 422 | Loss: 40.098077\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 424 | Loss: 40.035441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 426 | Loss: 40.027435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 428 | Loss: 39.930805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 430 | Loss: 39.994676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 432 | Loss: 40.100072\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 434 | Loss: 40.192822\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 436 | Loss: 40.197109\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:25 | Steps: 437 | Loss: 40.258798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:26 | Steps: 439 | Loss: 40.335927\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:26 | Steps: 441 | Loss: 40.400398\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:26 | Steps: 443 | Loss: 40.501158\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:26 | Steps: 445 | Loss: 40.471718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:26 | Steps: 447 | Loss: 40.579950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:26 | Steps: 449 | Loss: 40.759893\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:26 | Steps: 451 | Loss: 40.718421\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:26 | Steps: 453 | Loss: 40.802250\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:27 | Steps: 455 | Loss: 40.978874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:27 | Steps: 457 | Loss: 40.979146\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:27 | Steps: 459 | Loss: 40.985709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:27 | Steps: 461 | Loss: 40.970245\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:27 | Steps: 463 | Loss: 40.985981\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:27 | Steps: 466 | Loss: 40.989272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:27 | Steps: 468 | Loss: 40.954169\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:27 | Steps: 469 | Loss: 40.923133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:28 | Steps: 471 | Loss: 40.959521\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:28 | Steps: 473 | Loss: 40.964896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:28 | Steps: 476 | Loss: 41.270639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:28 | Steps: 478 | Loss: 41.405877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:28 | Steps: 480 | Loss: 41.443849\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:28 | Steps: 482 | Loss: 41.443223\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:28 | Steps: 484 | Loss: 41.435642\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:28 | Steps: 486 | Loss: 41.589911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:29 | Steps: 488 | Loss: 41.627720\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:29 | Steps: 490 | Loss: 41.621397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:29 | Steps: 492 | Loss: 41.670841\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:29 | Steps: 495 | Loss: 41.718066\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:29 | Steps: 497 | Loss: 41.872034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:29 | Steps: 499 | Loss: 41.907968\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:29 | Steps: 501 | Loss: 41.899472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:29 | Steps: 503 | Loss: 42.023386\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:30 | Steps: 505 | Loss: 42.112778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:30 | Steps: 507 | Loss: 42.150002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:30 | Steps: 509 | Loss: 42.215183\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:30 | Steps: 511 | Loss: 42.232551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:30 | Steps: 513 | Loss: 42.224292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:30 | Steps: 515 | Loss: 42.209670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:30 | Steps: 517 | Loss: 42.300888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:30 | Steps: 519 | Loss: 42.303527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:31 | Steps: 521 | Loss: 42.293737\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:31 | Steps: 523 | Loss: 42.228608\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:31 | Steps: 525 | Loss: 42.207022\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:31 | Steps: 527 | Loss: 42.158144\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:31 | Steps: 529 | Loss: 42.169422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:31 | Steps: 531 | Loss: 42.326828\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:31 | Steps: 533 | Loss: 42.416961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:31 | Steps: 535 | Loss: 42.349532\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:32 | Steps: 537 | Loss: 42.332552\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:32 | Steps: 539 | Loss: 42.352461\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:32 | Steps: 541 | Loss: 42.421450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:32 | Steps: 543 | Loss: 42.466563\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:32 | Steps: 545 | Loss: 42.421037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:32 | Steps: 547 | Loss: 42.461371\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:32 | Steps: 549 | Loss: 42.467435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:32 | Steps: 551 | Loss: 42.588041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:33 | Steps: 553 | Loss: 42.595545\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:33 | Steps: 555 | Loss: 42.585671\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:33 | Steps: 557 | Loss: 42.663959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:33 | Steps: 558 | Loss: 42.684264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:33 | Steps: 560 | Loss: 42.715736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:33 | Steps: 562 | Loss: 42.779680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:34 | Steps: 564 | Loss: 42.792735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:34 | Steps: 566 | Loss: 42.774992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:34 | Steps: 567 | Loss: 42.800812\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:34 | Steps: 569 | Loss: 42.882246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:34 | Steps: 571 | Loss: 42.900729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:34 | Steps: 573 | Loss: 42.893793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:34 | Steps: 575 | Loss: 42.913531\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:34 | Steps: 577 | Loss: 42.869599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:35 | Steps: 579 | Loss: 42.858402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:35 | Steps: 581 | Loss: 42.847544\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:35 | Steps: 583 | Loss: 42.843078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:35 | Steps: 585 | Loss: 42.865539\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:35 | Steps: 587 | Loss: 42.866413\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:35 | Steps: 589 | Loss: 42.893489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:35 | Steps: 591 | Loss: 43.058671\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:35 | Steps: 593 | Loss: 43.215192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:36 | Steps: 595 | Loss: 43.229548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:36 | Steps: 597 | Loss: 43.275920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:36 | Steps: 599 | Loss: 43.383057\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:36 | Steps: 601 | Loss: 43.416126\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:36 | Steps: 603 | Loss: 43.472314\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:36 | Steps: 605 | Loss: 43.579803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:36 | Steps: 607 | Loss: 43.646148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:36 | Steps: 609 | Loss: 43.759473\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:37 | Steps: 611 | Loss: 43.757417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:37 | Steps: 613 | Loss: 43.780852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:37 | Steps: 615 | Loss: 43.783816\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:37 | Steps: 617 | Loss: 43.869770\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:37 | Steps: 619 | Loss: 43.871611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:37 | Steps: 621 | Loss: 43.850599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:37 | Steps: 623 | Loss: 43.831414\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:38 | Steps: 625 | Loss: 43.813364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:38 | Steps: 627 | Loss: 43.761745\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:38 | Steps: 629 | Loss: 43.734460\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:38 | Steps: 631 | Loss: 43.730040\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:38 | Steps: 633 | Loss: 43.798639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:38 | Steps: 635 | Loss: 43.850494\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:38 | Steps: 637 | Loss: 43.874215\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:39 | Steps: 639 | Loss: 43.815417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:39 | Steps: 641 | Loss: 43.861099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:39 | Steps: 643 | Loss: 43.906391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:39 | Steps: 645 | Loss: 43.951818\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:39 | Steps: 647 | Loss: 44.015421\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:39 | Steps: 649 | Loss: 44.063008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:39 | Steps: 651 | Loss: 44.092907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:40 | Steps: 653 | Loss: 44.108613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:40 | Steps: 655 | Loss: 44.141512\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:40 | Steps: 657 | Loss: 44.195523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:40 | Steps: 659 | Loss: 44.255328\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:40 | Steps: 661 | Loss: 44.280138\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:40 | Steps: 662 | Loss: 44.265497\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:40 | Steps: 664 | Loss: 44.290693\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:40 | Steps: 666 | Loss: 44.367459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:41 | Steps: 668 | Loss: 44.459706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:41 | Steps: 670 | Loss: 44.485799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:41 | Steps: 672 | Loss: 44.497395\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:41 | Steps: 674 | Loss: 44.556803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:41 | Steps: 676 | Loss: 44.554878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:41 | Steps: 678 | Loss: 44.546037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:41 | Steps: 679 | Loss: 44.566702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:41 | Steps: 681 | Loss: 44.692604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:42 | Steps: 683 | Loss: 44.776829\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:42 | Steps: 685 | Loss: 44.780613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:42 | Steps: 687 | Loss: 44.783989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:42 | Steps: 689 | Loss: 44.749136\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:42 | Steps: 691 | Loss: 44.748114\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:42 | Steps: 693 | Loss: 44.765101\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:42 | Steps: 695 | Loss: 44.757636\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:42 | Steps: 697 | Loss: 44.806580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:43 | Steps: 699 | Loss: 44.835480\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:43 | Steps: 701 | Loss: 44.848647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:43 | Steps: 703 | Loss: 44.899164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:43 | Steps: 705 | Loss: 44.915166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:43 | Steps: 707 | Loss: 44.918614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:43 | Steps: 709 | Loss: 44.930155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:43 | Steps: 711 | Loss: 44.957634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:44 | Steps: 713 | Loss: 45.038502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:44 | Steps: 715 | Loss: 45.277149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:44 | Steps: 717 | Loss: 45.276137\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:44 | Steps: 719 | Loss: 45.325327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:44 | Steps: 721 | Loss: 45.317067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:44 | Steps: 723 | Loss: 45.344515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:44 | Steps: 724 | Loss: 45.318203\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:44 | Steps: 726 | Loss: 45.436823\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:45 | Steps: 728 | Loss: 45.457769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:45 | Steps: 730 | Loss: 45.451802\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:45 | Steps: 732 | Loss: 45.437687\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:45 | Steps: 734 | Loss: 45.487942\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:45 | Steps: 736 | Loss: 45.599637\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:45 | Steps: 738 | Loss: 45.661966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:45 | Steps: 740 | Loss: 45.670904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:45 | Steps: 742 | Loss: 45.729048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:46 | Steps: 744 | Loss: 45.761164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:46 | Steps: 746 | Loss: 45.723086\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:46 | Steps: 748 | Loss: 45.705740\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:46 | Steps: 750 | Loss: 45.734017\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:46 | Steps: 752 | Loss: 45.766918\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:46 | Steps: 754 | Loss: 45.722517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:46 | Steps: 756 | Loss: 45.683339\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:47 | Steps: 758 | Loss: 45.675751\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:47 | Steps: 760 | Loss: 45.687995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:47 | Steps: 762 | Loss: 45.643517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:47 | Steps: 764 | Loss: 45.663209\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:47 | Steps: 766 | Loss: 45.648884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:47 | Steps: 768 | Loss: 45.665312\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:47 | Steps: 770 | Loss: 45.726900\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:48 | Steps: 772 | Loss: 45.717387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:48 | Steps: 774 | Loss: 45.715844\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:48 | Steps: 776 | Loss: 45.726067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:48 | Steps: 778 | Loss: 45.763171\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:48 | Steps: 780 | Loss: 45.821202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:48 | Steps: 782 | Loss: 45.848851\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:48 | Steps: 784 | Loss: 45.827744\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:48 | Steps: 786 | Loss: 45.881218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:49 | Steps: 788 | Loss: 45.869947\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:49 | Steps: 790 | Loss: 45.889295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:49 | Steps: 792 | Loss: 45.916179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:49 | Steps: 794 | Loss: 46.007236\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:49 | Steps: 796 | Loss: 46.012922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:49 | Steps: 798 | Loss: 45.987646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:49 | Steps: 800 | Loss: 46.073660\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:50 | Steps: 802 | Loss: 46.155805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:50 | Steps: 804 | Loss: 46.164776\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:50 | Steps: 805 | Loss: 46.169638\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:50 | Steps: 807 | Loss: 46.152133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:50 | Steps: 809 | Loss: 46.165058\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:50 | Steps: 811 | Loss: 46.154204\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:50 | Steps: 813 | Loss: 46.138991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:50 | Steps: 814 | Loss: 46.144050\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:51 | Steps: 816 | Loss: 46.243732\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:51 | Steps: 818 | Loss: 46.244158\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:51 | Steps: 820 | Loss: 46.289878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:51 | Steps: 822 | Loss: 46.267148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:51 | Steps: 824 | Loss: 46.268952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:51 | Steps: 826 | Loss: 46.297959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:51 | Steps: 828 | Loss: 46.283133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:52 | Steps: 830 | Loss: 46.277658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:52 | Steps: 832 | Loss: 46.307278\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:52 | Steps: 834 | Loss: 46.388130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:52 | Steps: 836 | Loss: 46.416304\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:52 | Steps: 838 | Loss: 46.462237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:52 | Steps: 840 | Loss: 46.460799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:52 | Steps: 842 | Loss: 46.440606\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 844 | Loss: 46.450878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 846 | Loss: 46.448475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 847 | Loss: 46.468171\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 849 | Loss: 46.585502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 851 | Loss: 46.638525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 853 | Loss: 46.653029\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 855 | Loss: 46.700157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 856 | Loss: 46.745324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:53 | Steps: 858 | Loss: 46.790910\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:54 | Steps: 860 | Loss: 46.802927\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:54 | Steps: 862 | Loss: 46.845353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:54 | Steps: 864 | Loss: 46.868859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:54 | Steps: 866 | Loss: 46.848272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:54 | Steps: 868 | Loss: 46.939853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:54 | Steps: 870 | Loss: 46.963926\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:54 | Steps: 872 | Loss: 46.985676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:55 | Steps: 874 | Loss: 47.038105\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:55 | Steps: 876 | Loss: 47.055209\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:55 | Steps: 878 | Loss: 47.067888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:55 | Steps: 880 | Loss: 47.050801\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:55 | Steps: 882 | Loss: 47.035044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:55 | Steps: 884 | Loss: 47.095603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:55 | Steps: 886 | Loss: 47.104577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:56 | Steps: 888 | Loss: 47.140067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:56 | Steps: 890 | Loss: 47.098908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:56 | Steps: 892 | Loss: 47.121841\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:56 | Steps: 894 | Loss: 47.123877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:56 | Steps: 896 | Loss: 47.117608\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:56 | Steps: 898 | Loss: 47.109746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:56 | Steps: 900 | Loss: 47.154153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:56 | Steps: 902 | Loss: 47.150498\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:57 | Steps: 904 | Loss: 47.156583\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:57 | Steps: 906 | Loss: 47.184210\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:57 | Steps: 908 | Loss: 47.227659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:57 | Steps: 910 | Loss: 47.209698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:57 | Steps: 912 | Loss: 47.211145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:57 | Steps: 914 | Loss: 47.217773\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:57 | Steps: 916 | Loss: 47.285387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:58 | Steps: 918 | Loss: 47.327765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:58 | Steps: 920 | Loss: 47.303061\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:58 | Steps: 922 | Loss: 47.351176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:58 | Steps: 924 | Loss: 47.340517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:58 | Steps: 926 | Loss: 47.366789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:58 | Steps: 928 | Loss: 47.412495\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:58 | Steps: 930 | Loss: 47.523219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:59 | Steps: 932 | Loss: 47.543146\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:59 | Steps: 934 | Loss: 47.580880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:59 | Steps: 936 | Loss: 47.592985\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:59 | Steps: 938 | Loss: 47.626267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:59 | Steps: 940 | Loss: 47.630138\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:59 | Steps: 942 | Loss: 47.697352\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:59 | Steps: 943 | Loss: 47.710057\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:59 | Steps: 945 | Loss: 47.736578\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:00 | Steps: 947 | Loss: 47.736636\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:00 | Steps: 949 | Loss: 47.763578\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:00 | Steps: 950 | Loss: 47.778428\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:00 | Steps: 952 | Loss: 47.778044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:00 | Steps: 954 | Loss: 47.783262\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:00 | Steps: 956 | Loss: 47.782871\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:00 | Steps: 958 | Loss: 47.804393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:01 | Steps: 960 | Loss: 47.879765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:01 | Steps: 962 | Loss: 47.927939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:01 | Steps: 964 | Loss: 47.938649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:01 | Steps: 966 | Loss: 47.964891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:01 | Steps: 968 | Loss: 47.937840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:01 | Steps: 970 | Loss: 47.935271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:01 | Steps: 972 | Loss: 47.937994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:01 | Steps: 974 | Loss: 47.923747\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:02 | Steps: 976 | Loss: 47.912909\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:02 | Steps: 978 | Loss: 47.907817\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:02 | Steps: 980 | Loss: 47.950596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:02 | Steps: 982 | Loss: 47.982160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:02 | Steps: 984 | Loss: 47.997477\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:02 | Steps: 986 | Loss: 47.979175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:02 | Steps: 988 | Loss: 47.989329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:03 | Steps: 990 | Loss: 47.980116\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:03 | Steps: 992 | Loss: 47.974144\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:03 | Steps: 994 | Loss: 47.990518\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:03 | Steps: 996 | Loss: 48.014351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:03 | Steps: 997 | Loss: 48.009007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:03 | Steps: 999 | Loss: 48.035651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:03 | Steps: 1001 | Loss: 48.035356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:04 | Steps: 1003 | Loss: 48.025735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:04 | Steps: 1005 | Loss: 48.034906\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:04 | Steps: 1007 | Loss: 48.057741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:04 | Steps: 1009 | Loss: 48.104583\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:04 | Steps: 1011 | Loss: 48.143938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:04 | Steps: 1013 | Loss: 48.198954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:04 | Steps: 1015 | Loss: 48.195020\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:05 | Steps: 1016 | Loss: 48.198784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:05 | Steps: 1018 | Loss: 48.176099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:05 | Steps: 1020 | Loss: 48.193599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:05 | Steps: 1022 | Loss: 48.263178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:05 | Steps: 1024 | Loss: 48.291932\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:05 | Steps: 1026 | Loss: 48.322254\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:05 | Steps: 1028 | Loss: 48.344460\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:06 | Steps: 1030 | Loss: 48.362223\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:06 | Steps: 1032 | Loss: 48.340216\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:06 | Steps: 1034 | Loss: 48.383426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:06 | Steps: 1036 | Loss: 48.383008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:06 | Steps: 1038 | Loss: 48.382429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:06 | Steps: 1040 | Loss: 48.357201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:06 | Steps: 1042 | Loss: 48.406211\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:07 | Steps: 1044 | Loss: 48.436593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:07 | Steps: 1046 | Loss: 48.431220\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:07 | Steps: 1048 | Loss: 48.440370\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:07 | Steps: 1050 | Loss: 48.416676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:07 | Steps: 1052 | Loss: 48.400480\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:07 | Steps: 1054 | Loss: 48.414452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:08 | Steps: 1056 | Loss: 48.376267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:08 | Steps: 1058 | Loss: 48.371461\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:08 | Steps: 1060 | Loss: 48.358539\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:08 | Steps: 1062 | Loss: 48.365390\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:08 | Steps: 1064 | Loss: 48.370739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:08 | Steps: 1065 | Loss: 48.366748\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:08 | Steps: 1067 | Loss: 48.410354\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:08 | Steps: 1069 | Loss: 48.489074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:09 | Steps: 1071 | Loss: 48.513589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:09 | Steps: 1073 | Loss: 48.509154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:09 | Steps: 1074 | Loss: 48.511760\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:09 | Steps: 1076 | Loss: 48.518720\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:09 | Steps: 1078 | Loss: 48.515465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:09 | Steps: 1080 | Loss: 48.512730\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:09 | Steps: 1082 | Loss: 48.529442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:10 | Steps: 1084 | Loss: 48.574349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:10 | Steps: 1086 | Loss: 48.591372\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:10 | Steps: 1087 | Loss: 48.605147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:10 | Steps: 1089 | Loss: 48.644845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:10 | Steps: 1091 | Loss: 48.630766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:10 | Steps: 1093 | Loss: 48.681509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:10 | Steps: 1095 | Loss: 48.693196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:11 | Steps: 1097 | Loss: 48.691638\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:11 | Steps: 1099 | Loss: 48.721529\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:11 | Steps: 1101 | Loss: 48.751983\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:11 | Steps: 1103 | Loss: 48.768629\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:11 | Steps: 1105 | Loss: 48.836574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:11 | Steps: 1107 | Loss: 48.835271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:11 | Steps: 1109 | Loss: 48.832429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:12 | Steps: 1111 | Loss: 48.865349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:12 | Steps: 1113 | Loss: 48.866322\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:12 | Steps: 1115 | Loss: 48.852029\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:12 | Steps: 1117 | Loss: 48.844035\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:12 | Steps: 1119 | Loss: 48.901905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:12 | Steps: 1121 | Loss: 48.974784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:12 | Steps: 1123 | Loss: 49.017966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:13 | Steps: 1125 | Loss: 49.025962\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:13 | Steps: 1127 | Loss: 49.087033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:13 | Steps: 1129 | Loss: 49.113403\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:13 | Steps: 1131 | Loss: 49.122040\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:13 | Steps: 1133 | Loss: 49.120015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:13 | Steps: 1135 | Loss: 49.109895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:14 | Steps: 1137 | Loss: 49.120375\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:14 | Steps: 1139 | Loss: 49.158775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:14 | Steps: 1141 | Loss: 49.208445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:14 | Steps: 1143 | Loss: 49.197714\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:14 | Steps: 1145 | Loss: 49.210700\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:14 | Steps: 1147 | Loss: 49.180696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:14 | Steps: 1149 | Loss: 49.194876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:15 | Steps: 1151 | Loss: 49.164157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:15 | Steps: 1153 | Loss: 49.150489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:15 | Steps: 1154 | Loss: 49.164582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:15 | Steps: 1156 | Loss: 49.171916\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:15 | Steps: 1158 | Loss: 49.195374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:15 | Steps: 1160 | Loss: 49.226387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:15 | Steps: 1162 | Loss: 49.262941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:16 | Steps: 1164 | Loss: 49.314500\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:16 | Steps: 1166 | Loss: 49.332724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:16 | Steps: 1167 | Loss: 49.335785\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:16 | Steps: 1169 | Loss: 49.326801\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:16 | Steps: 1171 | Loss: 49.354958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:16 | Steps: 1173 | Loss: 49.347415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:16 | Steps: 1175 | Loss: 49.355386\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:17 | Steps: 1177 | Loss: 49.423996\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:17 | Steps: 1179 | Loss: 49.465641\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:17 | Steps: 1181 | Loss: 49.478100\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:17 | Steps: 1183 | Loss: 49.481037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:17 | Steps: 1185 | Loss: 49.477350\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:17 | Steps: 1187 | Loss: 49.503955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:17 | Steps: 1189 | Loss: 49.505691\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:18 | Steps: 1191 | Loss: 49.533862\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:18 | Steps: 1193 | Loss: 49.516506\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:18 | Steps: 1195 | Loss: 49.577224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:18 | Steps: 1197 | Loss: 49.619530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:18 | Steps: 1199 | Loss: 49.644398\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:18 | Steps: 1201 | Loss: 49.679099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:19 | Steps: 1203 | Loss: 49.688199\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:19 | Steps: 1205 | Loss: 49.701645\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:19 | Steps: 1207 | Loss: 49.722595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:19 | Steps: 1209 | Loss: 49.732612\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:19 | Steps: 1211 | Loss: 49.801858\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:19 | Steps: 1213 | Loss: 49.861342\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:19 | Steps: 1215 | Loss: 49.917082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:20 | Steps: 1216 | Loss: 49.925419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:20 | Steps: 1218 | Loss: 49.939437\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:20 | Steps: 1220 | Loss: 49.952414\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:20 | Steps: 1222 | Loss: 49.926805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:20 | Steps: 1224 | Loss: 49.917039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:20 | Steps: 1226 | Loss: 49.960280\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:20 | Steps: 1227 | Loss: 49.961378\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:20 | Steps: 1229 | Loss: 49.987141\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:21 | Steps: 1231 | Loss: 49.993457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:21 | Steps: 1233 | Loss: 50.010846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:21 | Steps: 1235 | Loss: 50.002408\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:21 | Steps: 1237 | Loss: 50.045192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:21 | Steps: 1238 | Loss: 50.069768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:21 | Steps: 1240 | Loss: 50.090781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:21 | Steps: 1242 | Loss: 50.096228\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:22 | Steps: 1244 | Loss: 50.127702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:22 | Steps: 1246 | Loss: 50.135599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:22 | Steps: 1248 | Loss: 50.133705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:22 | Steps: 1250 | Loss: 50.110455\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:22 | Steps: 1252 | Loss: 50.115279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:22 | Steps: 1254 | Loss: 50.140434\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:22 | Steps: 1256 | Loss: 50.130865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:23 | Steps: 1258 | Loss: 50.141022\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:23 | Steps: 1260 | Loss: 50.130431\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:23 | Steps: 1262 | Loss: 50.159792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:23 | Steps: 1264 | Loss: 50.160229\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:23 | Steps: 1266 | Loss: 50.170835\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:23 | Steps: 1267 | Loss: 50.181464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:23 | Steps: 1269 | Loss: 50.169694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:24 | Steps: 1271 | Loss: 50.174133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:24 | Steps: 1272 | Loss: 50.174788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:24 | Steps: 1274 | Loss: 50.158862\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:24 | Steps: 1276 | Loss: 50.164217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:24 | Steps: 1278 | Loss: 50.215956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:24 | Steps: 1280 | Loss: 50.237208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:24 | Steps: 1282 | Loss: 50.254504\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:25 | Steps: 1284 | Loss: 50.288678\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:25 | Steps: 1286 | Loss: 50.302734\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:25 | Steps: 1288 | Loss: 50.289509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:25 | Steps: 1290 | Loss: 50.293715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:25 | Steps: 1292 | Loss: 50.336136\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:25 | Steps: 1294 | Loss: 50.339816\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:25 | Steps: 1296 | Loss: 50.410299\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:26 | Steps: 1298 | Loss: 50.445867\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:26 | Steps: 1300 | Loss: 50.435516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:26 | Steps: 1302 | Loss: 50.469247\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:26 | Steps: 1304 | Loss: 50.501185\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:26 | Steps: 1306 | Loss: 50.508157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:26 | Steps: 1308 | Loss: 50.498307\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:27 | Steps: 1310 | Loss: 50.507270\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:27 | Steps: 1312 | Loss: 50.553011\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:27 | Steps: 1314 | Loss: 50.604393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:27 | Steps: 1316 | Loss: 50.614301\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:27 | Steps: 1318 | Loss: 50.620333\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:27 | Steps: 1320 | Loss: 50.592935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:27 | Steps: 1322 | Loss: 50.589808\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:28 | Steps: 1324 | Loss: 50.588564\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:28 | Steps: 1325 | Loss: 50.600677\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:28 | Steps: 1327 | Loss: 50.601423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:28 | Steps: 1329 | Loss: 50.656929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:28 | Steps: 1331 | Loss: 50.639004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:28 | Steps: 1333 | Loss: 50.632025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:28 | Steps: 1335 | Loss: 50.670769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:29 | Steps: 1337 | Loss: 50.726164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:29 | Steps: 1339 | Loss: 50.734607\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:29 | Steps: 1341 | Loss: 50.743579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:29 | Steps: 1343 | Loss: 50.767661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:29 | Steps: 1345 | Loss: 50.790435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:29 | Steps: 1347 | Loss: 50.781067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:29 | Steps: 1349 | Loss: 50.763330\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:30 | Steps: 1351 | Loss: 50.785790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:30 | Steps: 1353 | Loss: 50.780467\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:30 | Steps: 1355 | Loss: 50.786757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:30 | Steps: 1357 | Loss: 50.774559\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:30 | Steps: 1359 | Loss: 50.786315\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:31 | Steps: 1360 | Loss: 50.798316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:31 | Steps: 1362 | Loss: 50.809215\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:31 | Steps: 1364 | Loss: 50.847635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:31 | Steps: 1366 | Loss: 50.898131\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:32 | Steps: 1367 | Loss: 50.901673\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:32 | Steps: 1369 | Loss: 50.958973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:32 | Steps: 1371 | Loss: 50.960168\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:32 | Steps: 1372 | Loss: 50.962419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:32 | Steps: 1373 | Loss: 50.964764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:32 | Steps: 1375 | Loss: 50.970648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:32 | Steps: 1377 | Loss: 50.994188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:33 | Steps: 1379 | Loss: 51.007400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:33 | Steps: 1381 | Loss: 51.035366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:33 | Steps: 1383 | Loss: 51.078457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:33 | Steps: 1385 | Loss: 51.085443\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:33 | Steps: 1387 | Loss: 51.103403\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:33 | Steps: 1389 | Loss: 51.108149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:33 | Steps: 1391 | Loss: 51.141340\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:34 | Steps: 1393 | Loss: 51.156307\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:34 | Steps: 1395 | Loss: 51.162014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:34 | Steps: 1396 | Loss: 51.163431\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:34 | Steps: 1398 | Loss: 51.164442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:34 | Steps: 1399 | Loss: 51.172420\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:34 | Steps: 1401 | Loss: 51.216257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:34 | Steps: 1403 | Loss: 51.184324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:34 | Steps: 1405 | Loss: 51.194894\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:35 | Steps: 1407 | Loss: 51.207404\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:35 | Steps: 1409 | Loss: 51.254230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:35 | Steps: 1410 | Loss: 51.272568\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:35 | Steps: 1412 | Loss: 51.267201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:35 | Steps: 1414 | Loss: 51.271634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:35 | Steps: 1416 | Loss: 51.276922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:35 | Steps: 1418 | Loss: 51.265768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:36 | Steps: 1420 | Loss: 51.281201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:36 | Steps: 1422 | Loss: 51.327082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:36 | Steps: 1424 | Loss: 51.335657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:36 | Steps: 1426 | Loss: 51.341752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:36 | Steps: 1428 | Loss: 51.355264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:36 | Steps: 1430 | Loss: 51.342954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:37 | Steps: 1432 | Loss: 51.384019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:37 | Steps: 1434 | Loss: 51.399755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:37 | Steps: 1436 | Loss: 51.416442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:37 | Steps: 1438 | Loss: 51.438176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:37 | Steps: 1440 | Loss: 51.431136\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:37 | Steps: 1442 | Loss: 51.435386\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:37 | Steps: 1444 | Loss: 51.454675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:37 | Steps: 1446 | Loss: 51.506943\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:38 | Steps: 1448 | Loss: 51.507884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:38 | Steps: 1450 | Loss: 51.518336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:38 | Steps: 1452 | Loss: 51.552176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:38 | Steps: 1454 | Loss: 51.569620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:38 | Steps: 1456 | Loss: 51.575073\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:38 | Steps: 1458 | Loss: 51.567432\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:39 | Steps: 1460 | Loss: 51.568617\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:39 | Steps: 1462 | Loss: 51.581156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:39 | Steps: 1464 | Loss: 51.595472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:39 | Steps: 1466 | Loss: 51.585398\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:39 | Steps: 1468 | Loss: 51.599980\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:39 | Steps: 1469 | Loss: 51.601773\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:39 | Steps: 1471 | Loss: 51.600463\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:40 | Steps: 1473 | Loss: 51.591819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:40 | Steps: 1475 | Loss: 51.594179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:40 | Steps: 1477 | Loss: 51.618961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:40 | Steps: 1479 | Loss: 51.638181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:40 | Steps: 1481 | Loss: 51.653549\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:40 | Steps: 1483 | Loss: 51.679267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:40 | Steps: 1485 | Loss: 51.703256\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:41 | Steps: 1487 | Loss: 51.715418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:41 | Steps: 1489 | Loss: 51.723825\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:41 | Steps: 1491 | Loss: 51.728949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:41 | Steps: 1492 | Loss: 51.736436\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:41 | Steps: 1494 | Loss: 51.745656\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:41 | Steps: 1496 | Loss: 51.773727\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:41 | Steps: 1498 | Loss: 51.784333\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:42 | Steps: 1500 | Loss: 51.815961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:42 | Steps: 1502 | Loss: 51.839781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:42 | Steps: 1503 | Loss: 51.834119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:42 | Steps: 1505 | Loss: 51.832305\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:42 | Steps: 1507 | Loss: 51.861507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:42 | Steps: 1509 | Loss: 51.890038\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:42 | Steps: 1511 | Loss: 51.871246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:43 | Steps: 1513 | Loss: 51.885989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:43 | Steps: 1515 | Loss: 51.882490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:43 | Steps: 1517 | Loss: 51.902310\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:43 | Steps: 1519 | Loss: 51.906265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:43 | Steps: 1521 | Loss: 51.923738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:43 | Steps: 1523 | Loss: 51.927071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:44 | Steps: 1525 | Loss: 51.950411\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:44 | Steps: 1527 | Loss: 51.991222\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:44 | Steps: 1529 | Loss: 52.024576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:44 | Steps: 1531 | Loss: 52.029667\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:44 | Steps: 1533 | Loss: 52.040908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:44 | Steps: 1535 | Loss: 52.044847\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:44 | Steps: 1537 | Loss: 52.052434\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:45 | Steps: 1539 | Loss: 52.050896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:45 | Steps: 1541 | Loss: 52.058643\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:45 | Steps: 1542 | Loss: 52.069318\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:45 | Steps: 1544 | Loss: 52.129569\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:45 | Steps: 1546 | Loss: 52.155298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:45 | Steps: 1548 | Loss: 52.184129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:46 | Steps: 1550 | Loss: 52.198756\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:46 | Steps: 1552 | Loss: 52.207420\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:46 | Steps: 1554 | Loss: 52.195670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:46 | Steps: 1556 | Loss: 52.169876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:46 | Steps: 1558 | Loss: 52.203132\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:46 | Steps: 1560 | Loss: 52.218585\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:46 | Steps: 1561 | Loss: 52.220921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:47 | Steps: 1562 | Loss: 52.215752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:47 | Steps: 1564 | Loss: 52.221597\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:47 | Steps: 1566 | Loss: 52.214466\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:47 | Steps: 1567 | Loss: 52.215852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:47 | Steps: 1569 | Loss: 52.210968\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:47 | Steps: 1571 | Loss: 52.231349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:47 | Steps: 1572 | Loss: 52.253209\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:48 | Steps: 1574 | Loss: 52.279501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:48 | Steps: 1576 | Loss: 52.286207\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:48 | Steps: 1578 | Loss: 52.300444\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:48 | Steps: 1580 | Loss: 52.328401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:48 | Steps: 1582 | Loss: 52.341512\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:48 | Steps: 1584 | Loss: 52.354599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:48 | Steps: 1586 | Loss: 52.347204\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:49 | Steps: 1587 | Loss: 52.338230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:49 | Steps: 1589 | Loss: 52.329539\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:49 | Steps: 1591 | Loss: 52.344227\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:49 | Steps: 1592 | Loss: 52.352923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:49 | Steps: 1594 | Loss: 52.363820\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:49 | Steps: 1596 | Loss: 52.362479\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:49 | Steps: 1598 | Loss: 52.360676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:50 | Steps: 1600 | Loss: 52.365031\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:50 | Steps: 1602 | Loss: 52.380753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:50 | Steps: 1603 | Loss: 52.391888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:50 | Steps: 1605 | Loss: 52.409162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:50 | Steps: 1607 | Loss: 52.443238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:50 | Steps: 1609 | Loss: 52.450365\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:50 | Steps: 1611 | Loss: 52.449446\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:51 | Steps: 1612 | Loss: 52.447452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:51 | Steps: 1613 | Loss: 52.450743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:51 | Steps: 1615 | Loss: 52.436861\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:51 | Steps: 1617 | Loss: 52.440735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:51 | Steps: 1619 | Loss: 52.450610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:51 | Steps: 1621 | Loss: 52.473458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:51 | Steps: 1623 | Loss: 52.505847\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:52 | Steps: 1625 | Loss: 52.506678\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:52 | Steps: 1626 | Loss: 52.512518\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:52 | Steps: 1628 | Loss: 52.517861\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:52 | Steps: 1630 | Loss: 52.522734\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:52 | Steps: 1632 | Loss: 52.544835\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:52 | Steps: 1634 | Loss: 52.567585\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:53 | Steps: 1636 | Loss: 52.600387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:53 | Steps: 1638 | Loss: 52.621299\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:53 | Steps: 1640 | Loss: 52.665511\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:53 | Steps: 1642 | Loss: 52.666353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:53 | Steps: 1644 | Loss: 52.696949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:53 | Steps: 1646 | Loss: 52.708023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:53 | Steps: 1648 | Loss: 52.716157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:54 | Steps: 1650 | Loss: 52.709666\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:54 | Steps: 1652 | Loss: 52.705077\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:54 | Steps: 1654 | Loss: 52.701713\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:54 | Steps: 1656 | Loss: 52.731514\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:54 | Steps: 1657 | Loss: 52.756623\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:54 | Steps: 1659 | Loss: 52.800553\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:55 | Steps: 1661 | Loss: 52.839868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:55 | Steps: 1663 | Loss: 52.852576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:55 | Steps: 1665 | Loss: 52.858902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:55 | Steps: 1667 | Loss: 52.851008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:55 | Steps: 1669 | Loss: 52.914451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:55 | Steps: 1671 | Loss: 52.899447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:55 | Steps: 1673 | Loss: 52.904950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:56 | Steps: 1675 | Loss: 52.904400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:56 | Steps: 1677 | Loss: 52.909290\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:56 | Steps: 1679 | Loss: 52.913332\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:56 | Steps: 1681 | Loss: 52.904979\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:56 | Steps: 1683 | Loss: 52.921374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:56 | Steps: 1685 | Loss: 52.957729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:57 | Steps: 1687 | Loss: 52.983991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:57 | Steps: 1689 | Loss: 53.000279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:57 | Steps: 1691 | Loss: 53.025075\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:57 | Steps: 1693 | Loss: 53.058628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:57 | Steps: 1694 | Loss: 53.065037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:57 | Steps: 1696 | Loss: 53.058530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:57 | Steps: 1698 | Loss: 53.058074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:58 | Steps: 1700 | Loss: 53.091436\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:58 | Steps: 1702 | Loss: 53.109746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:58 | Steps: 1703 | Loss: 53.128791\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:58 | Steps: 1705 | Loss: 53.117076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:58 | Steps: 1707 | Loss: 53.108715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:58 | Steps: 1709 | Loss: 53.098221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:58 | Steps: 1711 | Loss: 53.107468\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:59 | Steps: 1713 | Loss: 53.106758\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:59 | Steps: 1715 | Loss: 53.137519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:59 | Steps: 1717 | Loss: 53.133550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:59 | Steps: 1719 | Loss: 53.175764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:59 | Steps: 1721 | Loss: 53.234466\n",
      "Epoch 1 |   Training | Elapsed Time: 0:01:59 | Steps: 1723 | Loss: 53.244716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:00 | Steps: 1725 | Loss: 53.267893\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:00 | Steps: 1727 | Loss: 53.309942\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:00 | Steps: 1729 | Loss: 53.338393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:00 | Steps: 1731 | Loss: 53.337241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:00 | Steps: 1733 | Loss: 53.342264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:00 | Steps: 1735 | Loss: 53.344078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:00 | Steps: 1737 | Loss: 53.360880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:01 | Steps: 1739 | Loss: 53.388293\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:01 | Steps: 1741 | Loss: 53.414208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:01 | Steps: 1743 | Loss: 53.435700\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:01 | Steps: 1745 | Loss: 53.457356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:01 | Steps: 1747 | Loss: 53.455603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:01 | Steps: 1749 | Loss: 53.478525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:02 | Steps: 1751 | Loss: 53.500280\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:02 | Steps: 1753 | Loss: 53.494581\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:02 | Steps: 1755 | Loss: 53.535682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:02 | Steps: 1756 | Loss: 53.543387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:02 | Steps: 1758 | Loss: 53.546074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:02 | Steps: 1760 | Loss: 53.568495\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:03 | Steps: 1762 | Loss: 53.607695\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:03 | Steps: 1764 | Loss: 53.626670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:03 | Steps: 1765 | Loss: 53.634610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:03 | Steps: 1767 | Loss: 53.645577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:03 | Steps: 1768 | Loss: 53.654464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:03 | Steps: 1769 | Loss: 53.655960\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:03 | Steps: 1770 | Loss: 53.650955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:03 | Steps: 1772 | Loss: 53.696829\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:04 | Steps: 1774 | Loss: 53.723582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:04 | Steps: 1776 | Loss: 53.744122\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:04 | Steps: 1778 | Loss: 53.768569\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:04 | Steps: 1780 | Loss: 53.773996\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:04 | Steps: 1782 | Loss: 53.786139\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:04 | Steps: 1784 | Loss: 53.789496\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:05 | Steps: 1785 | Loss: 53.786509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:05 | Steps: 1787 | Loss: 53.786941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:05 | Steps: 1789 | Loss: 53.815585\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:05 | Steps: 1790 | Loss: 53.841776\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:05 | Steps: 1792 | Loss: 53.875464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:05 | Steps: 1794 | Loss: 53.888714\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:05 | Steps: 1796 | Loss: 53.924076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:06 | Steps: 1797 | Loss: 53.927948\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:06 | Steps: 1799 | Loss: 53.945027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:06 | Steps: 1801 | Loss: 53.959944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:06 | Steps: 1803 | Loss: 53.959260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:06 | Steps: 1805 | Loss: 53.958491\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:06 | Steps: 1807 | Loss: 53.984001\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:07 | Steps: 1808 | Loss: 53.992094\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:07 | Steps: 1810 | Loss: 54.005048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:07 | Steps: 1812 | Loss: 53.998913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:07 | Steps: 1813 | Loss: 53.999235\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:07 | Steps: 1815 | Loss: 53.991130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:07 | Steps: 1816 | Loss: 53.992821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:07 | Steps: 1818 | Loss: 53.999823\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:08 | Steps: 1819 | Loss: 54.013914\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:08 | Steps: 1821 | Loss: 54.052344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:08 | Steps: 1822 | Loss: 54.061164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:08 | Steps: 1823 | Loss: 54.061584\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:08 | Steps: 1825 | Loss: 54.053574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:08 | Steps: 1827 | Loss: 54.092784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:08 | Steps: 1829 | Loss: 54.098794\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:09 | Steps: 1831 | Loss: 54.104591\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:09 | Steps: 1833 | Loss: 54.086919\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:09 | Steps: 1835 | Loss: 54.085094\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:09 | Steps: 1837 | Loss: 54.092975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:09 | Steps: 1839 | Loss: 54.068805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:09 | Steps: 1841 | Loss: 54.060017\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:10 | Steps: 1843 | Loss: 54.058076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:10 | Steps: 1845 | Loss: 54.060060\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:10 | Steps: 1847 | Loss: 54.060927\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:10 | Steps: 1849 | Loss: 54.085688\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:10 | Steps: 1851 | Loss: 54.088295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:10 | Steps: 1853 | Loss: 54.122700\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:10 | Steps: 1855 | Loss: 54.140546\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:11 | Steps: 1857 | Loss: 54.141147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:11 | Steps: 1859 | Loss: 54.158090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:11 | Steps: 1861 | Loss: 54.191809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:11 | Steps: 1863 | Loss: 54.194982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:11 | Steps: 1864 | Loss: 54.194574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:11 | Steps: 1865 | Loss: 54.190998\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:11 | Steps: 1867 | Loss: 54.192989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:12 | Steps: 1869 | Loss: 54.201806\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:12 | Steps: 1871 | Loss: 54.214349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:12 | Steps: 1873 | Loss: 54.259019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:12 | Steps: 1875 | Loss: 54.274762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:12 | Steps: 1877 | Loss: 54.290555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:12 | Steps: 1878 | Loss: 54.292967\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:13 | Steps: 1880 | Loss: 54.287115\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:13 | Steps: 1881 | Loss: 54.304503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:13 | Steps: 1882 | Loss: 54.329975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:13 | Steps: 1883 | Loss: 54.338691\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:13 | Steps: 1884 | Loss: 54.332335\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:13 | Steps: 1885 | Loss: 54.331618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:13 | Steps: 1887 | Loss: 54.358142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:14 | Steps: 1888 | Loss: 54.353465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:14 | Steps: 1889 | Loss: 54.349742\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:14 | Steps: 1890 | Loss: 54.351588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:14 | Steps: 1891 | Loss: 54.362947\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:14 | Steps: 1893 | Loss: 54.365708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:14 | Steps: 1894 | Loss: 54.370175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:14 | Steps: 1895 | Loss: 54.380979\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:15 | Steps: 1897 | Loss: 54.396145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:15 | Steps: 1899 | Loss: 54.389898\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:15 | Steps: 1901 | Loss: 54.435880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:15 | Steps: 1903 | Loss: 54.454824\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:15 | Steps: 1904 | Loss: 54.468309\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:15 | Steps: 1905 | Loss: 54.484123\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:15 | Steps: 1906 | Loss: 54.488353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:16 | Steps: 1908 | Loss: 54.520996\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:16 | Steps: 1909 | Loss: 54.522102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:16 | Steps: 1911 | Loss: 54.554476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:16 | Steps: 1912 | Loss: 54.553335\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:16 | Steps: 1914 | Loss: 54.562551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:16 | Steps: 1915 | Loss: 54.561121\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:16 | Steps: 1917 | Loss: 54.559579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:16 | Steps: 1919 | Loss: 54.559023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:17 | Steps: 1921 | Loss: 54.574506\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:17 | Steps: 1923 | Loss: 54.627241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:17 | Steps: 1925 | Loss: 54.636940\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:17 | Steps: 1927 | Loss: 54.677967\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:17 | Steps: 1929 | Loss: 54.705189\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:17 | Steps: 1931 | Loss: 54.709184\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:18 | Steps: 1933 | Loss: 54.715024\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:18 | Steps: 1935 | Loss: 54.700661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:18 | Steps: 1937 | Loss: 54.728629\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:18 | Steps: 1939 | Loss: 54.736754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:18 | Steps: 1941 | Loss: 54.742907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:18 | Steps: 1943 | Loss: 54.744262\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:18 | Steps: 1945 | Loss: 54.765508\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:19 | Steps: 1947 | Loss: 54.760369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:19 | Steps: 1949 | Loss: 54.747680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:19 | Steps: 1951 | Loss: 54.759366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:19 | Steps: 1953 | Loss: 54.770793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:19 | Steps: 1955 | Loss: 54.800312\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:19 | Steps: 1956 | Loss: 54.801966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:19 | Steps: 1957 | Loss: 54.803869\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:20 | Steps: 1959 | Loss: 54.818665\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:20 | Steps: 1961 | Loss: 54.830751\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:20 | Steps: 1963 | Loss: 54.845418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:20 | Steps: 1965 | Loss: 54.854710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:20 | Steps: 1967 | Loss: 54.844613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:20 | Steps: 1969 | Loss: 54.831618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:20 | Steps: 1971 | Loss: 54.841522\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:21 | Steps: 1973 | Loss: 54.877013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:21 | Steps: 1974 | Loss: 54.883042\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:21 | Steps: 1976 | Loss: 54.874189\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:21 | Steps: 1978 | Loss: 54.890192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:21 | Steps: 1980 | Loss: 54.886895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:21 | Steps: 1982 | Loss: 54.882403\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:22 | Steps: 1984 | Loss: 54.889937\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:22 | Steps: 1986 | Loss: 54.903075\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:22 | Steps: 1988 | Loss: 54.942915\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:22 | Steps: 1990 | Loss: 54.978245\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:22 | Steps: 1992 | Loss: 55.000544\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:22 | Steps: 1994 | Loss: 54.989886\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:22 | Steps: 1996 | Loss: 54.992285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:23 | Steps: 1998 | Loss: 54.991626\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:23 | Steps: 1999 | Loss: 55.000777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:23 | Steps: 2001 | Loss: 55.026780\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:23 | Steps: 2003 | Loss: 55.040262\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:23 | Steps: 2005 | Loss: 55.068961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:23 | Steps: 2007 | Loss: 55.089263\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:24 | Steps: 2009 | Loss: 55.106776\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:24 | Steps: 2011 | Loss: 55.117492\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:24 | Steps: 2013 | Loss: 55.128699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:24 | Steps: 2014 | Loss: 55.149774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:24 | Steps: 2016 | Loss: 55.142762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:24 | Steps: 2018 | Loss: 55.167447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:24 | Steps: 2020 | Loss: 55.157397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:25 | Steps: 2022 | Loss: 55.164558\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:25 | Steps: 2024 | Loss: 55.159323\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:25 | Steps: 2025 | Loss: 55.168603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:25 | Steps: 2027 | Loss: 55.188596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:25 | Steps: 2029 | Loss: 55.197259\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:25 | Steps: 2031 | Loss: 55.206086\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:25 | Steps: 2032 | Loss: 55.213445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:26 | Steps: 2034 | Loss: 55.229599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:26 | Steps: 2036 | Loss: 55.223863\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:26 | Steps: 2037 | Loss: 55.227714\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:26 | Steps: 2039 | Loss: 55.254265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:26 | Steps: 2040 | Loss: 55.272816\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:26 | Steps: 2042 | Loss: 55.305284\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:27 | Steps: 2043 | Loss: 55.313791\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:27 | Steps: 2044 | Loss: 55.306911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:27 | Steps: 2045 | Loss: 55.314855\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:27 | Steps: 2046 | Loss: 55.321548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:27 | Steps: 2048 | Loss: 55.323917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:27 | Steps: 2050 | Loss: 55.327089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:28 | Steps: 2052 | Loss: 55.326116\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:28 | Steps: 2054 | Loss: 55.321472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:28 | Steps: 2055 | Loss: 55.324003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:28 | Steps: 2057 | Loss: 55.320915\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:28 | Steps: 2059 | Loss: 55.348718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:28 | Steps: 2061 | Loss: 55.394866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:28 | Steps: 2063 | Loss: 55.410521\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:29 | Steps: 2065 | Loss: 55.434715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:29 | Steps: 2067 | Loss: 55.456506\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:29 | Steps: 2069 | Loss: 55.462022\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:29 | Steps: 2071 | Loss: 55.449805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:29 | Steps: 2073 | Loss: 55.454243\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:29 | Steps: 2075 | Loss: 55.459253\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:30 | Steps: 2077 | Loss: 55.467234\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:30 | Steps: 2079 | Loss: 55.472329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:30 | Steps: 2081 | Loss: 55.470673\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:30 | Steps: 2082 | Loss: 55.459555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:30 | Steps: 2084 | Loss: 55.470366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:30 | Steps: 2086 | Loss: 55.500181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:30 | Steps: 2087 | Loss: 55.520450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:30 | Steps: 2089 | Loss: 55.553983\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:31 | Steps: 2091 | Loss: 55.550781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:31 | Steps: 2093 | Loss: 55.567922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:31 | Steps: 2095 | Loss: 55.596683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:31 | Steps: 2097 | Loss: 55.619166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:31 | Steps: 2099 | Loss: 55.622863\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:31 | Steps: 2101 | Loss: 55.614550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:32 | Steps: 2103 | Loss: 55.604507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:32 | Steps: 2105 | Loss: 55.594959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:32 | Steps: 2106 | Loss: 55.606154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:32 | Steps: 2108 | Loss: 55.627545\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:32 | Steps: 2109 | Loss: 55.629409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:32 | Steps: 2111 | Loss: 55.632438\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:32 | Steps: 2113 | Loss: 55.628120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:32 | Steps: 2115 | Loss: 55.632152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:33 | Steps: 2117 | Loss: 55.650251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:33 | Steps: 2119 | Loss: 55.661352\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:33 | Steps: 2121 | Loss: 55.659540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:33 | Steps: 2123 | Loss: 55.683873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:33 | Steps: 2125 | Loss: 55.710347\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:33 | Steps: 2127 | Loss: 55.737059\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:34 | Steps: 2128 | Loss: 55.753135\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:34 | Steps: 2130 | Loss: 55.765045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:34 | Steps: 2131 | Loss: 55.773678\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:34 | Steps: 2132 | Loss: 55.771802\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:34 | Steps: 2133 | Loss: 55.775878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:34 | Steps: 2134 | Loss: 55.776131\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:35 | Steps: 2136 | Loss: 55.774265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:35 | Steps: 2137 | Loss: 55.782429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:35 | Steps: 2138 | Loss: 55.790174\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:35 | Steps: 2140 | Loss: 55.796944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:35 | Steps: 2142 | Loss: 55.815717\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:35 | Steps: 2144 | Loss: 55.830423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:35 | Steps: 2146 | Loss: 55.852808\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:36 | Steps: 2148 | Loss: 55.853193\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:36 | Steps: 2150 | Loss: 55.857233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:36 | Steps: 2152 | Loss: 55.867709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:36 | Steps: 2154 | Loss: 55.862110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:36 | Steps: 2156 | Loss: 55.889580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:36 | Steps: 2158 | Loss: 55.886144\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:37 | Steps: 2160 | Loss: 55.884809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:37 | Steps: 2162 | Loss: 55.900267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:37 | Steps: 2164 | Loss: 55.927173\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:37 | Steps: 2166 | Loss: 55.964914\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:37 | Steps: 2168 | Loss: 55.974744\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:37 | Steps: 2169 | Loss: 56.008592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:37 | Steps: 2171 | Loss: 56.006834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:38 | Steps: 2172 | Loss: 56.009365\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:38 | Steps: 2174 | Loss: 56.013759\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:38 | Steps: 2176 | Loss: 56.004779\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:38 | Steps: 2178 | Loss: 56.006381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:38 | Steps: 2180 | Loss: 56.020852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:38 | Steps: 2182 | Loss: 56.051765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:39 | Steps: 2184 | Loss: 56.078459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:39 | Steps: 2186 | Loss: 56.105501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:39 | Steps: 2188 | Loss: 56.114745\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:39 | Steps: 2190 | Loss: 56.134490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:39 | Steps: 2192 | Loss: 56.114266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:39 | Steps: 2194 | Loss: 56.119240\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:39 | Steps: 2195 | Loss: 56.129527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:40 | Steps: 2197 | Loss: 56.133010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:40 | Steps: 2199 | Loss: 56.141875\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:40 | Steps: 2201 | Loss: 56.152403\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:40 | Steps: 2203 | Loss: 56.154297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:40 | Steps: 2205 | Loss: 56.150689\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:40 | Steps: 2207 | Loss: 56.150011\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:40 | Steps: 2209 | Loss: 56.182210\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:41 | Steps: 2211 | Loss: 56.197991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:41 | Steps: 2213 | Loss: 56.199754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:41 | Steps: 2215 | Loss: 56.211922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:41 | Steps: 2217 | Loss: 56.220417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:41 | Steps: 2219 | Loss: 56.229057\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:41 | Steps: 2220 | Loss: 56.221392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:42 | Steps: 2222 | Loss: 56.201562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:42 | Steps: 2223 | Loss: 56.197881\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:42 | Steps: 2225 | Loss: 56.197487\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:42 | Steps: 2227 | Loss: 56.210224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:42 | Steps: 2229 | Loss: 56.219632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:42 | Steps: 2231 | Loss: 56.214394\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:42 | Steps: 2233 | Loss: 56.216447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:42 | Steps: 2234 | Loss: 56.210356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:43 | Steps: 2236 | Loss: 56.209202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:43 | Steps: 2238 | Loss: 56.204457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:43 | Steps: 2240 | Loss: 56.195475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:43 | Steps: 2241 | Loss: 56.202394\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:43 | Steps: 2243 | Loss: 56.232778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:43 | Steps: 2245 | Loss: 56.244676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:44 | Steps: 2247 | Loss: 56.241791\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:44 | Steps: 2249 | Loss: 56.258490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:44 | Steps: 2251 | Loss: 56.278725\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:44 | Steps: 2253 | Loss: 56.280111\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:44 | Steps: 2255 | Loss: 56.292896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:44 | Steps: 2257 | Loss: 56.305319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:44 | Steps: 2259 | Loss: 56.293401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:45 | Steps: 2261 | Loss: 56.306566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:45 | Steps: 2263 | Loss: 56.303660\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:45 | Steps: 2265 | Loss: 56.315696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:45 | Steps: 2267 | Loss: 56.324617\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:45 | Steps: 2269 | Loss: 56.326324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:45 | Steps: 2271 | Loss: 56.330749\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:46 | Steps: 2273 | Loss: 56.381715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:46 | Steps: 2275 | Loss: 56.390273\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:46 | Steps: 2277 | Loss: 56.398471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:46 | Steps: 2279 | Loss: 56.404548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:46 | Steps: 2281 | Loss: 56.414565\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:46 | Steps: 2283 | Loss: 56.419405\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:47 | Steps: 2285 | Loss: 56.424515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:47 | Steps: 2286 | Loss: 56.418200\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:47 | Steps: 2288 | Loss: 56.458207\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:47 | Steps: 2289 | Loss: 56.482532\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:47 | Steps: 2290 | Loss: 56.481208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:47 | Steps: 2291 | Loss: 56.494078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:47 | Steps: 2292 | Loss: 56.497526\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:48 | Steps: 2293 | Loss: 56.501000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:48 | Steps: 2294 | Loss: 56.511306\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:48 | Steps: 2296 | Loss: 56.522188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:48 | Steps: 2297 | Loss: 56.533741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:48 | Steps: 2298 | Loss: 56.525480\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:48 | Steps: 2299 | Loss: 56.533412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:48 | Steps: 2300 | Loss: 56.561183\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:49 | Steps: 2301 | Loss: 56.574230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:49 | Steps: 2303 | Loss: 56.573378\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:49 | Steps: 2305 | Loss: 56.599351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:49 | Steps: 2306 | Loss: 56.622534\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:49 | Steps: 2308 | Loss: 56.634234\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:49 | Steps: 2310 | Loss: 56.633808\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:49 | Steps: 2312 | Loss: 56.634724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:50 | Steps: 2314 | Loss: 56.634640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:50 | Steps: 2316 | Loss: 56.640963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:50 | Steps: 2318 | Loss: 56.629151\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:50 | Steps: 2320 | Loss: 56.641528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:50 | Steps: 2321 | Loss: 56.638649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:50 | Steps: 2323 | Loss: 56.636617\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:51 | Steps: 2325 | Loss: 56.664152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:51 | Steps: 2327 | Loss: 56.691305\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:51 | Steps: 2328 | Loss: 56.693042\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:51 | Steps: 2330 | Loss: 56.714623\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:51 | Steps: 2332 | Loss: 56.734285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:51 | Steps: 2334 | Loss: 56.732391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:52 | Steps: 2336 | Loss: 56.737980\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:52 | Steps: 2338 | Loss: 56.725208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:52 | Steps: 2340 | Loss: 56.716379\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:52 | Steps: 2341 | Loss: 56.708392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:52 | Steps: 2342 | Loss: 56.707130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:52 | Steps: 2343 | Loss: 56.699580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:52 | Steps: 2345 | Loss: 56.706045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:52 | Steps: 2346 | Loss: 56.703987\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:53 | Steps: 2348 | Loss: 56.709016\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:53 | Steps: 2350 | Loss: 56.715772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:53 | Steps: 2352 | Loss: 56.719378\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:53 | Steps: 2354 | Loss: 56.718483\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:53 | Steps: 2355 | Loss: 56.718513\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:53 | Steps: 2357 | Loss: 56.723244\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:53 | Steps: 2359 | Loss: 56.729285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:54 | Steps: 2360 | Loss: 56.747467\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:54 | Steps: 2362 | Loss: 56.778532\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:54 | Steps: 2364 | Loss: 56.794838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:54 | Steps: 2366 | Loss: 56.792083\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:54 | Steps: 2367 | Loss: 56.801997\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:54 | Steps: 2369 | Loss: 56.810067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:55 | Steps: 2371 | Loss: 56.812959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:55 | Steps: 2373 | Loss: 56.805974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:55 | Steps: 2375 | Loss: 56.799032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:55 | Steps: 2377 | Loss: 56.787353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:55 | Steps: 2379 | Loss: 56.801154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:55 | Steps: 2380 | Loss: 56.806063\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:55 | Steps: 2382 | Loss: 56.808183\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:56 | Steps: 2384 | Loss: 56.802953\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:56 | Steps: 2386 | Loss: 56.802452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:56 | Steps: 2388 | Loss: 56.801257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:56 | Steps: 2389 | Loss: 56.799929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:56 | Steps: 2391 | Loss: 56.820343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:56 | Steps: 2393 | Loss: 56.817564\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:57 | Steps: 2395 | Loss: 56.844595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:57 | Steps: 2397 | Loss: 56.876938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:57 | Steps: 2399 | Loss: 56.897527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:57 | Steps: 2401 | Loss: 56.901214\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:57 | Steps: 2403 | Loss: 56.888418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:57 | Steps: 2404 | Loss: 56.889346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:57 | Steps: 2406 | Loss: 56.887622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:58 | Steps: 2408 | Loss: 56.887995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:58 | Steps: 2409 | Loss: 56.889665\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:58 | Steps: 2411 | Loss: 56.903140\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:58 | Steps: 2413 | Loss: 56.908490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:58 | Steps: 2415 | Loss: 56.918714\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:58 | Steps: 2417 | Loss: 56.925559\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:59 | Steps: 2419 | Loss: 56.937334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:59 | Steps: 2421 | Loss: 56.968953\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:59 | Steps: 2423 | Loss: 56.982058\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:59 | Steps: 2425 | Loss: 57.005027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:59 | Steps: 2427 | Loss: 57.010620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:02:59 | Steps: 2429 | Loss: 57.021479\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:00 | Steps: 2430 | Loss: 57.018142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:00 | Steps: 2432 | Loss: 57.024439\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:00 | Steps: 2434 | Loss: 57.051206\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:00 | Steps: 2436 | Loss: 57.074190\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:00 | Steps: 2438 | Loss: 57.088178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:00 | Steps: 2439 | Loss: 57.102261\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:00 | Steps: 2440 | Loss: 57.108905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:01 | Steps: 2442 | Loss: 57.125664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:01 | Steps: 2444 | Loss: 57.128989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:01 | Steps: 2446 | Loss: 57.143645\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:01 | Steps: 2447 | Loss: 57.160036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:01 | Steps: 2449 | Loss: 57.173380\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:01 | Steps: 2451 | Loss: 57.183622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:01 | Steps: 2452 | Loss: 57.178020\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:02 | Steps: 2454 | Loss: 57.187279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:02 | Steps: 2455 | Loss: 57.192736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:02 | Steps: 2457 | Loss: 57.195428\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:02 | Steps: 2459 | Loss: 57.195043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:02 | Steps: 2461 | Loss: 57.201094\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:02 | Steps: 2463 | Loss: 57.214621\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:03 | Steps: 2464 | Loss: 57.212873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:03 | Steps: 2466 | Loss: 57.232028\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:03 | Steps: 2467 | Loss: 57.246389\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:03 | Steps: 2468 | Loss: 57.258902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:03 | Steps: 2469 | Loss: 57.264230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:03 | Steps: 2471 | Loss: 57.292032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:03 | Steps: 2472 | Loss: 57.316335\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:04 | Steps: 2474 | Loss: 57.342034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:04 | Steps: 2476 | Loss: 57.346485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:04 | Steps: 2478 | Loss: 57.345614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:04 | Steps: 2480 | Loss: 57.360304\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:04 | Steps: 2482 | Loss: 57.344571\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:04 | Steps: 2484 | Loss: 57.331882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:05 | Steps: 2486 | Loss: 57.322847\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:05 | Steps: 2488 | Loss: 57.337339\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:05 | Steps: 2490 | Loss: 57.339377\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:05 | Steps: 2492 | Loss: 57.342754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:05 | Steps: 2494 | Loss: 57.342691\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:05 | Steps: 2495 | Loss: 57.349201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:06 | Steps: 2497 | Loss: 57.354734\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:06 | Steps: 2499 | Loss: 57.347530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:06 | Steps: 2501 | Loss: 57.344696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:06 | Steps: 2503 | Loss: 57.367184\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:06 | Steps: 2504 | Loss: 57.377401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:06 | Steps: 2506 | Loss: 57.419193\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:06 | Steps: 2508 | Loss: 57.419758\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:07 | Steps: 2510 | Loss: 57.430089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:07 | Steps: 2512 | Loss: 57.431035\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:07 | Steps: 2513 | Loss: 57.442485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:07 | Steps: 2515 | Loss: 57.451859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:07 | Steps: 2517 | Loss: 57.445214\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:07 | Steps: 2518 | Loss: 57.447255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:07 | Steps: 2520 | Loss: 57.438761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:08 | Steps: 2521 | Loss: 57.442086\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:08 | Steps: 2523 | Loss: 57.464421\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:08 | Steps: 2525 | Loss: 57.456810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:08 | Steps: 2526 | Loss: 57.451008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:08 | Steps: 2528 | Loss: 57.446106\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:08 | Steps: 2530 | Loss: 57.449782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:08 | Steps: 2532 | Loss: 57.453270\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:09 | Steps: 2533 | Loss: 57.458211\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:09 | Steps: 2535 | Loss: 57.472724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:09 | Steps: 2537 | Loss: 57.481349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:09 | Steps: 2539 | Loss: 57.485780\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:09 | Steps: 2541 | Loss: 57.499053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:09 | Steps: 2542 | Loss: 57.497116\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:09 | Steps: 2544 | Loss: 57.498027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:10 | Steps: 2546 | Loss: 57.503286\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:10 | Steps: 2548 | Loss: 57.495096\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:10 | Steps: 2550 | Loss: 57.511612\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:10 | Steps: 2552 | Loss: 57.511076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:10 | Steps: 2553 | Loss: 57.511284\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:10 | Steps: 2555 | Loss: 57.514521\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:11 | Steps: 2557 | Loss: 57.532189\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:11 | Steps: 2559 | Loss: 57.534273\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:11 | Steps: 2561 | Loss: 57.556653\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:11 | Steps: 2563 | Loss: 57.552400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:11 | Steps: 2564 | Loss: 57.556072\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:11 | Steps: 2566 | Loss: 57.564329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:11 | Steps: 2568 | Loss: 57.566731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:12 | Steps: 2570 | Loss: 57.591647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:12 | Steps: 2572 | Loss: 57.611977\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:12 | Steps: 2574 | Loss: 57.608799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:12 | Steps: 2576 | Loss: 57.621670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:12 | Steps: 2577 | Loss: 57.629599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:12 | Steps: 2579 | Loss: 57.624637\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:13 | Steps: 2580 | Loss: 57.624659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:13 | Steps: 2582 | Loss: 57.623270\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:13 | Steps: 2584 | Loss: 57.658465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:13 | Steps: 2586 | Loss: 57.678739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:13 | Steps: 2588 | Loss: 57.692223\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:13 | Steps: 2590 | Loss: 57.692464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:13 | Steps: 2591 | Loss: 57.708501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:14 | Steps: 2593 | Loss: 57.720686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:14 | Steps: 2594 | Loss: 57.721172\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:14 | Steps: 2596 | Loss: 57.717852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:14 | Steps: 2598 | Loss: 57.734994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:14 | Steps: 2599 | Loss: 57.737928\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:14 | Steps: 2601 | Loss: 57.741106\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:14 | Steps: 2603 | Loss: 57.743896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:15 | Steps: 2605 | Loss: 57.743280\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:15 | Steps: 2607 | Loss: 57.742717\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:15 | Steps: 2609 | Loss: 57.748308\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:15 | Steps: 2611 | Loss: 57.743765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:15 | Steps: 2612 | Loss: 57.743952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:15 | Steps: 2613 | Loss: 57.746834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:15 | Steps: 2614 | Loss: 57.758304\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:16 | Steps: 2616 | Loss: 57.767947\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:16 | Steps: 2618 | Loss: 57.781356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:16 | Steps: 2620 | Loss: 57.803064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:16 | Steps: 2622 | Loss: 57.811119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:16 | Steps: 2624 | Loss: 57.821139\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:16 | Steps: 2626 | Loss: 57.830157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:17 | Steps: 2627 | Loss: 57.830353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:17 | Steps: 2629 | Loss: 57.832978\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:17 | Steps: 2631 | Loss: 57.821475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:17 | Steps: 2633 | Loss: 57.863472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:17 | Steps: 2634 | Loss: 57.860290\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:17 | Steps: 2636 | Loss: 57.861343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:17 | Steps: 2638 | Loss: 57.866704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:18 | Steps: 2640 | Loss: 57.873758\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:18 | Steps: 2642 | Loss: 57.884068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:18 | Steps: 2644 | Loss: 57.886525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:18 | Steps: 2646 | Loss: 57.890867\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:18 | Steps: 2648 | Loss: 57.894970\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:18 | Steps: 2650 | Loss: 57.897303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:19 | Steps: 2652 | Loss: 57.905884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:19 | Steps: 2654 | Loss: 57.924805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:19 | Steps: 2655 | Loss: 57.932613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:19 | Steps: 2657 | Loss: 57.931519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:19 | Steps: 2659 | Loss: 57.932589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:19 | Steps: 2661 | Loss: 57.929854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:19 | Steps: 2662 | Loss: 57.932956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:20 | Steps: 2664 | Loss: 57.941240\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:20 | Steps: 2665 | Loss: 57.943403\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:20 | Steps: 2667 | Loss: 57.962091\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:20 | Steps: 2669 | Loss: 57.956157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:20 | Steps: 2670 | Loss: 57.950930\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:20 | Steps: 2672 | Loss: 57.950716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:20 | Steps: 2674 | Loss: 57.945168\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:21 | Steps: 2675 | Loss: 57.950147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:21 | Steps: 2676 | Loss: 57.961934\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:21 | Steps: 2677 | Loss: 57.967346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:21 | Steps: 2678 | Loss: 57.971525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:21 | Steps: 2680 | Loss: 57.972121\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:21 | Steps: 2682 | Loss: 57.971090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:21 | Steps: 2684 | Loss: 57.968620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:22 | Steps: 2686 | Loss: 57.960213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:22 | Steps: 2688 | Loss: 57.954635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:22 | Steps: 2690 | Loss: 57.946972\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:22 | Steps: 2692 | Loss: 57.949339\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:22 | Steps: 2694 | Loss: 57.955688\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:22 | Steps: 2696 | Loss: 57.957236\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:23 | Steps: 2697 | Loss: 57.963104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:23 | Steps: 2699 | Loss: 57.972779\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:23 | Steps: 2700 | Loss: 57.973207\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:23 | Steps: 2702 | Loss: 57.971784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:23 | Steps: 2704 | Loss: 57.998045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:23 | Steps: 2706 | Loss: 58.021099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:24 | Steps: 2708 | Loss: 58.021775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:24 | Steps: 2709 | Loss: 58.036848\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:24 | Steps: 2711 | Loss: 58.061515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:24 | Steps: 2713 | Loss: 58.060359\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:24 | Steps: 2714 | Loss: 58.054579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:24 | Steps: 2716 | Loss: 58.063735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:24 | Steps: 2717 | Loss: 58.063760\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:25 | Steps: 2719 | Loss: 58.061189\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:25 | Steps: 2721 | Loss: 58.082674\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:25 | Steps: 2723 | Loss: 58.090546\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:25 | Steps: 2725 | Loss: 58.116885\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:25 | Steps: 2727 | Loss: 58.123640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:25 | Steps: 2729 | Loss: 58.133515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:26 | Steps: 2730 | Loss: 58.138846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:26 | Steps: 2732 | Loss: 58.158240\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:26 | Steps: 2734 | Loss: 58.165321\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:26 | Steps: 2736 | Loss: 58.155374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:26 | Steps: 2738 | Loss: 58.165152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:26 | Steps: 2740 | Loss: 58.172644\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:27 | Steps: 2741 | Loss: 58.171949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:27 | Steps: 2743 | Loss: 58.181959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:27 | Steps: 2744 | Loss: 58.193154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:27 | Steps: 2746 | Loss: 58.205151\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:27 | Steps: 2748 | Loss: 58.188618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:27 | Steps: 2749 | Loss: 58.191416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:27 | Steps: 2751 | Loss: 58.220298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:28 | Steps: 2753 | Loss: 58.231046\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:28 | Steps: 2755 | Loss: 58.244298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:28 | Steps: 2757 | Loss: 58.275350\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:28 | Steps: 2759 | Loss: 58.292972\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:28 | Steps: 2761 | Loss: 58.309563\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:28 | Steps: 2763 | Loss: 58.307092\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:29 | Steps: 2764 | Loss: 58.312884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:29 | Steps: 2766 | Loss: 58.308149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:29 | Steps: 2768 | Loss: 58.304763\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:29 | Steps: 2770 | Loss: 58.304853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:29 | Steps: 2772 | Loss: 58.301724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:29 | Steps: 2774 | Loss: 58.330543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:30 | Steps: 2776 | Loss: 58.360782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:30 | Steps: 2778 | Loss: 58.370801\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:30 | Steps: 2780 | Loss: 58.380197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:30 | Steps: 2782 | Loss: 58.385882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:30 | Steps: 2784 | Loss: 58.388419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:30 | Steps: 2786 | Loss: 58.388660\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:31 | Steps: 2788 | Loss: 58.381601\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:31 | Steps: 2790 | Loss: 58.394753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:31 | Steps: 2792 | Loss: 58.394063\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:31 | Steps: 2794 | Loss: 58.405135\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:31 | Steps: 2796 | Loss: 58.411363\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:31 | Steps: 2798 | Loss: 58.404954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:32 | Steps: 2799 | Loss: 58.404030\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:32 | Steps: 2801 | Loss: 58.417048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:32 | Steps: 2803 | Loss: 58.416958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:32 | Steps: 2804 | Loss: 58.413598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:32 | Steps: 2806 | Loss: 58.417920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:32 | Steps: 2807 | Loss: 58.415841\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:32 | Steps: 2809 | Loss: 58.437791\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:33 | Steps: 2811 | Loss: 58.458313\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:33 | Steps: 2813 | Loss: 58.453827\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:33 | Steps: 2815 | Loss: 58.459398\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:33 | Steps: 2817 | Loss: 58.474632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:33 | Steps: 2819 | Loss: 58.488168\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:33 | Steps: 2821 | Loss: 58.492426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:34 | Steps: 2823 | Loss: 58.480471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:34 | Steps: 2824 | Loss: 58.479950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:34 | Steps: 2826 | Loss: 58.473884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:34 | Steps: 2827 | Loss: 58.468110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:34 | Steps: 2829 | Loss: 58.463958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:34 | Steps: 2831 | Loss: 58.468143\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:34 | Steps: 2833 | Loss: 58.490020\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:35 | Steps: 2835 | Loss: 58.495041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:35 | Steps: 2837 | Loss: 58.486288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:35 | Steps: 2839 | Loss: 58.480731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:35 | Steps: 2841 | Loss: 58.479972\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:35 | Steps: 2843 | Loss: 58.478658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:35 | Steps: 2845 | Loss: 58.477826\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:36 | Steps: 2846 | Loss: 58.477620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:36 | Steps: 2848 | Loss: 58.484366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:36 | Steps: 2850 | Loss: 58.478025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:36 | Steps: 2852 | Loss: 58.504455\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:36 | Steps: 2854 | Loss: 58.505027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:36 | Steps: 2856 | Loss: 58.525898\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:37 | Steps: 2858 | Loss: 58.527840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:37 | Steps: 2860 | Loss: 58.541408\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:37 | Steps: 2862 | Loss: 58.550822\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:37 | Steps: 2864 | Loss: 58.550546\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:37 | Steps: 2865 | Loss: 58.550233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:37 | Steps: 2867 | Loss: 58.559696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:37 | Steps: 2868 | Loss: 58.558805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:38 | Steps: 2869 | Loss: 58.572603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:38 | Steps: 2871 | Loss: 58.601442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:38 | Steps: 2873 | Loss: 58.608519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:38 | Steps: 2875 | Loss: 58.608403\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:38 | Steps: 2877 | Loss: 58.608368\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:38 | Steps: 2879 | Loss: 58.628923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:39 | Steps: 2880 | Loss: 58.639631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:39 | Steps: 2882 | Loss: 58.646776\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:39 | Steps: 2884 | Loss: 58.665110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:39 | Steps: 2885 | Loss: 58.662081\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:39 | Steps: 2887 | Loss: 58.676407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:39 | Steps: 2889 | Loss: 58.684603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:40 | Steps: 2891 | Loss: 58.694510\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:40 | Steps: 2892 | Loss: 58.719491\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:40 | Steps: 2894 | Loss: 58.727727\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:40 | Steps: 2895 | Loss: 58.734932\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:40 | Steps: 2897 | Loss: 58.734237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:40 | Steps: 2899 | Loss: 58.735415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:40 | Steps: 2901 | Loss: 58.738152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:41 | Steps: 2903 | Loss: 58.739003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:41 | Steps: 2905 | Loss: 58.777041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:41 | Steps: 2907 | Loss: 58.807250\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:41 | Steps: 2909 | Loss: 58.825050\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:41 | Steps: 2911 | Loss: 58.830367\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:41 | Steps: 2913 | Loss: 58.842378\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:42 | Steps: 2915 | Loss: 58.844670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:42 | Steps: 2917 | Loss: 58.844675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:42 | Steps: 2919 | Loss: 58.843774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:42 | Steps: 2920 | Loss: 58.848677\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:42 | Steps: 2921 | Loss: 58.851004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:42 | Steps: 2922 | Loss: 58.856340\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:42 | Steps: 2924 | Loss: 58.864012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:43 | Steps: 2925 | Loss: 58.865865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:43 | Steps: 2926 | Loss: 58.868102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:43 | Steps: 2927 | Loss: 58.882795\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:43 | Steps: 2928 | Loss: 58.901107\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:43 | Steps: 2929 | Loss: 58.911373\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:43 | Steps: 2931 | Loss: 58.926649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:43 | Steps: 2933 | Loss: 58.934268\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:44 | Steps: 2935 | Loss: 58.935854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:44 | Steps: 2936 | Loss: 58.938803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:44 | Steps: 2938 | Loss: 58.940402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:44 | Steps: 2940 | Loss: 58.939836\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:44 | Steps: 2942 | Loss: 58.925161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:44 | Steps: 2944 | Loss: 58.919916\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:45 | Steps: 2946 | Loss: 58.944874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:45 | Steps: 2948 | Loss: 58.944218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:45 | Steps: 2950 | Loss: 58.947406\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:45 | Steps: 2952 | Loss: 58.953064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:45 | Steps: 2953 | Loss: 58.957516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:45 | Steps: 2955 | Loss: 58.965868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:45 | Steps: 2957 | Loss: 58.966709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:46 | Steps: 2958 | Loss: 58.969164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:46 | Steps: 2959 | Loss: 58.971187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:46 | Steps: 2961 | Loss: 59.001100\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:46 | Steps: 2962 | Loss: 59.012499\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:46 | Steps: 2963 | Loss: 59.023692\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:46 | Steps: 2965 | Loss: 59.017383\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:46 | Steps: 2966 | Loss: 59.016123\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:47 | Steps: 2967 | Loss: 59.012076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:47 | Steps: 2968 | Loss: 59.013143\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:47 | Steps: 2969 | Loss: 59.017708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:47 | Steps: 2970 | Loss: 59.018351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:47 | Steps: 2971 | Loss: 59.021737\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:47 | Steps: 2972 | Loss: 59.033476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:47 | Steps: 2973 | Loss: 59.036862\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:47 | Steps: 2974 | Loss: 59.041998\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:48 | Steps: 2976 | Loss: 59.041402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:48 | Steps: 2977 | Loss: 59.041409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:48 | Steps: 2978 | Loss: 59.041393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:48 | Steps: 2980 | Loss: 59.033148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:48 | Steps: 2982 | Loss: 59.029075\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:48 | Steps: 2984 | Loss: 59.046196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:49 | Steps: 2985 | Loss: 59.053147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:49 | Steps: 2986 | Loss: 59.058354\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:49 | Steps: 2988 | Loss: 59.066152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:49 | Steps: 2990 | Loss: 59.064316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:49 | Steps: 2992 | Loss: 59.066389\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:49 | Steps: 2993 | Loss: 59.066145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:49 | Steps: 2995 | Loss: 59.067028\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:50 | Steps: 2997 | Loss: 59.060273\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:50 | Steps: 2998 | Loss: 59.061164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:50 | Steps: 3000 | Loss: 59.069415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:50 | Steps: 3001 | Loss: 59.085002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:50 | Steps: 3003 | Loss: 59.083351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:50 | Steps: 3005 | Loss: 59.106769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:50 | Steps: 3007 | Loss: 59.109869\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:51 | Steps: 3008 | Loss: 59.111924\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:51 | Steps: 3010 | Loss: 59.123334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:51 | Steps: 3012 | Loss: 59.128848\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:51 | Steps: 3014 | Loss: 59.137466\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:51 | Steps: 3016 | Loss: 59.177333\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:51 | Steps: 3017 | Loss: 59.181718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:51 | Steps: 3019 | Loss: 59.173823\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:52 | Steps: 3021 | Loss: 59.182052\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:52 | Steps: 3023 | Loss: 59.181809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:52 | Steps: 3025 | Loss: 59.184572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:52 | Steps: 3027 | Loss: 59.184223\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:52 | Steps: 3028 | Loss: 59.193187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:52 | Steps: 3030 | Loss: 59.208410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:53 | Steps: 3032 | Loss: 59.212217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:53 | Steps: 3033 | Loss: 59.227572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:53 | Steps: 3035 | Loss: 59.240531\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:53 | Steps: 3037 | Loss: 59.249403\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:53 | Steps: 3039 | Loss: 59.291221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:53 | Steps: 3041 | Loss: 59.302706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:54 | Steps: 3043 | Loss: 59.325304\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:54 | Steps: 3045 | Loss: 59.341303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:54 | Steps: 3046 | Loss: 59.345516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:54 | Steps: 3048 | Loss: 59.360686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:54 | Steps: 3049 | Loss: 59.370142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:54 | Steps: 3051 | Loss: 59.370267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:54 | Steps: 3053 | Loss: 59.369971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:55 | Steps: 3055 | Loss: 59.370569\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:55 | Steps: 3056 | Loss: 59.394141\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:55 | Steps: 3058 | Loss: 59.403352\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:55 | Steps: 3060 | Loss: 59.407266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:55 | Steps: 3062 | Loss: 59.445213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:55 | Steps: 3064 | Loss: 59.445004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:56 | Steps: 3066 | Loss: 59.456683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:56 | Steps: 3067 | Loss: 59.467955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:56 | Steps: 3068 | Loss: 59.487577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:56 | Steps: 3070 | Loss: 59.496297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:56 | Steps: 3072 | Loss: 59.492754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:56 | Steps: 3074 | Loss: 59.499810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:56 | Steps: 3076 | Loss: 59.512341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:57 | Steps: 3078 | Loss: 59.517277\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:57 | Steps: 3080 | Loss: 59.518030\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:57 | Steps: 3082 | Loss: 59.517845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:57 | Steps: 3084 | Loss: 59.516753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:57 | Steps: 3086 | Loss: 59.513124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:57 | Steps: 3088 | Loss: 59.511032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:58 | Steps: 3089 | Loss: 59.517917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:58 | Steps: 3091 | Loss: 59.516698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:58 | Steps: 3093 | Loss: 59.531975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:58 | Steps: 3095 | Loss: 59.557151\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:58 | Steps: 3096 | Loss: 59.564555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:58 | Steps: 3098 | Loss: 59.570400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:58 | Steps: 3100 | Loss: 59.578616\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:59 | Steps: 3102 | Loss: 59.580346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:59 | Steps: 3104 | Loss: 59.589134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:59 | Steps: 3105 | Loss: 59.587170\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:59 | Steps: 3107 | Loss: 59.570800\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:59 | Steps: 3108 | Loss: 59.567958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:03:59 | Steps: 3110 | Loss: 59.600752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:00 | Steps: 3112 | Loss: 59.599954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:00 | Steps: 3113 | Loss: 59.600574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:00 | Steps: 3115 | Loss: 59.600626\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:00 | Steps: 3117 | Loss: 59.601990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:00 | Steps: 3118 | Loss: 59.602540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:00 | Steps: 3120 | Loss: 59.623000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:00 | Steps: 3121 | Loss: 59.618230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:01 | Steps: 3122 | Loss: 59.616677\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:01 | Steps: 3124 | Loss: 59.619994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:01 | Steps: 3126 | Loss: 59.626945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:01 | Steps: 3127 | Loss: 59.635971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:01 | Steps: 3129 | Loss: 59.652592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:01 | Steps: 3131 | Loss: 59.659887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:01 | Steps: 3132 | Loss: 59.660014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:02 | Steps: 3134 | Loss: 59.673593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:02 | Steps: 3136 | Loss: 59.669893\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:02 | Steps: 3137 | Loss: 59.672648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:02 | Steps: 3139 | Loss: 59.671665\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:02 | Steps: 3141 | Loss: 59.662811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:02 | Steps: 3143 | Loss: 59.655866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:02 | Steps: 3144 | Loss: 59.655453\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:03 | Steps: 3145 | Loss: 59.658414\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:03 | Steps: 3147 | Loss: 59.670350\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:03 | Steps: 3148 | Loss: 59.679598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:03 | Steps: 3150 | Loss: 59.680342\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:03 | Steps: 3151 | Loss: 59.674126\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:03 | Steps: 3152 | Loss: 59.677511\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:04 | Steps: 3153 | Loss: 59.673274\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:04 | Steps: 3154 | Loss: 59.670938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:04 | Steps: 3156 | Loss: 59.670614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:04 | Steps: 3157 | Loss: 59.672302\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:04 | Steps: 3158 | Loss: 59.670214\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:04 | Steps: 3159 | Loss: 59.672611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:05 | Steps: 3160 | Loss: 59.673406\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:05 | Steps: 3161 | Loss: 59.681692\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:05 | Steps: 3162 | Loss: 59.682746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:05 | Steps: 3163 | Loss: 59.681392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:05 | Steps: 3165 | Loss: 59.687376\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:05 | Steps: 3167 | Loss: 59.711046\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:05 | Steps: 3168 | Loss: 59.720209\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:06 | Steps: 3170 | Loss: 59.715952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:06 | Steps: 3172 | Loss: 59.724532\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:06 | Steps: 3174 | Loss: 59.741508\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:06 | Steps: 3176 | Loss: 59.738941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:06 | Steps: 3178 | Loss: 59.741459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:06 | Steps: 3179 | Loss: 59.741976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:06 | Steps: 3180 | Loss: 59.739340\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:07 | Steps: 3181 | Loss: 59.739160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:07 | Steps: 3183 | Loss: 59.735459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:07 | Steps: 3185 | Loss: 59.755993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:07 | Steps: 3187 | Loss: 59.761294\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:07 | Steps: 3189 | Loss: 59.767356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:07 | Steps: 3191 | Loss: 59.785582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:08 | Steps: 3193 | Loss: 59.787829\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:08 | Steps: 3194 | Loss: 59.791854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:08 | Steps: 3196 | Loss: 59.791482\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:08 | Steps: 3197 | Loss: 59.796336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:08 | Steps: 3198 | Loss: 59.801784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:08 | Steps: 3199 | Loss: 59.808306\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:08 | Steps: 3200 | Loss: 59.817188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:08 | Steps: 3202 | Loss: 59.817546\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:09 | Steps: 3204 | Loss: 59.824410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:09 | Steps: 3205 | Loss: 59.835879\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:09 | Steps: 3206 | Loss: 59.838357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:09 | Steps: 3207 | Loss: 59.841860\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:09 | Steps: 3208 | Loss: 59.836460\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:09 | Steps: 3210 | Loss: 59.856147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:09 | Steps: 3211 | Loss: 59.862736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:09 | Steps: 3213 | Loss: 59.859078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:10 | Steps: 3214 | Loss: 59.857364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:10 | Steps: 3216 | Loss: 59.866693\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:10 | Steps: 3217 | Loss: 59.868697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:10 | Steps: 3219 | Loss: 59.875215\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:10 | Steps: 3221 | Loss: 59.893011\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:10 | Steps: 3222 | Loss: 59.895357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:10 | Steps: 3223 | Loss: 59.899814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:11 | Steps: 3225 | Loss: 59.914480\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:11 | Steps: 3227 | Loss: 59.920682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:11 | Steps: 3229 | Loss: 59.926250\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:11 | Steps: 3230 | Loss: 59.931890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:11 | Steps: 3232 | Loss: 59.943207\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:11 | Steps: 3233 | Loss: 59.953826\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:11 | Steps: 3234 | Loss: 59.961866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:11 | Steps: 3235 | Loss: 59.968425\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:12 | Steps: 3237 | Loss: 59.981963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:12 | Steps: 3239 | Loss: 59.976868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:12 | Steps: 3240 | Loss: 59.984344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:12 | Steps: 3242 | Loss: 59.982734\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:12 | Steps: 3244 | Loss: 59.994514\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:12 | Steps: 3245 | Loss: 59.997519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:13 | Steps: 3247 | Loss: 60.001325\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:13 | Steps: 3249 | Loss: 60.001319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:13 | Steps: 3250 | Loss: 60.006683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:13 | Steps: 3252 | Loss: 60.016285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:13 | Steps: 3253 | Loss: 60.012561\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:13 | Steps: 3255 | Loss: 60.017961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:13 | Steps: 3257 | Loss: 60.025915\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:14 | Steps: 3259 | Loss: 60.038985\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:14 | Steps: 3261 | Loss: 60.059626\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:14 | Steps: 3262 | Loss: 60.072561\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:14 | Steps: 3263 | Loss: 60.079029\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:14 | Steps: 3264 | Loss: 60.095870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:14 | Steps: 3266 | Loss: 60.119170\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:15 | Steps: 3268 | Loss: 60.119539\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:15 | Steps: 3270 | Loss: 60.129481\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:15 | Steps: 3272 | Loss: 60.120566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:15 | Steps: 3273 | Loss: 60.114431\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:15 | Steps: 3275 | Loss: 60.117790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:15 | Steps: 3277 | Loss: 60.142092\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:16 | Steps: 3279 | Loss: 60.146562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:16 | Steps: 3281 | Loss: 60.153548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:16 | Steps: 3283 | Loss: 60.156241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:16 | Steps: 3285 | Loss: 60.162858\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:16 | Steps: 3287 | Loss: 60.162625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:16 | Steps: 3289 | Loss: 60.169489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:17 | Steps: 3291 | Loss: 60.170989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:17 | Steps: 3293 | Loss: 60.173778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:17 | Steps: 3295 | Loss: 60.181051\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:17 | Steps: 3297 | Loss: 60.205102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:17 | Steps: 3298 | Loss: 60.217706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:17 | Steps: 3299 | Loss: 60.220716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:17 | Steps: 3301 | Loss: 60.217110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:18 | Steps: 3303 | Loss: 60.218105\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:18 | Steps: 3304 | Loss: 60.223148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:18 | Steps: 3306 | Loss: 60.236078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:18 | Steps: 3308 | Loss: 60.246584\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:18 | Steps: 3310 | Loss: 60.262799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:18 | Steps: 3312 | Loss: 60.271050\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:19 | Steps: 3314 | Loss: 60.259802\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:19 | Steps: 3315 | Loss: 60.262096\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:19 | Steps: 3317 | Loss: 60.256147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:19 | Steps: 3319 | Loss: 60.257681\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:19 | Steps: 3321 | Loss: 60.275162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:19 | Steps: 3322 | Loss: 60.280391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:19 | Steps: 3324 | Loss: 60.294187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:20 | Steps: 3326 | Loss: 60.283506\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:20 | Steps: 3328 | Loss: 60.281980\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:20 | Steps: 3329 | Loss: 60.280192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:20 | Steps: 3331 | Loss: 60.279567\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:20 | Steps: 3333 | Loss: 60.279545\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:20 | Steps: 3335 | Loss: 60.281020\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:20 | Steps: 3337 | Loss: 60.291686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:21 | Steps: 3338 | Loss: 60.306045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:21 | Steps: 3340 | Loss: 60.341515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:21 | Steps: 3342 | Loss: 60.362865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:21 | Steps: 3343 | Loss: 60.363208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:21 | Steps: 3345 | Loss: 60.383153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:21 | Steps: 3347 | Loss: 60.390605\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:22 | Steps: 3349 | Loss: 60.387296\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:22 | Steps: 3351 | Loss: 60.385166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:22 | Steps: 3353 | Loss: 60.386011\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:22 | Steps: 3355 | Loss: 60.383449\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:22 | Steps: 3357 | Loss: 60.402457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:22 | Steps: 3359 | Loss: 60.401129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:23 | Steps: 3361 | Loss: 60.405197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:23 | Steps: 3363 | Loss: 60.422232\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:23 | Steps: 3365 | Loss: 60.425885\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:23 | Steps: 3367 | Loss: 60.428877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:23 | Steps: 3368 | Loss: 60.439187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:23 | Steps: 3369 | Loss: 60.440087\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:23 | Steps: 3371 | Loss: 60.470600\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:24 | Steps: 3373 | Loss: 60.474716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:24 | Steps: 3375 | Loss: 60.475892\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:24 | Steps: 3377 | Loss: 60.477278\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:24 | Steps: 3379 | Loss: 60.488811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:24 | Steps: 3380 | Loss: 60.501702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:24 | Steps: 3382 | Loss: 60.500917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:25 | Steps: 3384 | Loss: 60.508491\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:25 | Steps: 3385 | Loss: 60.515241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:25 | Steps: 3387 | Loss: 60.536494\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:25 | Steps: 3388 | Loss: 60.543615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:25 | Steps: 3390 | Loss: 60.546775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:25 | Steps: 3392 | Loss: 60.548524\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:25 | Steps: 3393 | Loss: 60.561525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:26 | Steps: 3394 | Loss: 60.568915\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:26 | Steps: 3396 | Loss: 60.571876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:26 | Steps: 3398 | Loss: 60.580149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:26 | Steps: 3399 | Loss: 60.596726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:26 | Steps: 3400 | Loss: 60.597698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:26 | Steps: 3402 | Loss: 60.598497\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:26 | Steps: 3403 | Loss: 60.600249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:27 | Steps: 3405 | Loss: 60.601661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:27 | Steps: 3407 | Loss: 60.616245\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:27 | Steps: 3408 | Loss: 60.631930\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:27 | Steps: 3410 | Loss: 60.628766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:27 | Steps: 3411 | Loss: 60.625934\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:27 | Steps: 3413 | Loss: 60.636574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:27 | Steps: 3415 | Loss: 60.646145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:28 | Steps: 3417 | Loss: 60.652070\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:28 | Steps: 3419 | Loss: 60.652336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:28 | Steps: 3421 | Loss: 60.654545\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:28 | Steps: 3422 | Loss: 60.652750\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:28 | Steps: 3424 | Loss: 60.647547\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:28 | Steps: 3425 | Loss: 60.645635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:28 | Steps: 3427 | Loss: 60.642133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:29 | Steps: 3429 | Loss: 60.669451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:29 | Steps: 3431 | Loss: 60.697524\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:29 | Steps: 3432 | Loss: 60.701426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:29 | Steps: 3434 | Loss: 60.711899\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:29 | Steps: 3435 | Loss: 60.713584\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:29 | Steps: 3437 | Loss: 60.716777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:30 | Steps: 3439 | Loss: 60.722352\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:30 | Steps: 3441 | Loss: 60.704067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:30 | Steps: 3443 | Loss: 60.695740\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:30 | Steps: 3445 | Loss: 60.725254\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:30 | Steps: 3446 | Loss: 60.730271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:30 | Steps: 3448 | Loss: 60.727859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:30 | Steps: 3450 | Loss: 60.731334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:31 | Steps: 3452 | Loss: 60.735933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:31 | Steps: 3454 | Loss: 60.732504\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:31 | Steps: 3456 | Loss: 60.735832\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:31 | Steps: 3458 | Loss: 60.736169\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:31 | Steps: 3460 | Loss: 60.732571\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:31 | Steps: 3461 | Loss: 60.732356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:32 | Steps: 3462 | Loss: 60.736598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:32 | Steps: 3464 | Loss: 60.748357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:32 | Steps: 3466 | Loss: 60.751550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:32 | Steps: 3467 | Loss: 60.753141\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:32 | Steps: 3469 | Loss: 60.755441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:32 | Steps: 3470 | Loss: 60.754884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:32 | Steps: 3472 | Loss: 60.759486\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:33 | Steps: 3474 | Loss: 60.760480\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:33 | Steps: 3476 | Loss: 60.756113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:33 | Steps: 3478 | Loss: 60.747691\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:33 | Steps: 3479 | Loss: 60.742591\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:33 | Steps: 3481 | Loss: 60.738849\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:33 | Steps: 3483 | Loss: 60.742081\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:34 | Steps: 3485 | Loss: 60.756109\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:34 | Steps: 3487 | Loss: 60.762767\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:34 | Steps: 3489 | Loss: 60.755994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:34 | Steps: 3491 | Loss: 60.754513\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:34 | Steps: 3493 | Loss: 60.750179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:34 | Steps: 3494 | Loss: 60.747625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:34 | Steps: 3495 | Loss: 60.749642\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:35 | Steps: 3497 | Loss: 60.754635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:35 | Steps: 3499 | Loss: 60.758017\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:35 | Steps: 3501 | Loss: 60.760663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:35 | Steps: 3503 | Loss: 60.759590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:35 | Steps: 3505 | Loss: 60.778392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:35 | Steps: 3507 | Loss: 60.788565\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:36 | Steps: 3508 | Loss: 60.792396\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:36 | Steps: 3510 | Loss: 60.790452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:36 | Steps: 3511 | Loss: 60.798617\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:36 | Steps: 3512 | Loss: 60.803134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:36 | Steps: 3514 | Loss: 60.802233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:36 | Steps: 3516 | Loss: 60.798698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:36 | Steps: 3517 | Loss: 60.801981\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:37 | Steps: 3519 | Loss: 60.809316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:37 | Steps: 3521 | Loss: 60.806389\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:37 | Steps: 3522 | Loss: 60.809396\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:37 | Steps: 3524 | Loss: 60.807101\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:37 | Steps: 3526 | Loss: 60.812372\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:37 | Steps: 3527 | Loss: 60.817998\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:37 | Steps: 3529 | Loss: 60.834114\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:38 | Steps: 3531 | Loss: 60.835151\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:38 | Steps: 3533 | Loss: 60.834942\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:38 | Steps: 3535 | Loss: 60.838156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:38 | Steps: 3537 | Loss: 60.850081\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:38 | Steps: 3539 | Loss: 60.862785\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:38 | Steps: 3541 | Loss: 60.859334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:39 | Steps: 3543 | Loss: 60.870569\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:39 | Steps: 3545 | Loss: 60.867154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:39 | Steps: 3547 | Loss: 60.867619\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:39 | Steps: 3549 | Loss: 60.868053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:39 | Steps: 3551 | Loss: 60.873824\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:39 | Steps: 3553 | Loss: 60.882180\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:40 | Steps: 3554 | Loss: 60.887218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:40 | Steps: 3556 | Loss: 60.907683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:40 | Steps: 3558 | Loss: 60.906496\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:40 | Steps: 3559 | Loss: 60.926507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:40 | Steps: 3561 | Loss: 60.928474\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:40 | Steps: 3563 | Loss: 60.922981\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:40 | Steps: 3564 | Loss: 60.934781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:41 | Steps: 3566 | Loss: 60.929870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:41 | Steps: 3568 | Loss: 60.928799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:41 | Steps: 3569 | Loss: 60.931912\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:41 | Steps: 3571 | Loss: 60.932150\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:41 | Steps: 3573 | Loss: 60.931079\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:41 | Steps: 3574 | Loss: 60.933124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:42 | Steps: 3576 | Loss: 60.930881\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:42 | Steps: 3578 | Loss: 60.932742\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:42 | Steps: 3580 | Loss: 60.931796\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:42 | Steps: 3581 | Loss: 60.933497\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:42 | Steps: 3583 | Loss: 60.939297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:42 | Steps: 3585 | Loss: 60.947954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:42 | Steps: 3586 | Loss: 60.950250\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:43 | Steps: 3588 | Loss: 60.981038\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:43 | Steps: 3590 | Loss: 60.991055\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:43 | Steps: 3592 | Loss: 61.009595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:43 | Steps: 3593 | Loss: 61.016741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:43 | Steps: 3595 | Loss: 61.020297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:43 | Steps: 3597 | Loss: 61.028985\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:44 | Steps: 3599 | Loss: 61.017238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:44 | Steps: 3600 | Loss: 61.015090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:44 | Steps: 3601 | Loss: 61.014516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:44 | Steps: 3603 | Loss: 61.031830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:44 | Steps: 3604 | Loss: 61.034274\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:44 | Steps: 3606 | Loss: 61.037128\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:44 | Steps: 3608 | Loss: 61.046966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:45 | Steps: 3609 | Loss: 61.049924\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:45 | Steps: 3611 | Loss: 61.055007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:45 | Steps: 3613 | Loss: 61.060856\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:45 | Steps: 3615 | Loss: 61.062882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:45 | Steps: 3617 | Loss: 61.061033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:45 | Steps: 3618 | Loss: 61.056702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:45 | Steps: 3620 | Loss: 61.058165\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:46 | Steps: 3622 | Loss: 61.076993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:46 | Steps: 3624 | Loss: 61.102165\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:46 | Steps: 3626 | Loss: 61.100463\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:46 | Steps: 3627 | Loss: 61.101189\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:46 | Steps: 3629 | Loss: 61.105686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:46 | Steps: 3630 | Loss: 61.108137\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:47 | Steps: 3632 | Loss: 61.125327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:47 | Steps: 3634 | Loss: 61.136458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:47 | Steps: 3636 | Loss: 61.136454\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:47 | Steps: 3637 | Loss: 61.130450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:47 | Steps: 3639 | Loss: 61.131864\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:47 | Steps: 3641 | Loss: 61.134716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:47 | Steps: 3642 | Loss: 61.134300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:48 | Steps: 3644 | Loss: 61.149708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:48 | Steps: 3645 | Loss: 61.147519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:48 | Steps: 3646 | Loss: 61.151687\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:48 | Steps: 3648 | Loss: 61.157793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:48 | Steps: 3650 | Loss: 61.154251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:48 | Steps: 3652 | Loss: 61.166379\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:48 | Steps: 3654 | Loss: 61.169456\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:49 | Steps: 3656 | Loss: 61.166585\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:49 | Steps: 3658 | Loss: 61.170410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:49 | Steps: 3660 | Loss: 61.178723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:49 | Steps: 3662 | Loss: 61.185708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:49 | Steps: 3664 | Loss: 61.194705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:50 | Steps: 3666 | Loss: 61.195729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:50 | Steps: 3668 | Loss: 61.198211\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:50 | Steps: 3670 | Loss: 61.217530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:50 | Steps: 3672 | Loss: 61.230798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:50 | Steps: 3674 | Loss: 61.238787\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:50 | Steps: 3676 | Loss: 61.241774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:51 | Steps: 3677 | Loss: 61.246322\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:51 | Steps: 3679 | Loss: 61.257509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:51 | Steps: 3681 | Loss: 61.259627\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:51 | Steps: 3683 | Loss: 61.266782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:51 | Steps: 3685 | Loss: 61.265078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:51 | Steps: 3686 | Loss: 61.263171\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:52 | Steps: 3688 | Loss: 61.258015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:52 | Steps: 3690 | Loss: 61.257976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:52 | Steps: 3692 | Loss: 61.267638\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:52 | Steps: 3694 | Loss: 61.274359\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:52 | Steps: 3696 | Loss: 61.290089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:52 | Steps: 3697 | Loss: 61.303755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:52 | Steps: 3699 | Loss: 61.320067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:53 | Steps: 3701 | Loss: 61.330128\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:53 | Steps: 3703 | Loss: 61.332250\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:53 | Steps: 3705 | Loss: 61.335314\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:53 | Steps: 3707 | Loss: 61.338648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:53 | Steps: 3709 | Loss: 61.346729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:54 | Steps: 3711 | Loss: 61.353970\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:54 | Steps: 3713 | Loss: 61.356165\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:54 | Steps: 3715 | Loss: 61.363294\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:54 | Steps: 3716 | Loss: 61.375418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:54 | Steps: 3718 | Loss: 61.372164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:54 | Steps: 3720 | Loss: 61.371921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:55 | Steps: 3722 | Loss: 61.379396\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:55 | Steps: 3724 | Loss: 61.387229\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:55 | Steps: 3726 | Loss: 61.397814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:55 | Steps: 3728 | Loss: 61.401653\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:55 | Steps: 3729 | Loss: 61.417859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:55 | Steps: 3731 | Loss: 61.413019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:55 | Steps: 3733 | Loss: 61.430432\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:56 | Steps: 3735 | Loss: 61.437743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:56 | Steps: 3736 | Loss: 61.443772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:56 | Steps: 3738 | Loss: 61.444646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:56 | Steps: 3740 | Loss: 61.439003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:56 | Steps: 3742 | Loss: 61.440183\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:56 | Steps: 3744 | Loss: 61.446856\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:57 | Steps: 3746 | Loss: 61.451632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:57 | Steps: 3747 | Loss: 61.449066\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:57 | Steps: 3748 | Loss: 61.453196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:57 | Steps: 3750 | Loss: 61.452902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:57 | Steps: 3752 | Loss: 61.457656\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:57 | Steps: 3753 | Loss: 61.458522\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:58 | Steps: 3755 | Loss: 61.478706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:58 | Steps: 3757 | Loss: 61.479590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:58 | Steps: 3759 | Loss: 61.492880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:58 | Steps: 3761 | Loss: 61.499257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:58 | Steps: 3763 | Loss: 61.496216\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:58 | Steps: 3764 | Loss: 61.494576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:58 | Steps: 3765 | Loss: 61.499810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:59 | Steps: 3767 | Loss: 61.491552\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:59 | Steps: 3769 | Loss: 61.478835\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:59 | Steps: 3770 | Loss: 61.473922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:59 | Steps: 3771 | Loss: 61.470962\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:59 | Steps: 3773 | Loss: 61.486647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:59 | Steps: 3774 | Loss: 61.491010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:04:59 | Steps: 3776 | Loss: 61.494057\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:00 | Steps: 3778 | Loss: 61.499079\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:00 | Steps: 3780 | Loss: 61.509798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:00 | Steps: 3782 | Loss: 61.504877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:00 | Steps: 3784 | Loss: 61.506834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:00 | Steps: 3785 | Loss: 61.508277\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:00 | Steps: 3787 | Loss: 61.519790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:01 | Steps: 3789 | Loss: 61.516235\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:01 | Steps: 3791 | Loss: 61.540834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:01 | Steps: 3793 | Loss: 61.557788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:01 | Steps: 3795 | Loss: 61.556934\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:01 | Steps: 3797 | Loss: 61.555178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:02 | Steps: 3799 | Loss: 61.560799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:02 | Steps: 3801 | Loss: 61.577393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:02 | Steps: 3803 | Loss: 61.588102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:02 | Steps: 3804 | Loss: 61.589076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:02 | Steps: 3806 | Loss: 61.604162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:02 | Steps: 3808 | Loss: 61.617166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:02 | Steps: 3809 | Loss: 61.614249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:03 | Steps: 3811 | Loss: 61.605708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:03 | Steps: 3813 | Loss: 61.599382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:03 | Steps: 3814 | Loss: 61.597198\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:03 | Steps: 3816 | Loss: 61.603358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:03 | Steps: 3817 | Loss: 61.607984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:03 | Steps: 3818 | Loss: 61.612113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:04 | Steps: 3820 | Loss: 61.608314\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:04 | Steps: 3822 | Loss: 61.606697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:04 | Steps: 3823 | Loss: 61.605843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:04 | Steps: 3825 | Loss: 61.603604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:04 | Steps: 3827 | Loss: 61.602950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:04 | Steps: 3828 | Loss: 61.602096\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:04 | Steps: 3830 | Loss: 61.601069\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:05 | Steps: 3832 | Loss: 61.600449\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:05 | Steps: 3834 | Loss: 61.604999\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:05 | Steps: 3836 | Loss: 61.614812\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:05 | Steps: 3837 | Loss: 61.615471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:05 | Steps: 3839 | Loss: 61.629463\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:05 | Steps: 3841 | Loss: 61.656305\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:06 | Steps: 3843 | Loss: 61.662745\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:06 | Steps: 3845 | Loss: 61.663694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:06 | Steps: 3846 | Loss: 61.659260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:06 | Steps: 3848 | Loss: 61.667853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:06 | Steps: 3850 | Loss: 61.667789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:06 | Steps: 3851 | Loss: 61.665391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:06 | Steps: 3852 | Loss: 61.662097\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:07 | Steps: 3854 | Loss: 61.662496\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:07 | Steps: 3855 | Loss: 61.666871\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:07 | Steps: 3856 | Loss: 61.665800\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:07 | Steps: 3858 | Loss: 61.672463\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:07 | Steps: 3860 | Loss: 61.686883\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:07 | Steps: 3861 | Loss: 61.691986\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:07 | Steps: 3863 | Loss: 61.697110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:08 | Steps: 3865 | Loss: 61.703523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:08 | Steps: 3867 | Loss: 61.718882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:08 | Steps: 3868 | Loss: 61.733235\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:08 | Steps: 3870 | Loss: 61.739552\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:08 | Steps: 3872 | Loss: 61.741017\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:08 | Steps: 3873 | Loss: 61.738945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:08 | Steps: 3875 | Loss: 61.739532\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:09 | Steps: 3877 | Loss: 61.766136\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:09 | Steps: 3879 | Loss: 61.772014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:09 | Steps: 3881 | Loss: 61.794989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:09 | Steps: 3883 | Loss: 61.806556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:09 | Steps: 3884 | Loss: 61.802334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:09 | Steps: 3886 | Loss: 61.818036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:10 | Steps: 3888 | Loss: 61.822285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:10 | Steps: 3890 | Loss: 61.821848\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:10 | Steps: 3892 | Loss: 61.827850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:10 | Steps: 3893 | Loss: 61.826201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:10 | Steps: 3895 | Loss: 61.832869\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:10 | Steps: 3896 | Loss: 61.837938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:11 | Steps: 3898 | Loss: 61.851655\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:11 | Steps: 3900 | Loss: 61.865705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:11 | Steps: 3902 | Loss: 61.867125\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:11 | Steps: 3903 | Loss: 61.886920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:11 | Steps: 3905 | Loss: 61.897955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:11 | Steps: 3907 | Loss: 61.902455\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:12 | Steps: 3909 | Loss: 61.904619\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:12 | Steps: 3910 | Loss: 61.904900\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:12 | Steps: 3912 | Loss: 61.897951\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:12 | Steps: 3914 | Loss: 61.912561\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:12 | Steps: 3916 | Loss: 61.923961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:12 | Steps: 3918 | Loss: 61.941178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:13 | Steps: 3920 | Loss: 61.952973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:13 | Steps: 3922 | Loss: 61.955312\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:13 | Steps: 3923 | Loss: 61.953605\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:13 | Steps: 3924 | Loss: 61.964473\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:13 | Steps: 3926 | Loss: 61.965694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:13 | Steps: 3928 | Loss: 61.966223\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:14 | Steps: 3930 | Loss: 61.964472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:14 | Steps: 3932 | Loss: 61.966725\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:14 | Steps: 3934 | Loss: 61.970766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:14 | Steps: 3935 | Loss: 61.968586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:14 | Steps: 3937 | Loss: 61.970545\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:14 | Steps: 3939 | Loss: 61.978984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:14 | Steps: 3940 | Loss: 61.981307\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:15 | Steps: 3942 | Loss: 61.980788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:15 | Steps: 3944 | Loss: 61.994715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:15 | Steps: 3946 | Loss: 62.008489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:15 | Steps: 3947 | Loss: 62.018621\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:15 | Steps: 3949 | Loss: 62.027279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:15 | Steps: 3950 | Loss: 62.026581\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:15 | Steps: 3951 | Loss: 62.024929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:16 | Steps: 3953 | Loss: 62.032945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:16 | Steps: 3955 | Loss: 62.028251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:16 | Steps: 3957 | Loss: 62.038939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:16 | Steps: 3959 | Loss: 62.059628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:16 | Steps: 3961 | Loss: 62.055848\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:16 | Steps: 3962 | Loss: 62.054089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:17 | Steps: 3964 | Loss: 62.059655\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:17 | Steps: 3966 | Loss: 62.071470\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:17 | Steps: 3968 | Loss: 62.073698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:17 | Steps: 3970 | Loss: 62.077685\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:17 | Steps: 3971 | Loss: 62.076764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:17 | Steps: 3973 | Loss: 62.087658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:18 | Steps: 3975 | Loss: 62.085500\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:18 | Steps: 3977 | Loss: 62.086956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:18 | Steps: 3978 | Loss: 62.092979\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:18 | Steps: 3980 | Loss: 62.105987\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:18 | Steps: 3982 | Loss: 62.129263\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:18 | Steps: 3984 | Loss: 62.127620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:19 | Steps: 3985 | Loss: 62.125941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:19 | Steps: 3987 | Loss: 62.132322\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:19 | Steps: 3989 | Loss: 62.140173\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:19 | Steps: 3991 | Loss: 62.154314\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:19 | Steps: 3993 | Loss: 62.154518\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:19 | Steps: 3995 | Loss: 62.148309\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:20 | Steps: 3997 | Loss: 62.142834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:20 | Steps: 3999 | Loss: 62.137672\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:20 | Steps: 4000 | Loss: 62.149630\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:20 | Steps: 4002 | Loss: 62.157590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:20 | Steps: 4004 | Loss: 62.158399\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:20 | Steps: 4005 | Loss: 62.155831\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:21 | Steps: 4007 | Loss: 62.141846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:21 | Steps: 4009 | Loss: 62.147962\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:21 | Steps: 4011 | Loss: 62.151822\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:21 | Steps: 4013 | Loss: 62.157002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:21 | Steps: 4015 | Loss: 62.155073\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:21 | Steps: 4016 | Loss: 62.155441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:22 | Steps: 4018 | Loss: 62.157634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:22 | Steps: 4020 | Loss: 62.174224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:22 | Steps: 4022 | Loss: 62.170456\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:22 | Steps: 4023 | Loss: 62.183199\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:22 | Steps: 4025 | Loss: 62.205479\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:22 | Steps: 4026 | Loss: 62.211324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:23 | Steps: 4028 | Loss: 62.212389\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:23 | Steps: 4030 | Loss: 62.215610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:23 | Steps: 4031 | Loss: 62.220153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:23 | Steps: 4033 | Loss: 62.229045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:23 | Steps: 4034 | Loss: 62.232502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:23 | Steps: 4035 | Loss: 62.237080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:23 | Steps: 4037 | Loss: 62.244184\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:24 | Steps: 4039 | Loss: 62.261994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:24 | Steps: 4040 | Loss: 62.264587\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:24 | Steps: 4042 | Loss: 62.262254\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:24 | Steps: 4044 | Loss: 62.262442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:24 | Steps: 4046 | Loss: 62.272991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:24 | Steps: 4048 | Loss: 62.276949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:25 | Steps: 4050 | Loss: 62.296747\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:25 | Steps: 4051 | Loss: 62.300779\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:25 | Steps: 4053 | Loss: 62.323302\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:25 | Steps: 4054 | Loss: 62.329091\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:25 | Steps: 4056 | Loss: 62.332261\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:25 | Steps: 4058 | Loss: 62.338918\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:26 | Steps: 4060 | Loss: 62.342178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:26 | Steps: 4062 | Loss: 62.345643\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:26 | Steps: 4064 | Loss: 62.350020\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:26 | Steps: 4066 | Loss: 62.349115\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:26 | Steps: 4067 | Loss: 62.347639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:26 | Steps: 4069 | Loss: 62.349552\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:26 | Steps: 4070 | Loss: 62.349823\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:27 | Steps: 4072 | Loss: 62.356318\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:27 | Steps: 4074 | Loss: 62.357553\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:27 | Steps: 4075 | Loss: 62.358400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:27 | Steps: 4077 | Loss: 62.372422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:27 | Steps: 4079 | Loss: 62.363530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:27 | Steps: 4080 | Loss: 62.357157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:27 | Steps: 4081 | Loss: 62.381150\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:28 | Steps: 4083 | Loss: 62.423175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:28 | Steps: 4085 | Loss: 62.423710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:28 | Steps: 4086 | Loss: 62.420003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:28 | Steps: 4088 | Loss: 62.444620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:28 | Steps: 4089 | Loss: 62.447572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:28 | Steps: 4090 | Loss: 62.451044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:29 | Steps: 4092 | Loss: 62.449501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:29 | Steps: 4094 | Loss: 62.450105\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:29 | Steps: 4095 | Loss: 62.456731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:29 | Steps: 4097 | Loss: 62.460457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:29 | Steps: 4099 | Loss: 62.461935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:29 | Steps: 4101 | Loss: 62.458153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:29 | Steps: 4102 | Loss: 62.457868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:30 | Steps: 4104 | Loss: 62.456818\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:30 | Steps: 4105 | Loss: 62.460009\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:30 | Steps: 4107 | Loss: 62.477562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:30 | Steps: 4108 | Loss: 62.488213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:30 | Steps: 4109 | Loss: 62.505065\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:30 | Steps: 4111 | Loss: 62.519139\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:30 | Steps: 4112 | Loss: 62.521026\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:31 | Steps: 4114 | Loss: 62.514809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:31 | Steps: 4116 | Loss: 62.518401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:31 | Steps: 4118 | Loss: 62.525393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:31 | Steps: 4120 | Loss: 62.526521\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:31 | Steps: 4121 | Loss: 62.524743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:31 | Steps: 4123 | Loss: 62.532278\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:32 | Steps: 4125 | Loss: 62.557724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:32 | Steps: 4126 | Loss: 62.558543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:32 | Steps: 4128 | Loss: 62.562441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:32 | Steps: 4129 | Loss: 62.565387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:32 | Steps: 4130 | Loss: 62.567368\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:32 | Steps: 4132 | Loss: 62.583237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:32 | Steps: 4134 | Loss: 62.581572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:33 | Steps: 4136 | Loss: 62.579926\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:33 | Steps: 4138 | Loss: 62.583064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:33 | Steps: 4140 | Loss: 62.605648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:33 | Steps: 4142 | Loss: 62.619582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:33 | Steps: 4144 | Loss: 62.616958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:33 | Steps: 4145 | Loss: 62.617078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:34 | Steps: 4147 | Loss: 62.628451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:34 | Steps: 4149 | Loss: 62.634219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:34 | Steps: 4150 | Loss: 62.639741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:34 | Steps: 4152 | Loss: 62.643251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:34 | Steps: 4154 | Loss: 62.640038\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:34 | Steps: 4156 | Loss: 62.635279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:35 | Steps: 4158 | Loss: 62.630779\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:35 | Steps: 4160 | Loss: 62.629575\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:35 | Steps: 4161 | Loss: 62.625679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:35 | Steps: 4163 | Loss: 62.628634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:35 | Steps: 4165 | Loss: 62.642618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:36 | Steps: 4167 | Loss: 62.647439\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:36 | Steps: 4168 | Loss: 62.657019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:36 | Steps: 4169 | Loss: 62.660526\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:36 | Steps: 4171 | Loss: 62.651725\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:36 | Steps: 4173 | Loss: 62.655621\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:36 | Steps: 4175 | Loss: 62.650558\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:36 | Steps: 4176 | Loss: 62.650651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:37 | Steps: 4178 | Loss: 62.648479\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:37 | Steps: 4180 | Loss: 62.658990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:37 | Steps: 4182 | Loss: 62.665430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:37 | Steps: 4184 | Loss: 62.669707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:37 | Steps: 4186 | Loss: 62.679153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:37 | Steps: 4187 | Loss: 62.681472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:38 | Steps: 4189 | Loss: 62.685008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:38 | Steps: 4191 | Loss: 62.702371\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:38 | Steps: 4192 | Loss: 62.707774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:38 | Steps: 4194 | Loss: 62.711879\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:38 | Steps: 4196 | Loss: 62.719002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:38 | Steps: 4197 | Loss: 62.721708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:39 | Steps: 4199 | Loss: 62.721084\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:39 | Steps: 4200 | Loss: 62.717654\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:39 | Steps: 4201 | Loss: 62.712952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:39 | Steps: 4202 | Loss: 62.711839\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:39 | Steps: 4204 | Loss: 62.710710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:39 | Steps: 4206 | Loss: 62.712452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:39 | Steps: 4208 | Loss: 62.715059\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:40 | Steps: 4209 | Loss: 62.717226\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:40 | Steps: 4211 | Loss: 62.723617\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:40 | Steps: 4212 | Loss: 62.726230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:40 | Steps: 4213 | Loss: 62.724787\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:40 | Steps: 4215 | Loss: 62.729376\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:40 | Steps: 4217 | Loss: 62.729534\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:40 | Steps: 4219 | Loss: 62.753199\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:41 | Steps: 4220 | Loss: 62.757458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:41 | Steps: 4222 | Loss: 62.761610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:41 | Steps: 4223 | Loss: 62.762246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:41 | Steps: 4225 | Loss: 62.764716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:41 | Steps: 4227 | Loss: 62.772341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:41 | Steps: 4229 | Loss: 62.793085\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:42 | Steps: 4230 | Loss: 62.795731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:42 | Steps: 4232 | Loss: 62.799904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:42 | Steps: 4233 | Loss: 62.799355\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:42 | Steps: 4235 | Loss: 62.797164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:42 | Steps: 4237 | Loss: 62.797366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:42 | Steps: 4239 | Loss: 62.800270\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:42 | Steps: 4240 | Loss: 62.803345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:43 | Steps: 4242 | Loss: 62.815744\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:43 | Steps: 4244 | Loss: 62.826966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:43 | Steps: 4245 | Loss: 62.834316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:43 | Steps: 4247 | Loss: 62.839527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:43 | Steps: 4249 | Loss: 62.852029\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:44 | Steps: 4251 | Loss: 62.855605\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:44 | Steps: 4252 | Loss: 62.855006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:44 | Steps: 4253 | Loss: 62.855121\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:44 | Steps: 4255 | Loss: 62.858896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:44 | Steps: 4257 | Loss: 62.865552\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:44 | Steps: 4259 | Loss: 62.879746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:44 | Steps: 4261 | Loss: 62.896177\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:45 | Steps: 4263 | Loss: 62.900125\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:45 | Steps: 4265 | Loss: 62.891657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:45 | Steps: 4267 | Loss: 62.895717\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:45 | Steps: 4268 | Loss: 62.895310\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:45 | Steps: 4270 | Loss: 62.904555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:45 | Steps: 4272 | Loss: 62.911148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:46 | Steps: 4273 | Loss: 62.913365\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:46 | Steps: 4275 | Loss: 62.916224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:46 | Steps: 4277 | Loss: 62.918724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:46 | Steps: 4279 | Loss: 62.921351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:46 | Steps: 4281 | Loss: 62.923886\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:47 | Steps: 4283 | Loss: 62.928735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:47 | Steps: 4285 | Loss: 62.931955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:47 | Steps: 4286 | Loss: 62.938890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:47 | Steps: 4287 | Loss: 62.936423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:47 | Steps: 4289 | Loss: 62.946577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:47 | Steps: 4290 | Loss: 62.947890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:47 | Steps: 4292 | Loss: 62.958605\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:48 | Steps: 4294 | Loss: 62.979840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:48 | Steps: 4295 | Loss: 62.989024\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:48 | Steps: 4297 | Loss: 63.000090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:48 | Steps: 4299 | Loss: 63.015640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:48 | Steps: 4301 | Loss: 63.020552\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:48 | Steps: 4303 | Loss: 63.026442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:49 | Steps: 4305 | Loss: 63.025036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:49 | Steps: 4307 | Loss: 63.026918\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:49 | Steps: 4308 | Loss: 63.023663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:49 | Steps: 4310 | Loss: 63.036610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:49 | Steps: 4312 | Loss: 63.048019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:49 | Steps: 4313 | Loss: 63.050178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:50 | Steps: 4314 | Loss: 63.048834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:50 | Steps: 4316 | Loss: 63.054925\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:50 | Steps: 4317 | Loss: 63.057673\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:50 | Steps: 4318 | Loss: 63.062116\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:50 | Steps: 4320 | Loss: 63.067512\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:50 | Steps: 4321 | Loss: 63.065498\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:50 | Steps: 4323 | Loss: 63.062736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:50 | Steps: 4324 | Loss: 63.062595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:51 | Steps: 4326 | Loss: 63.062603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:51 | Steps: 4327 | Loss: 63.062557\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:51 | Steps: 4329 | Loss: 63.067161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:51 | Steps: 4331 | Loss: 63.066662\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:51 | Steps: 4333 | Loss: 63.070185\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:52 | Steps: 4335 | Loss: 63.074964\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:52 | Steps: 4336 | Loss: 63.078843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:52 | Steps: 4338 | Loss: 63.088007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:52 | Steps: 4340 | Loss: 63.097013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:52 | Steps: 4342 | Loss: 63.099086\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:52 | Steps: 4344 | Loss: 63.094997\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:52 | Steps: 4345 | Loss: 63.094208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:53 | Steps: 4347 | Loss: 63.093295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:53 | Steps: 4348 | Loss: 63.091516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:53 | Steps: 4349 | Loss: 63.089625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:53 | Steps: 4351 | Loss: 63.103269\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:53 | Steps: 4353 | Loss: 63.119704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:53 | Steps: 4355 | Loss: 63.123490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:54 | Steps: 4357 | Loss: 63.115599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:54 | Steps: 4359 | Loss: 63.115084\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:54 | Steps: 4360 | Loss: 63.116282\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:54 | Steps: 4362 | Loss: 63.115700\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:54 | Steps: 4364 | Loss: 63.105893\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:54 | Steps: 4366 | Loss: 63.105213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:55 | Steps: 4368 | Loss: 63.106115\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:55 | Steps: 4370 | Loss: 63.109675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:55 | Steps: 4371 | Loss: 63.117013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:55 | Steps: 4373 | Loss: 63.115109\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:55 | Steps: 4374 | Loss: 63.121151\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:55 | Steps: 4376 | Loss: 63.152087\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:56 | Steps: 4378 | Loss: 63.160876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:56 | Steps: 4380 | Loss: 63.165600\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:56 | Steps: 4382 | Loss: 63.176683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:56 | Steps: 4383 | Loss: 63.185586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:56 | Steps: 4384 | Loss: 63.191758\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:56 | Steps: 4386 | Loss: 63.202948\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:57 | Steps: 4388 | Loss: 63.202226\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:57 | Steps: 4390 | Loss: 63.196952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:57 | Steps: 4392 | Loss: 63.201605\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:57 | Steps: 4394 | Loss: 63.201126\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:57 | Steps: 4395 | Loss: 63.199377\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:57 | Steps: 4397 | Loss: 63.208741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:57 | Steps: 4398 | Loss: 63.216537\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:58 | Steps: 4400 | Loss: 63.223633\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:58 | Steps: 4401 | Loss: 63.234979\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:58 | Steps: 4402 | Loss: 63.234407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:58 | Steps: 4404 | Loss: 63.243651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:58 | Steps: 4406 | Loss: 63.257160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:58 | Steps: 4407 | Loss: 63.257244\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:59 | Steps: 4409 | Loss: 63.260589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:59 | Steps: 4410 | Loss: 63.265974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:59 | Steps: 4412 | Loss: 63.290876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:59 | Steps: 4414 | Loss: 63.302965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:59 | Steps: 4415 | Loss: 63.306501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:59 | Steps: 4416 | Loss: 63.310738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:59 | Steps: 4417 | Loss: 63.322303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:05:59 | Steps: 4418 | Loss: 63.325579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:00 | Steps: 4420 | Loss: 63.317141\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:00 | Steps: 4422 | Loss: 63.319717\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:00 | Steps: 4423 | Loss: 63.330154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:00 | Steps: 4425 | Loss: 63.340366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:00 | Steps: 4427 | Loss: 63.341021\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:00 | Steps: 4429 | Loss: 63.345864\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:01 | Steps: 4431 | Loss: 63.359260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:01 | Steps: 4433 | Loss: 63.366994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:01 | Steps: 4435 | Loss: 63.378197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:01 | Steps: 4437 | Loss: 63.379827\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:01 | Steps: 4439 | Loss: 63.373047\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:01 | Steps: 4440 | Loss: 63.383196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:02 | Steps: 4442 | Loss: 63.388495\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:02 | Steps: 4444 | Loss: 63.392208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:02 | Steps: 4445 | Loss: 63.391729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:02 | Steps: 4446 | Loss: 63.389399\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:02 | Steps: 4447 | Loss: 63.391410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:02 | Steps: 4449 | Loss: 63.388021\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:03 | Steps: 4451 | Loss: 63.388676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:03 | Steps: 4453 | Loss: 63.398430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:03 | Steps: 4455 | Loss: 63.392865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:03 | Steps: 4457 | Loss: 63.389502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:03 | Steps: 4459 | Loss: 63.395208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:03 | Steps: 4460 | Loss: 63.400954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:03 | Steps: 4461 | Loss: 63.397556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:04 | Steps: 4463 | Loss: 63.395515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:04 | Steps: 4464 | Loss: 63.398679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:04 | Steps: 4466 | Loss: 63.399966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:04 | Steps: 4468 | Loss: 63.407693\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:04 | Steps: 4470 | Loss: 63.405295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:04 | Steps: 4472 | Loss: 63.407296\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:05 | Steps: 4473 | Loss: 63.408828\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:05 | Steps: 4475 | Loss: 63.416432\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:05 | Steps: 4476 | Loss: 63.419922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:05 | Steps: 4477 | Loss: 63.422537\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:05 | Steps: 4479 | Loss: 63.420557\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:05 | Steps: 4480 | Loss: 63.429780\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:05 | Steps: 4481 | Loss: 63.438005\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:06 | Steps: 4482 | Loss: 63.436876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:06 | Steps: 4484 | Loss: 63.445784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:06 | Steps: 4486 | Loss: 63.470080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:06 | Steps: 4487 | Loss: 63.472966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:06 | Steps: 4488 | Loss: 63.478584\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:06 | Steps: 4490 | Loss: 63.474602\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:06 | Steps: 4492 | Loss: 63.475896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:07 | Steps: 4493 | Loss: 63.472093\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:07 | Steps: 4495 | Loss: 63.465028\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:07 | Steps: 4497 | Loss: 63.474697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:07 | Steps: 4499 | Loss: 63.472246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:07 | Steps: 4501 | Loss: 63.478724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:07 | Steps: 4503 | Loss: 63.483888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:08 | Steps: 4505 | Loss: 63.487775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:08 | Steps: 4507 | Loss: 63.484313\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:08 | Steps: 4509 | Loss: 63.485369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:08 | Steps: 4510 | Loss: 63.492319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:08 | Steps: 4511 | Loss: 63.493129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:08 | Steps: 4513 | Loss: 63.494008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:08 | Steps: 4514 | Loss: 63.495208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:09 | Steps: 4516 | Loss: 63.496955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:09 | Steps: 4518 | Loss: 63.498192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:09 | Steps: 4519 | Loss: 63.508874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:09 | Steps: 4521 | Loss: 63.517194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:09 | Steps: 4523 | Loss: 63.515015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:09 | Steps: 4524 | Loss: 63.520641\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:10 | Steps: 4526 | Loss: 63.519383\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:10 | Steps: 4527 | Loss: 63.522000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:10 | Steps: 4529 | Loss: 63.524505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:10 | Steps: 4530 | Loss: 63.530092\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:10 | Steps: 4532 | Loss: 63.531818\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:10 | Steps: 4534 | Loss: 63.546107\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:11 | Steps: 4535 | Loss: 63.548109\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:11 | Steps: 4537 | Loss: 63.542889\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:11 | Steps: 4538 | Loss: 63.540590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:11 | Steps: 4539 | Loss: 63.538991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:11 | Steps: 4541 | Loss: 63.540235\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:11 | Steps: 4543 | Loss: 63.547951\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:11 | Steps: 4545 | Loss: 63.560173\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:12 | Steps: 4547 | Loss: 63.563924\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:12 | Steps: 4549 | Loss: 63.560351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:12 | Steps: 4550 | Loss: 63.560995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:12 | Steps: 4551 | Loss: 63.560164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:12 | Steps: 4553 | Loss: 63.559807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:12 | Steps: 4554 | Loss: 63.557793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:13 | Steps: 4556 | Loss: 63.554248\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:13 | Steps: 4558 | Loss: 63.556052\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:13 | Steps: 4560 | Loss: 63.563006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:13 | Steps: 4562 | Loss: 63.563445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:13 | Steps: 4563 | Loss: 63.561104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:13 | Steps: 4565 | Loss: 63.568599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:14 | Steps: 4567 | Loss: 63.579097\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:14 | Steps: 4568 | Loss: 63.580633\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:14 | Steps: 4569 | Loss: 63.578587\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:14 | Steps: 4571 | Loss: 63.576094\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:14 | Steps: 4573 | Loss: 63.587004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:14 | Steps: 4575 | Loss: 63.593778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:14 | Steps: 4576 | Loss: 63.594705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:14 | Steps: 4577 | Loss: 63.599909\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:15 | Steps: 4578 | Loss: 63.604788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:15 | Steps: 4579 | Loss: 63.625104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:15 | Steps: 4581 | Loss: 63.629350\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:15 | Steps: 4582 | Loss: 63.630065\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:15 | Steps: 4584 | Loss: 63.623242\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:15 | Steps: 4585 | Loss: 63.622803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:15 | Steps: 4587 | Loss: 63.628936\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:16 | Steps: 4588 | Loss: 63.629233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:16 | Steps: 4590 | Loss: 63.629246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:16 | Steps: 4592 | Loss: 63.635523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:16 | Steps: 4593 | Loss: 63.642693\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:16 | Steps: 4595 | Loss: 63.654791\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:16 | Steps: 4597 | Loss: 63.659618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:17 | Steps: 4599 | Loss: 63.668190\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:17 | Steps: 4601 | Loss: 63.677158\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:17 | Steps: 4602 | Loss: 63.681380\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:17 | Steps: 4604 | Loss: 63.685993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:17 | Steps: 4606 | Loss: 63.695634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:17 | Steps: 4608 | Loss: 63.706946\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:18 | Steps: 4610 | Loss: 63.708757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:18 | Steps: 4611 | Loss: 63.714781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:18 | Steps: 4613 | Loss: 63.725658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:18 | Steps: 4615 | Loss: 63.722720\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:18 | Steps: 4617 | Loss: 63.725770\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:19 | Steps: 4618 | Loss: 63.725123\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:19 | Steps: 4619 | Loss: 63.731190\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:19 | Steps: 4620 | Loss: 63.738645\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:19 | Steps: 4622 | Loss: 63.752296\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:19 | Steps: 4624 | Loss: 63.762410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:19 | Steps: 4626 | Loss: 63.771857\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:19 | Steps: 4627 | Loss: 63.775373\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:20 | Steps: 4629 | Loss: 63.777711\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:20 | Steps: 4630 | Loss: 63.773429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:20 | Steps: 4632 | Loss: 63.795599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:20 | Steps: 4634 | Loss: 63.798582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:20 | Steps: 4636 | Loss: 63.804025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:20 | Steps: 4638 | Loss: 63.808771\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:21 | Steps: 4640 | Loss: 63.801700\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:21 | Steps: 4641 | Loss: 63.807003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:21 | Steps: 4643 | Loss: 63.805048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:21 | Steps: 4645 | Loss: 63.810093\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:21 | Steps: 4646 | Loss: 63.809024\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:21 | Steps: 4648 | Loss: 63.809563\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:22 | Steps: 4649 | Loss: 63.810159\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:22 | Steps: 4650 | Loss: 63.812577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:22 | Steps: 4652 | Loss: 63.815776\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:22 | Steps: 4654 | Loss: 63.813208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:22 | Steps: 4656 | Loss: 63.811659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:22 | Steps: 4658 | Loss: 63.821037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:22 | Steps: 4659 | Loss: 63.822776\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:23 | Steps: 4661 | Loss: 63.834698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:23 | Steps: 4662 | Loss: 63.833689\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:23 | Steps: 4663 | Loss: 63.842678\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:23 | Steps: 4664 | Loss: 63.854652\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:23 | Steps: 4666 | Loss: 63.859819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:23 | Steps: 4668 | Loss: 63.864728\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:24 | Steps: 4670 | Loss: 63.883326\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:24 | Steps: 4672 | Loss: 63.887613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:24 | Steps: 4674 | Loss: 63.887051\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:24 | Steps: 4675 | Loss: 63.882160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:24 | Steps: 4676 | Loss: 63.876357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:24 | Steps: 4678 | Loss: 63.876732\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:24 | Steps: 4680 | Loss: 63.877415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:25 | Steps: 4682 | Loss: 63.884166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:25 | Steps: 4683 | Loss: 63.886900\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:25 | Steps: 4684 | Loss: 63.891492\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:25 | Steps: 4685 | Loss: 63.891845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:25 | Steps: 4687 | Loss: 63.896539\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:25 | Steps: 4689 | Loss: 63.897238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:25 | Steps: 4691 | Loss: 63.894736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:26 | Steps: 4692 | Loss: 63.899877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:26 | Steps: 4694 | Loss: 63.894285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:26 | Steps: 4696 | Loss: 63.902150\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:26 | Steps: 4697 | Loss: 63.912442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:26 | Steps: 4699 | Loss: 63.928348\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:26 | Steps: 4700 | Loss: 63.926266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:27 | Steps: 4702 | Loss: 63.927396\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:27 | Steps: 4704 | Loss: 63.929566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:27 | Steps: 4706 | Loss: 63.934846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:27 | Steps: 4707 | Loss: 63.940099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:27 | Steps: 4709 | Loss: 63.951762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:27 | Steps: 4711 | Loss: 63.955400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:28 | Steps: 4712 | Loss: 63.958788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:28 | Steps: 4713 | Loss: 63.962514\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:28 | Steps: 4714 | Loss: 63.965348\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:28 | Steps: 4716 | Loss: 63.970132\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:28 | Steps: 4717 | Loss: 63.968055\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:28 | Steps: 4719 | Loss: 63.965154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:28 | Steps: 4720 | Loss: 63.961912\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:29 | Steps: 4722 | Loss: 63.961366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:29 | Steps: 4724 | Loss: 63.961082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:29 | Steps: 4725 | Loss: 63.961273\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:29 | Steps: 4727 | Loss: 63.975073\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:29 | Steps: 4729 | Loss: 63.980013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:29 | Steps: 4731 | Loss: 63.974353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:30 | Steps: 4732 | Loss: 63.978013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:30 | Steps: 4733 | Loss: 63.978592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:30 | Steps: 4735 | Loss: 63.981814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:30 | Steps: 4736 | Loss: 63.982342\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:30 | Steps: 4738 | Loss: 63.978292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:30 | Steps: 4740 | Loss: 63.982156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:30 | Steps: 4741 | Loss: 63.981049\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:31 | Steps: 4742 | Loss: 63.980633\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:31 | Steps: 4744 | Loss: 63.986020\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:31 | Steps: 4745 | Loss: 63.990740\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:31 | Steps: 4747 | Loss: 63.991818\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:31 | Steps: 4748 | Loss: 63.989579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:31 | Steps: 4750 | Loss: 64.003990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:32 | Steps: 4752 | Loss: 64.010739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:32 | Steps: 4753 | Loss: 64.011981\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:32 | Steps: 4755 | Loss: 64.013374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:32 | Steps: 4757 | Loss: 64.027617\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:32 | Steps: 4758 | Loss: 64.026447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:32 | Steps: 4759 | Loss: 64.026752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:32 | Steps: 4761 | Loss: 64.036200\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:33 | Steps: 4762 | Loss: 64.035854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:33 | Steps: 4764 | Loss: 64.038308\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:33 | Steps: 4765 | Loss: 64.043286\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:33 | Steps: 4766 | Loss: 64.043167\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:33 | Steps: 4768 | Loss: 64.045768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:33 | Steps: 4770 | Loss: 64.046624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:33 | Steps: 4771 | Loss: 64.048857\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:34 | Steps: 4773 | Loss: 64.056975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:34 | Steps: 4775 | Loss: 64.063865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:34 | Steps: 4776 | Loss: 64.080702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:34 | Steps: 4778 | Loss: 64.088977\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:34 | Steps: 4780 | Loss: 64.093267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:34 | Steps: 4781 | Loss: 64.097185\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:35 | Steps: 4783 | Loss: 64.101465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:35 | Steps: 4785 | Loss: 64.112187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:35 | Steps: 4787 | Loss: 64.115613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:35 | Steps: 4788 | Loss: 64.120036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:35 | Steps: 4790 | Loss: 64.115846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:35 | Steps: 4792 | Loss: 64.123167\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:36 | Steps: 4793 | Loss: 64.127233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:36 | Steps: 4795 | Loss: 64.131534\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:36 | Steps: 4797 | Loss: 64.141406\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:36 | Steps: 4799 | Loss: 64.156589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:36 | Steps: 4801 | Loss: 64.165842\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:36 | Steps: 4802 | Loss: 64.163142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:37 | Steps: 4804 | Loss: 64.180120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:37 | Steps: 4806 | Loss: 64.189512\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:37 | Steps: 4807 | Loss: 64.187428\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:37 | Steps: 4809 | Loss: 64.186110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:37 | Steps: 4811 | Loss: 64.183891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:37 | Steps: 4812 | Loss: 64.182793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:38 | Steps: 4813 | Loss: 64.177607\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:38 | Steps: 4815 | Loss: 64.182836\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:38 | Steps: 4816 | Loss: 64.184294\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:38 | Steps: 4818 | Loss: 64.183230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:38 | Steps: 4819 | Loss: 64.183233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:38 | Steps: 4820 | Loss: 64.185590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:38 | Steps: 4821 | Loss: 64.185161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:38 | Steps: 4823 | Loss: 64.187644\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:39 | Steps: 4824 | Loss: 64.188904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:39 | Steps: 4825 | Loss: 64.190746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:39 | Steps: 4826 | Loss: 64.191032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:39 | Steps: 4827 | Loss: 64.189851\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:39 | Steps: 4829 | Loss: 64.189789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:39 | Steps: 4831 | Loss: 64.188024\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:39 | Steps: 4833 | Loss: 64.191611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:40 | Steps: 4835 | Loss: 64.195857\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:40 | Steps: 4836 | Loss: 64.209006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:40 | Steps: 4838 | Loss: 64.220947\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:40 | Steps: 4840 | Loss: 64.240173\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:40 | Steps: 4842 | Loss: 64.248593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:40 | Steps: 4843 | Loss: 64.252437\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:41 | Steps: 4845 | Loss: 64.250427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:41 | Steps: 4847 | Loss: 64.243298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:41 | Steps: 4848 | Loss: 64.240868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:41 | Steps: 4849 | Loss: 64.239840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:41 | Steps: 4851 | Loss: 64.246225\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:41 | Steps: 4853 | Loss: 64.244427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:42 | Steps: 4855 | Loss: 64.245862\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:42 | Steps: 4857 | Loss: 64.245730\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:42 | Steps: 4858 | Loss: 64.244208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:42 | Steps: 4859 | Loss: 64.243465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:42 | Steps: 4860 | Loss: 64.245344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:42 | Steps: 4862 | Loss: 64.247658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:42 | Steps: 4864 | Loss: 64.250363\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:43 | Steps: 4866 | Loss: 64.256201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:43 | Steps: 4867 | Loss: 64.261820\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:43 | Steps: 4868 | Loss: 64.275469\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:43 | Steps: 4870 | Loss: 64.281204\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:43 | Steps: 4871 | Loss: 64.282132\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:43 | Steps: 4872 | Loss: 64.283243\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:43 | Steps: 4873 | Loss: 64.290476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:44 | Steps: 4875 | Loss: 64.301050\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:44 | Steps: 4877 | Loss: 64.314807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:44 | Steps: 4879 | Loss: 64.313879\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:44 | Steps: 4880 | Loss: 64.313879\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:44 | Steps: 4882 | Loss: 64.310710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:44 | Steps: 4884 | Loss: 64.318441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:45 | Steps: 4885 | Loss: 64.322136\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:45 | Steps: 4887 | Loss: 64.332441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:45 | Steps: 4889 | Loss: 64.342540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:45 | Steps: 4891 | Loss: 64.345866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:45 | Steps: 4893 | Loss: 64.341895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:46 | Steps: 4894 | Loss: 64.344555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:46 | Steps: 4896 | Loss: 64.342050\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:46 | Steps: 4898 | Loss: 64.345586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:46 | Steps: 4899 | Loss: 64.347347\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:46 | Steps: 4900 | Loss: 64.344801\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:46 | Steps: 4901 | Loss: 64.342907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:46 | Steps: 4903 | Loss: 64.340369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:47 | Steps: 4904 | Loss: 64.346792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:47 | Steps: 4906 | Loss: 64.351649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:47 | Steps: 4907 | Loss: 64.350418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:47 | Steps: 4908 | Loss: 64.359750\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:47 | Steps: 4910 | Loss: 64.375556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:47 | Steps: 4912 | Loss: 64.392517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:47 | Steps: 4913 | Loss: 64.395435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:48 | Steps: 4915 | Loss: 64.398381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:48 | Steps: 4917 | Loss: 64.408539\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:48 | Steps: 4918 | Loss: 64.410233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:48 | Steps: 4919 | Loss: 64.410397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:48 | Steps: 4921 | Loss: 64.409963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:48 | Steps: 4922 | Loss: 64.408910\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:48 | Steps: 4923 | Loss: 64.411930\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:49 | Steps: 4925 | Loss: 64.418664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:49 | Steps: 4927 | Loss: 64.417211\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:49 | Steps: 4929 | Loss: 64.419802\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:49 | Steps: 4931 | Loss: 64.434797\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:49 | Steps: 4932 | Loss: 64.434016\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:49 | Steps: 4933 | Loss: 64.435257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:49 | Steps: 4934 | Loss: 64.442710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:50 | Steps: 4936 | Loss: 64.453894\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:50 | Steps: 4938 | Loss: 64.461733\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:50 | Steps: 4940 | Loss: 64.467862\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:50 | Steps: 4941 | Loss: 64.469576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:50 | Steps: 4943 | Loss: 64.469971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:50 | Steps: 4944 | Loss: 64.471345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:51 | Steps: 4945 | Loss: 64.470162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:51 | Steps: 4946 | Loss: 64.468576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:51 | Steps: 4948 | Loss: 64.479379\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:51 | Steps: 4950 | Loss: 64.475374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:51 | Steps: 4952 | Loss: 64.479819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:51 | Steps: 4953 | Loss: 64.479407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:52 | Steps: 4955 | Loss: 64.484228\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:52 | Steps: 4957 | Loss: 64.490924\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:52 | Steps: 4959 | Loss: 64.509736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:52 | Steps: 4961 | Loss: 64.509977\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:52 | Steps: 4962 | Loss: 64.507682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:52 | Steps: 4963 | Loss: 64.513281\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:53 | Steps: 4965 | Loss: 64.520640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:53 | Steps: 4967 | Loss: 64.521580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:53 | Steps: 4968 | Loss: 64.521272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:53 | Steps: 4969 | Loss: 64.527363\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:53 | Steps: 4970 | Loss: 64.531344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:53 | Steps: 4972 | Loss: 64.531097\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:53 | Steps: 4973 | Loss: 64.543051\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:54 | Steps: 4974 | Loss: 64.544903\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:54 | Steps: 4975 | Loss: 64.545729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:54 | Steps: 4977 | Loss: 64.557773\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:54 | Steps: 4978 | Loss: 64.562415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:54 | Steps: 4980 | Loss: 64.561840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:54 | Steps: 4981 | Loss: 64.566220\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:54 | Steps: 4983 | Loss: 64.568588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:55 | Steps: 4984 | Loss: 64.571676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:55 | Steps: 4986 | Loss: 64.574397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:55 | Steps: 4988 | Loss: 64.574279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:55 | Steps: 4990 | Loss: 64.578400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:55 | Steps: 4991 | Loss: 64.581255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:55 | Steps: 4992 | Loss: 64.582472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:56 | Steps: 4994 | Loss: 64.589403\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:56 | Steps: 4995 | Loss: 64.595634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:56 | Steps: 4997 | Loss: 64.600806\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:56 | Steps: 4998 | Loss: 64.612506\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:56 | Steps: 4999 | Loss: 64.621398\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:56 | Steps: 5000 | Loss: 64.624378\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:56 | Steps: 5002 | Loss: 64.627758\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:57 | Steps: 5003 | Loss: 64.626012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:57 | Steps: 5004 | Loss: 64.624440\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:57 | Steps: 5006 | Loss: 64.629142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:57 | Steps: 5008 | Loss: 64.620931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:57 | Steps: 5009 | Loss: 64.619487\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:57 | Steps: 5011 | Loss: 64.623786\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:57 | Steps: 5012 | Loss: 64.627126\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:58 | Steps: 5013 | Loss: 64.628627\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:58 | Steps: 5014 | Loss: 64.629202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:58 | Steps: 5015 | Loss: 64.630387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:58 | Steps: 5017 | Loss: 64.631870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:58 | Steps: 5018 | Loss: 64.633179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:58 | Steps: 5019 | Loss: 64.635824\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:58 | Steps: 5021 | Loss: 64.639790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:58 | Steps: 5022 | Loss: 64.639730\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:59 | Steps: 5024 | Loss: 64.652033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:59 | Steps: 5026 | Loss: 64.653699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:59 | Steps: 5027 | Loss: 64.655741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:59 | Steps: 5029 | Loss: 64.660287\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:59 | Steps: 5031 | Loss: 64.659873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:59 | Steps: 5032 | Loss: 64.665507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:06:59 | Steps: 5033 | Loss: 64.672435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:00 | Steps: 5034 | Loss: 64.673999\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:00 | Steps: 5036 | Loss: 64.687263\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:00 | Steps: 5037 | Loss: 64.686561\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:00 | Steps: 5039 | Loss: 64.686686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:00 | Steps: 5041 | Loss: 64.688819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:00 | Steps: 5042 | Loss: 64.689577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:01 | Steps: 5043 | Loss: 64.692724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:01 | Steps: 5045 | Loss: 64.698360\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:01 | Steps: 5046 | Loss: 64.703030\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:01 | Steps: 5048 | Loss: 64.707295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:01 | Steps: 5050 | Loss: 64.702965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:01 | Steps: 5051 | Loss: 64.701089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:01 | Steps: 5053 | Loss: 64.700267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:02 | Steps: 5055 | Loss: 64.695417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:02 | Steps: 5056 | Loss: 64.698787\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:02 | Steps: 5058 | Loss: 64.701089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:02 | Steps: 5059 | Loss: 64.701899\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:02 | Steps: 5060 | Loss: 64.698103\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:02 | Steps: 5061 | Loss: 64.692743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:02 | Steps: 5062 | Loss: 64.687929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:03 | Steps: 5063 | Loss: 64.687510\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:03 | Steps: 5065 | Loss: 64.683145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:03 | Steps: 5067 | Loss: 64.678119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:03 | Steps: 5069 | Loss: 64.675621\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:03 | Steps: 5071 | Loss: 64.676387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:03 | Steps: 5072 | Loss: 64.676723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:03 | Steps: 5073 | Loss: 64.676889\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:04 | Steps: 5075 | Loss: 64.682653\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:04 | Steps: 5076 | Loss: 64.686475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:04 | Steps: 5077 | Loss: 64.685902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:04 | Steps: 5079 | Loss: 64.694679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:04 | Steps: 5081 | Loss: 64.701599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:04 | Steps: 5083 | Loss: 64.710510\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:05 | Steps: 5085 | Loss: 64.729365\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:05 | Steps: 5086 | Loss: 64.731789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:05 | Steps: 5088 | Loss: 64.735203\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:05 | Steps: 5089 | Loss: 64.734095\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:05 | Steps: 5091 | Loss: 64.735926\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:05 | Steps: 5092 | Loss: 64.740239\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:06 | Steps: 5093 | Loss: 64.745756\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:06 | Steps: 5094 | Loss: 64.750004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:06 | Steps: 5096 | Loss: 64.746651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:06 | Steps: 5098 | Loss: 64.748407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:06 | Steps: 5100 | Loss: 64.751271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:06 | Steps: 5101 | Loss: 64.750982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:07 | Steps: 5103 | Loss: 64.766191\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:07 | Steps: 5104 | Loss: 64.769031\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:07 | Steps: 5105 | Loss: 64.777528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:07 | Steps: 5107 | Loss: 64.785505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:07 | Steps: 5109 | Loss: 64.796032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:07 | Steps: 5110 | Loss: 64.799855\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:07 | Steps: 5111 | Loss: 64.802491\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:07 | Steps: 5112 | Loss: 64.802761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:08 | Steps: 5113 | Loss: 64.805864\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:08 | Steps: 5115 | Loss: 64.813493\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:08 | Steps: 5117 | Loss: 64.819228\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:08 | Steps: 5118 | Loss: 64.819989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:08 | Steps: 5120 | Loss: 64.821646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:08 | Steps: 5121 | Loss: 64.821551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:08 | Steps: 5122 | Loss: 64.818778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:09 | Steps: 5123 | Loss: 64.822127\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:09 | Steps: 5125 | Loss: 64.820254\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:09 | Steps: 5126 | Loss: 64.819216\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:09 | Steps: 5128 | Loss: 64.819179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:09 | Steps: 5130 | Loss: 64.826078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:09 | Steps: 5131 | Loss: 64.828562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:09 | Steps: 5132 | Loss: 64.834358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:10 | Steps: 5134 | Loss: 64.842945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:10 | Steps: 5135 | Loss: 64.850894\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:10 | Steps: 5137 | Loss: 64.864226\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:10 | Steps: 5138 | Loss: 64.866719\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:10 | Steps: 5139 | Loss: 64.864929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:10 | Steps: 5140 | Loss: 64.863824\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:10 | Steps: 5142 | Loss: 64.880689\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:11 | Steps: 5143 | Loss: 64.885013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:11 | Steps: 5144 | Loss: 64.886359\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:11 | Steps: 5146 | Loss: 64.884947\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:11 | Steps: 5148 | Loss: 64.883032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:11 | Steps: 5150 | Loss: 64.887696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:11 | Steps: 5151 | Loss: 64.896475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:11 | Steps: 5152 | Loss: 64.901565\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:12 | Steps: 5153 | Loss: 64.901404\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:12 | Steps: 5154 | Loss: 64.908264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:12 | Steps: 5155 | Loss: 64.913274\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:12 | Steps: 5157 | Loss: 64.913198\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:12 | Steps: 5159 | Loss: 64.912216\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:12 | Steps: 5161 | Loss: 64.908350\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:12 | Steps: 5162 | Loss: 64.913143\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:13 | Steps: 5163 | Loss: 64.913040\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:13 | Steps: 5164 | Loss: 64.915870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:13 | Steps: 5166 | Loss: 64.922750\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:13 | Steps: 5167 | Loss: 64.924652\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:13 | Steps: 5168 | Loss: 64.926569\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:13 | Steps: 5170 | Loss: 64.939458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:13 | Steps: 5172 | Loss: 64.945936\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:14 | Steps: 5174 | Loss: 64.948496\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:14 | Steps: 5175 | Loss: 64.947884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:14 | Steps: 5177 | Loss: 64.954913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:14 | Steps: 5179 | Loss: 64.952419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:14 | Steps: 5180 | Loss: 64.955638\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:14 | Steps: 5182 | Loss: 64.967410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:15 | Steps: 5183 | Loss: 64.966559\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:15 | Steps: 5184 | Loss: 64.966589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:15 | Steps: 5185 | Loss: 64.972845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:15 | Steps: 5186 | Loss: 64.983164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:15 | Steps: 5187 | Loss: 64.984937\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:15 | Steps: 5189 | Loss: 64.987754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:15 | Steps: 5190 | Loss: 64.987322\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:15 | Steps: 5191 | Loss: 64.989999\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:16 | Steps: 5193 | Loss: 64.996154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:16 | Steps: 5194 | Loss: 64.991040\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:16 | Steps: 5196 | Loss: 64.983895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:16 | Steps: 5198 | Loss: 64.995901\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:16 | Steps: 5199 | Loss: 64.992080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:16 | Steps: 5201 | Loss: 64.992579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:16 | Steps: 5202 | Loss: 64.992884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:17 | Steps: 5203 | Loss: 64.998319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:17 | Steps: 5205 | Loss: 65.009554\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:17 | Steps: 5207 | Loss: 65.009303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:17 | Steps: 5208 | Loss: 65.009079\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:17 | Steps: 5210 | Loss: 65.013132\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:17 | Steps: 5212 | Loss: 65.019260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:18 | Steps: 5213 | Loss: 65.019955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:18 | Steps: 5215 | Loss: 65.020640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:18 | Steps: 5217 | Loss: 65.026850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:18 | Steps: 5218 | Loss: 65.026997\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:18 | Steps: 5220 | Loss: 65.044409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:18 | Steps: 5221 | Loss: 65.039084\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:18 | Steps: 5222 | Loss: 65.045668\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:19 | Steps: 5224 | Loss: 65.040596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:19 | Steps: 5226 | Loss: 65.041586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:19 | Steps: 5227 | Loss: 65.042067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:19 | Steps: 5228 | Loss: 65.048986\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:19 | Steps: 5229 | Loss: 65.056140\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:19 | Steps: 5230 | Loss: 65.062438\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:19 | Steps: 5232 | Loss: 65.059317\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:20 | Steps: 5233 | Loss: 65.057866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:20 | Steps: 5234 | Loss: 65.054699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:20 | Steps: 5236 | Loss: 65.053669\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:20 | Steps: 5238 | Loss: 65.047461\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:20 | Steps: 5239 | Loss: 65.045944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:20 | Steps: 5240 | Loss: 65.056706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:20 | Steps: 5241 | Loss: 65.061842\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:21 | Steps: 5242 | Loss: 65.069674\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:21 | Steps: 5243 | Loss: 65.075181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:21 | Steps: 5244 | Loss: 65.079220\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:21 | Steps: 5246 | Loss: 65.073927\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:21 | Steps: 5247 | Loss: 65.069710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:21 | Steps: 5249 | Loss: 65.068216\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:21 | Steps: 5250 | Loss: 65.068729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:21 | Steps: 5251 | Loss: 65.069318\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:22 | Steps: 5253 | Loss: 65.073911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:22 | Steps: 5255 | Loss: 65.068206\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:22 | Steps: 5257 | Loss: 65.070753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:22 | Steps: 5258 | Loss: 65.069730\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:22 | Steps: 5260 | Loss: 65.080530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:22 | Steps: 5262 | Loss: 65.088471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:23 | Steps: 5263 | Loss: 65.100068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:23 | Steps: 5264 | Loss: 65.099479\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:23 | Steps: 5266 | Loss: 65.100503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:23 | Steps: 5267 | Loss: 65.102670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:23 | Steps: 5269 | Loss: 65.101081\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:23 | Steps: 5271 | Loss: 65.104537\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:24 | Steps: 5273 | Loss: 65.110229\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:24 | Steps: 5274 | Loss: 65.111380\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:24 | Steps: 5275 | Loss: 65.113754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:24 | Steps: 5277 | Loss: 65.123715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:24 | Steps: 5278 | Loss: 65.130796\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:24 | Steps: 5279 | Loss: 65.132458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:24 | Steps: 5281 | Loss: 65.131199\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:25 | Steps: 5283 | Loss: 65.132090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:25 | Steps: 5284 | Loss: 65.133374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:25 | Steps: 5285 | Loss: 65.139424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:25 | Steps: 5286 | Loss: 65.142749\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:25 | Steps: 5288 | Loss: 65.141892\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:25 | Steps: 5290 | Loss: 65.148165\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:25 | Steps: 5291 | Loss: 65.150990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:26 | Steps: 5293 | Loss: 65.159782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:26 | Steps: 5295 | Loss: 65.170531\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:26 | Steps: 5296 | Loss: 65.179852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:26 | Steps: 5298 | Loss: 65.186672\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:26 | Steps: 5299 | Loss: 65.190425\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:26 | Steps: 5300 | Loss: 65.194013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:26 | Steps: 5301 | Loss: 65.195462\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:27 | Steps: 5303 | Loss: 65.205156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:27 | Steps: 5304 | Loss: 65.206594\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:27 | Steps: 5306 | Loss: 65.212833\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:27 | Steps: 5308 | Loss: 65.214221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:27 | Steps: 5309 | Loss: 65.215152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:27 | Steps: 5310 | Loss: 65.216332\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:27 | Steps: 5311 | Loss: 65.219815\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:28 | Steps: 5312 | Loss: 65.224854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:28 | Steps: 5314 | Loss: 65.228552\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:28 | Steps: 5315 | Loss: 65.226735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:28 | Steps: 5317 | Loss: 65.236237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:28 | Steps: 5318 | Loss: 65.241754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:28 | Steps: 5320 | Loss: 65.252183\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:28 | Steps: 5321 | Loss: 65.256204\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:29 | Steps: 5322 | Loss: 65.250881\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:29 | Steps: 5324 | Loss: 65.266023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:29 | Steps: 5326 | Loss: 65.268045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:29 | Steps: 5327 | Loss: 65.267410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:29 | Steps: 5328 | Loss: 65.267766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:29 | Steps: 5330 | Loss: 65.266195\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:30 | Steps: 5332 | Loss: 65.280036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:30 | Steps: 5334 | Loss: 65.273867\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:30 | Steps: 5335 | Loss: 65.274119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:30 | Steps: 5337 | Loss: 65.276179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:30 | Steps: 5339 | Loss: 65.278316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:30 | Steps: 5340 | Loss: 65.277726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:31 | Steps: 5342 | Loss: 65.278784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:31 | Steps: 5343 | Loss: 65.284134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:31 | Steps: 5344 | Loss: 65.285089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:31 | Steps: 5345 | Loss: 65.286461\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:31 | Steps: 5347 | Loss: 65.288120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:31 | Steps: 5348 | Loss: 65.287210\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:31 | Steps: 5350 | Loss: 65.292841\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:32 | Steps: 5352 | Loss: 65.299500\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:32 | Steps: 5353 | Loss: 65.303452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:32 | Steps: 5354 | Loss: 65.305879\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:32 | Steps: 5355 | Loss: 65.305976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:32 | Steps: 5357 | Loss: 65.322787\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:32 | Steps: 5358 | Loss: 65.328638\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:32 | Steps: 5359 | Loss: 65.328043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:32 | Steps: 5360 | Loss: 65.331366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:33 | Steps: 5361 | Loss: 65.339157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:33 | Steps: 5362 | Loss: 65.341159\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:33 | Steps: 5363 | Loss: 65.341553\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:33 | Steps: 5365 | Loss: 65.343670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:33 | Steps: 5367 | Loss: 65.346527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:33 | Steps: 5368 | Loss: 65.352084\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:33 | Steps: 5370 | Loss: 65.344364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:33 | Steps: 5371 | Loss: 65.347090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:34 | Steps: 5372 | Loss: 65.346762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:34 | Steps: 5374 | Loss: 65.360391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:34 | Steps: 5375 | Loss: 65.358093\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:34 | Steps: 5377 | Loss: 65.363459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:34 | Steps: 5378 | Loss: 65.364651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:34 | Steps: 5379 | Loss: 65.368438\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:34 | Steps: 5380 | Loss: 65.368605\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:35 | Steps: 5382 | Loss: 65.368422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:35 | Steps: 5383 | Loss: 65.370069\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:35 | Steps: 5384 | Loss: 65.375454\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:35 | Steps: 5385 | Loss: 65.373407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:35 | Steps: 5386 | Loss: 65.374371\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:35 | Steps: 5387 | Loss: 65.377528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:35 | Steps: 5389 | Loss: 65.384157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:36 | Steps: 5391 | Loss: 65.398385\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:36 | Steps: 5392 | Loss: 65.396377\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:36 | Steps: 5394 | Loss: 65.397204\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:36 | Steps: 5396 | Loss: 65.397233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:36 | Steps: 5397 | Loss: 65.397974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:36 | Steps: 5399 | Loss: 65.404169\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:37 | Steps: 5400 | Loss: 65.410731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:37 | Steps: 5402 | Loss: 65.416053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:37 | Steps: 5404 | Loss: 65.409908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:37 | Steps: 5406 | Loss: 65.411036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:37 | Steps: 5407 | Loss: 65.419420\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:37 | Steps: 5409 | Loss: 65.425664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:38 | Steps: 5410 | Loss: 65.428647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:38 | Steps: 5411 | Loss: 65.432697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:38 | Steps: 5413 | Loss: 65.431467\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:38 | Steps: 5415 | Loss: 65.433195\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:38 | Steps: 5417 | Loss: 65.436004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:39 | Steps: 5419 | Loss: 65.435784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:39 | Steps: 5421 | Loss: 65.432333\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:39 | Steps: 5422 | Loss: 65.435025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:39 | Steps: 5423 | Loss: 65.436203\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:39 | Steps: 5425 | Loss: 65.437579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:39 | Steps: 5426 | Loss: 65.436338\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:40 | Steps: 5428 | Loss: 65.440193\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:40 | Steps: 5429 | Loss: 65.442964\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:40 | Steps: 5431 | Loss: 65.472324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:40 | Steps: 5432 | Loss: 65.475437\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:40 | Steps: 5434 | Loss: 65.490516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:40 | Steps: 5435 | Loss: 65.493008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:40 | Steps: 5436 | Loss: 65.494051\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:40 | Steps: 5437 | Loss: 65.491801\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:41 | Steps: 5438 | Loss: 65.491037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:41 | Steps: 5440 | Loss: 65.490540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:41 | Steps: 5441 | Loss: 65.490051\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:41 | Steps: 5442 | Loss: 65.491690\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:41 | Steps: 5444 | Loss: 65.500168\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:41 | Steps: 5445 | Loss: 65.505657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:41 | Steps: 5446 | Loss: 65.509589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:41 | Steps: 5447 | Loss: 65.508852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:42 | Steps: 5448 | Loss: 65.513896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:42 | Steps: 5450 | Loss: 65.520157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:42 | Steps: 5452 | Loss: 65.524359\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:42 | Steps: 5454 | Loss: 65.532006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:42 | Steps: 5455 | Loss: 65.532704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:42 | Steps: 5457 | Loss: 65.546541\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:43 | Steps: 5459 | Loss: 65.548764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:43 | Steps: 5461 | Loss: 65.550279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:43 | Steps: 5463 | Loss: 65.561162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:43 | Steps: 5464 | Loss: 65.557071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:43 | Steps: 5465 | Loss: 65.555694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:43 | Steps: 5466 | Loss: 65.556701\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:43 | Steps: 5467 | Loss: 65.556887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:44 | Steps: 5468 | Loss: 65.560544\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:44 | Steps: 5470 | Loss: 65.567026\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:44 | Steps: 5471 | Loss: 65.573371\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:44 | Steps: 5473 | Loss: 65.575965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:44 | Steps: 5475 | Loss: 65.591288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:44 | Steps: 5477 | Loss: 65.591466\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:45 | Steps: 5478 | Loss: 65.591781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:45 | Steps: 5479 | Loss: 65.590735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:45 | Steps: 5481 | Loss: 65.602207\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:45 | Steps: 5482 | Loss: 65.597775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:45 | Steps: 5484 | Loss: 65.594212\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:45 | Steps: 5485 | Loss: 65.599167\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:45 | Steps: 5486 | Loss: 65.605359\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:45 | Steps: 5487 | Loss: 65.605345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:46 | Steps: 5489 | Loss: 65.602809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:46 | Steps: 5490 | Loss: 65.605702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:46 | Steps: 5491 | Loss: 65.609278\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:46 | Steps: 5492 | Loss: 65.611192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:46 | Steps: 5493 | Loss: 65.612726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:46 | Steps: 5494 | Loss: 65.612571\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:46 | Steps: 5495 | Loss: 65.610939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:47 | Steps: 5497 | Loss: 65.613032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:47 | Steps: 5498 | Loss: 65.615716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:47 | Steps: 5500 | Loss: 65.614016\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:47 | Steps: 5501 | Loss: 65.612994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:47 | Steps: 5503 | Loss: 65.612560\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:47 | Steps: 5504 | Loss: 65.615376\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:47 | Steps: 5505 | Loss: 65.615831\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:48 | Steps: 5507 | Loss: 65.622423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:48 | Steps: 5508 | Loss: 65.626618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:48 | Steps: 5510 | Loss: 65.636304\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:48 | Steps: 5512 | Loss: 65.640100\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:48 | Steps: 5514 | Loss: 65.642048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:48 | Steps: 5515 | Loss: 65.644255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:49 | Steps: 5517 | Loss: 65.648217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:49 | Steps: 5518 | Loss: 65.644226\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:49 | Steps: 5519 | Loss: 65.640830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:49 | Steps: 5521 | Loss: 65.639151\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:49 | Steps: 5522 | Loss: 65.640971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:49 | Steps: 5523 | Loss: 65.645478\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:49 | Steps: 5525 | Loss: 65.649628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:50 | Steps: 5527 | Loss: 65.651026\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:50 | Steps: 5528 | Loss: 65.653593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:50 | Steps: 5529 | Loss: 65.653255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:50 | Steps: 5531 | Loss: 65.667424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:50 | Steps: 5533 | Loss: 65.670891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:50 | Steps: 5534 | Loss: 65.671262\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:50 | Steps: 5535 | Loss: 65.673897\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:50 | Steps: 5536 | Loss: 65.671502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:51 | Steps: 5537 | Loss: 65.668811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:51 | Steps: 5539 | Loss: 65.678255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:51 | Steps: 5540 | Loss: 65.687030\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:51 | Steps: 5542 | Loss: 65.690400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:51 | Steps: 5543 | Loss: 65.692451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:51 | Steps: 5544 | Loss: 65.691833\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:51 | Steps: 5546 | Loss: 65.694405\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:52 | Steps: 5547 | Loss: 65.698523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:52 | Steps: 5549 | Loss: 65.696720\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:52 | Steps: 5550 | Loss: 65.694839\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:52 | Steps: 5551 | Loss: 65.693043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:52 | Steps: 5553 | Loss: 65.688252\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:52 | Steps: 5554 | Loss: 65.687453\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:52 | Steps: 5555 | Loss: 65.686629\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:53 | Steps: 5557 | Loss: 65.687345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:53 | Steps: 5558 | Loss: 65.691439\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:53 | Steps: 5559 | Loss: 65.698555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:53 | Steps: 5561 | Loss: 65.705675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:53 | Steps: 5562 | Loss: 65.702181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:53 | Steps: 5564 | Loss: 65.698968\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:54 | Steps: 5565 | Loss: 65.701680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:54 | Steps: 5567 | Loss: 65.702768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:54 | Steps: 5569 | Loss: 65.701200\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:54 | Steps: 5570 | Loss: 65.703338\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:54 | Steps: 5572 | Loss: 65.703902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:54 | Steps: 5574 | Loss: 65.703100\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:54 | Steps: 5575 | Loss: 65.711966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:55 | Steps: 5576 | Loss: 65.718653\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:55 | Steps: 5577 | Loss: 65.719317\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:55 | Steps: 5578 | Loss: 65.723186\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:55 | Steps: 5580 | Loss: 65.736173\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:55 | Steps: 5582 | Loss: 65.747621\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:55 | Steps: 5583 | Loss: 65.747245\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:56 | Steps: 5585 | Loss: 65.754471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:56 | Steps: 5586 | Loss: 65.759525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:56 | Steps: 5588 | Loss: 65.773659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:56 | Steps: 5589 | Loss: 65.777258\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:56 | Steps: 5590 | Loss: 65.781544\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:56 | Steps: 5591 | Loss: 65.790275\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:56 | Steps: 5592 | Loss: 65.790739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:57 | Steps: 5593 | Loss: 65.790702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:57 | Steps: 5595 | Loss: 65.800371\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:57 | Steps: 5596 | Loss: 65.807416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:57 | Steps: 5598 | Loss: 65.807236\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:57 | Steps: 5599 | Loss: 65.809419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:57 | Steps: 5601 | Loss: 65.812415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5602 | Loss: 65.814731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5603 | Loss: 65.817407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5604 | Loss: 65.818231\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5605 | Loss: 65.819312\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5606 | Loss: 65.825582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5608 | Loss: 65.829893\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5609 | Loss: 65.829850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5610 | Loss: 65.832120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:58 | Steps: 5611 | Loss: 65.832097\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:59 | Steps: 5612 | Loss: 65.836848\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:59 | Steps: 5613 | Loss: 65.843644\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:59 | Steps: 5614 | Loss: 65.851503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:59 | Steps: 5616 | Loss: 65.855188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:59 | Steps: 5617 | Loss: 65.854217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:07:59 | Steps: 5619 | Loss: 65.863596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5621 | Loss: 65.875485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5622 | Loss: 65.878073\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5623 | Loss: 65.883043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5625 | Loss: 65.887963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5626 | Loss: 65.887900\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5627 | Loss: 65.890609\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5628 | Loss: 65.891786\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5629 | Loss: 65.889288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:00 | Steps: 5630 | Loss: 65.888279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:01 | Steps: 5631 | Loss: 65.891292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:01 | Steps: 5632 | Loss: 65.896101\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:01 | Steps: 5633 | Loss: 65.899401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:01 | Steps: 5635 | Loss: 65.904304\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:01 | Steps: 5637 | Loss: 65.911685\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:01 | Steps: 5638 | Loss: 65.916840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5640 | Loss: 65.911507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5641 | Loss: 65.922968\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5642 | Loss: 65.925770\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5643 | Loss: 65.925430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5645 | Loss: 65.927405\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5646 | Loss: 65.926876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5647 | Loss: 65.933838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5648 | Loss: 65.929011\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:02 | Steps: 5649 | Loss: 65.924683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:03 | Steps: 5650 | Loss: 65.925496\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:03 | Steps: 5651 | Loss: 65.930560\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:03 | Steps: 5653 | Loss: 65.934291\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:03 | Steps: 5655 | Loss: 65.933456\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:03 | Steps: 5656 | Loss: 65.934152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:03 | Steps: 5658 | Loss: 65.934596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:03 | Steps: 5659 | Loss: 65.935706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:04 | Steps: 5660 | Loss: 65.938123\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:04 | Steps: 5662 | Loss: 65.938814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:04 | Steps: 5663 | Loss: 65.941223\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:04 | Steps: 5665 | Loss: 65.942684\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:04 | Steps: 5666 | Loss: 65.945212\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:04 | Steps: 5667 | Loss: 65.949297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:04 | Steps: 5668 | Loss: 65.951821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:05 | Steps: 5670 | Loss: 65.955878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:05 | Steps: 5672 | Loss: 65.953740\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:05 | Steps: 5673 | Loss: 65.953205\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:05 | Steps: 5674 | Loss: 65.959197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:05 | Steps: 5676 | Loss: 65.966952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:05 | Steps: 5678 | Loss: 65.973899\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:06 | Steps: 5680 | Loss: 65.981622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:06 | Steps: 5682 | Loss: 65.989600\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:06 | Steps: 5683 | Loss: 65.995398\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:06 | Steps: 5685 | Loss: 65.994992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:06 | Steps: 5687 | Loss: 65.996326\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:06 | Steps: 5688 | Loss: 65.999908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:06 | Steps: 5689 | Loss: 66.006852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:07 | Steps: 5690 | Loss: 66.004562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:07 | Steps: 5691 | Loss: 65.999695\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:07 | Steps: 5693 | Loss: 65.995476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:07 | Steps: 5695 | Loss: 65.993034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:07 | Steps: 5697 | Loss: 66.002429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:07 | Steps: 5698 | Loss: 66.006550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:08 | Steps: 5700 | Loss: 66.007874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:08 | Steps: 5701 | Loss: 66.009768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:08 | Steps: 5702 | Loss: 66.009955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:08 | Steps: 5703 | Loss: 66.009082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:08 | Steps: 5705 | Loss: 66.004557\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:08 | Steps: 5706 | Loss: 66.004465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:08 | Steps: 5708 | Loss: 66.007339\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:09 | Steps: 5709 | Loss: 66.006939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:09 | Steps: 5711 | Loss: 66.007335\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:09 | Steps: 5713 | Loss: 66.010704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:09 | Steps: 5714 | Loss: 66.007998\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:09 | Steps: 5715 | Loss: 66.015896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:09 | Steps: 5716 | Loss: 66.026843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:09 | Steps: 5717 | Loss: 66.038233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:10 | Steps: 5718 | Loss: 66.041270\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:10 | Steps: 5719 | Loss: 66.040531\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:10 | Steps: 5720 | Loss: 66.040301\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:10 | Steps: 5722 | Loss: 66.046471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:10 | Steps: 5724 | Loss: 66.048796\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:10 | Steps: 5726 | Loss: 66.061369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:10 | Steps: 5727 | Loss: 66.065960\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:11 | Steps: 5728 | Loss: 66.069271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:11 | Steps: 5729 | Loss: 66.075620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:11 | Steps: 5731 | Loss: 66.081631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:11 | Steps: 5732 | Loss: 66.080995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:11 | Steps: 5734 | Loss: 66.081778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:11 | Steps: 5735 | Loss: 66.082643\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:11 | Steps: 5737 | Loss: 66.082677\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:12 | Steps: 5738 | Loss: 66.087999\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:12 | Steps: 5739 | Loss: 66.092803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:12 | Steps: 5740 | Loss: 66.100144\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:12 | Steps: 5741 | Loss: 66.105508\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:12 | Steps: 5743 | Loss: 66.107366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:12 | Steps: 5744 | Loss: 66.104309\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:12 | Steps: 5746 | Loss: 66.108993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:13 | Steps: 5747 | Loss: 66.112574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:13 | Steps: 5749 | Loss: 66.116637\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:13 | Steps: 5751 | Loss: 66.112779\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:13 | Steps: 5753 | Loss: 66.110995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:13 | Steps: 5755 | Loss: 66.115086\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:13 | Steps: 5756 | Loss: 66.118956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:14 | Steps: 5758 | Loss: 66.128821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:14 | Steps: 5759 | Loss: 66.131157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:14 | Steps: 5760 | Loss: 66.139464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:14 | Steps: 5762 | Loss: 66.141644\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:14 | Steps: 5763 | Loss: 66.142547\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:14 | Steps: 5764 | Loss: 66.141835\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:14 | Steps: 5765 | Loss: 66.154659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:15 | Steps: 5767 | Loss: 66.162024\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:15 | Steps: 5769 | Loss: 66.167911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:15 | Steps: 5770 | Loss: 66.167935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:15 | Steps: 5772 | Loss: 66.170655\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:15 | Steps: 5773 | Loss: 66.173393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:15 | Steps: 5774 | Loss: 66.173353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:16 | Steps: 5776 | Loss: 66.180039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:16 | Steps: 5778 | Loss: 66.178342\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:16 | Steps: 5780 | Loss: 66.179124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:16 | Steps: 5781 | Loss: 66.181517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:16 | Steps: 5782 | Loss: 66.185722\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:16 | Steps: 5784 | Loss: 66.185892\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:16 | Steps: 5785 | Loss: 66.183625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:17 | Steps: 5786 | Loss: 66.185026\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:17 | Steps: 5787 | Loss: 66.189728\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:17 | Steps: 5789 | Loss: 66.196575\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:17 | Steps: 5790 | Loss: 66.196455\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:17 | Steps: 5792 | Loss: 66.206987\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:17 | Steps: 5793 | Loss: 66.211019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:17 | Steps: 5794 | Loss: 66.220311\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:18 | Steps: 5795 | Loss: 66.223591\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:18 | Steps: 5796 | Loss: 66.226395\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:18 | Steps: 5798 | Loss: 66.232252\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:18 | Steps: 5799 | Loss: 66.236505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:18 | Steps: 5801 | Loss: 66.244904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:18 | Steps: 5802 | Loss: 66.246523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:18 | Steps: 5804 | Loss: 66.270827\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:19 | Steps: 5805 | Loss: 66.269756\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:19 | Steps: 5806 | Loss: 66.275093\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:19 | Steps: 5807 | Loss: 66.276834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:19 | Steps: 5809 | Loss: 66.278012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:19 | Steps: 5810 | Loss: 66.283358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:19 | Steps: 5812 | Loss: 66.282256\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:19 | Steps: 5814 | Loss: 66.288417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:20 | Steps: 5816 | Loss: 66.297004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:20 | Steps: 5818 | Loss: 66.312122\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:20 | Steps: 5819 | Loss: 66.317065\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:20 | Steps: 5820 | Loss: 66.319938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:20 | Steps: 5821 | Loss: 66.325555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:20 | Steps: 5823 | Loss: 66.321643\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:21 | Steps: 5824 | Loss: 66.322469\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:21 | Steps: 5825 | Loss: 66.324921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:21 | Steps: 5827 | Loss: 66.324117\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:21 | Steps: 5829 | Loss: 66.329641\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:21 | Steps: 5830 | Loss: 66.326171\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:21 | Steps: 5831 | Loss: 66.324709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:21 | Steps: 5832 | Loss: 66.322531\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:22 | Steps: 5833 | Loss: 66.321743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:22 | Steps: 5834 | Loss: 66.327260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:22 | Steps: 5835 | Loss: 66.324833\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:22 | Steps: 5836 | Loss: 66.325783\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:22 | Steps: 5838 | Loss: 66.325584\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:22 | Steps: 5839 | Loss: 66.324288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:22 | Steps: 5841 | Loss: 66.325251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:23 | Steps: 5842 | Loss: 66.325465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:23 | Steps: 5844 | Loss: 66.333258\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:23 | Steps: 5845 | Loss: 66.334819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:23 | Steps: 5847 | Loss: 66.336967\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:23 | Steps: 5848 | Loss: 66.339044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:23 | Steps: 5849 | Loss: 66.338646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:23 | Steps: 5851 | Loss: 66.346928\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:24 | Steps: 5853 | Loss: 66.368613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:24 | Steps: 5855 | Loss: 66.385254\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:24 | Steps: 5857 | Loss: 66.395956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:24 | Steps: 5859 | Loss: 66.396654\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:24 | Steps: 5861 | Loss: 66.390916\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:25 | Steps: 5863 | Loss: 66.389537\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:25 | Steps: 5864 | Loss: 66.390134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:25 | Steps: 5865 | Loss: 66.396229\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:25 | Steps: 5867 | Loss: 66.399145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:25 | Steps: 5869 | Loss: 66.401515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:25 | Steps: 5870 | Loss: 66.405090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:26 | Steps: 5872 | Loss: 66.415314\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:26 | Steps: 5873 | Loss: 66.415587\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:26 | Steps: 5874 | Loss: 66.420846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:26 | Steps: 5876 | Loss: 66.421172\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:26 | Steps: 5877 | Loss: 66.420313\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:26 | Steps: 5878 | Loss: 66.420135\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:27 | Steps: 5879 | Loss: 66.427997\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:27 | Steps: 5880 | Loss: 66.429666\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:27 | Steps: 5881 | Loss: 66.429860\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:27 | Steps: 5882 | Loss: 66.430346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:27 | Steps: 5883 | Loss: 66.429346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:27 | Steps: 5884 | Loss: 66.429715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:27 | Steps: 5885 | Loss: 66.430746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:27 | Steps: 5886 | Loss: 66.431430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:28 | Steps: 5888 | Loss: 66.436445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:28 | Steps: 5889 | Loss: 66.441440\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:28 | Steps: 5891 | Loss: 66.442243\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:28 | Steps: 5893 | Loss: 66.433810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:28 | Steps: 5895 | Loss: 66.430790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:28 | Steps: 5896 | Loss: 66.428405\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:28 | Steps: 5897 | Loss: 66.430761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:29 | Steps: 5898 | Loss: 66.429895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:29 | Steps: 5900 | Loss: 66.435140\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:29 | Steps: 5902 | Loss: 66.441353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:29 | Steps: 5904 | Loss: 66.451047\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:29 | Steps: 5905 | Loss: 66.450648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:29 | Steps: 5906 | Loss: 66.448329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:30 | Steps: 5908 | Loss: 66.449905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:30 | Steps: 5909 | Loss: 66.452247\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:30 | Steps: 5910 | Loss: 66.451155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:30 | Steps: 5911 | Loss: 66.449078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:30 | Steps: 5912 | Loss: 66.446657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:30 | Steps: 5914 | Loss: 66.443156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:31 | Steps: 5916 | Loss: 66.448769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:31 | Steps: 5918 | Loss: 66.450644\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:31 | Steps: 5919 | Loss: 66.447284\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:31 | Steps: 5920 | Loss: 66.458056\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:31 | Steps: 5921 | Loss: 66.469696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:31 | Steps: 5923 | Loss: 66.467032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:31 | Steps: 5924 | Loss: 66.467832\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:31 | Steps: 5925 | Loss: 66.470273\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:32 | Steps: 5926 | Loss: 66.471194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:32 | Steps: 5927 | Loss: 66.470640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:32 | Steps: 5928 | Loss: 66.469148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:32 | Steps: 5930 | Loss: 66.465388\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:32 | Steps: 5931 | Loss: 66.464844\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:32 | Steps: 5932 | Loss: 66.464773\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:32 | Steps: 5933 | Loss: 66.465162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:32 | Steps: 5934 | Loss: 66.469604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:33 | Steps: 5935 | Loss: 66.470888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:33 | Steps: 5937 | Loss: 66.477625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:33 | Steps: 5938 | Loss: 66.481497\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:33 | Steps: 5939 | Loss: 66.482516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:33 | Steps: 5940 | Loss: 66.490597\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:33 | Steps: 5942 | Loss: 66.504590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:33 | Steps: 5943 | Loss: 66.510559\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:34 | Steps: 5944 | Loss: 66.515118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:34 | Steps: 5945 | Loss: 66.519188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:34 | Steps: 5946 | Loss: 66.520631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:34 | Steps: 5947 | Loss: 66.523895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:34 | Steps: 5948 | Loss: 66.526292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:34 | Steps: 5949 | Loss: 66.532016\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:34 | Steps: 5951 | Loss: 66.535186\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:35 | Steps: 5953 | Loss: 66.535153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:35 | Steps: 5954 | Loss: 66.544289\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:35 | Steps: 5955 | Loss: 66.553424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:35 | Steps: 5956 | Loss: 66.560202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:35 | Steps: 5957 | Loss: 66.559224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:35 | Steps: 5958 | Loss: 66.561186\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:35 | Steps: 5960 | Loss: 66.563213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:35 | Steps: 5961 | Loss: 66.568270\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:36 | Steps: 5962 | Loss: 66.571578\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:36 | Steps: 5963 | Loss: 66.577577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:36 | Steps: 5964 | Loss: 66.579226\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:36 | Steps: 5965 | Loss: 66.588680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:36 | Steps: 5967 | Loss: 66.598358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:36 | Steps: 5968 | Loss: 66.600682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:36 | Steps: 5969 | Loss: 66.603732\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:36 | Steps: 5970 | Loss: 66.600756\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:37 | Steps: 5971 | Loss: 66.600736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:37 | Steps: 5973 | Loss: 66.607922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:37 | Steps: 5975 | Loss: 66.611032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:37 | Steps: 5976 | Loss: 66.614022\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:37 | Steps: 5978 | Loss: 66.609766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:37 | Steps: 5979 | Loss: 66.608982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:38 | Steps: 5981 | Loss: 66.619918\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:38 | Steps: 5982 | Loss: 66.616127\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:38 | Steps: 5984 | Loss: 66.627895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:38 | Steps: 5985 | Loss: 66.634963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:38 | Steps: 5987 | Loss: 66.638931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:38 | Steps: 5988 | Loss: 66.636873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:38 | Steps: 5990 | Loss: 66.643681\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:39 | Steps: 5992 | Loss: 66.641387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:39 | Steps: 5993 | Loss: 66.644574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:39 | Steps: 5994 | Loss: 66.645951\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:39 | Steps: 5996 | Loss: 66.645433\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:39 | Steps: 5997 | Loss: 66.645978\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:39 | Steps: 5998 | Loss: 66.645166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:39 | Steps: 5999 | Loss: 66.647610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:40 | Steps: 6000 | Loss: 66.645594\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:40 | Steps: 6001 | Loss: 66.643992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:40 | Steps: 6002 | Loss: 66.646955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:40 | Steps: 6004 | Loss: 66.660968\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:40 | Steps: 6005 | Loss: 66.663707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:40 | Steps: 6006 | Loss: 66.666315\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:40 | Steps: 6008 | Loss: 66.668006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:41 | Steps: 6009 | Loss: 66.673746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:41 | Steps: 6011 | Loss: 66.677597\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:41 | Steps: 6012 | Loss: 66.685095\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:41 | Steps: 6013 | Loss: 66.689489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:41 | Steps: 6015 | Loss: 66.703819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:41 | Steps: 6016 | Loss: 66.705807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:41 | Steps: 6017 | Loss: 66.707683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:41 | Steps: 6018 | Loss: 66.709369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:42 | Steps: 6019 | Loss: 66.704615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:42 | Steps: 6020 | Loss: 66.702527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:42 | Steps: 6021 | Loss: 66.701887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:42 | Steps: 6022 | Loss: 66.701226\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:42 | Steps: 6023 | Loss: 66.702217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:42 | Steps: 6024 | Loss: 66.707941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:42 | Steps: 6026 | Loss: 66.708772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:42 | Steps: 6027 | Loss: 66.708229\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:43 | Steps: 6028 | Loss: 66.708449\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:43 | Steps: 6030 | Loss: 66.712975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:43 | Steps: 6031 | Loss: 66.713722\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:43 | Steps: 6032 | Loss: 66.714725\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:43 | Steps: 6033 | Loss: 66.721714\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:43 | Steps: 6035 | Loss: 66.724626\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:43 | Steps: 6036 | Loss: 66.726357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:44 | Steps: 6037 | Loss: 66.726504\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:44 | Steps: 6038 | Loss: 66.726070\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:44 | Steps: 6040 | Loss: 66.728843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:44 | Steps: 6042 | Loss: 66.736103\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:44 | Steps: 6043 | Loss: 66.737277\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:44 | Steps: 6045 | Loss: 66.740779\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:45 | Steps: 6047 | Loss: 66.740071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:45 | Steps: 6048 | Loss: 66.739188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:45 | Steps: 6049 | Loss: 66.742439\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:45 | Steps: 6051 | Loss: 66.750789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:45 | Steps: 6052 | Loss: 66.749501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:45 | Steps: 6054 | Loss: 66.746950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:45 | Steps: 6056 | Loss: 66.750805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:46 | Steps: 6058 | Loss: 66.747446\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:46 | Steps: 6059 | Loss: 66.751120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:46 | Steps: 6061 | Loss: 66.757548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:46 | Steps: 6062 | Loss: 66.753082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:46 | Steps: 6063 | Loss: 66.755900\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:46 | Steps: 6064 | Loss: 66.754981\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:46 | Steps: 6065 | Loss: 66.752269\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:47 | Steps: 6066 | Loss: 66.751415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:47 | Steps: 6068 | Loss: 66.751595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:47 | Steps: 6069 | Loss: 66.748695\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:47 | Steps: 6070 | Loss: 66.747160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:47 | Steps: 6071 | Loss: 66.745349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:47 | Steps: 6072 | Loss: 66.745199\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:47 | Steps: 6073 | Loss: 66.745954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:47 | Steps: 6074 | Loss: 66.745331\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:48 | Steps: 6075 | Loss: 66.745670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:48 | Steps: 6077 | Loss: 66.750381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:48 | Steps: 6079 | Loss: 66.760294\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:48 | Steps: 6081 | Loss: 66.761652\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:48 | Steps: 6082 | Loss: 66.761810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:48 | Steps: 6084 | Loss: 66.776154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:49 | Steps: 6085 | Loss: 66.779868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:49 | Steps: 6086 | Loss: 66.781266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:49 | Steps: 6088 | Loss: 66.786579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:49 | Steps: 6089 | Loss: 66.788681\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:49 | Steps: 6090 | Loss: 66.788003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:49 | Steps: 6091 | Loss: 66.793373\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:49 | Steps: 6092 | Loss: 66.799445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:50 | Steps: 6093 | Loss: 66.799987\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:50 | Steps: 6095 | Loss: 66.799913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:50 | Steps: 6096 | Loss: 66.799824\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:50 | Steps: 6097 | Loss: 66.802226\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:50 | Steps: 6098 | Loss: 66.803994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:50 | Steps: 6099 | Loss: 66.802351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:50 | Steps: 6101 | Loss: 66.804279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:50 | Steps: 6102 | Loss: 66.806349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:51 | Steps: 6103 | Loss: 66.803883\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:51 | Steps: 6105 | Loss: 66.809157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:51 | Steps: 6106 | Loss: 66.817726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:51 | Steps: 6107 | Loss: 66.819235\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:51 | Steps: 6108 | Loss: 66.819432\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:51 | Steps: 6110 | Loss: 66.825991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:51 | Steps: 6111 | Loss: 66.830974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:52 | Steps: 6113 | Loss: 66.835474\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:52 | Steps: 6114 | Loss: 66.838171\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:52 | Steps: 6115 | Loss: 66.841661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:52 | Steps: 6116 | Loss: 66.846551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:52 | Steps: 6117 | Loss: 66.848941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:52 | Steps: 6118 | Loss: 66.856281\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:52 | Steps: 6119 | Loss: 66.855901\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:52 | Steps: 6120 | Loss: 66.856668\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:53 | Steps: 6121 | Loss: 66.858859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:53 | Steps: 6122 | Loss: 66.864046\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:53 | Steps: 6124 | Loss: 66.858490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:53 | Steps: 6125 | Loss: 66.859225\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:53 | Steps: 6127 | Loss: 66.879446\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:53 | Steps: 6129 | Loss: 66.880803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:54 | Steps: 6130 | Loss: 66.882753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:54 | Steps: 6132 | Loss: 66.891430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:54 | Steps: 6134 | Loss: 66.903228\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:54 | Steps: 6135 | Loss: 66.914690\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:54 | Steps: 6136 | Loss: 66.918566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:54 | Steps: 6137 | Loss: 66.915941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:54 | Steps: 6138 | Loss: 66.915101\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:54 | Steps: 6139 | Loss: 66.922407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:55 | Steps: 6141 | Loss: 66.924035\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:55 | Steps: 6143 | Loss: 66.924972\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:55 | Steps: 6145 | Loss: 66.925204\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:56 | Steps: 6146 | Loss: 66.921674\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:56 | Steps: 6147 | Loss: 66.923468\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:56 | Steps: 6148 | Loss: 66.928370\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:56 | Steps: 6150 | Loss: 66.920527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:56 | Steps: 6151 | Loss: 66.924218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:56 | Steps: 6153 | Loss: 66.926927\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:56 | Steps: 6154 | Loss: 66.925875\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:57 | Steps: 6155 | Loss: 66.925122\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:57 | Steps: 6156 | Loss: 66.926503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:57 | Steps: 6158 | Loss: 66.931229\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:57 | Steps: 6159 | Loss: 66.934069\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:57 | Steps: 6160 | Loss: 66.935962\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:57 | Steps: 6162 | Loss: 66.934799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:57 | Steps: 6163 | Loss: 66.937876\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:58 | Steps: 6164 | Loss: 66.938426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:58 | Steps: 6165 | Loss: 66.935029\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:58 | Steps: 6167 | Loss: 66.934253\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:58 | Steps: 6169 | Loss: 66.935699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:58 | Steps: 6170 | Loss: 66.937420\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:58 | Steps: 6171 | Loss: 66.943337\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:58 | Steps: 6172 | Loss: 66.945792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:59 | Steps: 6174 | Loss: 66.954344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:59 | Steps: 6175 | Loss: 66.954400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:59 | Steps: 6176 | Loss: 66.952654\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:59 | Steps: 6178 | Loss: 66.955661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:59 | Steps: 6179 | Loss: 66.952762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:59 | Steps: 6180 | Loss: 66.949179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:08:59 | Steps: 6182 | Loss: 66.954211\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:00 | Steps: 6183 | Loss: 66.952044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:00 | Steps: 6185 | Loss: 66.956356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:00 | Steps: 6186 | Loss: 66.955086\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:00 | Steps: 6187 | Loss: 66.956480\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:00 | Steps: 6189 | Loss: 66.960062\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:00 | Steps: 6191 | Loss: 66.960074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:01 | Steps: 6193 | Loss: 66.965859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:01 | Steps: 6194 | Loss: 66.973524\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:01 | Steps: 6195 | Loss: 66.973947\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:01 | Steps: 6196 | Loss: 66.974215\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:01 | Steps: 6198 | Loss: 66.981041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:01 | Steps: 6200 | Loss: 66.986834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:02 | Steps: 6202 | Loss: 66.991741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:02 | Steps: 6204 | Loss: 66.992767\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:02 | Steps: 6205 | Loss: 66.992744\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:02 | Steps: 6206 | Loss: 66.998124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:02 | Steps: 6207 | Loss: 67.002509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:02 | Steps: 6208 | Loss: 67.004980\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:02 | Steps: 6209 | Loss: 67.006340\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6211 | Loss: 67.018830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6212 | Loss: 67.018463\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6213 | Loss: 67.020138\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6214 | Loss: 67.019249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6216 | Loss: 67.017931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6217 | Loss: 67.018343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6218 | Loss: 67.018090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6219 | Loss: 67.013267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:03 | Steps: 6220 | Loss: 67.021325\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:04 | Steps: 6221 | Loss: 67.027457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:04 | Steps: 6222 | Loss: 67.032415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:04 | Steps: 6224 | Loss: 67.036196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:04 | Steps: 6225 | Loss: 67.035227\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:04 | Steps: 6227 | Loss: 67.039274\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:04 | Steps: 6228 | Loss: 67.039967\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:04 | Steps: 6229 | Loss: 67.042433\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:05 | Steps: 6231 | Loss: 67.041992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:05 | Steps: 6232 | Loss: 67.041406\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:05 | Steps: 6234 | Loss: 67.044282\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:05 | Steps: 6235 | Loss: 67.045815\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:05 | Steps: 6236 | Loss: 67.044821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:05 | Steps: 6237 | Loss: 67.044324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:05 | Steps: 6239 | Loss: 67.051145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:06 | Steps: 6241 | Loss: 67.054931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:06 | Steps: 6242 | Loss: 67.061412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:06 | Steps: 6244 | Loss: 67.072095\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:06 | Steps: 6245 | Loss: 67.075928\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:06 | Steps: 6247 | Loss: 67.077298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:07 | Steps: 6249 | Loss: 67.074706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:07 | Steps: 6250 | Loss: 67.077590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:07 | Steps: 6251 | Loss: 67.079043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:07 | Steps: 6252 | Loss: 67.082188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:07 | Steps: 6253 | Loss: 67.081524\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:07 | Steps: 6254 | Loss: 67.084041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:07 | Steps: 6256 | Loss: 67.085571\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:07 | Steps: 6257 | Loss: 67.085331\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:08 | Steps: 6258 | Loss: 67.085236\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:08 | Steps: 6259 | Loss: 67.099696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:08 | Steps: 6260 | Loss: 67.105698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:08 | Steps: 6262 | Loss: 67.106548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:08 | Steps: 6263 | Loss: 67.107973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:08 | Steps: 6264 | Loss: 67.104593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:08 | Steps: 6265 | Loss: 67.104923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:08 | Steps: 6266 | Loss: 67.105654\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:09 | Steps: 6267 | Loss: 67.105363\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:09 | Steps: 6268 | Loss: 67.108766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:09 | Steps: 6270 | Loss: 67.115501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:09 | Steps: 6272 | Loss: 67.122330\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:09 | Steps: 6273 | Loss: 67.126049\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:09 | Steps: 6275 | Loss: 67.135445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:09 | Steps: 6276 | Loss: 67.143358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:10 | Steps: 6278 | Loss: 67.148143\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:10 | Steps: 6279 | Loss: 67.153430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:10 | Steps: 6281 | Loss: 67.155340\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:10 | Steps: 6282 | Loss: 67.156446\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:10 | Steps: 6283 | Loss: 67.156780\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:10 | Steps: 6284 | Loss: 67.168968\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:10 | Steps: 6285 | Loss: 67.173958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:11 | Steps: 6287 | Loss: 67.176692\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:11 | Steps: 6288 | Loss: 67.182628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:11 | Steps: 6289 | Loss: 67.191429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:11 | Steps: 6291 | Loss: 67.189477\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:11 | Steps: 6292 | Loss: 67.186871\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:11 | Steps: 6293 | Loss: 67.185699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:11 | Steps: 6294 | Loss: 67.192649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:12 | Steps: 6295 | Loss: 67.192501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:12 | Steps: 6297 | Loss: 67.192853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:12 | Steps: 6298 | Loss: 67.198608\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:12 | Steps: 6299 | Loss: 67.200775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:12 | Steps: 6300 | Loss: 67.207261\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:12 | Steps: 6301 | Loss: 67.211527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:12 | Steps: 6302 | Loss: 67.214245\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:12 | Steps: 6303 | Loss: 67.218599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6304 | Loss: 67.221008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6305 | Loss: 67.233013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6306 | Loss: 67.232708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6307 | Loss: 67.234731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6308 | Loss: 67.233345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6309 | Loss: 67.237310\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6310 | Loss: 67.235118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6311 | Loss: 67.234013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:13 | Steps: 6312 | Loss: 67.233868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:14 | Steps: 6314 | Loss: 67.235231\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:14 | Steps: 6315 | Loss: 67.237300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:14 | Steps: 6316 | Loss: 67.235602\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:14 | Steps: 6317 | Loss: 67.234300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:14 | Steps: 6318 | Loss: 67.236361\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:14 | Steps: 6319 | Loss: 67.237008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:14 | Steps: 6321 | Loss: 67.236657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6322 | Loss: 67.237487\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6323 | Loss: 67.241887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6324 | Loss: 67.241897\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6325 | Loss: 67.243044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6326 | Loss: 67.243328\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6327 | Loss: 67.244971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6328 | Loss: 67.247227\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6329 | Loss: 67.247991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:15 | Steps: 6330 | Loss: 67.247118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:16 | Steps: 6331 | Loss: 67.249269\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:16 | Steps: 6333 | Loss: 67.258781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:16 | Steps: 6335 | Loss: 67.259045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:16 | Steps: 6336 | Loss: 67.256817\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:16 | Steps: 6338 | Loss: 67.257877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:16 | Steps: 6339 | Loss: 67.267800\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:17 | Steps: 6340 | Loss: 67.269842\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:17 | Steps: 6341 | Loss: 67.278071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:17 | Steps: 6343 | Loss: 67.278718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:17 | Steps: 6344 | Loss: 67.275281\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:17 | Steps: 6346 | Loss: 67.276102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:17 | Steps: 6347 | Loss: 67.277194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:18 | Steps: 6349 | Loss: 67.273890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:18 | Steps: 6351 | Loss: 67.269318\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:18 | Steps: 6352 | Loss: 67.271416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:18 | Steps: 6353 | Loss: 67.270596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:18 | Steps: 6354 | Loss: 67.270505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:18 | Steps: 6355 | Loss: 67.270936\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:18 | Steps: 6356 | Loss: 67.273883\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:18 | Steps: 6357 | Loss: 67.275540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:19 | Steps: 6358 | Loss: 67.275445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:19 | Steps: 6359 | Loss: 67.274293\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:19 | Steps: 6360 | Loss: 67.277157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:19 | Steps: 6362 | Loss: 67.280220\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:19 | Steps: 6363 | Loss: 67.282567\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:19 | Steps: 6365 | Loss: 67.279352\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:19 | Steps: 6366 | Loss: 67.279019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:20 | Steps: 6367 | Loss: 67.286199\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:20 | Steps: 6369 | Loss: 67.300399\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:20 | Steps: 6370 | Loss: 67.307286\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:20 | Steps: 6371 | Loss: 67.303339\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:20 | Steps: 6372 | Loss: 67.304397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:20 | Steps: 6373 | Loss: 67.304071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:20 | Steps: 6374 | Loss: 67.302090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:20 | Steps: 6375 | Loss: 67.306292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:21 | Steps: 6377 | Loss: 67.314805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:21 | Steps: 6378 | Loss: 67.320505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:21 | Steps: 6379 | Loss: 67.326858\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:21 | Steps: 6381 | Loss: 67.325343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:21 | Steps: 6382 | Loss: 67.325300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:21 | Steps: 6383 | Loss: 67.325707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:21 | Steps: 6384 | Loss: 67.326902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:22 | Steps: 6386 | Loss: 67.331624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:22 | Steps: 6387 | Loss: 67.337759\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:22 | Steps: 6388 | Loss: 67.341955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:22 | Steps: 6389 | Loss: 67.340696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:22 | Steps: 6390 | Loss: 67.338423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:22 | Steps: 6391 | Loss: 67.340664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:22 | Steps: 6392 | Loss: 67.339332\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:22 | Steps: 6393 | Loss: 67.338640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:23 | Steps: 6395 | Loss: 67.336903\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:23 | Steps: 6396 | Loss: 67.339221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:23 | Steps: 6398 | Loss: 67.340395\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:23 | Steps: 6399 | Loss: 67.341278\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:23 | Steps: 6400 | Loss: 67.342477\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:23 | Steps: 6401 | Loss: 67.345515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:23 | Steps: 6402 | Loss: 67.345726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:23 | Steps: 6403 | Loss: 67.347166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:24 | Steps: 6404 | Loss: 67.350244\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:24 | Steps: 6406 | Loss: 67.365374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:24 | Steps: 6407 | Loss: 67.367247\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:24 | Steps: 6409 | Loss: 67.367059\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:24 | Steps: 6411 | Loss: 67.371350\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:24 | Steps: 6412 | Loss: 67.368873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:25 | Steps: 6414 | Loss: 67.371964\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:25 | Steps: 6415 | Loss: 67.374012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:25 | Steps: 6416 | Loss: 67.371127\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:25 | Steps: 6418 | Loss: 67.373429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:25 | Steps: 6420 | Loss: 67.381853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:25 | Steps: 6421 | Loss: 67.392173\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:26 | Steps: 6422 | Loss: 67.391054\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:26 | Steps: 6423 | Loss: 67.393632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:26 | Steps: 6424 | Loss: 67.397377\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:26 | Steps: 6425 | Loss: 67.403945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:26 | Steps: 6427 | Loss: 67.413059\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:26 | Steps: 6428 | Loss: 67.418343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:26 | Steps: 6430 | Loss: 67.422721\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:27 | Steps: 6431 | Loss: 67.424987\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:27 | Steps: 6432 | Loss: 67.429067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:27 | Steps: 6434 | Loss: 67.443701\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:27 | Steps: 6436 | Loss: 67.449720\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:27 | Steps: 6437 | Loss: 67.449500\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:27 | Steps: 6438 | Loss: 67.448400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:27 | Steps: 6439 | Loss: 67.447258\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6440 | Loss: 67.458580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6441 | Loss: 67.468249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6442 | Loss: 67.470085\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6443 | Loss: 67.473572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6444 | Loss: 67.476280\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6445 | Loss: 67.477451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6446 | Loss: 67.480592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6448 | Loss: 67.491265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:28 | Steps: 6449 | Loss: 67.495157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:29 | Steps: 6450 | Loss: 67.491234\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:29 | Steps: 6451 | Loss: 67.499554\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:29 | Steps: 6452 | Loss: 67.505059\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:29 | Steps: 6453 | Loss: 67.506648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:29 | Steps: 6455 | Loss: 67.518880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:29 | Steps: 6456 | Loss: 67.518654\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:29 | Steps: 6458 | Loss: 67.517291\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:30 | Steps: 6459 | Loss: 67.516716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:30 | Steps: 6460 | Loss: 67.515751\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:30 | Steps: 6462 | Loss: 67.514821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:30 | Steps: 6464 | Loss: 67.508660\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:30 | Steps: 6465 | Loss: 67.515300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:30 | Steps: 6467 | Loss: 67.518663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:31 | Steps: 6468 | Loss: 67.517316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:31 | Steps: 6470 | Loss: 67.530990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:31 | Steps: 6471 | Loss: 67.540179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:31 | Steps: 6472 | Loss: 67.541922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:31 | Steps: 6473 | Loss: 67.541770\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:31 | Steps: 6474 | Loss: 67.544116\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:31 | Steps: 6475 | Loss: 67.549713\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:32 | Steps: 6477 | Loss: 67.554181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:32 | Steps: 6478 | Loss: 67.556971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:32 | Steps: 6480 | Loss: 67.556084\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:32 | Steps: 6481 | Loss: 67.556712\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:32 | Steps: 6482 | Loss: 67.560132\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:32 | Steps: 6484 | Loss: 67.564001\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:32 | Steps: 6485 | Loss: 67.564944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:32 | Steps: 6486 | Loss: 67.567058\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:33 | Steps: 6487 | Loss: 67.570561\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:33 | Steps: 6488 | Loss: 67.567852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:33 | Steps: 6489 | Loss: 67.566407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:33 | Steps: 6491 | Loss: 67.565975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:33 | Steps: 6492 | Loss: 67.566608\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:33 | Steps: 6493 | Loss: 67.568507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:33 | Steps: 6494 | Loss: 67.571582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:33 | Steps: 6495 | Loss: 67.574354\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:34 | Steps: 6496 | Loss: 67.576829\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:34 | Steps: 6497 | Loss: 67.574856\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:34 | Steps: 6499 | Loss: 67.576708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:34 | Steps: 6501 | Loss: 67.568290\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:34 | Steps: 6502 | Loss: 67.565920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:34 | Steps: 6504 | Loss: 67.567148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:35 | Steps: 6505 | Loss: 67.566628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:35 | Steps: 6507 | Loss: 67.571542\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:35 | Steps: 6508 | Loss: 67.573707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:35 | Steps: 6509 | Loss: 67.576422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:35 | Steps: 6510 | Loss: 67.576849\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:35 | Steps: 6512 | Loss: 67.579715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:35 | Steps: 6513 | Loss: 67.584099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:36 | Steps: 6514 | Loss: 67.585661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:36 | Steps: 6515 | Loss: 67.585566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:36 | Steps: 6517 | Loss: 67.586472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:36 | Steps: 6519 | Loss: 67.588473\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:36 | Steps: 6520 | Loss: 67.590027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:36 | Steps: 6522 | Loss: 67.590082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:37 | Steps: 6524 | Loss: 67.597648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:37 | Steps: 6525 | Loss: 67.600855\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:37 | Steps: 6526 | Loss: 67.600046\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:37 | Steps: 6527 | Loss: 67.602807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:37 | Steps: 6528 | Loss: 67.603921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:37 | Steps: 6529 | Loss: 67.605423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:37 | Steps: 6530 | Loss: 67.605386\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:37 | Steps: 6531 | Loss: 67.607840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6532 | Loss: 67.609353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6533 | Loss: 67.611836\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6534 | Loss: 67.616452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6535 | Loss: 67.621443\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6536 | Loss: 67.625361\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6537 | Loss: 67.629591\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6538 | Loss: 67.635679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6539 | Loss: 67.635474\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:38 | Steps: 6540 | Loss: 67.633682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:39 | Steps: 6541 | Loss: 67.632078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:39 | Steps: 6542 | Loss: 67.631490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:39 | Steps: 6543 | Loss: 67.631977\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:39 | Steps: 6544 | Loss: 67.631235\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:39 | Steps: 6545 | Loss: 67.634486\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:39 | Steps: 6547 | Loss: 67.641009\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:39 | Steps: 6548 | Loss: 67.644271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:40 | Steps: 6550 | Loss: 67.644272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:40 | Steps: 6551 | Loss: 67.643482\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:40 | Steps: 6552 | Loss: 67.644671\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:40 | Steps: 6554 | Loss: 67.643093\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:40 | Steps: 6555 | Loss: 67.642167\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:40 | Steps: 6556 | Loss: 67.640283\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:40 | Steps: 6557 | Loss: 67.638279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:40 | Steps: 6558 | Loss: 67.641992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:41 | Steps: 6559 | Loss: 67.642586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:41 | Steps: 6560 | Loss: 67.646570\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:41 | Steps: 6561 | Loss: 67.645802\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:41 | Steps: 6563 | Loss: 67.645291\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:41 | Steps: 6565 | Loss: 67.651743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:41 | Steps: 6566 | Loss: 67.657518\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:41 | Steps: 6567 | Loss: 67.658659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:42 | Steps: 6568 | Loss: 67.663510\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:42 | Steps: 6569 | Loss: 67.664845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:42 | Steps: 6570 | Loss: 67.666117\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:42 | Steps: 6571 | Loss: 67.663489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:42 | Steps: 6573 | Loss: 67.675030\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:42 | Steps: 6574 | Loss: 67.681084\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:42 | Steps: 6575 | Loss: 67.685598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:42 | Steps: 6576 | Loss: 67.687402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:43 | Steps: 6577 | Loss: 67.688375\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:43 | Steps: 6578 | Loss: 67.692246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:43 | Steps: 6580 | Loss: 67.703054\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:43 | Steps: 6581 | Loss: 67.708699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:43 | Steps: 6582 | Loss: 67.714111\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:43 | Steps: 6583 | Loss: 67.714228\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:43 | Steps: 6585 | Loss: 67.714369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:44 | Steps: 6587 | Loss: 67.714088\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:44 | Steps: 6588 | Loss: 67.717153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:44 | Steps: 6589 | Loss: 67.716145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:44 | Steps: 6590 | Loss: 67.718186\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:44 | Steps: 6591 | Loss: 67.721615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:44 | Steps: 6592 | Loss: 67.719174\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:44 | Steps: 6594 | Loss: 67.722928\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:45 | Steps: 6596 | Loss: 67.732852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:45 | Steps: 6597 | Loss: 67.742296\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:45 | Steps: 6598 | Loss: 67.749475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:45 | Steps: 6600 | Loss: 67.751004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:45 | Steps: 6601 | Loss: 67.752452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:45 | Steps: 6603 | Loss: 67.756373\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:46 | Steps: 6605 | Loss: 67.761959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:46 | Steps: 6606 | Loss: 67.764415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:46 | Steps: 6607 | Loss: 67.765798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:46 | Steps: 6608 | Loss: 67.771055\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:46 | Steps: 6609 | Loss: 67.767448\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:46 | Steps: 6610 | Loss: 67.765187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:46 | Steps: 6612 | Loss: 67.775013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:47 | Steps: 6613 | Loss: 67.775788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:47 | Steps: 6615 | Loss: 67.776690\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:47 | Steps: 6617 | Loss: 67.780152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:47 | Steps: 6618 | Loss: 67.781929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:47 | Steps: 6619 | Loss: 67.789775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:47 | Steps: 6620 | Loss: 67.795928\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:47 | Steps: 6621 | Loss: 67.799503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:48 | Steps: 6622 | Loss: 67.799305\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:48 | Steps: 6623 | Loss: 67.809085\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:48 | Steps: 6624 | Loss: 67.809877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:48 | Steps: 6626 | Loss: 67.812853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:48 | Steps: 6627 | Loss: 67.812971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:48 | Steps: 6628 | Loss: 67.817409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:48 | Steps: 6629 | Loss: 67.817923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:48 | Steps: 6630 | Loss: 67.817257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:49 | Steps: 6631 | Loss: 67.814162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:49 | Steps: 6632 | Loss: 67.815404\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:49 | Steps: 6633 | Loss: 67.814707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:49 | Steps: 6634 | Loss: 67.813415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:49 | Steps: 6635 | Loss: 67.811298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:49 | Steps: 6636 | Loss: 67.815410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:49 | Steps: 6637 | Loss: 67.815097\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:49 | Steps: 6639 | Loss: 67.816224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6640 | Loss: 67.818526\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6641 | Loss: 67.820421\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6642 | Loss: 67.824658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6643 | Loss: 67.824671\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6644 | Loss: 67.827248\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6645 | Loss: 67.825350\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6646 | Loss: 67.826636\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6647 | Loss: 67.827316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:50 | Steps: 6648 | Loss: 67.829709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:51 | Steps: 6649 | Loss: 67.830845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:51 | Steps: 6650 | Loss: 67.833504\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:51 | Steps: 6651 | Loss: 67.836074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:51 | Steps: 6652 | Loss: 67.836613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:51 | Steps: 6654 | Loss: 67.835213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:51 | Steps: 6655 | Loss: 67.841079\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:51 | Steps: 6656 | Loss: 67.841331\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:52 | Steps: 6657 | Loss: 67.848911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:52 | Steps: 6658 | Loss: 67.856416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:52 | Steps: 6659 | Loss: 67.860264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:52 | Steps: 6660 | Loss: 67.859807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:52 | Steps: 6661 | Loss: 67.857525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:52 | Steps: 6662 | Loss: 67.855572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:52 | Steps: 6663 | Loss: 67.857196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:53 | Steps: 6665 | Loss: 67.856372\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:53 | Steps: 6666 | Loss: 67.853963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:53 | Steps: 6667 | Loss: 67.857778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:53 | Steps: 6669 | Loss: 67.859045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:53 | Steps: 6671 | Loss: 67.859077\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:54 | Steps: 6672 | Loss: 67.861502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:54 | Steps: 6673 | Loss: 67.861551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:54 | Steps: 6674 | Loss: 67.861896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:54 | Steps: 6675 | Loss: 67.865796\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:54 | Steps: 6677 | Loss: 67.867586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:54 | Steps: 6678 | Loss: 67.867482\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:54 | Steps: 6679 | Loss: 67.869992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:55 | Steps: 6680 | Loss: 67.874121\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:55 | Steps: 6681 | Loss: 67.873614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:55 | Steps: 6682 | Loss: 67.872704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:55 | Steps: 6683 | Loss: 67.879231\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:55 | Steps: 6685 | Loss: 67.882009\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:55 | Steps: 6687 | Loss: 67.881822\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:55 | Steps: 6688 | Loss: 67.883748\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:56 | Steps: 6689 | Loss: 67.886123\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:56 | Steps: 6691 | Loss: 67.888054\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:56 | Steps: 6692 | Loss: 67.895418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:56 | Steps: 6693 | Loss: 67.896033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:56 | Steps: 6694 | Loss: 67.893246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:56 | Steps: 6696 | Loss: 67.890567\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:57 | Steps: 6697 | Loss: 67.891515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:57 | Steps: 6698 | Loss: 67.890329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:57 | Steps: 6699 | Loss: 67.895821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:57 | Steps: 6700 | Loss: 67.901124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:57 | Steps: 6701 | Loss: 67.906229\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:57 | Steps: 6703 | Loss: 67.903364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:57 | Steps: 6704 | Loss: 67.901303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:57 | Steps: 6705 | Loss: 67.905125\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:58 | Steps: 6706 | Loss: 67.905035\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:58 | Steps: 6707 | Loss: 67.907124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:58 | Steps: 6709 | Loss: 67.908459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:58 | Steps: 6710 | Loss: 67.907067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:58 | Steps: 6711 | Loss: 67.905035\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:58 | Steps: 6712 | Loss: 67.907349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:58 | Steps: 6713 | Loss: 67.908590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:59 | Steps: 6715 | Loss: 67.908322\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:59 | Steps: 6716 | Loss: 67.915556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:59 | Steps: 6717 | Loss: 67.916819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:59 | Steps: 6718 | Loss: 67.913527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:59 | Steps: 6720 | Loss: 67.917108\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:59 | Steps: 6721 | Loss: 67.917365\n",
      "Epoch 1 |   Training | Elapsed Time: 0:09:59 | Steps: 6722 | Loss: 67.920341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:00 | Steps: 6724 | Loss: 67.924194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:00 | Steps: 6725 | Loss: 67.925533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:00 | Steps: 6726 | Loss: 67.935021\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:00 | Steps: 6727 | Loss: 67.939091\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:00 | Steps: 6728 | Loss: 67.940240\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:00 | Steps: 6730 | Loss: 67.945476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:00 | Steps: 6731 | Loss: 67.947169\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:01 | Steps: 6732 | Loss: 67.949276\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:01 | Steps: 6733 | Loss: 67.949562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:01 | Steps: 6734 | Loss: 67.951437\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:01 | Steps: 6736 | Loss: 67.952991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:01 | Steps: 6737 | Loss: 67.955108\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:01 | Steps: 6738 | Loss: 67.952941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:01 | Steps: 6739 | Loss: 67.951381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:01 | Steps: 6740 | Loss: 67.953039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:02 | Steps: 6741 | Loss: 67.955215\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:02 | Steps: 6742 | Loss: 67.955607\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:02 | Steps: 6744 | Loss: 67.959761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:02 | Steps: 6745 | Loss: 67.962883\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:02 | Steps: 6747 | Loss: 67.977520\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:02 | Steps: 6748 | Loss: 67.977989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:03 | Steps: 6750 | Loss: 67.986919\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:03 | Steps: 6752 | Loss: 67.990830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:03 | Steps: 6753 | Loss: 67.994817\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:03 | Steps: 6754 | Loss: 67.995724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:03 | Steps: 6755 | Loss: 67.998386\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:03 | Steps: 6757 | Loss: 68.003140\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:04 | Steps: 6759 | Loss: 68.006293\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:04 | Steps: 6760 | Loss: 68.006741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:04 | Steps: 6761 | Loss: 68.007154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:04 | Steps: 6762 | Loss: 68.008366\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:04 | Steps: 6763 | Loss: 68.008813\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:04 | Steps: 6764 | Loss: 68.010484\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:04 | Steps: 6765 | Loss: 68.011236\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:04 | Steps: 6766 | Loss: 68.013458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:05 | Steps: 6767 | Loss: 68.022233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:05 | Steps: 6768 | Loss: 68.026345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:05 | Steps: 6770 | Loss: 68.033202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:05 | Steps: 6771 | Loss: 68.038039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:05 | Steps: 6772 | Loss: 68.034894\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:05 | Steps: 6773 | Loss: 68.042726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:05 | Steps: 6774 | Loss: 68.042754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:06 | Steps: 6776 | Loss: 68.045123\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:06 | Steps: 6777 | Loss: 68.043034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:06 | Steps: 6778 | Loss: 68.041622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:06 | Steps: 6780 | Loss: 68.044577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:06 | Steps: 6781 | Loss: 68.041063\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:06 | Steps: 6782 | Loss: 68.036701\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:06 | Steps: 6783 | Loss: 68.038872\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6784 | Loss: 68.036385\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6785 | Loss: 68.037908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6786 | Loss: 68.036249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6787 | Loss: 68.047309\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6788 | Loss: 68.048877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6789 | Loss: 68.051792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6790 | Loss: 68.053635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6791 | Loss: 68.055219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:07 | Steps: 6792 | Loss: 68.055060\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:08 | Steps: 6793 | Loss: 68.055401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:08 | Steps: 6794 | Loss: 68.058777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:08 | Steps: 6796 | Loss: 68.066533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:08 | Steps: 6797 | Loss: 68.066108\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:08 | Steps: 6798 | Loss: 68.066274\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:08 | Steps: 6799 | Loss: 68.069155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:08 | Steps: 6800 | Loss: 68.069540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:08 | Steps: 6801 | Loss: 68.068472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:09 | Steps: 6802 | Loss: 68.074149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:09 | Steps: 6803 | Loss: 68.077390\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:09 | Steps: 6805 | Loss: 68.086396\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:09 | Steps: 6806 | Loss: 68.085881\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:09 | Steps: 6807 | Loss: 68.085459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:09 | Steps: 6808 | Loss: 68.086016\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:09 | Steps: 6809 | Loss: 68.083122\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:09 | Steps: 6810 | Loss: 68.080689\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:10 | Steps: 6811 | Loss: 68.076892\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:10 | Steps: 6812 | Loss: 68.078370\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:10 | Steps: 6813 | Loss: 68.077593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:10 | Steps: 6814 | Loss: 68.077433\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:10 | Steps: 6816 | Loss: 68.084460\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:10 | Steps: 6817 | Loss: 68.086068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:10 | Steps: 6818 | Loss: 68.086439\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:10 | Steps: 6819 | Loss: 68.089706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:11 | Steps: 6821 | Loss: 68.097898\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:11 | Steps: 6822 | Loss: 68.101593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:11 | Steps: 6823 | Loss: 68.103721\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:11 | Steps: 6824 | Loss: 68.104632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:11 | Steps: 6825 | Loss: 68.108192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:11 | Steps: 6827 | Loss: 68.111397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:11 | Steps: 6828 | Loss: 68.113491\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:12 | Steps: 6829 | Loss: 68.114248\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:12 | Steps: 6830 | Loss: 68.116944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:12 | Steps: 6831 | Loss: 68.118965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:12 | Steps: 6832 | Loss: 68.124104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:12 | Steps: 6833 | Loss: 68.124978\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:12 | Steps: 6834 | Loss: 68.124399\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:12 | Steps: 6836 | Loss: 68.125172\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:13 | Steps: 6838 | Loss: 68.126444\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:13 | Steps: 6839 | Loss: 68.127380\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:13 | Steps: 6840 | Loss: 68.124297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:13 | Steps: 6841 | Loss: 68.125444\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:13 | Steps: 6842 | Loss: 68.128900\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:13 | Steps: 6843 | Loss: 68.129681\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:13 | Steps: 6845 | Loss: 68.134633\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:14 | Steps: 6846 | Loss: 68.131799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:14 | Steps: 6847 | Loss: 68.134004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:14 | Steps: 6848 | Loss: 68.132486\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:14 | Steps: 6850 | Loss: 68.135320\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:14 | Steps: 6851 | Loss: 68.135001\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:14 | Steps: 6852 | Loss: 68.134402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:14 | Steps: 6853 | Loss: 68.135003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:14 | Steps: 6854 | Loss: 68.136850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6855 | Loss: 68.136329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6856 | Loss: 68.134364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6857 | Loss: 68.133599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6858 | Loss: 68.132566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6859 | Loss: 68.135945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6860 | Loss: 68.136697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6861 | Loss: 68.139557\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6862 | Loss: 68.139467\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:15 | Steps: 6863 | Loss: 68.144202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:16 | Steps: 6864 | Loss: 68.151724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:16 | Steps: 6865 | Loss: 68.162288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:16 | Steps: 6866 | Loss: 68.161258\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:16 | Steps: 6867 | Loss: 68.163484\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:16 | Steps: 6868 | Loss: 68.171002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:16 | Steps: 6869 | Loss: 68.170392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:16 | Steps: 6870 | Loss: 68.173100\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:16 | Steps: 6871 | Loss: 68.174412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:17 | Steps: 6872 | Loss: 68.172580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:17 | Steps: 6873 | Loss: 68.170638\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:17 | Steps: 6874 | Loss: 68.171082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:17 | Steps: 6875 | Loss: 68.169940\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:17 | Steps: 6876 | Loss: 68.173166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:17 | Steps: 6877 | Loss: 68.174924\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:17 | Steps: 6878 | Loss: 68.178599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:17 | Steps: 6879 | Loss: 68.178590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:18 | Steps: 6881 | Loss: 68.188925\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:18 | Steps: 6883 | Loss: 68.195052\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:18 | Steps: 6885 | Loss: 68.201452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:18 | Steps: 6887 | Loss: 68.211219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:18 | Steps: 6888 | Loss: 68.212341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:18 | Steps: 6889 | Loss: 68.215854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:19 | Steps: 6890 | Loss: 68.216069\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:19 | Steps: 6891 | Loss: 68.214852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:19 | Steps: 6892 | Loss: 68.214207\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:19 | Steps: 6893 | Loss: 68.214064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:19 | Steps: 6894 | Loss: 68.214908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:19 | Steps: 6895 | Loss: 68.213015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:19 | Steps: 6896 | Loss: 68.215450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:19 | Steps: 6897 | Loss: 68.215489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:20 | Steps: 6899 | Loss: 68.217056\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:20 | Steps: 6900 | Loss: 68.224438\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:20 | Steps: 6901 | Loss: 68.227497\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:20 | Steps: 6902 | Loss: 68.229317\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:20 | Steps: 6904 | Loss: 68.235646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:20 | Steps: 6905 | Loss: 68.236705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:21 | Steps: 6907 | Loss: 68.241196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:21 | Steps: 6909 | Loss: 68.242393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:21 | Steps: 6910 | Loss: 68.243573\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:21 | Steps: 6912 | Loss: 68.249476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:21 | Steps: 6913 | Loss: 68.260319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:21 | Steps: 6914 | Loss: 68.257577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:21 | Steps: 6915 | Loss: 68.254179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:22 | Steps: 6916 | Loss: 68.256870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:22 | Steps: 6917 | Loss: 68.257276\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:22 | Steps: 6918 | Loss: 68.256564\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:22 | Steps: 6920 | Loss: 68.257112\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:22 | Steps: 6921 | Loss: 68.258644\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:22 | Steps: 6923 | Loss: 68.260130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:22 | Steps: 6924 | Loss: 68.260100\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:23 | Steps: 6925 | Loss: 68.259971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:23 | Steps: 6926 | Loss: 68.262187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:23 | Steps: 6928 | Loss: 68.262927\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:23 | Steps: 6930 | Loss: 68.268325\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:23 | Steps: 6931 | Loss: 68.268538\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:23 | Steps: 6932 | Loss: 68.270502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:24 | Steps: 6933 | Loss: 68.271417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:24 | Steps: 6935 | Loss: 68.269972\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:24 | Steps: 6936 | Loss: 68.273902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:24 | Steps: 6938 | Loss: 68.287230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:24 | Steps: 6939 | Loss: 68.289986\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:24 | Steps: 6940 | Loss: 68.294629\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:24 | Steps: 6942 | Loss: 68.296983\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:25 | Steps: 6944 | Loss: 68.299652\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:25 | Steps: 6945 | Loss: 68.302898\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:25 | Steps: 6947 | Loss: 68.299224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:25 | Steps: 6949 | Loss: 68.299464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:25 | Steps: 6950 | Loss: 68.299087\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:26 | Steps: 6952 | Loss: 68.301311\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:26 | Steps: 6953 | Loss: 68.305255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:26 | Steps: 6954 | Loss: 68.305709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:26 | Steps: 6955 | Loss: 68.306341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:26 | Steps: 6957 | Loss: 68.306699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:26 | Steps: 6958 | Loss: 68.308958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:26 | Steps: 6959 | Loss: 68.311905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:26 | Steps: 6960 | Loss: 68.312235\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:27 | Steps: 6961 | Loss: 68.314277\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:27 | Steps: 6962 | Loss: 68.314219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:27 | Steps: 6963 | Loss: 68.313943\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:27 | Steps: 6965 | Loss: 68.323175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:27 | Steps: 6966 | Loss: 68.329438\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:27 | Steps: 6968 | Loss: 68.336267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:28 | Steps: 6970 | Loss: 68.338397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:28 | Steps: 6971 | Loss: 68.341389\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:28 | Steps: 6972 | Loss: 68.347866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:28 | Steps: 6973 | Loss: 68.352874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:28 | Steps: 6974 | Loss: 68.359709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:28 | Steps: 6976 | Loss: 68.358391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:29 | Steps: 6977 | Loss: 68.355517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:29 | Steps: 6978 | Loss: 68.354974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:29 | Steps: 6979 | Loss: 68.354344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:29 | Steps: 6980 | Loss: 68.360404\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:29 | Steps: 6981 | Loss: 68.365498\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:29 | Steps: 6983 | Loss: 68.362926\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:29 | Steps: 6985 | Loss: 68.362939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:30 | Steps: 6986 | Loss: 68.365149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:30 | Steps: 6987 | Loss: 68.364764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:30 | Steps: 6988 | Loss: 68.367077\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:30 | Steps: 6989 | Loss: 68.367738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:30 | Steps: 6991 | Loss: 68.364266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:30 | Steps: 6992 | Loss: 68.362798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:30 | Steps: 6993 | Loss: 68.362517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:31 | Steps: 6995 | Loss: 68.364769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:31 | Steps: 6996 | Loss: 68.373034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:31 | Steps: 6997 | Loss: 68.373498\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:31 | Steps: 6999 | Loss: 68.374007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:31 | Steps: 7001 | Loss: 68.374619\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:31 | Steps: 7002 | Loss: 68.375427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:32 | Steps: 7003 | Loss: 68.375975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:32 | Steps: 7005 | Loss: 68.377170\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:32 | Steps: 7006 | Loss: 68.379370\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:32 | Steps: 7008 | Loss: 68.385418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:32 | Steps: 7009 | Loss: 68.388331\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:32 | Steps: 7011 | Loss: 68.397732\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:33 | Steps: 7013 | Loss: 68.400834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:33 | Steps: 7015 | Loss: 68.404935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:33 | Steps: 7016 | Loss: 68.411954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:33 | Steps: 7017 | Loss: 68.417555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:33 | Steps: 7019 | Loss: 68.416613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:34 | Steps: 7021 | Loss: 68.415686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:34 | Steps: 7023 | Loss: 68.419834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:34 | Steps: 7024 | Loss: 68.421519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:35 | Steps: 7025 | Loss: 68.423613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:35 | Steps: 7026 | Loss: 68.423993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:35 | Steps: 7027 | Loss: 68.428592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:35 | Steps: 7028 | Loss: 68.433702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:35 | Steps: 7029 | Loss: 68.436984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:35 | Steps: 7031 | Loss: 68.442571\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:35 | Steps: 7032 | Loss: 68.445775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:36 | Steps: 7033 | Loss: 68.449515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:36 | Steps: 7035 | Loss: 68.455424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:36 | Steps: 7036 | Loss: 68.461213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:36 | Steps: 7037 | Loss: 68.465424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:36 | Steps: 7038 | Loss: 68.471198\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:36 | Steps: 7039 | Loss: 68.474465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:36 | Steps: 7040 | Loss: 68.476883\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:37 | Steps: 7041 | Loss: 68.477161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:37 | Steps: 7042 | Loss: 68.482067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:37 | Steps: 7044 | Loss: 68.487295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:37 | Steps: 7046 | Loss: 68.496129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:37 | Steps: 7047 | Loss: 68.504189\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:37 | Steps: 7048 | Loss: 68.513064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:37 | Steps: 7049 | Loss: 68.516326\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:37 | Steps: 7050 | Loss: 68.518459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:38 | Steps: 7051 | Loss: 68.519243\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:38 | Steps: 7052 | Loss: 68.517445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:38 | Steps: 7053 | Loss: 68.517112\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:38 | Steps: 7054 | Loss: 68.521666\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:38 | Steps: 7056 | Loss: 68.520241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:38 | Steps: 7058 | Loss: 68.525852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:39 | Steps: 7059 | Loss: 68.524352\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:39 | Steps: 7060 | Loss: 68.521320\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:39 | Steps: 7061 | Loss: 68.529588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:39 | Steps: 7062 | Loss: 68.530595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:39 | Steps: 7064 | Loss: 68.532950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:39 | Steps: 7065 | Loss: 68.538052\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:39 | Steps: 7066 | Loss: 68.534832\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:39 | Steps: 7067 | Loss: 68.535674\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:40 | Steps: 7068 | Loss: 68.535273\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:40 | Steps: 7070 | Loss: 68.539916\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:40 | Steps: 7071 | Loss: 68.542603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:40 | Steps: 7072 | Loss: 68.543316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:40 | Steps: 7073 | Loss: 68.542765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:40 | Steps: 7074 | Loss: 68.544891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:41 | Steps: 7075 | Loss: 68.547108\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:41 | Steps: 7076 | Loss: 68.550134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:41 | Steps: 7077 | Loss: 68.554573\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:41 | Steps: 7078 | Loss: 68.555594\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:41 | Steps: 7080 | Loss: 68.555091\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:41 | Steps: 7081 | Loss: 68.558034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:41 | Steps: 7082 | Loss: 68.559382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:41 | Steps: 7083 | Loss: 68.564958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:42 | Steps: 7084 | Loss: 68.565190\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:42 | Steps: 7085 | Loss: 68.565946\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:42 | Steps: 7086 | Loss: 68.567717\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:42 | Steps: 7088 | Loss: 68.565027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:42 | Steps: 7090 | Loss: 68.565442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:42 | Steps: 7091 | Loss: 68.566483\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:42 | Steps: 7092 | Loss: 68.570835\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:43 | Steps: 7093 | Loss: 68.571521\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:43 | Steps: 7094 | Loss: 68.572813\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:43 | Steps: 7095 | Loss: 68.573514\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:43 | Steps: 7096 | Loss: 68.578906\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:43 | Steps: 7097 | Loss: 68.580913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:43 | Steps: 7099 | Loss: 68.582141\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:43 | Steps: 7100 | Loss: 68.583856\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:43 | Steps: 7101 | Loss: 68.583097\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:44 | Steps: 7103 | Loss: 68.591475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:44 | Steps: 7104 | Loss: 68.592663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:44 | Steps: 7106 | Loss: 68.595179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:44 | Steps: 7107 | Loss: 68.595290\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:44 | Steps: 7108 | Loss: 68.596956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:44 | Steps: 7110 | Loss: 68.598047\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:45 | Steps: 7111 | Loss: 68.602068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:45 | Steps: 7112 | Loss: 68.602476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:45 | Steps: 7113 | Loss: 68.606441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:45 | Steps: 7114 | Loss: 68.610484\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:45 | Steps: 7115 | Loss: 68.612285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:45 | Steps: 7116 | Loss: 68.616033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:45 | Steps: 7117 | Loss: 68.618251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:45 | Steps: 7118 | Loss: 68.614728\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:46 | Steps: 7119 | Loss: 68.611694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:46 | Steps: 7120 | Loss: 68.611953\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:46 | Steps: 7122 | Loss: 68.616965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:46 | Steps: 7123 | Loss: 68.621953\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:46 | Steps: 7124 | Loss: 68.625891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:46 | Steps: 7125 | Loss: 68.628662\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:46 | Steps: 7126 | Loss: 68.625108\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:47 | Steps: 7128 | Loss: 68.622176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:47 | Steps: 7129 | Loss: 68.620433\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:47 | Steps: 7130 | Loss: 68.621185\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:47 | Steps: 7131 | Loss: 68.619309\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:47 | Steps: 7132 | Loss: 68.618958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:47 | Steps: 7133 | Loss: 68.622105\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:47 | Steps: 7134 | Loss: 68.621358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:47 | Steps: 7135 | Loss: 68.621031\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:48 | Steps: 7136 | Loss: 68.619444\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:48 | Steps: 7137 | Loss: 68.626458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:48 | Steps: 7138 | Loss: 68.631068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:48 | Steps: 7140 | Loss: 68.630639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:48 | Steps: 7141 | Loss: 68.634039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:48 | Steps: 7142 | Loss: 68.639528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:48 | Steps: 7143 | Loss: 68.640451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:48 | Steps: 7144 | Loss: 68.639922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:49 | Steps: 7145 | Loss: 68.639997\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:49 | Steps: 7146 | Loss: 68.639931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:49 | Steps: 7147 | Loss: 68.638194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:49 | Steps: 7148 | Loss: 68.640888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:49 | Steps: 7149 | Loss: 68.649451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:49 | Steps: 7150 | Loss: 68.650081\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:49 | Steps: 7151 | Loss: 68.651150\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:49 | Steps: 7152 | Loss: 68.654120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:50 | Steps: 7154 | Loss: 68.664840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:50 | Steps: 7155 | Loss: 68.668530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:50 | Steps: 7156 | Loss: 68.675990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:50 | Steps: 7157 | Loss: 68.673843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:50 | Steps: 7158 | Loss: 68.671724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:50 | Steps: 7159 | Loss: 68.672816\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:50 | Steps: 7160 | Loss: 68.675471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:50 | Steps: 7161 | Loss: 68.676807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:51 | Steps: 7163 | Loss: 68.679290\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:51 | Steps: 7164 | Loss: 68.680044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:51 | Steps: 7165 | Loss: 68.681638\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:51 | Steps: 7166 | Loss: 68.683954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:51 | Steps: 7167 | Loss: 68.687426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:51 | Steps: 7168 | Loss: 68.693698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:51 | Steps: 7169 | Loss: 68.696660\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:52 | Steps: 7170 | Loss: 68.699073\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:52 | Steps: 7171 | Loss: 68.702946\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:52 | Steps: 7172 | Loss: 68.704636\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:52 | Steps: 7173 | Loss: 68.704874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:52 | Steps: 7175 | Loss: 68.701695\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:52 | Steps: 7177 | Loss: 68.704907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:52 | Steps: 7178 | Loss: 68.717179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:53 | Steps: 7179 | Loss: 68.724941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:53 | Steps: 7180 | Loss: 68.724430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:53 | Steps: 7181 | Loss: 68.727223\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:53 | Steps: 7182 | Loss: 68.726354\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:53 | Steps: 7183 | Loss: 68.727408\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:53 | Steps: 7184 | Loss: 68.730650\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:53 | Steps: 7185 | Loss: 68.740174\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:53 | Steps: 7186 | Loss: 68.743155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:54 | Steps: 7187 | Loss: 68.748179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:54 | Steps: 7188 | Loss: 68.750382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:54 | Steps: 7190 | Loss: 68.753053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:54 | Steps: 7191 | Loss: 68.757675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:54 | Steps: 7192 | Loss: 68.762152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:54 | Steps: 7193 | Loss: 68.764470\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:54 | Steps: 7194 | Loss: 68.766792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:55 | Steps: 7195 | Loss: 68.766399\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:55 | Steps: 7196 | Loss: 68.765373\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:55 | Steps: 7197 | Loss: 68.769052\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:55 | Steps: 7198 | Loss: 68.766444\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:55 | Steps: 7199 | Loss: 68.762408\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:55 | Steps: 7201 | Loss: 68.772586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:55 | Steps: 7202 | Loss: 68.772952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:56 | Steps: 7203 | Loss: 68.770901\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:56 | Steps: 7204 | Loss: 68.774152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:56 | Steps: 7206 | Loss: 68.786528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:56 | Steps: 7208 | Loss: 68.783663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:56 | Steps: 7209 | Loss: 68.784918\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:56 | Steps: 7210 | Loss: 68.785084\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:56 | Steps: 7211 | Loss: 68.791330\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:57 | Steps: 7213 | Loss: 68.795854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:57 | Steps: 7214 | Loss: 68.796635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:57 | Steps: 7215 | Loss: 68.797018\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:57 | Steps: 7216 | Loss: 68.799095\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:57 | Steps: 7217 | Loss: 68.800062\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:57 | Steps: 7218 | Loss: 68.801451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:57 | Steps: 7219 | Loss: 68.801038\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:57 | Steps: 7220 | Loss: 68.804602\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:58 | Steps: 7221 | Loss: 68.807861\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:58 | Steps: 7222 | Loss: 68.809119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:58 | Steps: 7223 | Loss: 68.807661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:58 | Steps: 7225 | Loss: 68.810341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:58 | Steps: 7227 | Loss: 68.813194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:58 | Steps: 7228 | Loss: 68.813682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7229 | Loss: 68.821282\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7230 | Loss: 68.825759\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7231 | Loss: 68.827610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7232 | Loss: 68.828691\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7233 | Loss: 68.826152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7234 | Loss: 68.829882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7235 | Loss: 68.832956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7236 | Loss: 68.833295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:10:59 | Steps: 7237 | Loss: 68.830226\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:00 | Steps: 7239 | Loss: 68.833525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:00 | Steps: 7240 | Loss: 68.833042\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:00 | Steps: 7241 | Loss: 68.835372\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:00 | Steps: 7242 | Loss: 68.839729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:00 | Steps: 7244 | Loss: 68.846121\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:00 | Steps: 7245 | Loss: 68.846469\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:01 | Steps: 7247 | Loss: 68.849713\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:01 | Steps: 7248 | Loss: 68.855006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:01 | Steps: 7249 | Loss: 68.855753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:01 | Steps: 7250 | Loss: 68.863382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:01 | Steps: 7251 | Loss: 68.867407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:01 | Steps: 7252 | Loss: 68.869177\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:01 | Steps: 7253 | Loss: 68.871694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7254 | Loss: 68.874642\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7255 | Loss: 68.872519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7256 | Loss: 68.872854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7257 | Loss: 68.876551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7258 | Loss: 68.875972\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7259 | Loss: 68.875318\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7260 | Loss: 68.876134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7261 | Loss: 68.876478\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:02 | Steps: 7262 | Loss: 68.878093\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:03 | Steps: 7263 | Loss: 68.881059\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:03 | Steps: 7264 | Loss: 68.883647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:03 | Steps: 7265 | Loss: 68.885393\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:03 | Steps: 7266 | Loss: 68.884618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:03 | Steps: 7267 | Loss: 68.884815\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:03 | Steps: 7268 | Loss: 68.883423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:03 | Steps: 7270 | Loss: 68.882445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:04 | Steps: 7271 | Loss: 68.882984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:04 | Steps: 7272 | Loss: 68.882263\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:04 | Steps: 7274 | Loss: 68.892975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:04 | Steps: 7275 | Loss: 68.897971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:04 | Steps: 7276 | Loss: 68.903899\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:04 | Steps: 7277 | Loss: 68.901868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:04 | Steps: 7278 | Loss: 68.905685\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:05 | Steps: 7279 | Loss: 68.909025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:05 | Steps: 7281 | Loss: 68.911436\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:05 | Steps: 7282 | Loss: 68.912795\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:05 | Steps: 7283 | Loss: 68.914313\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:05 | Steps: 7284 | Loss: 68.913640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:05 | Steps: 7285 | Loss: 68.915815\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:05 | Steps: 7286 | Loss: 68.917679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:05 | Steps: 7287 | Loss: 68.915739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:06 | Steps: 7289 | Loss: 68.916627\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:06 | Steps: 7290 | Loss: 68.921956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:06 | Steps: 7291 | Loss: 68.925834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:06 | Steps: 7292 | Loss: 68.925815\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:06 | Steps: 7293 | Loss: 68.927315\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:06 | Steps: 7295 | Loss: 68.939964\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:07 | Steps: 7296 | Loss: 68.940515\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:07 | Steps: 7297 | Loss: 68.939680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:07 | Steps: 7299 | Loss: 68.942287\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:07 | Steps: 7300 | Loss: 68.939997\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:07 | Steps: 7301 | Loss: 68.942821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:07 | Steps: 7302 | Loss: 68.949792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:07 | Steps: 7303 | Loss: 68.954294\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:07 | Steps: 7304 | Loss: 68.953000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:08 | Steps: 7305 | Loss: 68.953519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:08 | Steps: 7307 | Loss: 68.961877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:08 | Steps: 7309 | Loss: 68.969467\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:08 | Steps: 7310 | Loss: 68.971174\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:08 | Steps: 7311 | Loss: 68.975432\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:09 | Steps: 7313 | Loss: 68.980255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:09 | Steps: 7314 | Loss: 68.986332\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:09 | Steps: 7315 | Loss: 68.987751\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:09 | Steps: 7316 | Loss: 68.987985\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:09 | Steps: 7318 | Loss: 68.989650\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:09 | Steps: 7319 | Loss: 68.990934\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:09 | Steps: 7321 | Loss: 68.998755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:10 | Steps: 7322 | Loss: 68.998634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:10 | Steps: 7323 | Loss: 69.004666\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:10 | Steps: 7325 | Loss: 69.013197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:10 | Steps: 7326 | Loss: 69.020612\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:10 | Steps: 7327 | Loss: 69.021923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:10 | Steps: 7328 | Loss: 69.026258\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7330 | Loss: 69.031692\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7331 | Loss: 69.030884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7332 | Loss: 69.029939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7333 | Loss: 69.029514\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7334 | Loss: 69.032078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7335 | Loss: 69.031855\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7336 | Loss: 69.027886\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7337 | Loss: 69.027419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:11 | Steps: 7338 | Loss: 69.026782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:12 | Steps: 7339 | Loss: 69.025650\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:12 | Steps: 7340 | Loss: 69.025851\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:12 | Steps: 7342 | Loss: 69.032364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:12 | Steps: 7344 | Loss: 69.036246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:12 | Steps: 7345 | Loss: 69.035218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:12 | Steps: 7346 | Loss: 69.037899\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:13 | Steps: 7348 | Loss: 69.043892\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:13 | Steps: 7349 | Loss: 69.042908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:13 | Steps: 7350 | Loss: 69.047025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:13 | Steps: 7352 | Loss: 69.048398\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:13 | Steps: 7353 | Loss: 69.059102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:13 | Steps: 7354 | Loss: 69.065172\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:14 | Steps: 7356 | Loss: 69.070950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:14 | Steps: 7357 | Loss: 69.070368\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:14 | Steps: 7358 | Loss: 69.072765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:14 | Steps: 7360 | Loss: 69.073604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:14 | Steps: 7361 | Loss: 69.071310\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:14 | Steps: 7362 | Loss: 69.070210\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:14 | Steps: 7364 | Loss: 69.071309\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:15 | Steps: 7365 | Loss: 69.070972\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:15 | Steps: 7366 | Loss: 69.071116\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:15 | Steps: 7367 | Loss: 69.075202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:15 | Steps: 7368 | Loss: 69.076895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:15 | Steps: 7370 | Loss: 69.091435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:15 | Steps: 7371 | Loss: 69.093907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:15 | Steps: 7372 | Loss: 69.099155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:16 | Steps: 7373 | Loss: 69.103329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:16 | Steps: 7374 | Loss: 69.104670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:16 | Steps: 7375 | Loss: 69.105113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:16 | Steps: 7376 | Loss: 69.102474\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:16 | Steps: 7377 | Loss: 69.105648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:16 | Steps: 7378 | Loss: 69.113177\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:16 | Steps: 7379 | Loss: 69.115572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:16 | Steps: 7380 | Loss: 69.119007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:17 | Steps: 7382 | Loss: 69.122292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:17 | Steps: 7383 | Loss: 69.126110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:17 | Steps: 7384 | Loss: 69.130961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:17 | Steps: 7385 | Loss: 69.133367\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:17 | Steps: 7386 | Loss: 69.132033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:17 | Steps: 7387 | Loss: 69.131723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:17 | Steps: 7388 | Loss: 69.131160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:17 | Steps: 7389 | Loss: 69.132368\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:18 | Steps: 7390 | Loss: 69.130320\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:18 | Steps: 7391 | Loss: 69.129414\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:18 | Steps: 7393 | Loss: 69.136271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:18 | Steps: 7394 | Loss: 69.141320\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:18 | Steps: 7395 | Loss: 69.144782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:18 | Steps: 7397 | Loss: 69.139330\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:18 | Steps: 7398 | Loss: 69.141053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:19 | Steps: 7399 | Loss: 69.142388\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:19 | Steps: 7400 | Loss: 69.142260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:19 | Steps: 7401 | Loss: 69.142841\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:19 | Steps: 7403 | Loss: 69.142542\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:19 | Steps: 7404 | Loss: 69.144120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:19 | Steps: 7405 | Loss: 69.145048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:19 | Steps: 7406 | Loss: 69.149535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:19 | Steps: 7407 | Loss: 69.157266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:20 | Steps: 7408 | Loss: 69.157706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:20 | Steps: 7409 | Loss: 69.160689\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:20 | Steps: 7410 | Loss: 69.165705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:20 | Steps: 7411 | Loss: 69.168479\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:20 | Steps: 7412 | Loss: 69.168774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:20 | Steps: 7413 | Loss: 69.168874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:20 | Steps: 7415 | Loss: 69.167563\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7416 | Loss: 69.168405\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7417 | Loss: 69.169590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7418 | Loss: 69.167245\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7419 | Loss: 69.169942\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7420 | Loss: 69.176247\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7421 | Loss: 69.180533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7422 | Loss: 69.182319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7423 | Loss: 69.179581\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:21 | Steps: 7424 | Loss: 69.179435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:22 | Steps: 7425 | Loss: 69.184127\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:22 | Steps: 7426 | Loss: 69.186104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:22 | Steps: 7427 | Loss: 69.185681\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:22 | Steps: 7429 | Loss: 69.187854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:22 | Steps: 7431 | Loss: 69.196436\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:22 | Steps: 7432 | Loss: 69.199427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7433 | Loss: 69.206742\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7434 | Loss: 69.215143\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7435 | Loss: 69.216614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7436 | Loss: 69.219647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7437 | Loss: 69.223205\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7438 | Loss: 69.227272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7439 | Loss: 69.231312\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7440 | Loss: 69.235365\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:23 | Steps: 7441 | Loss: 69.240279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:24 | Steps: 7442 | Loss: 69.241708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:24 | Steps: 7443 | Loss: 69.246322\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:24 | Steps: 7444 | Loss: 69.245651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:24 | Steps: 7445 | Loss: 69.246783\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:24 | Steps: 7446 | Loss: 69.247292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:24 | Steps: 7447 | Loss: 69.249501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:24 | Steps: 7448 | Loss: 69.247281\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:24 | Steps: 7449 | Loss: 69.247264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:25 | Steps: 7450 | Loss: 69.252821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:25 | Steps: 7451 | Loss: 69.257010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:25 | Steps: 7452 | Loss: 69.264036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:25 | Steps: 7453 | Loss: 69.268391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:25 | Steps: 7454 | Loss: 69.272653\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:25 | Steps: 7456 | Loss: 69.272488\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:25 | Steps: 7457 | Loss: 69.272279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:26 | Steps: 7458 | Loss: 69.273556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:26 | Steps: 7459 | Loss: 69.277264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:26 | Steps: 7461 | Loss: 69.281219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:26 | Steps: 7462 | Loss: 69.277620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:26 | Steps: 7463 | Loss: 69.274369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:26 | Steps: 7464 | Loss: 69.272331\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:26 | Steps: 7465 | Loss: 69.271108\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:26 | Steps: 7466 | Loss: 69.275177\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:27 | Steps: 7467 | Loss: 69.277731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:27 | Steps: 7468 | Loss: 69.279464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:27 | Steps: 7469 | Loss: 69.280543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:27 | Steps: 7470 | Loss: 69.282447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:27 | Steps: 7471 | Loss: 69.289748\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:27 | Steps: 7473 | Loss: 69.289062\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:27 | Steps: 7474 | Loss: 69.287670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:28 | Steps: 7475 | Loss: 69.289424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:28 | Steps: 7476 | Loss: 69.293020\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:28 | Steps: 7477 | Loss: 69.295670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:28 | Steps: 7478 | Loss: 69.294007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:28 | Steps: 7479 | Loss: 69.295914\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:28 | Steps: 7481 | Loss: 69.298588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:28 | Steps: 7482 | Loss: 69.299251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:28 | Steps: 7483 | Loss: 69.304147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:29 | Steps: 7484 | Loss: 69.311010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:29 | Steps: 7485 | Loss: 69.311540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:29 | Steps: 7486 | Loss: 69.314797\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:29 | Steps: 7487 | Loss: 69.317772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:29 | Steps: 7488 | Loss: 69.315917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:29 | Steps: 7489 | Loss: 69.314867\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:29 | Steps: 7490 | Loss: 69.313810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:29 | Steps: 7491 | Loss: 69.315718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:30 | Steps: 7492 | Loss: 69.321759\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:30 | Steps: 7493 | Loss: 69.323325\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:30 | Steps: 7494 | Loss: 69.322717\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:30 | Steps: 7496 | Loss: 69.326872\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:30 | Steps: 7497 | Loss: 69.331522\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:30 | Steps: 7498 | Loss: 69.330390\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:30 | Steps: 7499 | Loss: 69.333782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:30 | Steps: 7500 | Loss: 69.334880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:31 | Steps: 7502 | Loss: 69.333706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:31 | Steps: 7503 | Loss: 69.331028\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:31 | Steps: 7504 | Loss: 69.331298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:31 | Steps: 7505 | Loss: 69.330530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:31 | Steps: 7507 | Loss: 69.329595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:31 | Steps: 7509 | Loss: 69.330783\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:32 | Steps: 7510 | Loss: 69.331954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:32 | Steps: 7511 | Loss: 69.334983\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:32 | Steps: 7512 | Loss: 69.336129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:32 | Steps: 7513 | Loss: 69.335396\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:32 | Steps: 7514 | Loss: 69.339117\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:32 | Steps: 7515 | Loss: 69.337806\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:32 | Steps: 7516 | Loss: 69.338648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:32 | Steps: 7517 | Loss: 69.338538\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:33 | Steps: 7518 | Loss: 69.339076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:33 | Steps: 7520 | Loss: 69.343163\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:33 | Steps: 7521 | Loss: 69.343667\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:33 | Steps: 7522 | Loss: 69.345387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:33 | Steps: 7523 | Loss: 69.345330\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:33 | Steps: 7524 | Loss: 69.346375\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:33 | Steps: 7525 | Loss: 69.349224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:34 | Steps: 7526 | Loss: 69.354466\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:34 | Steps: 7527 | Loss: 69.353666\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:34 | Steps: 7528 | Loss: 69.354724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:34 | Steps: 7529 | Loss: 69.355583\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:34 | Steps: 7531 | Loss: 69.362816\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:34 | Steps: 7532 | Loss: 69.366548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:34 | Steps: 7533 | Loss: 69.368196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:34 | Steps: 7534 | Loss: 69.368606\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:35 | Steps: 7536 | Loss: 69.367323\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:35 | Steps: 7537 | Loss: 69.366115\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:35 | Steps: 7538 | Loss: 69.365324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:35 | Steps: 7539 | Loss: 69.364959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:35 | Steps: 7540 | Loss: 69.365103\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:35 | Steps: 7542 | Loss: 69.376184\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:36 | Steps: 7543 | Loss: 69.375831\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:36 | Steps: 7544 | Loss: 69.372448\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:36 | Steps: 7545 | Loss: 69.371284\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:36 | Steps: 7546 | Loss: 69.370610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:36 | Steps: 7547 | Loss: 69.371797\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:36 | Steps: 7548 | Loss: 69.374504\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:36 | Steps: 7549 | Loss: 69.376257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:36 | Steps: 7550 | Loss: 69.378173\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:37 | Steps: 7552 | Loss: 69.377529\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:37 | Steps: 7554 | Loss: 69.378411\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:37 | Steps: 7555 | Loss: 69.377499\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:37 | Steps: 7556 | Loss: 69.383755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:37 | Steps: 7557 | Loss: 69.385668\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:37 | Steps: 7559 | Loss: 69.384821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:38 | Steps: 7560 | Loss: 69.387309\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:38 | Steps: 7561 | Loss: 69.387915\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:38 | Steps: 7562 | Loss: 69.388473\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:38 | Steps: 7564 | Loss: 69.391663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:38 | Steps: 7565 | Loss: 69.389553\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:38 | Steps: 7566 | Loss: 69.394985\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:38 | Steps: 7567 | Loss: 69.397134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:39 | Steps: 7568 | Loss: 69.399817\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:39 | Steps: 7569 | Loss: 69.401143\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:39 | Steps: 7570 | Loss: 69.412132\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:39 | Steps: 7571 | Loss: 69.423285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:39 | Steps: 7572 | Loss: 69.435831\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:39 | Steps: 7574 | Loss: 69.443683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:39 | Steps: 7575 | Loss: 69.444337\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:40 | Steps: 7576 | Loss: 69.446653\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:40 | Steps: 7577 | Loss: 69.456742\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:40 | Steps: 7578 | Loss: 69.457800\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:40 | Steps: 7579 | Loss: 69.455283\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:40 | Steps: 7580 | Loss: 69.457206\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:40 | Steps: 7582 | Loss: 69.461430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:40 | Steps: 7584 | Loss: 69.464706\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:41 | Steps: 7585 | Loss: 69.466447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:41 | Steps: 7586 | Loss: 69.471913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:41 | Steps: 7587 | Loss: 69.475486\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:41 | Steps: 7588 | Loss: 69.478747\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:41 | Steps: 7589 | Loss: 69.483422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:41 | Steps: 7590 | Loss: 69.487623\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:41 | Steps: 7591 | Loss: 69.489973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:42 | Steps: 7593 | Loss: 69.498107\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:42 | Steps: 7594 | Loss: 69.500544\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:42 | Steps: 7595 | Loss: 69.503753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:42 | Steps: 7596 | Loss: 69.506409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:42 | Steps: 7597 | Loss: 69.511166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:42 | Steps: 7598 | Loss: 69.515272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:42 | Steps: 7599 | Loss: 69.525999\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:42 | Steps: 7600 | Loss: 69.526440\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:43 | Steps: 7601 | Loss: 69.528757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:43 | Steps: 7602 | Loss: 69.527443\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:43 | Steps: 7603 | Loss: 69.527764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:43 | Steps: 7604 | Loss: 69.529126\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:43 | Steps: 7606 | Loss: 69.532409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:43 | Steps: 7607 | Loss: 69.537056\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:43 | Steps: 7608 | Loss: 69.540639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:44 | Steps: 7610 | Loss: 69.541543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:44 | Steps: 7611 | Loss: 69.542342\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:44 | Steps: 7612 | Loss: 69.546520\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:44 | Steps: 7613 | Loss: 69.548435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:44 | Steps: 7614 | Loss: 69.551488\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:44 | Steps: 7616 | Loss: 69.551533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:44 | Steps: 7617 | Loss: 69.549327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:45 | Steps: 7618 | Loss: 69.556349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:45 | Steps: 7619 | Loss: 69.553045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:45 | Steps: 7621 | Loss: 69.555684\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:45 | Steps: 7623 | Loss: 69.555563\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:45 | Steps: 7624 | Loss: 69.555484\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:45 | Steps: 7625 | Loss: 69.556379\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:46 | Steps: 7626 | Loss: 69.557198\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:46 | Steps: 7628 | Loss: 69.552415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:46 | Steps: 7629 | Loss: 69.548993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:46 | Steps: 7630 | Loss: 69.549920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:46 | Steps: 7631 | Loss: 69.548498\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:46 | Steps: 7633 | Loss: 69.549248\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:46 | Steps: 7634 | Loss: 69.549617\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:47 | Steps: 7635 | Loss: 69.550752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:47 | Steps: 7636 | Loss: 69.555503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:47 | Steps: 7637 | Loss: 69.554431\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:47 | Steps: 7639 | Loss: 69.557536\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:47 | Steps: 7640 | Loss: 69.558800\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:47 | Steps: 7641 | Loss: 69.562422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:47 | Steps: 7642 | Loss: 69.564374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:48 | Steps: 7643 | Loss: 69.563771\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:48 | Steps: 7644 | Loss: 69.565869\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:48 | Steps: 7646 | Loss: 69.567462\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:48 | Steps: 7647 | Loss: 69.569756\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:48 | Steps: 7649 | Loss: 69.579715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:48 | Steps: 7650 | Loss: 69.582556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:48 | Steps: 7651 | Loss: 69.585839\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:49 | Steps: 7652 | Loss: 69.588364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:49 | Steps: 7654 | Loss: 69.590236\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:49 | Steps: 7655 | Loss: 69.593767\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:49 | Steps: 7656 | Loss: 69.590276\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:49 | Steps: 7657 | Loss: 69.590833\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:49 | Steps: 7658 | Loss: 69.590742\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:50 | Steps: 7660 | Loss: 69.592731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:50 | Steps: 7661 | Loss: 69.593593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:50 | Steps: 7662 | Loss: 69.594245\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:50 | Steps: 7663 | Loss: 69.597616\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:50 | Steps: 7664 | Loss: 69.601639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:50 | Steps: 7666 | Loss: 69.605886\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:50 | Steps: 7667 | Loss: 69.605773\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:51 | Steps: 7668 | Loss: 69.604381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:51 | Steps: 7669 | Loss: 69.608977\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:51 | Steps: 7670 | Loss: 69.612636\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:51 | Steps: 7671 | Loss: 69.613049\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:51 | Steps: 7673 | Loss: 69.618086\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:51 | Steps: 7674 | Loss: 69.620230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:51 | Steps: 7675 | Loss: 69.622068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:52 | Steps: 7676 | Loss: 69.625456\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:52 | Steps: 7677 | Loss: 69.631181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:52 | Steps: 7678 | Loss: 69.632973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:52 | Steps: 7680 | Loss: 69.639887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:52 | Steps: 7681 | Loss: 69.642816\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:52 | Steps: 7683 | Loss: 69.640550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:53 | Steps: 7684 | Loss: 69.641300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:53 | Steps: 7685 | Loss: 69.640311\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:53 | Steps: 7686 | Loss: 69.644531\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:53 | Steps: 7687 | Loss: 69.649666\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:53 | Steps: 7688 | Loss: 69.647205\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:53 | Steps: 7689 | Loss: 69.646386\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:53 | Steps: 7690 | Loss: 69.647095\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:53 | Steps: 7691 | Loss: 69.647435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:54 | Steps: 7692 | Loss: 69.647611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:54 | Steps: 7693 | Loss: 69.648546\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:54 | Steps: 7694 | Loss: 69.648325\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:54 | Steps: 7695 | Loss: 69.648574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:54 | Steps: 7697 | Loss: 69.655907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:54 | Steps: 7698 | Loss: 69.658654\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:54 | Steps: 7699 | Loss: 69.656192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:54 | Steps: 7700 | Loss: 69.656760\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:55 | Steps: 7701 | Loss: 69.660139\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:55 | Steps: 7702 | Loss: 69.659551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:55 | Steps: 7703 | Loss: 69.662032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:55 | Steps: 7704 | Loss: 69.670269\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:55 | Steps: 7706 | Loss: 69.678249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:55 | Steps: 7707 | Loss: 69.678362\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:55 | Steps: 7708 | Loss: 69.679670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:56 | Steps: 7709 | Loss: 69.680817\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:56 | Steps: 7710 | Loss: 69.679175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:56 | Steps: 7711 | Loss: 69.681430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:56 | Steps: 7712 | Loss: 69.683793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:56 | Steps: 7714 | Loss: 69.693745\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:56 | Steps: 7716 | Loss: 69.703567\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:56 | Steps: 7717 | Loss: 69.706356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:57 | Steps: 7718 | Loss: 69.710699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:57 | Steps: 7719 | Loss: 69.716184\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:57 | Steps: 7720 | Loss: 69.720934\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:57 | Steps: 7721 | Loss: 69.724688\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:57 | Steps: 7722 | Loss: 69.732044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:57 | Steps: 7723 | Loss: 69.733536\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:57 | Steps: 7724 | Loss: 69.734917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:57 | Steps: 7725 | Loss: 69.735744\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:58 | Steps: 7727 | Loss: 69.739900\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:58 | Steps: 7728 | Loss: 69.739981\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:58 | Steps: 7729 | Loss: 69.748088\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:58 | Steps: 7730 | Loss: 69.748333\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:58 | Steps: 7732 | Loss: 69.749040\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:58 | Steps: 7733 | Loss: 69.751604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:59 | Steps: 7734 | Loss: 69.758753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:59 | Steps: 7735 | Loss: 69.763306\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:59 | Steps: 7736 | Loss: 69.765242\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:59 | Steps: 7738 | Loss: 69.776767\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:59 | Steps: 7739 | Loss: 69.774074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:59 | Steps: 7740 | Loss: 69.772723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:11:59 | Steps: 7741 | Loss: 69.775485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:00 | Steps: 7743 | Loss: 69.777209\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:00 | Steps: 7744 | Loss: 69.778721\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:00 | Steps: 7745 | Loss: 69.780792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:00 | Steps: 7746 | Loss: 69.777711\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:00 | Steps: 7747 | Loss: 69.774039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:00 | Steps: 7749 | Loss: 69.772404\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:00 | Steps: 7750 | Loss: 69.776761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:01 | Steps: 7751 | Loss: 69.777258\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:01 | Steps: 7752 | Loss: 69.779324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:01 | Steps: 7754 | Loss: 69.783636\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:01 | Steps: 7755 | Loss: 69.784195\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:01 | Steps: 7756 | Loss: 69.787592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:01 | Steps: 7758 | Loss: 69.791914\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:01 | Steps: 7759 | Loss: 69.792877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:02 | Steps: 7760 | Loss: 69.792814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:02 | Steps: 7761 | Loss: 69.794450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:02 | Steps: 7762 | Loss: 69.795878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:02 | Steps: 7763 | Loss: 69.798673\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:02 | Steps: 7764 | Loss: 69.801852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:02 | Steps: 7765 | Loss: 69.802677\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:02 | Steps: 7766 | Loss: 69.806279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:02 | Steps: 7767 | Loss: 69.807439\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:03 | Steps: 7768 | Loss: 69.808419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:03 | Steps: 7770 | Loss: 69.808647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:03 | Steps: 7771 | Loss: 69.808619\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:03 | Steps: 7772 | Loss: 69.812066\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:03 | Steps: 7773 | Loss: 69.816242\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:03 | Steps: 7774 | Loss: 69.818587\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:03 | Steps: 7775 | Loss: 69.822285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:04 | Steps: 7776 | Loss: 69.820729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:04 | Steps: 7778 | Loss: 69.823688\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:04 | Steps: 7779 | Loss: 69.820855\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:04 | Steps: 7780 | Loss: 69.818614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:04 | Steps: 7781 | Loss: 69.817589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:04 | Steps: 7782 | Loss: 69.817191\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:04 | Steps: 7783 | Loss: 69.820042\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:05 | Steps: 7784 | Loss: 69.819875\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:05 | Steps: 7785 | Loss: 69.823185\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:05 | Steps: 7787 | Loss: 69.828646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:05 | Steps: 7789 | Loss: 69.839103\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:05 | Steps: 7790 | Loss: 69.841790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:05 | Steps: 7791 | Loss: 69.842905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:05 | Steps: 7792 | Loss: 69.848264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:06 | Steps: 7794 | Loss: 69.845505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:06 | Steps: 7795 | Loss: 69.846795\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:06 | Steps: 7796 | Loss: 69.850427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:06 | Steps: 7798 | Loss: 69.856955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:06 | Steps: 7799 | Loss: 69.856817\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:06 | Steps: 7800 | Loss: 69.859155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:07 | Steps: 7801 | Loss: 69.856186\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:07 | Steps: 7802 | Loss: 69.857475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:07 | Steps: 7804 | Loss: 69.862085\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:07 | Steps: 7805 | Loss: 69.864526\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:07 | Steps: 7806 | Loss: 69.872980\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:07 | Steps: 7807 | Loss: 69.874992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:07 | Steps: 7808 | Loss: 69.876022\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:08 | Steps: 7810 | Loss: 69.875315\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:08 | Steps: 7811 | Loss: 69.875954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:08 | Steps: 7812 | Loss: 69.873212\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:08 | Steps: 7813 | Loss: 69.872159\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:08 | Steps: 7814 | Loss: 69.877704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:08 | Steps: 7815 | Loss: 69.882401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:08 | Steps: 7816 | Loss: 69.879791\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:08 | Steps: 7817 | Loss: 69.878041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:09 | Steps: 7818 | Loss: 69.874253\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:09 | Steps: 7820 | Loss: 69.876153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:09 | Steps: 7821 | Loss: 69.878068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:09 | Steps: 7822 | Loss: 69.878257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:09 | Steps: 7823 | Loss: 69.877912\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:09 | Steps: 7824 | Loss: 69.878632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:09 | Steps: 7825 | Loss: 69.878007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:10 | Steps: 7826 | Loss: 69.878443\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:10 | Steps: 7827 | Loss: 69.881271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:10 | Steps: 7828 | Loss: 69.883023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:10 | Steps: 7829 | Loss: 69.881363\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:10 | Steps: 7830 | Loss: 69.882942\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:10 | Steps: 7831 | Loss: 69.884452\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:10 | Steps: 7833 | Loss: 69.889862\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:10 | Steps: 7834 | Loss: 69.890699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:11 | Steps: 7835 | Loss: 69.889871\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:11 | Steps: 7836 | Loss: 69.897685\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:11 | Steps: 7837 | Loss: 69.903686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:11 | Steps: 7838 | Loss: 69.906053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:11 | Steps: 7840 | Loss: 69.911929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:11 | Steps: 7842 | Loss: 69.916323\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:12 | Steps: 7843 | Loss: 69.922604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:12 | Steps: 7844 | Loss: 69.923449\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:12 | Steps: 7845 | Loss: 69.920960\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:12 | Steps: 7846 | Loss: 69.919374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:12 | Steps: 7847 | Loss: 69.920285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:12 | Steps: 7848 | Loss: 69.920305\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:12 | Steps: 7849 | Loss: 69.920505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:12 | Steps: 7850 | Loss: 69.922595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:13 | Steps: 7851 | Loss: 69.924168\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:13 | Steps: 7852 | Loss: 69.928488\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:13 | Steps: 7853 | Loss: 69.931587\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:13 | Steps: 7854 | Loss: 69.938041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:13 | Steps: 7855 | Loss: 69.939315\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:13 | Steps: 7857 | Loss: 69.943110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:13 | Steps: 7858 | Loss: 69.947732\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:14 | Steps: 7859 | Loss: 69.953206\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:14 | Steps: 7860 | Loss: 69.955401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:14 | Steps: 7861 | Loss: 69.957864\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:14 | Steps: 7862 | Loss: 69.956931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:14 | Steps: 7863 | Loss: 69.957002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:14 | Steps: 7864 | Loss: 69.960124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:14 | Steps: 7865 | Loss: 69.965817\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:14 | Steps: 7866 | Loss: 69.968850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7867 | Loss: 69.969516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7868 | Loss: 69.969909\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7869 | Loss: 69.972551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7870 | Loss: 69.978988\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7871 | Loss: 69.983765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7872 | Loss: 69.988873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7873 | Loss: 69.990727\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7874 | Loss: 69.992027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:15 | Steps: 7875 | Loss: 69.989548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:16 | Steps: 7876 | Loss: 69.990012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:16 | Steps: 7877 | Loss: 69.995627\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:16 | Steps: 7878 | Loss: 69.996595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:16 | Steps: 7879 | Loss: 70.003320\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:16 | Steps: 7880 | Loss: 70.004111\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:16 | Steps: 7882 | Loss: 70.005230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:16 | Steps: 7883 | Loss: 70.004976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:17 | Steps: 7884 | Loss: 70.008905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:17 | Steps: 7885 | Loss: 70.010834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:17 | Steps: 7887 | Loss: 70.013222\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:17 | Steps: 7888 | Loss: 70.012756\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:17 | Steps: 7889 | Loss: 70.011158\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:17 | Steps: 7890 | Loss: 70.014624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:17 | Steps: 7891 | Loss: 70.020404\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:18 | Steps: 7892 | Loss: 70.023426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:18 | Steps: 7893 | Loss: 70.023284\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:18 | Steps: 7894 | Loss: 70.026268\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:18 | Steps: 7896 | Loss: 70.028454\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:18 | Steps: 7897 | Loss: 70.030109\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:18 | Steps: 7898 | Loss: 70.035347\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:18 | Steps: 7899 | Loss: 70.037669\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:19 | Steps: 7900 | Loss: 70.041303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:19 | Steps: 7901 | Loss: 70.045192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:19 | Steps: 7903 | Loss: 70.052704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:19 | Steps: 7905 | Loss: 70.050402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:19 | Steps: 7906 | Loss: 70.055224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:19 | Steps: 7907 | Loss: 70.053602\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:20 | Steps: 7908 | Loss: 70.058148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:20 | Steps: 7909 | Loss: 70.058023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:20 | Steps: 7911 | Loss: 70.060747\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:20 | Steps: 7912 | Loss: 70.060523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:20 | Steps: 7913 | Loss: 70.060351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:20 | Steps: 7915 | Loss: 70.064188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:21 | Steps: 7916 | Loss: 70.072414\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:21 | Steps: 7917 | Loss: 70.071135\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:21 | Steps: 7919 | Loss: 70.079019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:21 | Steps: 7920 | Loss: 70.083344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:21 | Steps: 7921 | Loss: 70.087069\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:21 | Steps: 7922 | Loss: 70.088042\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:21 | Steps: 7924 | Loss: 70.091447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:22 | Steps: 7925 | Loss: 70.092522\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:22 | Steps: 7926 | Loss: 70.094171\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:22 | Steps: 7927 | Loss: 70.098414\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:22 | Steps: 7928 | Loss: 70.102990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:22 | Steps: 7929 | Loss: 70.102551\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:22 | Steps: 7930 | Loss: 70.101752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:22 | Steps: 7931 | Loss: 70.101824\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:22 | Steps: 7932 | Loss: 70.105916\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:23 | Steps: 7933 | Loss: 70.104775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:23 | Steps: 7934 | Loss: 70.102610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:23 | Steps: 7935 | Loss: 70.103273\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:23 | Steps: 7937 | Loss: 70.114594\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:23 | Steps: 7938 | Loss: 70.118688\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:23 | Steps: 7939 | Loss: 70.116434\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:24 | Steps: 7941 | Loss: 70.120913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:24 | Steps: 7943 | Loss: 70.125656\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:24 | Steps: 7944 | Loss: 70.125787\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:24 | Steps: 7945 | Loss: 70.127178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:24 | Steps: 7946 | Loss: 70.127432\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:24 | Steps: 7948 | Loss: 70.132789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:24 | Steps: 7949 | Loss: 70.135532\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:25 | Steps: 7950 | Loss: 70.137792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:25 | Steps: 7951 | Loss: 70.138675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:25 | Steps: 7952 | Loss: 70.141074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:25 | Steps: 7953 | Loss: 70.142983\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:25 | Steps: 7954 | Loss: 70.144522\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:25 | Steps: 7955 | Loss: 70.154113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:25 | Steps: 7957 | Loss: 70.160657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:26 | Steps: 7958 | Loss: 70.164913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:26 | Steps: 7959 | Loss: 70.165521\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:26 | Steps: 7960 | Loss: 70.166707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:26 | Steps: 7961 | Loss: 70.166797\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:26 | Steps: 7962 | Loss: 70.168708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:26 | Steps: 7963 | Loss: 70.177351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:26 | Steps: 7964 | Loss: 70.179729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:27 | Steps: 7965 | Loss: 70.181988\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:27 | Steps: 7966 | Loss: 70.183533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:27 | Steps: 7967 | Loss: 70.183945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:27 | Steps: 7969 | Loss: 70.182234\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:27 | Steps: 7970 | Loss: 70.181659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:27 | Steps: 7971 | Loss: 70.184156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:27 | Steps: 7972 | Loss: 70.187982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:28 | Steps: 7973 | Loss: 70.192410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:28 | Steps: 7974 | Loss: 70.201181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:28 | Steps: 7975 | Loss: 70.209619\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:28 | Steps: 7976 | Loss: 70.213756\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:28 | Steps: 7977 | Loss: 70.219690\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:28 | Steps: 7978 | Loss: 70.227334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:28 | Steps: 7979 | Loss: 70.232182\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:28 | Steps: 7980 | Loss: 70.235107\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:29 | Steps: 7981 | Loss: 70.237142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:29 | Steps: 7982 | Loss: 70.237051\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:29 | Steps: 7983 | Loss: 70.244447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:29 | Steps: 7984 | Loss: 70.247494\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:29 | Steps: 7985 | Loss: 70.248939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:29 | Steps: 7986 | Loss: 70.250941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:29 | Steps: 7987 | Loss: 70.255546\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:29 | Steps: 7988 | Loss: 70.260760\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:30 | Steps: 7989 | Loss: 70.262102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:30 | Steps: 7990 | Loss: 70.265531\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:30 | Steps: 7991 | Loss: 70.268583\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:30 | Steps: 7992 | Loss: 70.266550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:30 | Steps: 7993 | Loss: 70.265336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:30 | Steps: 7994 | Loss: 70.269801\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:30 | Steps: 7995 | Loss: 70.270453\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:31 | Steps: 7997 | Loss: 70.271907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:31 | Steps: 7998 | Loss: 70.275518\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:31 | Steps: 7999 | Loss: 70.273110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:31 | Steps: 8000 | Loss: 70.269997\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:31 | Steps: 8001 | Loss: 70.271995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:31 | Steps: 8002 | Loss: 70.271949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:31 | Steps: 8003 | Loss: 70.272347\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:32 | Steps: 8005 | Loss: 70.273184\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:32 | Steps: 8006 | Loss: 70.274071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:32 | Steps: 8007 | Loss: 70.275185\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:32 | Steps: 8008 | Loss: 70.274853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:32 | Steps: 8010 | Loss: 70.278680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:32 | Steps: 8011 | Loss: 70.281128\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:32 | Steps: 8012 | Loss: 70.282800\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:33 | Steps: 8013 | Loss: 70.283667\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:33 | Steps: 8014 | Loss: 70.288609\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:33 | Steps: 8015 | Loss: 70.292648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:33 | Steps: 8016 | Loss: 70.292082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:33 | Steps: 8017 | Loss: 70.292276\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:33 | Steps: 8018 | Loss: 70.291684\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:33 | Steps: 8019 | Loss: 70.288662\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:33 | Steps: 8020 | Loss: 70.292895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:34 | Steps: 8021 | Loss: 70.296264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:34 | Steps: 8023 | Loss: 70.304579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:34 | Steps: 8024 | Loss: 70.308762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:34 | Steps: 8025 | Loss: 70.312232\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:34 | Steps: 8027 | Loss: 70.312237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:34 | Steps: 8028 | Loss: 70.314392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:35 | Steps: 8029 | Loss: 70.311732\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:35 | Steps: 8030 | Loss: 70.309300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:35 | Steps: 8031 | Loss: 70.310267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:35 | Steps: 8032 | Loss: 70.310980\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:35 | Steps: 8034 | Loss: 70.314553\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:35 | Steps: 8035 | Loss: 70.317317\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:35 | Steps: 8036 | Loss: 70.318107\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:36 | Steps: 8037 | Loss: 70.317859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:36 | Steps: 8039 | Loss: 70.318987\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:36 | Steps: 8040 | Loss: 70.320147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:36 | Steps: 8041 | Loss: 70.320609\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:36 | Steps: 8043 | Loss: 70.323047\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:36 | Steps: 8044 | Loss: 70.324003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:37 | Steps: 8045 | Loss: 70.323321\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:37 | Steps: 8046 | Loss: 70.327252\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:37 | Steps: 8048 | Loss: 70.337023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:37 | Steps: 8049 | Loss: 70.341275\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:37 | Steps: 8050 | Loss: 70.342907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:37 | Steps: 8051 | Loss: 70.343633\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:37 | Steps: 8052 | Loss: 70.345476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:37 | Steps: 8053 | Loss: 70.350533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:38 | Steps: 8054 | Loss: 70.353028\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:38 | Steps: 8055 | Loss: 70.353297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:38 | Steps: 8056 | Loss: 70.350902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:38 | Steps: 8057 | Loss: 70.350162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:38 | Steps: 8058 | Loss: 70.349962\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:38 | Steps: 8059 | Loss: 70.349012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:38 | Steps: 8060 | Loss: 70.351291\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:39 | Steps: 8061 | Loss: 70.354809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:39 | Steps: 8062 | Loss: 70.352436\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:39 | Steps: 8064 | Loss: 70.353203\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:39 | Steps: 8065 | Loss: 70.354482\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:39 | Steps: 8066 | Loss: 70.354297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:39 | Steps: 8067 | Loss: 70.355064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:39 | Steps: 8068 | Loss: 70.355476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:40 | Steps: 8069 | Loss: 70.355180\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:40 | Steps: 8070 | Loss: 70.357824\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:40 | Steps: 8072 | Loss: 70.367300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:40 | Steps: 8073 | Loss: 70.368738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:40 | Steps: 8074 | Loss: 70.369011\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:40 | Steps: 8075 | Loss: 70.369568\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:40 | Steps: 8076 | Loss: 70.371839\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:40 | Steps: 8077 | Loss: 70.376934\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:41 | Steps: 8078 | Loss: 70.379301\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:41 | Steps: 8079 | Loss: 70.379234\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:41 | Steps: 8080 | Loss: 70.380885\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:41 | Steps: 8081 | Loss: 70.379856\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:41 | Steps: 8082 | Loss: 70.380389\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:41 | Steps: 8083 | Loss: 70.386053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:41 | Steps: 8084 | Loss: 70.390266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:42 | Steps: 8085 | Loss: 70.396070\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:42 | Steps: 8086 | Loss: 70.398155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:42 | Steps: 8087 | Loss: 70.402527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:42 | Steps: 8089 | Loss: 70.411201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:42 | Steps: 8090 | Loss: 70.414025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:42 | Steps: 8091 | Loss: 70.423692\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:42 | Steps: 8092 | Loss: 70.430218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:43 | Steps: 8093 | Loss: 70.432087\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:43 | Steps: 8094 | Loss: 70.433172\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:43 | Steps: 8096 | Loss: 70.431528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:43 | Steps: 8097 | Loss: 70.433185\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:43 | Steps: 8098 | Loss: 70.432364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:43 | Steps: 8099 | Loss: 70.432067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:43 | Steps: 8100 | Loss: 70.434043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:44 | Steps: 8101 | Loss: 70.438535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:44 | Steps: 8103 | Loss: 70.448910\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:44 | Steps: 8104 | Loss: 70.453505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:44 | Steps: 8105 | Loss: 70.457475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:44 | Steps: 8106 | Loss: 70.454954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:44 | Steps: 8107 | Loss: 70.455740\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:44 | Steps: 8108 | Loss: 70.459070\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:45 | Steps: 8109 | Loss: 70.461928\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:45 | Steps: 8110 | Loss: 70.466457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:45 | Steps: 8111 | Loss: 70.465500\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:45 | Steps: 8112 | Loss: 70.464658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:45 | Steps: 8113 | Loss: 70.463280\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:45 | Steps: 8114 | Loss: 70.461752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:45 | Steps: 8115 | Loss: 70.459959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:45 | Steps: 8116 | Loss: 70.457424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:46 | Steps: 8117 | Loss: 70.454753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:46 | Steps: 8118 | Loss: 70.454152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:46 | Steps: 8119 | Loss: 70.452481\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:46 | Steps: 8121 | Loss: 70.462422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:46 | Steps: 8122 | Loss: 70.460764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:46 | Steps: 8123 | Loss: 70.458558\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:47 | Steps: 8124 | Loss: 70.458062\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:47 | Steps: 8125 | Loss: 70.458631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:47 | Steps: 8126 | Loss: 70.459602\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:47 | Steps: 8127 | Loss: 70.462046\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:47 | Steps: 8128 | Loss: 70.463288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:47 | Steps: 8129 | Loss: 70.463624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:47 | Steps: 8130 | Loss: 70.461891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:48 | Steps: 8131 | Loss: 70.463759\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:48 | Steps: 8132 | Loss: 70.468058\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:48 | Steps: 8134 | Loss: 70.474495\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:48 | Steps: 8135 | Loss: 70.477344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:48 | Steps: 8136 | Loss: 70.474216\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:48 | Steps: 8137 | Loss: 70.473645\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:49 | Steps: 8138 | Loss: 70.476890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:49 | Steps: 8139 | Loss: 70.478957\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:49 | Steps: 8140 | Loss: 70.487156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:49 | Steps: 8141 | Loss: 70.487931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:49 | Steps: 8142 | Loss: 70.492658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:49 | Steps: 8143 | Loss: 70.493043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:49 | Steps: 8144 | Loss: 70.494413\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:49 | Steps: 8145 | Loss: 70.498560\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:50 | Steps: 8146 | Loss: 70.499957\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:50 | Steps: 8147 | Loss: 70.498507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:50 | Steps: 8148 | Loss: 70.498034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:50 | Steps: 8149 | Loss: 70.497818\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:50 | Steps: 8150 | Loss: 70.499974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:50 | Steps: 8151 | Loss: 70.502422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:50 | Steps: 8152 | Loss: 70.504352\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:50 | Steps: 8153 | Loss: 70.507646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:51 | Steps: 8154 | Loss: 70.511334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:51 | Steps: 8155 | Loss: 70.510616\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:51 | Steps: 8156 | Loss: 70.509335\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:51 | Steps: 8157 | Loss: 70.512723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:51 | Steps: 8159 | Loss: 70.519368\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:51 | Steps: 8160 | Loss: 70.521726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:52 | Steps: 8161 | Loss: 70.522374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:52 | Steps: 8162 | Loss: 70.523218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:52 | Steps: 8163 | Loss: 70.522645\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:52 | Steps: 8164 | Loss: 70.520595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:52 | Steps: 8165 | Loss: 70.522080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:52 | Steps: 8166 | Loss: 70.520071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:52 | Steps: 8167 | Loss: 70.522057\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:52 | Steps: 8168 | Loss: 70.521589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:53 | Steps: 8169 | Loss: 70.521048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:53 | Steps: 8171 | Loss: 70.526060\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:53 | Steps: 8172 | Loss: 70.528092\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:53 | Steps: 8173 | Loss: 70.529941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:53 | Steps: 8174 | Loss: 70.533343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:53 | Steps: 8175 | Loss: 70.540042\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:53 | Steps: 8176 | Loss: 70.539725\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:54 | Steps: 8177 | Loss: 70.539416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:54 | Steps: 8178 | Loss: 70.536668\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:54 | Steps: 8179 | Loss: 70.542529\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:54 | Steps: 8180 | Loss: 70.547007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:54 | Steps: 8181 | Loss: 70.548272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:54 | Steps: 8182 | Loss: 70.550772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:54 | Steps: 8183 | Loss: 70.549317\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:55 | Steps: 8184 | Loss: 70.550745\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:55 | Steps: 8185 | Loss: 70.553911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:55 | Steps: 8186 | Loss: 70.555523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:55 | Steps: 8187 | Loss: 70.557687\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:55 | Steps: 8188 | Loss: 70.557805\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:55 | Steps: 8189 | Loss: 70.559764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:55 | Steps: 8190 | Loss: 70.560081\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:55 | Steps: 8191 | Loss: 70.562014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:56 | Steps: 8192 | Loss: 70.559611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:56 | Steps: 8193 | Loss: 70.556604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:56 | Steps: 8194 | Loss: 70.558409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:56 | Steps: 8195 | Loss: 70.563838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:56 | Steps: 8196 | Loss: 70.564446\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:56 | Steps: 8197 | Loss: 70.564940\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:56 | Steps: 8198 | Loss: 70.564749\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:57 | Steps: 8199 | Loss: 70.563014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:57 | Steps: 8200 | Loss: 70.567659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:57 | Steps: 8201 | Loss: 70.569789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:57 | Steps: 8202 | Loss: 70.573829\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:57 | Steps: 8203 | Loss: 70.578778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:57 | Steps: 8204 | Loss: 70.580154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:57 | Steps: 8206 | Loss: 70.588743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:58 | Steps: 8207 | Loss: 70.590580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:58 | Steps: 8208 | Loss: 70.591042\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:58 | Steps: 8209 | Loss: 70.591130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:58 | Steps: 8210 | Loss: 70.592899\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:58 | Steps: 8211 | Loss: 70.597838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:58 | Steps: 8212 | Loss: 70.598218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:58 | Steps: 8213 | Loss: 70.600424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:58 | Steps: 8214 | Loss: 70.599735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:59 | Steps: 8215 | Loss: 70.604950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:59 | Steps: 8216 | Loss: 70.609487\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:59 | Steps: 8217 | Loss: 70.614061\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:59 | Steps: 8218 | Loss: 70.619155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:59 | Steps: 8219 | Loss: 70.620176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:59 | Steps: 8220 | Loss: 70.624887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:12:59 | Steps: 8221 | Loss: 70.629142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:00 | Steps: 8222 | Loss: 70.635693\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:00 | Steps: 8223 | Loss: 70.636025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:00 | Steps: 8224 | Loss: 70.637989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:00 | Steps: 8225 | Loss: 70.639388\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:00 | Steps: 8226 | Loss: 70.639218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:00 | Steps: 8227 | Loss: 70.644281\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:00 | Steps: 8228 | Loss: 70.644753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:00 | Steps: 8229 | Loss: 70.646678\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:01 | Steps: 8230 | Loss: 70.647201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:01 | Steps: 8231 | Loss: 70.649112\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:01 | Steps: 8232 | Loss: 70.649840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:01 | Steps: 8233 | Loss: 70.656480\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:01 | Steps: 8234 | Loss: 70.659741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:01 | Steps: 8235 | Loss: 70.664886\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:01 | Steps: 8236 | Loss: 70.669146\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:02 | Steps: 8237 | Loss: 70.672014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:02 | Steps: 8238 | Loss: 70.673479\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:02 | Steps: 8239 | Loss: 70.678236\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:02 | Steps: 8241 | Loss: 70.679804\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:02 | Steps: 8242 | Loss: 70.676194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:02 | Steps: 8243 | Loss: 70.674070\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:02 | Steps: 8244 | Loss: 70.677703\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:03 | Steps: 8245 | Loss: 70.679682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:03 | Steps: 8246 | Loss: 70.680015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:03 | Steps: 8247 | Loss: 70.682650\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:03 | Steps: 8248 | Loss: 70.688032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:03 | Steps: 8249 | Loss: 70.690762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:03 | Steps: 8250 | Loss: 70.687797\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:03 | Steps: 8251 | Loss: 70.686170\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:04 | Steps: 8252 | Loss: 70.686158\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:04 | Steps: 8253 | Loss: 70.687269\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:04 | Steps: 8254 | Loss: 70.687298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:04 | Steps: 8255 | Loss: 70.692665\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:04 | Steps: 8256 | Loss: 70.692754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:04 | Steps: 8257 | Loss: 70.693150\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:04 | Steps: 8258 | Loss: 70.694198\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:05 | Steps: 8259 | Loss: 70.695026\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:05 | Steps: 8260 | Loss: 70.696620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:05 | Steps: 8261 | Loss: 70.698749\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:05 | Steps: 8262 | Loss: 70.700879\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:05 | Steps: 8263 | Loss: 70.705399\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:05 | Steps: 8264 | Loss: 70.706965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:05 | Steps: 8265 | Loss: 70.704891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:06 | Steps: 8266 | Loss: 70.704398\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:06 | Steps: 8267 | Loss: 70.704688\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:06 | Steps: 8268 | Loss: 70.707145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:06 | Steps: 8269 | Loss: 70.709517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:06 | Steps: 8270 | Loss: 70.711990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:06 | Steps: 8271 | Loss: 70.716388\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:06 | Steps: 8272 | Loss: 70.719799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:06 | Steps: 8273 | Loss: 70.723159\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:07 | Steps: 8274 | Loss: 70.722792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:07 | Steps: 8275 | Loss: 70.723718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:07 | Steps: 8276 | Loss: 70.725986\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:07 | Steps: 8277 | Loss: 70.725115\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:07 | Steps: 8278 | Loss: 70.722119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:07 | Steps: 8279 | Loss: 70.726246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:07 | Steps: 8280 | Loss: 70.726809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:08 | Steps: 8281 | Loss: 70.728434\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:08 | Steps: 8282 | Loss: 70.730611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:08 | Steps: 8283 | Loss: 70.732076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:08 | Steps: 8284 | Loss: 70.731283\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:08 | Steps: 8285 | Loss: 70.736061\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:08 | Steps: 8286 | Loss: 70.740214\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:08 | Steps: 8287 | Loss: 70.742025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:09 | Steps: 8288 | Loss: 70.741345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:09 | Steps: 8289 | Loss: 70.740417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:09 | Steps: 8290 | Loss: 70.743548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:09 | Steps: 8291 | Loss: 70.744202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:09 | Steps: 8292 | Loss: 70.747054\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:09 | Steps: 8293 | Loss: 70.748047\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:09 | Steps: 8294 | Loss: 70.750449\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:10 | Steps: 8295 | Loss: 70.754721\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:10 | Steps: 8296 | Loss: 70.757421\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:10 | Steps: 8297 | Loss: 70.762774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:10 | Steps: 8298 | Loss: 70.766561\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:10 | Steps: 8299 | Loss: 70.765110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:10 | Steps: 8300 | Loss: 70.765640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:10 | Steps: 8301 | Loss: 70.764338\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:11 | Steps: 8302 | Loss: 70.764840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:11 | Steps: 8303 | Loss: 70.763593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:11 | Steps: 8304 | Loss: 70.764006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:11 | Steps: 8305 | Loss: 70.760624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:11 | Steps: 8306 | Loss: 70.764976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:11 | Steps: 8307 | Loss: 70.768622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:11 | Steps: 8308 | Loss: 70.766634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:12 | Steps: 8309 | Loss: 70.767492\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:12 | Steps: 8310 | Loss: 70.768495\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:12 | Steps: 8311 | Loss: 70.768854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:12 | Steps: 8312 | Loss: 70.770319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:12 | Steps: 8313 | Loss: 70.769562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:12 | Steps: 8314 | Loss: 70.770397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:13 | Steps: 8315 | Loss: 70.769381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:13 | Steps: 8316 | Loss: 70.769574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:13 | Steps: 8317 | Loss: 70.768681\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:13 | Steps: 8318 | Loss: 70.770944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:13 | Steps: 8319 | Loss: 70.772743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:13 | Steps: 8320 | Loss: 70.775217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:13 | Steps: 8321 | Loss: 70.777781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:14 | Steps: 8322 | Loss: 70.780207\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:14 | Steps: 8323 | Loss: 70.781350\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:14 | Steps: 8324 | Loss: 70.788000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:14 | Steps: 8325 | Loss: 70.794465\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:14 | Steps: 8326 | Loss: 70.794014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:14 | Steps: 8327 | Loss: 70.794593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:14 | Steps: 8328 | Loss: 70.800035\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:15 | Steps: 8329 | Loss: 70.803146\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:15 | Steps: 8330 | Loss: 70.803803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:15 | Steps: 8331 | Loss: 70.809899\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:15 | Steps: 8332 | Loss: 70.821040\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:15 | Steps: 8333 | Loss: 70.820692\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:16 | Steps: 8334 | Loss: 70.822866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:16 | Steps: 8335 | Loss: 70.828772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:16 | Steps: 8336 | Loss: 70.834631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:16 | Steps: 8337 | Loss: 70.836060\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:16 | Steps: 8338 | Loss: 70.836453\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:17 | Steps: 8339 | Loss: 70.835793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:17 | Steps: 8340 | Loss: 70.837695\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:17 | Steps: 8341 | Loss: 70.842588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:17 | Steps: 8342 | Loss: 70.843087\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:17 | Steps: 8343 | Loss: 70.847079\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:17 | Steps: 8344 | Loss: 70.850205\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:17 | Steps: 8345 | Loss: 70.852902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:18 | Steps: 8346 | Loss: 70.854132\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:18 | Steps: 8347 | Loss: 70.854351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:18 | Steps: 8348 | Loss: 70.857240\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:18 | Steps: 8349 | Loss: 70.855797\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:18 | Steps: 8350 | Loss: 70.855853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:18 | Steps: 8351 | Loss: 70.857589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:19 | Steps: 8352 | Loss: 70.869866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:19 | Steps: 8353 | Loss: 70.871868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:19 | Steps: 8354 | Loss: 70.875640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:19 | Steps: 8355 | Loss: 70.878926\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:19 | Steps: 8356 | Loss: 70.883810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:19 | Steps: 8357 | Loss: 70.891916\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:19 | Steps: 8358 | Loss: 70.896572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:20 | Steps: 8359 | Loss: 70.895014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:20 | Steps: 8360 | Loss: 70.893547\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:20 | Steps: 8361 | Loss: 70.894422\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:20 | Steps: 8362 | Loss: 70.892535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:20 | Steps: 8363 | Loss: 70.890755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:20 | Steps: 8364 | Loss: 70.891669\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:20 | Steps: 8365 | Loss: 70.890421\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:21 | Steps: 8366 | Loss: 70.892693\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:21 | Steps: 8367 | Loss: 70.889419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:21 | Steps: 8368 | Loss: 70.887934\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:21 | Steps: 8369 | Loss: 70.888356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:21 | Steps: 8370 | Loss: 70.888903\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:21 | Steps: 8371 | Loss: 70.893458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:21 | Steps: 8372 | Loss: 70.895482\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:22 | Steps: 8373 | Loss: 70.898844\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:22 | Steps: 8374 | Loss: 70.902035\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:22 | Steps: 8375 | Loss: 70.904709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:22 | Steps: 8376 | Loss: 70.903911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:22 | Steps: 8377 | Loss: 70.905790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:22 | Steps: 8378 | Loss: 70.908836\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:22 | Steps: 8379 | Loss: 70.908600\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:22 | Steps: 8380 | Loss: 70.905895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:23 | Steps: 8381 | Loss: 70.909104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:23 | Steps: 8382 | Loss: 70.909952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:23 | Steps: 8383 | Loss: 70.914806\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:23 | Steps: 8384 | Loss: 70.917628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:23 | Steps: 8385 | Loss: 70.917614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:23 | Steps: 8386 | Loss: 70.915580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:23 | Steps: 8388 | Loss: 70.919417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:24 | Steps: 8389 | Loss: 70.922295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:24 | Steps: 8390 | Loss: 70.926903\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:24 | Steps: 8391 | Loss: 70.927833\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:24 | Steps: 8393 | Loss: 70.930175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:24 | Steps: 8394 | Loss: 70.934297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:24 | Steps: 8395 | Loss: 70.938988\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:24 | Steps: 8396 | Loss: 70.940522\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:25 | Steps: 8397 | Loss: 70.942594\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:25 | Steps: 8398 | Loss: 70.941024\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:25 | Steps: 8399 | Loss: 70.945808\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:25 | Steps: 8400 | Loss: 70.950562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:25 | Steps: 8402 | Loss: 70.956381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:25 | Steps: 8403 | Loss: 70.958255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:25 | Steps: 8404 | Loss: 70.960211\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:26 | Steps: 8405 | Loss: 70.965073\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:26 | Steps: 8406 | Loss: 70.966941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:26 | Steps: 8407 | Loss: 70.964819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:26 | Steps: 8408 | Loss: 70.963536\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:26 | Steps: 8410 | Loss: 70.963989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:26 | Steps: 8411 | Loss: 70.960905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:27 | Steps: 8412 | Loss: 70.965426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:27 | Steps: 8413 | Loss: 70.970860\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:27 | Steps: 8414 | Loss: 70.973681\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:27 | Steps: 8415 | Loss: 70.973272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:27 | Steps: 8416 | Loss: 70.973118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:27 | Steps: 8418 | Loss: 70.974771\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:27 | Steps: 8419 | Loss: 70.975843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:28 | Steps: 8420 | Loss: 70.979532\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:28 | Steps: 8421 | Loss: 70.982037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:28 | Steps: 8422 | Loss: 70.983768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:28 | Steps: 8423 | Loss: 70.983666\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:28 | Steps: 8424 | Loss: 70.987145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:28 | Steps: 8425 | Loss: 70.988298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:28 | Steps: 8427 | Loss: 70.995433\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:29 | Steps: 8428 | Loss: 70.997995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:29 | Steps: 8429 | Loss: 70.996908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:29 | Steps: 8430 | Loss: 70.996509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:29 | Steps: 8431 | Loss: 70.998321\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:29 | Steps: 8432 | Loss: 70.999351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:29 | Steps: 8433 | Loss: 70.999274\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:29 | Steps: 8434 | Loss: 70.997640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:30 | Steps: 8435 | Loss: 70.999626\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:30 | Steps: 8436 | Loss: 71.004632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:30 | Steps: 8437 | Loss: 71.013034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:30 | Steps: 8438 | Loss: 71.016131\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:30 | Steps: 8439 | Loss: 71.016415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:30 | Steps: 8440 | Loss: 71.017364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:30 | Steps: 8441 | Loss: 71.018695\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:30 | Steps: 8442 | Loss: 71.026064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:31 | Steps: 8443 | Loss: 71.030700\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:31 | Steps: 8444 | Loss: 71.035471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:31 | Steps: 8445 | Loss: 71.041957\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:31 | Steps: 8446 | Loss: 71.041538\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:31 | Steps: 8447 | Loss: 71.041956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:31 | Steps: 8448 | Loss: 71.042164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:31 | Steps: 8449 | Loss: 71.043442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:32 | Steps: 8450 | Loss: 71.045905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:32 | Steps: 8451 | Loss: 71.046383\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:32 | Steps: 8452 | Loss: 71.046565\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:32 | Steps: 8454 | Loss: 71.051037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:32 | Steps: 8455 | Loss: 71.052426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:32 | Steps: 8456 | Loss: 71.051181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:32 | Steps: 8457 | Loss: 71.051952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:33 | Steps: 8458 | Loss: 71.054631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:33 | Steps: 8459 | Loss: 71.060875\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:33 | Steps: 8460 | Loss: 71.061890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:33 | Steps: 8462 | Loss: 71.059511\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:33 | Steps: 8463 | Loss: 71.062558\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:33 | Steps: 8464 | Loss: 71.060530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:33 | Steps: 8465 | Loss: 71.057235\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:34 | Steps: 8467 | Loss: 71.060580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:34 | Steps: 8468 | Loss: 71.062866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:34 | Steps: 8470 | Loss: 71.070688\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:34 | Steps: 8471 | Loss: 71.069902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:34 | Steps: 8472 | Loss: 71.067954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:35 | Steps: 8474 | Loss: 71.065663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:35 | Steps: 8475 | Loss: 71.070809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:35 | Steps: 8476 | Loss: 71.073033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:35 | Steps: 8477 | Loss: 71.075547\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:35 | Steps: 8479 | Loss: 71.077496\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:35 | Steps: 8480 | Loss: 71.077451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:35 | Steps: 8481 | Loss: 71.081098\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:36 | Steps: 8482 | Loss: 71.084220\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:36 | Steps: 8483 | Loss: 71.088095\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:36 | Steps: 8484 | Loss: 71.088355\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:36 | Steps: 8485 | Loss: 71.086970\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:36 | Steps: 8486 | Loss: 71.088342\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:36 | Steps: 8487 | Loss: 71.088753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:36 | Steps: 8488 | Loss: 71.090027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:36 | Steps: 8489 | Loss: 71.093859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:37 | Steps: 8490 | Loss: 71.094406\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:37 | Steps: 8491 | Loss: 71.092000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:37 | Steps: 8492 | Loss: 71.097391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:37 | Steps: 8493 | Loss: 71.095774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:37 | Steps: 8494 | Loss: 71.098239\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:37 | Steps: 8495 | Loss: 71.098576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:37 | Steps: 8496 | Loss: 71.101475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:37 | Steps: 8497 | Loss: 71.104212\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:38 | Steps: 8498 | Loss: 71.101779\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:38 | Steps: 8499 | Loss: 71.101877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:38 | Steps: 8500 | Loss: 71.102942\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:38 | Steps: 8501 | Loss: 71.111017\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:38 | Steps: 8502 | Loss: 71.113015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:38 | Steps: 8504 | Loss: 71.118570\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:38 | Steps: 8505 | Loss: 71.119549\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:39 | Steps: 8506 | Loss: 71.124424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:39 | Steps: 8507 | Loss: 71.123725\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:39 | Steps: 8508 | Loss: 71.125708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:39 | Steps: 8509 | Loss: 71.126340\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:39 | Steps: 8510 | Loss: 71.128399\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:39 | Steps: 8511 | Loss: 71.130999\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:39 | Steps: 8512 | Loss: 71.132513\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:39 | Steps: 8513 | Loss: 71.136343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:40 | Steps: 8514 | Loss: 71.139830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:40 | Steps: 8515 | Loss: 71.139610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:40 | Steps: 8516 | Loss: 71.139004\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:40 | Steps: 8517 | Loss: 71.141337\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:40 | Steps: 8518 | Loss: 71.138729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:40 | Steps: 8519 | Loss: 71.140219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:40 | Steps: 8520 | Loss: 71.146419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:40 | Steps: 8521 | Loss: 71.148015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:41 | Steps: 8522 | Loss: 71.146562\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:41 | Steps: 8523 | Loss: 71.147369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:41 | Steps: 8524 | Loss: 71.149012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:41 | Steps: 8525 | Loss: 71.152664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:41 | Steps: 8526 | Loss: 71.153680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:41 | Steps: 8527 | Loss: 71.153008\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:41 | Steps: 8528 | Loss: 71.154841\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:41 | Steps: 8529 | Loss: 71.155770\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:42 | Steps: 8530 | Loss: 71.155667\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:42 | Steps: 8531 | Loss: 71.155923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:42 | Steps: 8532 | Loss: 71.156792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:42 | Steps: 8534 | Loss: 71.161485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:42 | Steps: 8535 | Loss: 71.160037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:42 | Steps: 8536 | Loss: 71.161778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:43 | Steps: 8537 | Loss: 71.163453\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:43 | Steps: 8538 | Loss: 71.162855\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:43 | Steps: 8540 | Loss: 71.162209\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:43 | Steps: 8541 | Loss: 71.166775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:43 | Steps: 8542 | Loss: 71.169679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:43 | Steps: 8543 | Loss: 71.171669\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:43 | Steps: 8544 | Loss: 71.174548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:43 | Steps: 8545 | Loss: 71.177264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:44 | Steps: 8546 | Loss: 71.177426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:44 | Steps: 8547 | Loss: 71.185443\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:44 | Steps: 8548 | Loss: 71.189071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:44 | Steps: 8549 | Loss: 71.187842\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:44 | Steps: 8550 | Loss: 71.186361\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:44 | Steps: 8551 | Loss: 71.184807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:44 | Steps: 8552 | Loss: 71.185521\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:45 | Steps: 8553 | Loss: 71.188647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:45 | Steps: 8554 | Loss: 71.189067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:45 | Steps: 8555 | Loss: 71.194990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:45 | Steps: 8556 | Loss: 71.197137\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:45 | Steps: 8557 | Loss: 71.198771\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:45 | Steps: 8558 | Loss: 71.202803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:45 | Steps: 8559 | Loss: 71.205156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:45 | Steps: 8560 | Loss: 71.212037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:46 | Steps: 8561 | Loss: 71.211512\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:46 | Steps: 8562 | Loss: 71.214943\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:46 | Steps: 8563 | Loss: 71.212548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:46 | Steps: 8564 | Loss: 71.212637\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:46 | Steps: 8566 | Loss: 71.211595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:46 | Steps: 8567 | Loss: 71.212473\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:47 | Steps: 8568 | Loss: 71.215039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:47 | Steps: 8569 | Loss: 71.217325\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:47 | Steps: 8570 | Loss: 71.220376\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:47 | Steps: 8571 | Loss: 71.226679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:47 | Steps: 8573 | Loss: 71.237778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:47 | Steps: 8574 | Loss: 71.239766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:47 | Steps: 8575 | Loss: 71.238887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:47 | Steps: 8576 | Loss: 71.238935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:48 | Steps: 8577 | Loss: 71.239785\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:48 | Steps: 8578 | Loss: 71.238838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:48 | Steps: 8579 | Loss: 71.238819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:48 | Steps: 8580 | Loss: 71.237427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:48 | Steps: 8581 | Loss: 71.234284\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:48 | Steps: 8582 | Loss: 71.231585\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:48 | Steps: 8583 | Loss: 71.231909\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:49 | Steps: 8584 | Loss: 71.230983\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:49 | Steps: 8585 | Loss: 71.234385\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:49 | Steps: 8586 | Loss: 71.236187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:49 | Steps: 8587 | Loss: 71.238701\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:49 | Steps: 8588 | Loss: 71.239148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:49 | Steps: 8590 | Loss: 71.244495\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:49 | Steps: 8591 | Loss: 71.247919\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:50 | Steps: 8592 | Loss: 71.248867\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:50 | Steps: 8593 | Loss: 71.252647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:50 | Steps: 8594 | Loss: 71.254795\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:50 | Steps: 8595 | Loss: 71.260084\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:50 | Steps: 8597 | Loss: 71.263299\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:50 | Steps: 8598 | Loss: 71.262707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:51 | Steps: 8599 | Loss: 71.263572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:51 | Steps: 8600 | Loss: 71.264166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:51 | Steps: 8601 | Loss: 71.263904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:51 | Steps: 8602 | Loss: 71.264057\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:51 | Steps: 8603 | Loss: 71.267181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:51 | Steps: 8604 | Loss: 71.268924\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:51 | Steps: 8605 | Loss: 71.271657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:51 | Steps: 8606 | Loss: 71.277080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:52 | Steps: 8607 | Loss: 71.277935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:52 | Steps: 8608 | Loss: 71.281634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:52 | Steps: 8609 | Loss: 71.281806\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:52 | Steps: 8610 | Loss: 71.278416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:52 | Steps: 8611 | Loss: 71.276960\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:52 | Steps: 8612 | Loss: 71.278875\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:52 | Steps: 8613 | Loss: 71.278911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:52 | Steps: 8614 | Loss: 71.278241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:53 | Steps: 8615 | Loss: 71.280052\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:53 | Steps: 8616 | Loss: 71.284944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:53 | Steps: 8617 | Loss: 71.292267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:53 | Steps: 8618 | Loss: 71.295416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:53 | Steps: 8619 | Loss: 71.297866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:53 | Steps: 8620 | Loss: 71.298106\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:53 | Steps: 8621 | Loss: 71.298974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:53 | Steps: 8622 | Loss: 71.303457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:54 | Steps: 8623 | Loss: 71.303124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:54 | Steps: 8624 | Loss: 71.306280\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:54 | Steps: 8625 | Loss: 71.304475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:54 | Steps: 8626 | Loss: 71.304595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:54 | Steps: 8627 | Loss: 71.305249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:54 | Steps: 8628 | Loss: 71.306996\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:54 | Steps: 8629 | Loss: 71.306747\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:55 | Steps: 8630 | Loss: 71.308256\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:55 | Steps: 8631 | Loss: 71.310608\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:55 | Steps: 8632 | Loss: 71.312991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:55 | Steps: 8633 | Loss: 71.316263\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:55 | Steps: 8634 | Loss: 71.319253\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:55 | Steps: 8635 | Loss: 71.316715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:55 | Steps: 8636 | Loss: 71.316832\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:55 | Steps: 8637 | Loss: 71.316913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:56 | Steps: 8638 | Loss: 71.317564\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:56 | Steps: 8639 | Loss: 71.315971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:56 | Steps: 8640 | Loss: 71.315438\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:56 | Steps: 8641 | Loss: 71.321434\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:56 | Steps: 8642 | Loss: 71.323880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:56 | Steps: 8643 | Loss: 71.325147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:56 | Steps: 8644 | Loss: 71.328114\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:57 | Steps: 8646 | Loss: 71.333307\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:57 | Steps: 8647 | Loss: 71.332919\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:57 | Steps: 8648 | Loss: 71.334090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:57 | Steps: 8649 | Loss: 71.335234\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:57 | Steps: 8650 | Loss: 71.340611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:57 | Steps: 8651 | Loss: 71.339708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:57 | Steps: 8652 | Loss: 71.344702\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:58 | Steps: 8653 | Loss: 71.348592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:58 | Steps: 8654 | Loss: 71.351935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:58 | Steps: 8656 | Loss: 71.352812\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:58 | Steps: 8657 | Loss: 71.357737\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:58 | Steps: 8658 | Loss: 71.362297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:58 | Steps: 8659 | Loss: 71.372519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:58 | Steps: 8660 | Loss: 71.387001\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:58 | Steps: 8661 | Loss: 71.390064\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:59 | Steps: 8662 | Loss: 71.392962\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:59 | Steps: 8663 | Loss: 71.396852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:59 | Steps: 8664 | Loss: 71.408511\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:59 | Steps: 8665 | Loss: 71.413200\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:59 | Steps: 8666 | Loss: 71.413965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:59 | Steps: 8667 | Loss: 71.415718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:13:59 | Steps: 8668 | Loss: 71.417755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:00 | Steps: 8669 | Loss: 71.420141\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:00 | Steps: 8670 | Loss: 71.421275\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:00 | Steps: 8671 | Loss: 71.426341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:00 | Steps: 8672 | Loss: 71.426429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:00 | Steps: 8673 | Loss: 71.434982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:00 | Steps: 8674 | Loss: 71.439643\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:00 | Steps: 8675 | Loss: 71.444172\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:00 | Steps: 8676 | Loss: 71.448747\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:01 | Steps: 8677 | Loss: 71.448956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:01 | Steps: 8678 | Loss: 71.451046\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:01 | Steps: 8680 | Loss: 71.461664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:01 | Steps: 8681 | Loss: 71.461649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:01 | Steps: 8682 | Loss: 71.464490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:01 | Steps: 8683 | Loss: 71.467202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:01 | Steps: 8684 | Loss: 71.470385\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:02 | Steps: 8685 | Loss: 71.475664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:02 | Steps: 8686 | Loss: 71.484017\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:02 | Steps: 8687 | Loss: 71.486748\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:02 | Steps: 8688 | Loss: 71.490735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:02 | Steps: 8689 | Loss: 71.497792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:02 | Steps: 8690 | Loss: 71.502217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:02 | Steps: 8691 | Loss: 71.505162\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:03 | Steps: 8692 | Loss: 71.506833\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:03 | Steps: 8693 | Loss: 71.508074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:03 | Steps: 8694 | Loss: 71.507249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:03 | Steps: 8695 | Loss: 71.505224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:03 | Steps: 8696 | Loss: 71.505182\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:03 | Steps: 8697 | Loss: 71.507128\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:03 | Steps: 8698 | Loss: 71.508156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:03 | Steps: 8699 | Loss: 71.506156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:04 | Steps: 8700 | Loss: 71.509170\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:04 | Steps: 8701 | Loss: 71.518917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:04 | Steps: 8702 | Loss: 71.517573\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:04 | Steps: 8703 | Loss: 71.515165\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:04 | Steps: 8704 | Loss: 71.514310\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:04 | Steps: 8705 | Loss: 71.515010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:04 | Steps: 8706 | Loss: 71.515818\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:05 | Steps: 8707 | Loss: 71.518855\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:05 | Steps: 8708 | Loss: 71.520113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:05 | Steps: 8709 | Loss: 71.521902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:05 | Steps: 8710 | Loss: 71.525995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:05 | Steps: 8712 | Loss: 71.529673\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:05 | Steps: 8713 | Loss: 71.534648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:05 | Steps: 8714 | Loss: 71.540675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:06 | Steps: 8715 | Loss: 71.543123\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:06 | Steps: 8716 | Loss: 71.549963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:06 | Steps: 8717 | Loss: 71.549212\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:06 | Steps: 8718 | Loss: 71.551775\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:06 | Steps: 8719 | Loss: 71.557045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:06 | Steps: 8720 | Loss: 71.561581\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:06 | Steps: 8721 | Loss: 71.562498\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:06 | Steps: 8722 | Loss: 71.561566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:07 | Steps: 8723 | Loss: 71.561161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:07 | Steps: 8725 | Loss: 71.565724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:07 | Steps: 8726 | Loss: 71.563334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:07 | Steps: 8727 | Loss: 71.562103\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:07 | Steps: 8728 | Loss: 71.562156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:07 | Steps: 8729 | Loss: 71.564670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:07 | Steps: 8730 | Loss: 71.565379\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:08 | Steps: 8731 | Loss: 71.566557\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:08 | Steps: 8732 | Loss: 71.566689\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:08 | Steps: 8733 | Loss: 71.567660\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:08 | Steps: 8734 | Loss: 71.567195\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:08 | Steps: 8735 | Loss: 71.568454\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:08 | Steps: 8736 | Loss: 71.573402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:08 | Steps: 8737 | Loss: 71.579139\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:09 | Steps: 8738 | Loss: 71.580510\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:09 | Steps: 8739 | Loss: 71.582002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:09 | Steps: 8740 | Loss: 71.584943\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:09 | Steps: 8741 | Loss: 71.584572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:09 | Steps: 8742 | Loss: 71.582938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:09 | Steps: 8743 | Loss: 71.584395\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:09 | Steps: 8744 | Loss: 71.586958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:10 | Steps: 8745 | Loss: 71.587197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:10 | Steps: 8746 | Loss: 71.584852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:10 | Steps: 8747 | Loss: 71.585059\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:10 | Steps: 8748 | Loss: 71.585755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:10 | Steps: 8749 | Loss: 71.590011\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:10 | Steps: 8751 | Loss: 71.593847\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:10 | Steps: 8752 | Loss: 71.593416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:11 | Steps: 8753 | Loss: 71.593273\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:11 | Steps: 8754 | Loss: 71.594125\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:11 | Steps: 8755 | Loss: 71.594009\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:11 | Steps: 8756 | Loss: 71.594411\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:11 | Steps: 8757 | Loss: 71.598585\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:11 | Steps: 8758 | Loss: 71.600003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:11 | Steps: 8759 | Loss: 71.599098\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:11 | Steps: 8760 | Loss: 71.600711\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:12 | Steps: 8761 | Loss: 71.602296\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:12 | Steps: 8762 | Loss: 71.601295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:12 | Steps: 8763 | Loss: 71.600690\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:12 | Steps: 8764 | Loss: 71.602917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:12 | Steps: 8765 | Loss: 71.605516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:12 | Steps: 8766 | Loss: 71.612450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:12 | Steps: 8767 | Loss: 71.614115\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:12 | Steps: 8768 | Loss: 71.615237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:13 | Steps: 8769 | Loss: 71.615831\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:13 | Steps: 8770 | Loss: 71.619888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:13 | Steps: 8771 | Loss: 71.624708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:13 | Steps: 8772 | Loss: 71.630783\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:13 | Steps: 8773 | Loss: 71.632719\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:13 | Steps: 8774 | Loss: 71.635523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:13 | Steps: 8775 | Loss: 71.638198\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:13 | Steps: 8776 | Loss: 71.638254\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:14 | Steps: 8777 | Loss: 71.638239\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:14 | Steps: 8778 | Loss: 71.643191\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:14 | Steps: 8779 | Loss: 71.643581\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:14 | Steps: 8780 | Loss: 71.647811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:14 | Steps: 8781 | Loss: 71.648852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:14 | Steps: 8782 | Loss: 71.652400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:14 | Steps: 8783 | Loss: 71.654993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:15 | Steps: 8784 | Loss: 71.659157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:15 | Steps: 8785 | Loss: 71.667137\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:15 | Steps: 8786 | Loss: 71.667670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:15 | Steps: 8787 | Loss: 71.666464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:15 | Steps: 8788 | Loss: 71.665241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:15 | Steps: 8789 | Loss: 71.665915\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:15 | Steps: 8790 | Loss: 71.667796\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:15 | Steps: 8791 | Loss: 71.669044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:16 | Steps: 8792 | Loss: 71.675263\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:16 | Steps: 8793 | Loss: 71.680569\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:16 | Steps: 8794 | Loss: 71.678633\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:16 | Steps: 8795 | Loss: 71.679246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:16 | Steps: 8796 | Loss: 71.684663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:16 | Steps: 8797 | Loss: 71.684954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:16 | Steps: 8798 | Loss: 71.688187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:17 | Steps: 8799 | Loss: 71.687878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:17 | Steps: 8800 | Loss: 71.685897\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:17 | Steps: 8801 | Loss: 71.685018\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:17 | Steps: 8802 | Loss: 71.685750\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:17 | Steps: 8803 | Loss: 71.684260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:17 | Steps: 8804 | Loss: 71.684999\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:17 | Steps: 8805 | Loss: 71.688641\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:17 | Steps: 8806 | Loss: 71.692521\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:18 | Steps: 8807 | Loss: 71.695757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:18 | Steps: 8808 | Loss: 71.696863\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:18 | Steps: 8809 | Loss: 71.700441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:18 | Steps: 8810 | Loss: 71.703154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:18 | Steps: 8811 | Loss: 71.703994\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:18 | Steps: 8812 | Loss: 71.705438\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:18 | Steps: 8814 | Loss: 71.709405\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:19 | Steps: 8815 | Loss: 71.710216\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:19 | Steps: 8816 | Loss: 71.713741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:19 | Steps: 8817 | Loss: 71.716870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:19 | Steps: 8818 | Loss: 71.720181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:19 | Steps: 8819 | Loss: 71.718790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:19 | Steps: 8820 | Loss: 71.722508\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:19 | Steps: 8821 | Loss: 71.720983\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:19 | Steps: 8822 | Loss: 71.718880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:20 | Steps: 8824 | Loss: 71.721072\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:20 | Steps: 8825 | Loss: 71.725144\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:20 | Steps: 8826 | Loss: 71.730463\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:20 | Steps: 8827 | Loss: 71.734466\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:20 | Steps: 8828 | Loss: 71.734599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:20 | Steps: 8829 | Loss: 71.737885\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:21 | Steps: 8830 | Loss: 71.737345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:21 | Steps: 8831 | Loss: 71.735890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:21 | Steps: 8832 | Loss: 71.741738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:21 | Steps: 8833 | Loss: 71.741576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:21 | Steps: 8834 | Loss: 71.745043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:21 | Steps: 8835 | Loss: 71.748586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:21 | Steps: 8836 | Loss: 71.751049\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:21 | Steps: 8837 | Loss: 71.751904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:22 | Steps: 8838 | Loss: 71.752094\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:22 | Steps: 8839 | Loss: 71.752179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:22 | Steps: 8840 | Loss: 71.749765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:22 | Steps: 8841 | Loss: 71.749457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:22 | Steps: 8842 | Loss: 71.752230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:22 | Steps: 8843 | Loss: 71.751068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:22 | Steps: 8844 | Loss: 71.749030\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:23 | Steps: 8845 | Loss: 71.750513\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:23 | Steps: 8846 | Loss: 71.752788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:23 | Steps: 8847 | Loss: 71.756165\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:23 | Steps: 8848 | Loss: 71.757627\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:23 | Steps: 8849 | Loss: 71.756992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:23 | Steps: 8851 | Loss: 71.754316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:24 | Steps: 8853 | Loss: 71.758774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:24 | Steps: 8854 | Loss: 71.760121\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:24 | Steps: 8855 | Loss: 71.763839\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:24 | Steps: 8856 | Loss: 71.763178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:24 | Steps: 8857 | Loss: 71.764937\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:24 | Steps: 8858 | Loss: 71.768280\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:25 | Steps: 8859 | Loss: 71.768288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:25 | Steps: 8860 | Loss: 71.771953\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:25 | Steps: 8861 | Loss: 71.774460\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:25 | Steps: 8862 | Loss: 71.775954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:25 | Steps: 8863 | Loss: 71.780155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:25 | Steps: 8864 | Loss: 71.781745\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:25 | Steps: 8865 | Loss: 71.786186\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:25 | Steps: 8866 | Loss: 71.790161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:26 | Steps: 8867 | Loss: 71.789357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:26 | Steps: 8868 | Loss: 71.791224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:26 | Steps: 8869 | Loss: 71.791580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:26 | Steps: 8870 | Loss: 71.793989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:26 | Steps: 8871 | Loss: 71.796382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:26 | Steps: 8872 | Loss: 71.799417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:26 | Steps: 8873 | Loss: 71.806063\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:27 | Steps: 8874 | Loss: 71.806557\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:27 | Steps: 8875 | Loss: 71.810475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:27 | Steps: 8876 | Loss: 71.815320\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:27 | Steps: 8877 | Loss: 71.817544\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:27 | Steps: 8878 | Loss: 71.818062\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:27 | Steps: 8879 | Loss: 71.818610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:27 | Steps: 8881 | Loss: 71.818262\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:28 | Steps: 8882 | Loss: 71.825129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:28 | Steps: 8883 | Loss: 71.825358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:28 | Steps: 8884 | Loss: 71.830160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:28 | Steps: 8885 | Loss: 71.834801\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:28 | Steps: 8886 | Loss: 71.837127\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:28 | Steps: 8887 | Loss: 71.842503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:28 | Steps: 8888 | Loss: 71.845539\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:28 | Steps: 8889 | Loss: 71.842977\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:29 | Steps: 8890 | Loss: 71.846655\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:29 | Steps: 8891 | Loss: 71.848067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:29 | Steps: 8892 | Loss: 71.850761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:29 | Steps: 8893 | Loss: 71.852075\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:29 | Steps: 8894 | Loss: 71.850229\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:29 | Steps: 8895 | Loss: 71.849012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:29 | Steps: 8896 | Loss: 71.848218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:30 | Steps: 8897 | Loss: 71.845303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:30 | Steps: 8898 | Loss: 71.843233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:30 | Steps: 8899 | Loss: 71.844256\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:30 | Steps: 8900 | Loss: 71.843670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:30 | Steps: 8901 | Loss: 71.843496\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:30 | Steps: 8902 | Loss: 71.843203\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:30 | Steps: 8903 | Loss: 71.840991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:30 | Steps: 8904 | Loss: 71.840328\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:31 | Steps: 8905 | Loss: 71.842415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:31 | Steps: 8906 | Loss: 71.841611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:31 | Steps: 8907 | Loss: 71.841291\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:31 | Steps: 8908 | Loss: 71.843069\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:31 | Steps: 8909 | Loss: 71.845414\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:31 | Steps: 8910 | Loss: 71.850984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:31 | Steps: 8911 | Loss: 71.853444\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:32 | Steps: 8912 | Loss: 71.855849\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:32 | Steps: 8913 | Loss: 71.860105\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:32 | Steps: 8914 | Loss: 71.863894\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:32 | Steps: 8915 | Loss: 71.867858\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:32 | Steps: 8916 | Loss: 71.866137\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:32 | Steps: 8917 | Loss: 71.865286\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:32 | Steps: 8918 | Loss: 71.866192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:32 | Steps: 8919 | Loss: 71.869072\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:33 | Steps: 8920 | Loss: 71.871076\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:33 | Steps: 8921 | Loss: 71.870407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:33 | Steps: 8922 | Loss: 71.869757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:33 | Steps: 8923 | Loss: 71.873711\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:33 | Steps: 8924 | Loss: 71.873872\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:33 | Steps: 8925 | Loss: 71.872436\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:33 | Steps: 8926 | Loss: 71.872636\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:34 | Steps: 8927 | Loss: 71.872990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:34 | Steps: 8928 | Loss: 71.876470\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:34 | Steps: 8929 | Loss: 71.877362\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:34 | Steps: 8930 | Loss: 71.875971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:34 | Steps: 8931 | Loss: 71.883343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:34 | Steps: 8932 | Loss: 71.885250\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:34 | Steps: 8933 | Loss: 71.888185\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:34 | Steps: 8934 | Loss: 71.889648\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:35 | Steps: 8935 | Loss: 71.889874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:35 | Steps: 8936 | Loss: 71.889424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:35 | Steps: 8937 | Loss: 71.893085\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:35 | Steps: 8938 | Loss: 71.895348\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:35 | Steps: 8939 | Loss: 71.896174\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:35 | Steps: 8940 | Loss: 71.897885\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:35 | Steps: 8941 | Loss: 71.898329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:36 | Steps: 8942 | Loss: 71.902118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:36 | Steps: 8944 | Loss: 71.905442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:36 | Steps: 8945 | Loss: 71.903598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:36 | Steps: 8946 | Loss: 71.903287\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:36 | Steps: 8947 | Loss: 71.902920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:36 | Steps: 8948 | Loss: 71.900752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:36 | Steps: 8949 | Loss: 71.906772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:37 | Steps: 8950 | Loss: 71.905319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:37 | Steps: 8951 | Loss: 71.904238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:37 | Steps: 8952 | Loss: 71.906222\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:37 | Steps: 8953 | Loss: 71.910181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:37 | Steps: 8954 | Loss: 71.911174\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:37 | Steps: 8955 | Loss: 71.911554\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:37 | Steps: 8956 | Loss: 71.910880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:38 | Steps: 8957 | Loss: 71.913877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:38 | Steps: 8958 | Loss: 71.914108\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:38 | Steps: 8959 | Loss: 71.915114\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:38 | Steps: 8960 | Loss: 71.915461\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:38 | Steps: 8961 | Loss: 71.917055\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:38 | Steps: 8962 | Loss: 71.918005\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:38 | Steps: 8963 | Loss: 71.920596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:38 | Steps: 8964 | Loss: 71.920283\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:39 | Steps: 8966 | Loss: 71.932975\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:39 | Steps: 8967 | Loss: 71.936375\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:39 | Steps: 8968 | Loss: 71.939743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:39 | Steps: 8969 | Loss: 71.951413\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:39 | Steps: 8970 | Loss: 71.957991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:39 | Steps: 8971 | Loss: 71.961723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:39 | Steps: 8972 | Loss: 71.963111\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:40 | Steps: 8973 | Loss: 71.965514\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:40 | Steps: 8974 | Loss: 71.966552\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:40 | Steps: 8975 | Loss: 71.967215\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:40 | Steps: 8976 | Loss: 71.969080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:40 | Steps: 8977 | Loss: 71.967534\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:40 | Steps: 8978 | Loss: 71.970233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:40 | Steps: 8979 | Loss: 71.972859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:41 | Steps: 8980 | Loss: 71.975142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:41 | Steps: 8981 | Loss: 71.980961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:41 | Steps: 8982 | Loss: 71.989712\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:41 | Steps: 8983 | Loss: 71.995679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:41 | Steps: 8984 | Loss: 71.996029\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:41 | Steps: 8985 | Loss: 71.995279\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:41 | Steps: 8986 | Loss: 71.994966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:41 | Steps: 8987 | Loss: 71.999337\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:42 | Steps: 8988 | Loss: 71.999456\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:42 | Steps: 8989 | Loss: 72.001978\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:42 | Steps: 8990 | Loss: 72.005821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:42 | Steps: 8991 | Loss: 72.014516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:42 | Steps: 8992 | Loss: 72.019504\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:42 | Steps: 8993 | Loss: 72.020753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:42 | Steps: 8994 | Loss: 72.024748\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:43 | Steps: 8995 | Loss: 72.025080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:43 | Steps: 8996 | Loss: 72.024246\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:43 | Steps: 8997 | Loss: 72.024190\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:43 | Steps: 8998 | Loss: 72.025019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:43 | Steps: 8999 | Loss: 72.024138\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:43 | Steps: 9000 | Loss: 72.020793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:43 | Steps: 9001 | Loss: 72.022616\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:44 | Steps: 9002 | Loss: 72.023506\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:44 | Steps: 9003 | Loss: 72.023130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:44 | Steps: 9004 | Loss: 72.025882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:44 | Steps: 9005 | Loss: 72.031345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:44 | Steps: 9006 | Loss: 72.030894\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:44 | Steps: 9007 | Loss: 72.029330\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:44 | Steps: 9008 | Loss: 72.027941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:44 | Steps: 9009 | Loss: 72.026572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:45 | Steps: 9010 | Loss: 72.027090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:45 | Steps: 9011 | Loss: 72.027485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:45 | Steps: 9013 | Loss: 72.028789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:45 | Steps: 9014 | Loss: 72.033542\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:45 | Steps: 9015 | Loss: 72.035354\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:45 | Steps: 9016 | Loss: 72.034957\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:45 | Steps: 9017 | Loss: 72.036188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:46 | Steps: 9018 | Loss: 72.038276\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:46 | Steps: 9019 | Loss: 72.039178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:46 | Steps: 9020 | Loss: 72.042416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:46 | Steps: 9021 | Loss: 72.044582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:46 | Steps: 9022 | Loss: 72.043153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:46 | Steps: 9023 | Loss: 72.042685\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:46 | Steps: 9024 | Loss: 72.043481\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:47 | Steps: 9025 | Loss: 72.045051\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:47 | Steps: 9026 | Loss: 72.046749\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:47 | Steps: 9027 | Loss: 72.052576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:47 | Steps: 9028 | Loss: 72.055408\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:47 | Steps: 9029 | Loss: 72.054334\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:47 | Steps: 9030 | Loss: 72.055958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:47 | Steps: 9031 | Loss: 72.058574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:48 | Steps: 9032 | Loss: 72.057542\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:48 | Steps: 9033 | Loss: 72.058353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:48 | Steps: 9034 | Loss: 72.061277\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:48 | Steps: 9035 | Loss: 72.064527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:48 | Steps: 9036 | Loss: 72.065010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:48 | Steps: 9037 | Loss: 72.069710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:48 | Steps: 9038 | Loss: 72.072304\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:48 | Steps: 9039 | Loss: 72.071387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:49 | Steps: 9040 | Loss: 72.076029\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:49 | Steps: 9041 | Loss: 72.078904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:49 | Steps: 9042 | Loss: 72.079846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:49 | Steps: 9043 | Loss: 72.083219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:49 | Steps: 9044 | Loss: 72.084739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:49 | Steps: 9045 | Loss: 72.088665\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:49 | Steps: 9046 | Loss: 72.094650\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:50 | Steps: 9047 | Loss: 72.094799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:50 | Steps: 9048 | Loss: 72.093046\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:50 | Steps: 9049 | Loss: 72.092418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:50 | Steps: 9050 | Loss: 72.091814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:50 | Steps: 9051 | Loss: 72.088845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:50 | Steps: 9052 | Loss: 72.085847\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:50 | Steps: 9053 | Loss: 72.090103\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:51 | Steps: 9054 | Loss: 72.093579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:51 | Steps: 9055 | Loss: 72.093305\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:51 | Steps: 9056 | Loss: 72.092156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:51 | Steps: 9057 | Loss: 72.093827\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:51 | Steps: 9058 | Loss: 72.095079\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:51 | Steps: 9059 | Loss: 72.096041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:51 | Steps: 9060 | Loss: 72.096071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:51 | Steps: 9061 | Loss: 72.095375\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:52 | Steps: 9062 | Loss: 72.095774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:52 | Steps: 9063 | Loss: 72.096933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:52 | Steps: 9064 | Loss: 72.096149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:52 | Steps: 9065 | Loss: 72.098580\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:52 | Steps: 9066 | Loss: 72.099982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:52 | Steps: 9067 | Loss: 72.103056\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:52 | Steps: 9068 | Loss: 72.105292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:53 | Steps: 9069 | Loss: 72.104727\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:53 | Steps: 9070 | Loss: 72.107834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:53 | Steps: 9071 | Loss: 72.112592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:53 | Steps: 9072 | Loss: 72.113704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:53 | Steps: 9073 | Loss: 72.115481\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:53 | Steps: 9074 | Loss: 72.116860\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:53 | Steps: 9075 | Loss: 72.121365\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:53 | Steps: 9076 | Loss: 72.122727\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:54 | Steps: 9077 | Loss: 72.123037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:54 | Steps: 9079 | Loss: 72.126823\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:54 | Steps: 9080 | Loss: 72.130680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:54 | Steps: 9081 | Loss: 72.135939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:54 | Steps: 9082 | Loss: 72.138384\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:54 | Steps: 9083 | Loss: 72.145417\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:55 | Steps: 9084 | Loss: 72.144800\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:55 | Steps: 9085 | Loss: 72.143313\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:55 | Steps: 9086 | Loss: 72.144037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:55 | Steps: 9087 | Loss: 72.149588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:55 | Steps: 9088 | Loss: 72.149415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:55 | Steps: 9089 | Loss: 72.150421\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:55 | Steps: 9090 | Loss: 72.154238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:56 | Steps: 9091 | Loss: 72.157255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:56 | Steps: 9092 | Loss: 72.155738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:56 | Steps: 9093 | Loss: 72.152625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:56 | Steps: 9094 | Loss: 72.156130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:56 | Steps: 9095 | Loss: 72.156364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:56 | Steps: 9096 | Loss: 72.157554\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:56 | Steps: 9098 | Loss: 72.152820\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:56 | Steps: 9099 | Loss: 72.151724\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:57 | Steps: 9100 | Loss: 72.152335\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:57 | Steps: 9101 | Loss: 72.156669\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:57 | Steps: 9102 | Loss: 72.154316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:57 | Steps: 9103 | Loss: 72.152387\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:57 | Steps: 9104 | Loss: 72.154143\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:57 | Steps: 9105 | Loss: 72.156503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:58 | Steps: 9106 | Loss: 72.159784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:58 | Steps: 9107 | Loss: 72.162016\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:58 | Steps: 9108 | Loss: 72.163541\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:58 | Steps: 9109 | Loss: 72.165471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:58 | Steps: 9110 | Loss: 72.167959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:58 | Steps: 9111 | Loss: 72.169743\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:58 | Steps: 9112 | Loss: 72.170913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:59 | Steps: 9113 | Loss: 72.170281\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:59 | Steps: 9114 | Loss: 72.171071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:59 | Steps: 9115 | Loss: 72.170659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:59 | Steps: 9116 | Loss: 72.175606\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:59 | Steps: 9117 | Loss: 72.176714\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:59 | Steps: 9118 | Loss: 72.176938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:14:59 | Steps: 9119 | Loss: 72.176119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:00 | Steps: 9120 | Loss: 72.175598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:00 | Steps: 9121 | Loss: 72.176464\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:00 | Steps: 9122 | Loss: 72.178705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:00 | Steps: 9123 | Loss: 72.180021\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:00 | Steps: 9124 | Loss: 72.182622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:00 | Steps: 9125 | Loss: 72.191718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:00 | Steps: 9126 | Loss: 72.196518\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:00 | Steps: 9127 | Loss: 72.199925\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:01 | Steps: 9128 | Loss: 72.202529\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:01 | Steps: 9129 | Loss: 72.202576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:01 | Steps: 9130 | Loss: 72.208926\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:01 | Steps: 9131 | Loss: 72.216048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:01 | Steps: 9132 | Loss: 72.220307\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:01 | Steps: 9133 | Loss: 72.220431\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:01 | Steps: 9134 | Loss: 72.221760\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:01 | Steps: 9135 | Loss: 72.224049\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:02 | Steps: 9136 | Loss: 72.226600\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:02 | Steps: 9137 | Loss: 72.229147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:02 | Steps: 9138 | Loss: 72.233380\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:02 | Steps: 9139 | Loss: 72.234630\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:02 | Steps: 9140 | Loss: 72.234697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:02 | Steps: 9141 | Loss: 72.233647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:02 | Steps: 9142 | Loss: 72.231349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:03 | Steps: 9143 | Loss: 72.235710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:03 | Steps: 9144 | Loss: 72.236737\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:03 | Steps: 9145 | Loss: 72.236725\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:03 | Steps: 9146 | Loss: 72.240034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:03 | Steps: 9147 | Loss: 72.243265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:03 | Steps: 9148 | Loss: 72.245933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:03 | Steps: 9149 | Loss: 72.245834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:04 | Steps: 9150 | Loss: 72.244803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:04 | Steps: 9151 | Loss: 72.243941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:04 | Steps: 9152 | Loss: 72.244410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:04 | Steps: 9153 | Loss: 72.245182\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:04 | Steps: 9154 | Loss: 72.246103\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:04 | Steps: 9155 | Loss: 72.245124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:04 | Steps: 9156 | Loss: 72.250946\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:05 | Steps: 9157 | Loss: 72.256115\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:05 | Steps: 9158 | Loss: 72.254840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:05 | Steps: 9159 | Loss: 72.254032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:05 | Steps: 9160 | Loss: 72.259037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:05 | Steps: 9161 | Loss: 72.265780\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:05 | Steps: 9162 | Loss: 72.267660\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:05 | Steps: 9163 | Loss: 72.267514\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:06 | Steps: 9164 | Loss: 72.270181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:06 | Steps: 9165 | Loss: 72.270351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:06 | Steps: 9166 | Loss: 72.282592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:06 | Steps: 9167 | Loss: 72.284224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:06 | Steps: 9168 | Loss: 72.283877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:06 | Steps: 9169 | Loss: 72.284157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:06 | Steps: 9170 | Loss: 72.285604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:06 | Steps: 9171 | Loss: 72.290005\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:07 | Steps: 9172 | Loss: 72.291811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:07 | Steps: 9173 | Loss: 72.291767\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:07 | Steps: 9174 | Loss: 72.294127\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:07 | Steps: 9175 | Loss: 72.296023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:07 | Steps: 9176 | Loss: 72.298921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:07 | Steps: 9177 | Loss: 72.299651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:08 | Steps: 9178 | Loss: 72.306960\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:08 | Steps: 9179 | Loss: 72.307032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:08 | Steps: 9180 | Loss: 72.306148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:08 | Steps: 9181 | Loss: 72.309857\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:08 | Steps: 9182 | Loss: 72.311315\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:08 | Steps: 9183 | Loss: 72.315489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:08 | Steps: 9184 | Loss: 72.320981\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:09 | Steps: 9185 | Loss: 72.324349\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:09 | Steps: 9186 | Loss: 72.323772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:09 | Steps: 9187 | Loss: 72.325475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:09 | Steps: 9188 | Loss: 72.327574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:09 | Steps: 9189 | Loss: 72.330148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:09 | Steps: 9190 | Loss: 72.332260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:09 | Steps: 9191 | Loss: 72.334402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:09 | Steps: 9192 | Loss: 72.333834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:10 | Steps: 9193 | Loss: 72.332301\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:10 | Steps: 9194 | Loss: 72.329828\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:10 | Steps: 9195 | Loss: 72.327038\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:10 | Steps: 9196 | Loss: 72.325154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:10 | Steps: 9197 | Loss: 72.324390\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:10 | Steps: 9198 | Loss: 72.326369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:10 | Steps: 9199 | Loss: 72.328587\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:11 | Steps: 9200 | Loss: 72.331631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:11 | Steps: 9201 | Loss: 72.333548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:11 | Steps: 9202 | Loss: 72.337568\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:11 | Steps: 9203 | Loss: 72.342320\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:11 | Steps: 9204 | Loss: 72.343768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:11 | Steps: 9205 | Loss: 72.344680\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:11 | Steps: 9206 | Loss: 72.346189\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:12 | Steps: 9207 | Loss: 72.348012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:12 | Steps: 9208 | Loss: 72.349795\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:12 | Steps: 9209 | Loss: 72.356016\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:12 | Steps: 9210 | Loss: 72.356687\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:12 | Steps: 9211 | Loss: 72.357029\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:12 | Steps: 9212 | Loss: 72.356765\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:12 | Steps: 9213 | Loss: 72.356343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:12 | Steps: 9214 | Loss: 72.359658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:13 | Steps: 9215 | Loss: 72.361932\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:13 | Steps: 9216 | Loss: 72.363792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:13 | Steps: 9217 | Loss: 72.363871\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:13 | Steps: 9218 | Loss: 72.366071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:13 | Steps: 9219 | Loss: 72.369799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:13 | Steps: 9220 | Loss: 72.370410\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:13 | Steps: 9221 | Loss: 72.372639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:14 | Steps: 9222 | Loss: 72.371742\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:14 | Steps: 9223 | Loss: 72.372142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:14 | Steps: 9224 | Loss: 72.371088\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:14 | Steps: 9225 | Loss: 72.370697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:14 | Steps: 9226 | Loss: 72.375568\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:14 | Steps: 9227 | Loss: 72.377785\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:14 | Steps: 9228 | Loss: 72.380687\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:15 | Steps: 9229 | Loss: 72.381766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:15 | Steps: 9230 | Loss: 72.384541\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:15 | Steps: 9232 | Loss: 72.384920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:15 | Steps: 9233 | Loss: 72.385992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:15 | Steps: 9234 | Loss: 72.390184\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:15 | Steps: 9235 | Loss: 72.390707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:15 | Steps: 9236 | Loss: 72.393074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:16 | Steps: 9237 | Loss: 72.395659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:16 | Steps: 9238 | Loss: 72.398466\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:16 | Steps: 9239 | Loss: 72.398862\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:16 | Steps: 9240 | Loss: 72.398729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:16 | Steps: 9241 | Loss: 72.400419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:16 | Steps: 9242 | Loss: 72.401129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:16 | Steps: 9243 | Loss: 72.402843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:17 | Steps: 9244 | Loss: 72.404691\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:17 | Steps: 9245 | Loss: 72.406006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:17 | Steps: 9246 | Loss: 72.406341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:17 | Steps: 9247 | Loss: 72.411136\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:17 | Steps: 9248 | Loss: 72.415285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:17 | Steps: 9249 | Loss: 72.417468\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:17 | Steps: 9250 | Loss: 72.430518\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:17 | Steps: 9251 | Loss: 72.433781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:18 | Steps: 9252 | Loss: 72.432454\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:18 | Steps: 9253 | Loss: 72.434054\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:18 | Steps: 9254 | Loss: 72.434045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:18 | Steps: 9255 | Loss: 72.439329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:18 | Steps: 9256 | Loss: 72.442128\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:18 | Steps: 9257 | Loss: 72.440891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:18 | Steps: 9258 | Loss: 72.442134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:19 | Steps: 9259 | Loss: 72.444890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:19 | Steps: 9260 | Loss: 72.445390\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:19 | Steps: 9261 | Loss: 72.445519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:19 | Steps: 9262 | Loss: 72.446956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:19 | Steps: 9263 | Loss: 72.452460\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:19 | Steps: 9264 | Loss: 72.454528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:19 | Steps: 9265 | Loss: 72.458797\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:20 | Steps: 9266 | Loss: 72.468641\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:20 | Steps: 9267 | Loss: 72.469252\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:20 | Steps: 9268 | Loss: 72.469317\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:20 | Steps: 9269 | Loss: 72.476131\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:20 | Steps: 9270 | Loss: 72.481369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:20 | Steps: 9271 | Loss: 72.481041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:20 | Steps: 9272 | Loss: 72.480353\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:21 | Steps: 9273 | Loss: 72.481596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:21 | Steps: 9274 | Loss: 72.488807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:21 | Steps: 9275 | Loss: 72.492827\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:21 | Steps: 9276 | Loss: 72.501311\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:21 | Steps: 9277 | Loss: 72.503397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:21 | Steps: 9278 | Loss: 72.503736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:21 | Steps: 9279 | Loss: 72.508221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:22 | Steps: 9280 | Loss: 72.510424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:22 | Steps: 9281 | Loss: 72.509380\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:22 | Steps: 9282 | Loss: 72.507644\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:22 | Steps: 9283 | Loss: 72.505433\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:22 | Steps: 9284 | Loss: 72.504973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:22 | Steps: 9285 | Loss: 72.508451\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:22 | Steps: 9286 | Loss: 72.509425\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:22 | Steps: 9287 | Loss: 72.506976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:23 | Steps: 9288 | Loss: 72.507104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:23 | Steps: 9289 | Loss: 72.507939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:23 | Steps: 9290 | Loss: 72.508846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:23 | Steps: 9291 | Loss: 72.510471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:23 | Steps: 9293 | Loss: 72.514271\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:23 | Steps: 9294 | Loss: 72.516276\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:24 | Steps: 9295 | Loss: 72.517106\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:24 | Steps: 9296 | Loss: 72.522658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:24 | Steps: 9297 | Loss: 72.524632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:24 | Steps: 9298 | Loss: 72.526757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:24 | Steps: 9299 | Loss: 72.527610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:24 | Steps: 9300 | Loss: 72.526221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:24 | Steps: 9301 | Loss: 72.526574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:25 | Steps: 9302 | Loss: 72.528601\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:25 | Steps: 9303 | Loss: 72.530472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:25 | Steps: 9304 | Loss: 72.532500\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:25 | Steps: 9305 | Loss: 72.531655\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:25 | Steps: 9306 | Loss: 72.535104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:25 | Steps: 9307 | Loss: 72.536262\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:25 | Steps: 9308 | Loss: 72.537161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:26 | Steps: 9309 | Loss: 72.537650\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:26 | Steps: 9310 | Loss: 72.538946\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:26 | Steps: 9311 | Loss: 72.541095\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:26 | Steps: 9312 | Loss: 72.545757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:26 | Steps: 9313 | Loss: 72.549431\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:26 | Steps: 9314 | Loss: 72.552558\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:26 | Steps: 9315 | Loss: 72.555313\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:27 | Steps: 9316 | Loss: 72.559486\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:27 | Steps: 9317 | Loss: 72.558468\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:27 | Steps: 9318 | Loss: 72.557589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:27 | Steps: 9319 | Loss: 72.556096\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:27 | Steps: 9320 | Loss: 72.562870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:27 | Steps: 9321 | Loss: 72.560928\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:27 | Steps: 9322 | Loss: 72.561732\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:27 | Steps: 9323 | Loss: 72.566621\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:28 | Steps: 9324 | Loss: 72.570361\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:28 | Steps: 9325 | Loss: 72.569171\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:28 | Steps: 9326 | Loss: 72.569726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:28 | Steps: 9327 | Loss: 72.570316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:28 | Steps: 9328 | Loss: 72.566850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:28 | Steps: 9329 | Loss: 72.568741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:28 | Steps: 9330 | Loss: 72.570072\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:28 | Steps: 9331 | Loss: 72.569543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:29 | Steps: 9332 | Loss: 72.569418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:29 | Steps: 9333 | Loss: 72.570498\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:29 | Steps: 9334 | Loss: 72.571734\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:29 | Steps: 9335 | Loss: 72.572873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:29 | Steps: 9336 | Loss: 72.574083\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:29 | Steps: 9337 | Loss: 72.579113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:29 | Steps: 9338 | Loss: 72.579240\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:30 | Steps: 9339 | Loss: 72.580866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:30 | Steps: 9340 | Loss: 72.585065\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:30 | Steps: 9341 | Loss: 72.586240\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:30 | Steps: 9342 | Loss: 72.586529\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:30 | Steps: 9343 | Loss: 72.589923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:30 | Steps: 9344 | Loss: 72.588998\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:30 | Steps: 9345 | Loss: 72.592655\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:31 | Steps: 9346 | Loss: 72.594641\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:31 | Steps: 9347 | Loss: 72.595441\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:31 | Steps: 9348 | Loss: 72.601389\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:31 | Steps: 9349 | Loss: 72.606966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:31 | Steps: 9350 | Loss: 72.610691\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:31 | Steps: 9351 | Loss: 72.614412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:31 | Steps: 9352 | Loss: 72.615974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:32 | Steps: 9353 | Loss: 72.616083\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:32 | Steps: 9354 | Loss: 72.620801\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:32 | Steps: 9355 | Loss: 72.620517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:32 | Steps: 9356 | Loss: 72.620937\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:32 | Steps: 9357 | Loss: 72.621191\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:32 | Steps: 9358 | Loss: 72.624623\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:32 | Steps: 9359 | Loss: 72.631758\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:32 | Steps: 9360 | Loss: 72.631903\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:33 | Steps: 9361 | Loss: 72.633145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:33 | Steps: 9362 | Loss: 72.638814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:33 | Steps: 9363 | Loss: 72.640141\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:33 | Steps: 9364 | Loss: 72.639859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:33 | Steps: 9365 | Loss: 72.639409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:33 | Steps: 9366 | Loss: 72.638825\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:33 | Steps: 9367 | Loss: 72.637204\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:34 | Steps: 9368 | Loss: 72.640696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:34 | Steps: 9369 | Loss: 72.642376\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:34 | Steps: 9370 | Loss: 72.644302\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:34 | Steps: 9371 | Loss: 72.643055\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:34 | Steps: 9372 | Loss: 72.642463\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:34 | Steps: 9373 | Loss: 72.643763\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:34 | Steps: 9374 | Loss: 72.643674\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:35 | Steps: 9375 | Loss: 72.645392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:35 | Steps: 9376 | Loss: 72.647254\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:35 | Steps: 9377 | Loss: 72.647759\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:35 | Steps: 9378 | Loss: 72.653707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:35 | Steps: 9379 | Loss: 72.655426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:35 | Steps: 9380 | Loss: 72.656577\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:35 | Steps: 9381 | Loss: 72.656407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:36 | Steps: 9382 | Loss: 72.656535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:36 | Steps: 9383 | Loss: 72.656556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:36 | Steps: 9384 | Loss: 72.659027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:36 | Steps: 9385 | Loss: 72.660015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:36 | Steps: 9386 | Loss: 72.663713\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:36 | Steps: 9387 | Loss: 72.665762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:36 | Steps: 9388 | Loss: 72.668610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:37 | Steps: 9389 | Loss: 72.670099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:37 | Steps: 9390 | Loss: 72.669559\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:37 | Steps: 9391 | Loss: 72.669477\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:37 | Steps: 9392 | Loss: 72.672550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:37 | Steps: 9393 | Loss: 72.674077\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:37 | Steps: 9394 | Loss: 72.676669\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:37 | Steps: 9395 | Loss: 72.679830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:38 | Steps: 9396 | Loss: 72.680354\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:38 | Steps: 9397 | Loss: 72.682104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:38 | Steps: 9398 | Loss: 72.684631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:38 | Steps: 9399 | Loss: 72.690009\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:38 | Steps: 9400 | Loss: 72.689030\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:38 | Steps: 9401 | Loss: 72.687649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:38 | Steps: 9402 | Loss: 72.692519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:39 | Steps: 9403 | Loss: 72.692978\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:39 | Steps: 9404 | Loss: 72.695129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:39 | Steps: 9405 | Loss: 72.697110\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:39 | Steps: 9406 | Loss: 72.698819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:39 | Steps: 9407 | Loss: 72.697376\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:39 | Steps: 9408 | Loss: 72.695534\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:39 | Steps: 9409 | Loss: 72.691867\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:39 | Steps: 9410 | Loss: 72.696902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:40 | Steps: 9411 | Loss: 72.698449\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:40 | Steps: 9412 | Loss: 72.702596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:40 | Steps: 9413 | Loss: 72.704439\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:40 | Steps: 9414 | Loss: 72.704074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:40 | Steps: 9415 | Loss: 72.704000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:40 | Steps: 9416 | Loss: 72.703976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:40 | Steps: 9417 | Loss: 72.703177\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:41 | Steps: 9418 | Loss: 72.705146\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:41 | Steps: 9419 | Loss: 72.705689\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:41 | Steps: 9420 | Loss: 72.705884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:41 | Steps: 9421 | Loss: 72.711090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:41 | Steps: 9422 | Loss: 72.711971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:41 | Steps: 9423 | Loss: 72.716006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:41 | Steps: 9424 | Loss: 72.717749\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:42 | Steps: 9425 | Loss: 72.717044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:42 | Steps: 9426 | Loss: 72.721241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:42 | Steps: 9427 | Loss: 72.723979\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:42 | Steps: 9428 | Loss: 72.723140\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:42 | Steps: 9429 | Loss: 72.726605\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:42 | Steps: 9430 | Loss: 72.730119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:42 | Steps: 9431 | Loss: 72.729882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:43 | Steps: 9432 | Loss: 72.734964\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:43 | Steps: 9433 | Loss: 72.742910\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:43 | Steps: 9434 | Loss: 72.744319\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:43 | Steps: 9435 | Loss: 72.748194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:43 | Steps: 9436 | Loss: 72.750526\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:43 | Steps: 9437 | Loss: 72.753713\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:43 | Steps: 9438 | Loss: 72.761208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:44 | Steps: 9439 | Loss: 72.760199\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:44 | Steps: 9440 | Loss: 72.762860\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:44 | Steps: 9441 | Loss: 72.762949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:44 | Steps: 9442 | Loss: 72.764513\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:44 | Steps: 9443 | Loss: 72.763266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:44 | Steps: 9444 | Loss: 72.763944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:44 | Steps: 9445 | Loss: 72.766427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:45 | Steps: 9446 | Loss: 72.769327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:45 | Steps: 9447 | Loss: 72.773019\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:45 | Steps: 9448 | Loss: 72.774921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:45 | Steps: 9449 | Loss: 72.775402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:45 | Steps: 9450 | Loss: 72.777740\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:45 | Steps: 9451 | Loss: 72.779171\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:45 | Steps: 9452 | Loss: 72.780209\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:46 | Steps: 9453 | Loss: 72.780902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:46 | Steps: 9454 | Loss: 72.780348\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:46 | Steps: 9455 | Loss: 72.789830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:46 | Steps: 9456 | Loss: 72.787629\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:46 | Steps: 9457 | Loss: 72.789635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:46 | Steps: 9458 | Loss: 72.791048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:46 | Steps: 9459 | Loss: 72.793197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:47 | Steps: 9460 | Loss: 72.796382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:47 | Steps: 9461 | Loss: 72.795244\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:47 | Steps: 9462 | Loss: 72.794618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:47 | Steps: 9463 | Loss: 72.794428\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:47 | Steps: 9464 | Loss: 72.794404\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:47 | Steps: 9465 | Loss: 72.796080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:47 | Steps: 9466 | Loss: 72.799533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:48 | Steps: 9467 | Loss: 72.800193\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:48 | Steps: 9468 | Loss: 72.802761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:48 | Steps: 9469 | Loss: 72.806125\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:48 | Steps: 9470 | Loss: 72.808640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:48 | Steps: 9471 | Loss: 72.812001\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:48 | Steps: 9472 | Loss: 72.811181\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:48 | Steps: 9473 | Loss: 72.811842\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:49 | Steps: 9474 | Loss: 72.814912\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:49 | Steps: 9475 | Loss: 72.814574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:49 | Steps: 9476 | Loss: 72.813496\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:49 | Steps: 9477 | Loss: 72.815769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:49 | Steps: 9478 | Loss: 72.819772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:49 | Steps: 9479 | Loss: 72.822471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:49 | Steps: 9480 | Loss: 72.825073\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:50 | Steps: 9481 | Loss: 72.830503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:50 | Steps: 9482 | Loss: 72.830322\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:50 | Steps: 9483 | Loss: 72.833846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:50 | Steps: 9484 | Loss: 72.832921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:50 | Steps: 9485 | Loss: 72.834344\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:50 | Steps: 9486 | Loss: 72.835166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:50 | Steps: 9487 | Loss: 72.839231\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:50 | Steps: 9488 | Loss: 72.843739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:51 | Steps: 9489 | Loss: 72.843295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:51 | Steps: 9490 | Loss: 72.843916\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:51 | Steps: 9491 | Loss: 72.840520\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:51 | Steps: 9492 | Loss: 72.842790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:51 | Steps: 9493 | Loss: 72.844863\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:51 | Steps: 9494 | Loss: 72.847923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:52 | Steps: 9495 | Loss: 72.849336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:52 | Steps: 9497 | Loss: 72.851722\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:52 | Steps: 9498 | Loss: 72.852792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:52 | Steps: 9499 | Loss: 72.855905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:52 | Steps: 9500 | Loss: 72.862976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:52 | Steps: 9501 | Loss: 72.864435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:52 | Steps: 9502 | Loss: 72.862842\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:53 | Steps: 9503 | Loss: 72.865623\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:53 | Steps: 9504 | Loss: 72.868043\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:53 | Steps: 9505 | Loss: 72.869446\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:53 | Steps: 9506 | Loss: 72.880285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:53 | Steps: 9507 | Loss: 72.887442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:53 | Steps: 9508 | Loss: 72.890555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:53 | Steps: 9509 | Loss: 72.892993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:54 | Steps: 9510 | Loss: 72.893301\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:54 | Steps: 9511 | Loss: 72.894097\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:54 | Steps: 9512 | Loss: 72.893208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:54 | Steps: 9513 | Loss: 72.894708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:54 | Steps: 9514 | Loss: 72.895179\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:54 | Steps: 9515 | Loss: 72.899686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:54 | Steps: 9516 | Loss: 72.902045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:55 | Steps: 9517 | Loss: 72.905192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:55 | Steps: 9518 | Loss: 72.913357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:55 | Steps: 9519 | Loss: 72.917034\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:55 | Steps: 9520 | Loss: 72.916684\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:55 | Steps: 9521 | Loss: 72.922337\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:55 | Steps: 9522 | Loss: 72.924495\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:55 | Steps: 9523 | Loss: 72.928101\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:56 | Steps: 9524 | Loss: 72.932060\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:56 | Steps: 9525 | Loss: 72.931604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:56 | Steps: 9526 | Loss: 72.932598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:56 | Steps: 9527 | Loss: 72.934120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:56 | Steps: 9528 | Loss: 72.933358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:56 | Steps: 9529 | Loss: 72.934287\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:56 | Steps: 9530 | Loss: 72.933991\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:57 | Steps: 9531 | Loss: 72.934290\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:57 | Steps: 9532 | Loss: 72.935839\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:57 | Steps: 9533 | Loss: 72.936120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:57 | Steps: 9534 | Loss: 72.939296\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:57 | Steps: 9535 | Loss: 72.941887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:57 | Steps: 9536 | Loss: 72.944665\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:57 | Steps: 9537 | Loss: 72.950022\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:58 | Steps: 9538 | Loss: 72.953662\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:58 | Steps: 9539 | Loss: 72.954541\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:58 | Steps: 9540 | Loss: 72.953589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:58 | Steps: 9541 | Loss: 72.956118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:58 | Steps: 9542 | Loss: 72.958863\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:58 | Steps: 9543 | Loss: 72.959070\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:58 | Steps: 9544 | Loss: 72.956306\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:59 | Steps: 9545 | Loss: 72.957676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:59 | Steps: 9546 | Loss: 72.956940\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:59 | Steps: 9547 | Loss: 72.957915\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:59 | Steps: 9548 | Loss: 72.960880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:59 | Steps: 9549 | Loss: 72.965516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:59 | Steps: 9550 | Loss: 72.967752\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:59 | Steps: 9551 | Loss: 72.969309\n",
      "Epoch 1 |   Training | Elapsed Time: 0:15:59 | Steps: 9552 | Loss: 72.968988\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:00 | Steps: 9553 | Loss: 72.968701\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:00 | Steps: 9554 | Loss: 72.973783\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:00 | Steps: 9555 | Loss: 72.972691\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:00 | Steps: 9556 | Loss: 72.976773\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:00 | Steps: 9557 | Loss: 72.981503\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:00 | Steps: 9558 | Loss: 72.981817\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:01 | Steps: 9559 | Loss: 72.981427\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:01 | Steps: 9560 | Loss: 72.978109\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:01 | Steps: 9561 | Loss: 72.978293\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:01 | Steps: 9562 | Loss: 72.984080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:01 | Steps: 9563 | Loss: 72.987213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:01 | Steps: 9564 | Loss: 72.990023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:01 | Steps: 9565 | Loss: 72.994885\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:01 | Steps: 9566 | Loss: 72.995694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:02 | Steps: 9567 | Loss: 72.997523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:02 | Steps: 9568 | Loss: 72.998995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:02 | Steps: 9569 | Loss: 72.997575\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:02 | Steps: 9570 | Loss: 72.999474\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:02 | Steps: 9571 | Loss: 72.999554\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:02 | Steps: 9572 | Loss: 72.998420\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:02 | Steps: 9573 | Loss: 73.001160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:03 | Steps: 9574 | Loss: 73.000742\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:03 | Steps: 9575 | Loss: 72.998632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:03 | Steps: 9576 | Loss: 73.002633\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:03 | Steps: 9578 | Loss: 73.005021\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:03 | Steps: 9579 | Loss: 73.008499\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:03 | Steps: 9580 | Loss: 73.008792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:04 | Steps: 9581 | Loss: 73.009766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:04 | Steps: 9582 | Loss: 73.010202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:04 | Steps: 9583 | Loss: 73.010799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:04 | Steps: 9584 | Loss: 73.013707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:04 | Steps: 9585 | Loss: 73.020541\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:04 | Steps: 9586 | Loss: 73.024940\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:04 | Steps: 9587 | Loss: 73.031649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:05 | Steps: 9588 | Loss: 73.039061\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:05 | Steps: 9589 | Loss: 73.038757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:05 | Steps: 9590 | Loss: 73.041941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:05 | Steps: 9591 | Loss: 73.044870\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:05 | Steps: 9592 | Loss: 73.046368\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:05 | Steps: 9593 | Loss: 73.047308\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:05 | Steps: 9594 | Loss: 73.050667\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:05 | Steps: 9595 | Loss: 73.055016\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:06 | Steps: 9596 | Loss: 73.059476\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:06 | Steps: 9597 | Loss: 73.061134\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:06 | Steps: 9598 | Loss: 73.060286\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:06 | Steps: 9599 | Loss: 73.061790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:06 | Steps: 9600 | Loss: 73.063587\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:06 | Steps: 9601 | Loss: 73.064739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:06 | Steps: 9602 | Loss: 73.066548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:07 | Steps: 9603 | Loss: 73.068661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:07 | Steps: 9604 | Loss: 73.068102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:07 | Steps: 9605 | Loss: 73.066450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:07 | Steps: 9606 | Loss: 73.066495\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:07 | Steps: 9607 | Loss: 73.065078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:07 | Steps: 9608 | Loss: 73.064341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:07 | Steps: 9609 | Loss: 73.069490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:08 | Steps: 9610 | Loss: 73.073125\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:08 | Steps: 9611 | Loss: 73.072450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:08 | Steps: 9612 | Loss: 73.071276\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:08 | Steps: 9613 | Loss: 73.069269\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:08 | Steps: 9614 | Loss: 73.067310\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:08 | Steps: 9615 | Loss: 73.064913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:08 | Steps: 9616 | Loss: 73.063548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:09 | Steps: 9617 | Loss: 73.066535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:09 | Steps: 9618 | Loss: 73.069091\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:09 | Steps: 9619 | Loss: 73.072718\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:09 | Steps: 9620 | Loss: 73.073774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:09 | Steps: 9621 | Loss: 73.075645\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:09 | Steps: 9622 | Loss: 73.077948\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:09 | Steps: 9623 | Loss: 73.081308\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:10 | Steps: 9624 | Loss: 73.081871\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:10 | Steps: 9625 | Loss: 73.082281\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:10 | Steps: 9626 | Loss: 73.083573\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:10 | Steps: 9627 | Loss: 73.083455\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:10 | Steps: 9628 | Loss: 73.083554\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:10 | Steps: 9629 | Loss: 73.083913\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:10 | Steps: 9630 | Loss: 73.086729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:11 | Steps: 9631 | Loss: 73.089895\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:11 | Steps: 9632 | Loss: 73.088906\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:11 | Steps: 9633 | Loss: 73.088382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:11 | Steps: 9634 | Loss: 73.089213\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:11 | Steps: 9635 | Loss: 73.091792\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:11 | Steps: 9636 | Loss: 73.091842\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:11 | Steps: 9637 | Loss: 73.093026\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:12 | Steps: 9638 | Loss: 73.092717\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:12 | Steps: 9639 | Loss: 73.098264\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:12 | Steps: 9640 | Loss: 73.103098\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:12 | Steps: 9641 | Loss: 73.104996\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:12 | Steps: 9642 | Loss: 73.111858\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:12 | Steps: 9643 | Loss: 73.113714\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:12 | Steps: 9644 | Loss: 73.115232\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:13 | Steps: 9645 | Loss: 73.114755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:13 | Steps: 9646 | Loss: 73.114710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:13 | Steps: 9647 | Loss: 73.115911\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:13 | Steps: 9648 | Loss: 73.119305\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:13 | Steps: 9649 | Loss: 73.119351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:13 | Steps: 9650 | Loss: 73.117909\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:13 | Steps: 9651 | Loss: 73.113874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:14 | Steps: 9652 | Loss: 73.116738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:14 | Steps: 9653 | Loss: 73.115149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:14 | Steps: 9654 | Loss: 73.115355\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:14 | Steps: 9655 | Loss: 73.116547\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:14 | Steps: 9656 | Loss: 73.118543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:14 | Steps: 9657 | Loss: 73.118685\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:14 | Steps: 9658 | Loss: 73.117091\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:15 | Steps: 9659 | Loss: 73.120169\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:15 | Steps: 9660 | Loss: 73.123341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:15 | Steps: 9661 | Loss: 73.125846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:15 | Steps: 9662 | Loss: 73.132771\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:15 | Steps: 9663 | Loss: 73.131062\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:15 | Steps: 9664 | Loss: 73.133148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:15 | Steps: 9665 | Loss: 73.134946\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:16 | Steps: 9666 | Loss: 73.137917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:16 | Steps: 9667 | Loss: 73.140124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:16 | Steps: 9668 | Loss: 73.141866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:16 | Steps: 9669 | Loss: 73.141739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:16 | Steps: 9670 | Loss: 73.142434\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:16 | Steps: 9671 | Loss: 73.142153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:16 | Steps: 9672 | Loss: 73.142639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:17 | Steps: 9673 | Loss: 73.146154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:17 | Steps: 9674 | Loss: 73.148995\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:17 | Steps: 9675 | Loss: 73.153133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:17 | Steps: 9676 | Loss: 73.160945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:17 | Steps: 9677 | Loss: 73.164177\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:17 | Steps: 9678 | Loss: 73.171454\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:17 | Steps: 9679 | Loss: 73.170100\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:18 | Steps: 9680 | Loss: 73.169600\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:18 | Steps: 9681 | Loss: 73.170571\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:18 | Steps: 9682 | Loss: 73.173625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:18 | Steps: 9683 | Loss: 73.176499\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:18 | Steps: 9684 | Loss: 73.184418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:18 | Steps: 9685 | Loss: 73.191411\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:18 | Steps: 9686 | Loss: 73.189738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:19 | Steps: 9687 | Loss: 73.194596\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:19 | Steps: 9688 | Loss: 73.195790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:19 | Steps: 9689 | Loss: 73.196224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:19 | Steps: 9690 | Loss: 73.195386\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:19 | Steps: 9691 | Loss: 73.193571\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:19 | Steps: 9692 | Loss: 73.194612\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:19 | Steps: 9693 | Loss: 73.195907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:20 | Steps: 9694 | Loss: 73.202905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:20 | Steps: 9695 | Loss: 73.200509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:20 | Steps: 9696 | Loss: 73.200787\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:20 | Steps: 9697 | Loss: 73.201845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:20 | Steps: 9698 | Loss: 73.205089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:20 | Steps: 9699 | Loss: 73.205984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:20 | Steps: 9700 | Loss: 73.209907\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:21 | Steps: 9701 | Loss: 73.211794\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:21 | Steps: 9702 | Loss: 73.216394\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:21 | Steps: 9703 | Loss: 73.219432\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:21 | Steps: 9704 | Loss: 73.220077\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:21 | Steps: 9705 | Loss: 73.222251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:21 | Steps: 9706 | Loss: 73.222838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:21 | Steps: 9707 | Loss: 73.224238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:22 | Steps: 9708 | Loss: 73.222593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:22 | Steps: 9709 | Loss: 73.220063\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:22 | Steps: 9710 | Loss: 73.220285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:22 | Steps: 9711 | Loss: 73.224468\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:22 | Steps: 9712 | Loss: 73.228560\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:22 | Steps: 9713 | Loss: 73.231388\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:22 | Steps: 9714 | Loss: 73.235740\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:23 | Steps: 9715 | Loss: 73.237617\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:23 | Steps: 9716 | Loss: 73.239021\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:23 | Steps: 9717 | Loss: 73.241949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:23 | Steps: 9718 | Loss: 73.241804\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:23 | Steps: 9719 | Loss: 73.240412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:23 | Steps: 9720 | Loss: 73.243755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:24 | Steps: 9721 | Loss: 73.245113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:24 | Steps: 9722 | Loss: 73.245276\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:24 | Steps: 9723 | Loss: 73.245963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:24 | Steps: 9724 | Loss: 73.249255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:24 | Steps: 9725 | Loss: 73.254370\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:24 | Steps: 9726 | Loss: 73.255012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:24 | Steps: 9727 | Loss: 73.255157\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:24 | Steps: 9728 | Loss: 73.255411\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:25 | Steps: 9729 | Loss: 73.259402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:25 | Steps: 9730 | Loss: 73.262485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:25 | Steps: 9731 | Loss: 73.260558\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:25 | Steps: 9732 | Loss: 73.260971\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:25 | Steps: 9733 | Loss: 73.261376\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:25 | Steps: 9734 | Loss: 73.263089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:25 | Steps: 9735 | Loss: 73.263096\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:26 | Steps: 9736 | Loss: 73.262295\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:26 | Steps: 9737 | Loss: 73.263227\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:26 | Steps: 9738 | Loss: 73.262037\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:26 | Steps: 9739 | Loss: 73.263754\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:26 | Steps: 9740 | Loss: 73.266693\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:26 | Steps: 9741 | Loss: 73.267178\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:27 | Steps: 9742 | Loss: 73.270312\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:27 | Steps: 9743 | Loss: 73.279475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:27 | Steps: 9744 | Loss: 73.283553\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:27 | Steps: 9745 | Loss: 73.284540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:27 | Steps: 9746 | Loss: 73.292201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:27 | Steps: 9747 | Loss: 73.293848\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:27 | Steps: 9748 | Loss: 73.296232\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:28 | Steps: 9749 | Loss: 73.298346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:28 | Steps: 9750 | Loss: 73.299328\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:28 | Steps: 9751 | Loss: 73.303017\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:28 | Steps: 9752 | Loss: 73.306092\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:28 | Steps: 9753 | Loss: 73.312425\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:28 | Steps: 9754 | Loss: 73.310973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:28 | Steps: 9755 | Loss: 73.312470\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:29 | Steps: 9756 | Loss: 73.313993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:29 | Steps: 9757 | Loss: 73.317144\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:29 | Steps: 9758 | Loss: 73.320670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:29 | Steps: 9759 | Loss: 73.323906\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:29 | Steps: 9760 | Loss: 73.322493\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:29 | Steps: 9761 | Loss: 73.325592\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:29 | Steps: 9762 | Loss: 73.326696\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:30 | Steps: 9763 | Loss: 73.328610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:30 | Steps: 9764 | Loss: 73.330615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:30 | Steps: 9765 | Loss: 73.330315\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:30 | Steps: 9766 | Loss: 73.331359\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:30 | Steps: 9767 | Loss: 73.328976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:30 | Steps: 9768 | Loss: 73.329556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:30 | Steps: 9769 | Loss: 73.329381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:31 | Steps: 9770 | Loss: 73.333382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:31 | Steps: 9771 | Loss: 73.332611\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:31 | Steps: 9772 | Loss: 73.332541\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:31 | Steps: 9773 | Loss: 73.336920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:31 | Steps: 9774 | Loss: 73.337117\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:31 | Steps: 9775 | Loss: 73.338584\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:31 | Steps: 9776 | Loss: 73.343482\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:32 | Steps: 9777 | Loss: 73.343782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:32 | Steps: 9778 | Loss: 73.344374\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:32 | Steps: 9779 | Loss: 73.343951\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:32 | Steps: 9780 | Loss: 73.347719\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:32 | Steps: 9781 | Loss: 73.347901\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:32 | Steps: 9782 | Loss: 73.347773\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:32 | Steps: 9783 | Loss: 73.348258\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:33 | Steps: 9784 | Loss: 73.349604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:33 | Steps: 9785 | Loss: 73.350813\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:33 | Steps: 9786 | Loss: 73.355270\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:33 | Steps: 9787 | Loss: 73.358067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:33 | Steps: 9788 | Loss: 73.365486\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:33 | Steps: 9789 | Loss: 73.367675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:33 | Steps: 9790 | Loss: 73.366071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:34 | Steps: 9791 | Loss: 73.366096\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:34 | Steps: 9792 | Loss: 73.368926\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:34 | Steps: 9793 | Loss: 73.371763\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:34 | Steps: 9794 | Loss: 73.375701\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:34 | Steps: 9795 | Loss: 73.380055\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:34 | Steps: 9796 | Loss: 73.379814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:34 | Steps: 9797 | Loss: 73.380604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:35 | Steps: 9798 | Loss: 73.379717\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:35 | Steps: 9799 | Loss: 73.378973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:35 | Steps: 9800 | Loss: 73.384041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:35 | Steps: 9801 | Loss: 73.386708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:35 | Steps: 9802 | Loss: 73.389739\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:35 | Steps: 9803 | Loss: 73.390449\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:35 | Steps: 9804 | Loss: 73.389509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:36 | Steps: 9805 | Loss: 73.389445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:36 | Steps: 9806 | Loss: 73.391564\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:36 | Steps: 9807 | Loss: 73.392788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:36 | Steps: 9808 | Loss: 73.394124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:36 | Steps: 9809 | Loss: 73.400336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:36 | Steps: 9810 | Loss: 73.402067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:37 | Steps: 9811 | Loss: 73.402965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:37 | Steps: 9812 | Loss: 73.403777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:37 | Steps: 9813 | Loss: 73.405686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:37 | Steps: 9814 | Loss: 73.405436\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:37 | Steps: 9815 | Loss: 73.407149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:37 | Steps: 9816 | Loss: 73.410156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:37 | Steps: 9817 | Loss: 73.412777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:38 | Steps: 9818 | Loss: 73.420133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:38 | Steps: 9819 | Loss: 73.420947\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:38 | Steps: 9820 | Loss: 73.423719\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:38 | Steps: 9821 | Loss: 73.429618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:38 | Steps: 9822 | Loss: 73.433882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:38 | Steps: 9823 | Loss: 73.434778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:38 | Steps: 9824 | Loss: 73.439075\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:39 | Steps: 9825 | Loss: 73.441548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:39 | Steps: 9826 | Loss: 73.444072\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:39 | Steps: 9827 | Loss: 73.443603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:39 | Steps: 9828 | Loss: 73.441258\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:39 | Steps: 9829 | Loss: 73.442056\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:39 | Steps: 9830 | Loss: 73.444111\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:39 | Steps: 9831 | Loss: 73.443958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:40 | Steps: 9832 | Loss: 73.446853\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:40 | Steps: 9833 | Loss: 73.449664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:40 | Steps: 9834 | Loss: 73.450947\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:40 | Steps: 9835 | Loss: 73.449859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:40 | Steps: 9836 | Loss: 73.453699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:40 | Steps: 9837 | Loss: 73.453847\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:40 | Steps: 9838 | Loss: 73.453899\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:41 | Steps: 9839 | Loss: 73.456624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:41 | Steps: 9840 | Loss: 73.454535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:41 | Steps: 9841 | Loss: 73.456435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:41 | Steps: 9842 | Loss: 73.459712\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:41 | Steps: 9843 | Loss: 73.462460\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:41 | Steps: 9844 | Loss: 73.463469\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:41 | Steps: 9845 | Loss: 73.465788\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:42 | Steps: 9846 | Loss: 73.466564\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:42 | Steps: 9847 | Loss: 73.467294\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:42 | Steps: 9848 | Loss: 73.470504\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:42 | Steps: 9849 | Loss: 73.470007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:42 | Steps: 9850 | Loss: 73.470814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:42 | Steps: 9851 | Loss: 73.472014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:42 | Steps: 9852 | Loss: 73.473118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:43 | Steps: 9853 | Loss: 73.473051\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:43 | Steps: 9854 | Loss: 73.474035\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:43 | Steps: 9855 | Loss: 73.474357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:43 | Steps: 9856 | Loss: 73.475485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:43 | Steps: 9857 | Loss: 73.475397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:43 | Steps: 9858 | Loss: 73.477993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:43 | Steps: 9859 | Loss: 73.478979\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:44 | Steps: 9860 | Loss: 73.480944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:44 | Steps: 9861 | Loss: 73.484002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:44 | Steps: 9862 | Loss: 73.492303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:44 | Steps: 9863 | Loss: 73.496107\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:44 | Steps: 9864 | Loss: 73.496820\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:44 | Steps: 9865 | Loss: 73.499640\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:45 | Steps: 9866 | Loss: 73.498544\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:45 | Steps: 9867 | Loss: 73.500528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:45 | Steps: 9868 | Loss: 73.500186\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:45 | Steps: 9869 | Loss: 73.501970\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:45 | Steps: 9870 | Loss: 73.504925\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:45 | Steps: 9871 | Loss: 73.505762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:45 | Steps: 9872 | Loss: 73.507880\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:46 | Steps: 9873 | Loss: 73.510744\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:46 | Steps: 9874 | Loss: 73.514697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:46 | Steps: 9875 | Loss: 73.516905\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:46 | Steps: 9876 | Loss: 73.521163\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:46 | Steps: 9877 | Loss: 73.523308\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:46 | Steps: 9878 | Loss: 73.525505\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:46 | Steps: 9879 | Loss: 73.526961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:47 | Steps: 9880 | Loss: 73.526093\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:47 | Steps: 9881 | Loss: 73.525370\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:47 | Steps: 9882 | Loss: 73.524036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:47 | Steps: 9883 | Loss: 73.524566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:47 | Steps: 9884 | Loss: 73.525384\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:47 | Steps: 9885 | Loss: 73.528597\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:47 | Steps: 9886 | Loss: 73.529533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:48 | Steps: 9887 | Loss: 73.529484\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:48 | Steps: 9888 | Loss: 73.527721\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:48 | Steps: 9889 | Loss: 73.525301\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:48 | Steps: 9890 | Loss: 73.526395\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:48 | Steps: 9891 | Loss: 73.524686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:48 | Steps: 9892 | Loss: 73.521412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:48 | Steps: 9893 | Loss: 73.520759\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:49 | Steps: 9894 | Loss: 73.520799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:49 | Steps: 9895 | Loss: 73.520620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:49 | Steps: 9896 | Loss: 73.522027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:49 | Steps: 9897 | Loss: 73.523803\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:49 | Steps: 9898 | Loss: 73.525257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:49 | Steps: 9899 | Loss: 73.529814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:49 | Steps: 9900 | Loss: 73.534175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:50 | Steps: 9901 | Loss: 73.537318\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:50 | Steps: 9902 | Loss: 73.538794\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:50 | Steps: 9903 | Loss: 73.537651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:50 | Steps: 9904 | Loss: 73.538769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:50 | Steps: 9905 | Loss: 73.538916\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:50 | Steps: 9906 | Loss: 73.538370\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:51 | Steps: 9907 | Loss: 73.541144\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:51 | Steps: 9908 | Loss: 73.543777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:51 | Steps: 9909 | Loss: 73.544494\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:51 | Steps: 9910 | Loss: 73.548384\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:51 | Steps: 9911 | Loss: 73.548845\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:51 | Steps: 9912 | Loss: 73.547873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:51 | Steps: 9913 | Loss: 73.548487\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:52 | Steps: 9914 | Loss: 73.552381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:52 | Steps: 9915 | Loss: 73.552259\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:52 | Steps: 9916 | Loss: 73.554750\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:52 | Steps: 9917 | Loss: 73.556517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:52 | Steps: 9918 | Loss: 73.560292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:52 | Steps: 9919 | Loss: 73.560670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:52 | Steps: 9920 | Loss: 73.560726\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:53 | Steps: 9921 | Loss: 73.557797\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:53 | Steps: 9922 | Loss: 73.562260\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:53 | Steps: 9923 | Loss: 73.561442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:53 | Steps: 9924 | Loss: 73.562053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:53 | Steps: 9925 | Loss: 73.562469\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:53 | Steps: 9926 | Loss: 73.563166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:53 | Steps: 9927 | Loss: 73.564570\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:54 | Steps: 9928 | Loss: 73.565840\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:54 | Steps: 9929 | Loss: 73.568554\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:54 | Steps: 9930 | Loss: 73.568336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:54 | Steps: 9931 | Loss: 73.572248\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:54 | Steps: 9932 | Loss: 73.572618\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:54 | Steps: 9933 | Loss: 73.574933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:55 | Steps: 9934 | Loss: 73.577720\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:55 | Steps: 9935 | Loss: 73.581433\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:55 | Steps: 9936 | Loss: 73.590359\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:55 | Steps: 9937 | Loss: 73.591952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:55 | Steps: 9938 | Loss: 73.597557\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:55 | Steps: 9939 | Loss: 73.598299\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:55 | Steps: 9940 | Loss: 73.600461\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:56 | Steps: 9941 | Loss: 73.599620\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:56 | Steps: 9942 | Loss: 73.601609\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:56 | Steps: 9943 | Loss: 73.603006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:56 | Steps: 9944 | Loss: 73.606933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:56 | Steps: 9945 | Loss: 73.610920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:56 | Steps: 9946 | Loss: 73.611628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:57 | Steps: 9947 | Loss: 73.611922\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:57 | Steps: 9948 | Loss: 73.611772\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:57 | Steps: 9949 | Loss: 73.614635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:57 | Steps: 9950 | Loss: 73.622241\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:57 | Steps: 9951 | Loss: 73.623624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:57 | Steps: 9952 | Loss: 73.626059\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:57 | Steps: 9953 | Loss: 73.625835\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:58 | Steps: 9954 | Loss: 73.623957\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:58 | Steps: 9955 | Loss: 73.622626\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:58 | Steps: 9956 | Loss: 73.624595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:58 | Steps: 9957 | Loss: 73.623012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:58 | Steps: 9958 | Loss: 73.621419\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:58 | Steps: 9959 | Loss: 73.622067\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:59 | Steps: 9960 | Loss: 73.623615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:59 | Steps: 9961 | Loss: 73.627729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:59 | Steps: 9962 | Loss: 73.628415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:59 | Steps: 9963 | Loss: 73.632586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:59 | Steps: 9964 | Loss: 73.634931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:59 | Steps: 9965 | Loss: 73.639136\n",
      "Epoch 1 |   Training | Elapsed Time: 0:16:59 | Steps: 9966 | Loss: 73.639186\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:00 | Steps: 9967 | Loss: 73.640735\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:00 | Steps: 9968 | Loss: 73.639954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:00 | Steps: 9969 | Loss: 73.643723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:00 | Steps: 9970 | Loss: 73.645843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:00 | Steps: 9971 | Loss: 73.645247\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:00 | Steps: 9972 | Loss: 73.644902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:00 | Steps: 9973 | Loss: 73.646773\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:01 | Steps: 9974 | Loss: 73.647722\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:01 | Steps: 9975 | Loss: 73.649897\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:01 | Steps: 9976 | Loss: 73.653704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:01 | Steps: 9977 | Loss: 73.653412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:01 | Steps: 9978 | Loss: 73.652524\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:01 | Steps: 9979 | Loss: 73.655164\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:02 | Steps: 9980 | Loss: 73.655844\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:02 | Steps: 9981 | Loss: 73.657528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:02 | Steps: 9982 | Loss: 73.658721\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:02 | Steps: 9983 | Loss: 73.657576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:02 | Steps: 9984 | Loss: 73.658469\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:02 | Steps: 9985 | Loss: 73.669105\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:02 | Steps: 9986 | Loss: 73.669316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:03 | Steps: 9987 | Loss: 73.669929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:03 | Steps: 9988 | Loss: 73.669512\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:03 | Steps: 9989 | Loss: 73.673036\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:03 | Steps: 9990 | Loss: 73.679039\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:03 | Steps: 9991 | Loss: 73.681124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:03 | Steps: 9992 | Loss: 73.685113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:03 | Steps: 9993 | Loss: 73.687715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:04 | Steps: 9994 | Loss: 73.690844\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:04 | Steps: 9995 | Loss: 73.689763\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:04 | Steps: 9996 | Loss: 73.690795\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:04 | Steps: 9997 | Loss: 73.693819\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:04 | Steps: 9998 | Loss: 73.694923\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:04 | Steps: 9999 | Loss: 73.700713\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:04 | Steps: 10000 | Loss: 73.705423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:05 | Steps: 10001 | Loss: 73.709015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:05 | Steps: 10002 | Loss: 73.714555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:05 | Steps: 10003 | Loss: 73.719784\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:05 | Steps: 10004 | Loss: 73.720054\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:05 | Steps: 10005 | Loss: 73.724117\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:05 | Steps: 10006 | Loss: 73.724402\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:06 | Steps: 10007 | Loss: 73.724057\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:06 | Steps: 10008 | Loss: 73.726628\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:06 | Steps: 10009 | Loss: 73.731799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:06 | Steps: 10010 | Loss: 73.736298\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:06 | Steps: 10011 | Loss: 73.741993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:06 | Steps: 10012 | Loss: 73.744625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:06 | Steps: 10013 | Loss: 73.743300\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:07 | Steps: 10014 | Loss: 73.742595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:07 | Steps: 10015 | Loss: 73.743080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:07 | Steps: 10016 | Loss: 73.745364\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:07 | Steps: 10017 | Loss: 73.746094\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:07 | Steps: 10018 | Loss: 73.745392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:07 | Steps: 10019 | Loss: 73.747517\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:08 | Steps: 10020 | Loss: 73.749045\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:08 | Steps: 10021 | Loss: 73.748645\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:08 | Steps: 10022 | Loss: 73.751535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:08 | Steps: 10023 | Loss: 73.756062\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:08 | Steps: 10024 | Loss: 73.760337\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:08 | Steps: 10025 | Loss: 73.759869\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:08 | Steps: 10026 | Loss: 73.759161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:08 | Steps: 10027 | Loss: 73.761221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:09 | Steps: 10028 | Loss: 73.761881\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:09 | Steps: 10029 | Loss: 73.764811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:09 | Steps: 10030 | Loss: 73.768622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:09 | Steps: 10031 | Loss: 73.774341\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:09 | Steps: 10032 | Loss: 73.774303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:09 | Steps: 10033 | Loss: 73.776285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:10 | Steps: 10034 | Loss: 73.776351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:10 | Steps: 10035 | Loss: 73.780160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:10 | Steps: 10036 | Loss: 73.786355\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:10 | Steps: 10037 | Loss: 73.786949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:10 | Steps: 10038 | Loss: 73.785838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:10 | Steps: 10039 | Loss: 73.791163\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:10 | Steps: 10040 | Loss: 73.796522\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:11 | Steps: 10041 | Loss: 73.796882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:11 | Steps: 10042 | Loss: 73.797198\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:11 | Steps: 10043 | Loss: 73.798154\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:11 | Steps: 10044 | Loss: 73.798401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:11 | Steps: 10045 | Loss: 73.800823\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:11 | Steps: 10046 | Loss: 73.802958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:12 | Steps: 10047 | Loss: 73.804881\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:12 | Steps: 10048 | Loss: 73.806850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:12 | Steps: 10049 | Loss: 73.807608\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:12 | Steps: 10050 | Loss: 73.807058\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:12 | Steps: 10051 | Loss: 73.809996\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:12 | Steps: 10052 | Loss: 73.817083\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:12 | Steps: 10053 | Loss: 73.816568\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:13 | Steps: 10054 | Loss: 73.817589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:13 | Steps: 10055 | Loss: 73.824678\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:13 | Steps: 10056 | Loss: 73.827763\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:13 | Steps: 10057 | Loss: 73.828798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:13 | Steps: 10058 | Loss: 73.828148\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:13 | Steps: 10059 | Loss: 73.830463\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:13 | Steps: 10060 | Loss: 73.832423\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:14 | Steps: 10061 | Loss: 73.834722\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:14 | Steps: 10062 | Loss: 73.836245\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:14 | Steps: 10063 | Loss: 73.835133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:14 | Steps: 10064 | Loss: 73.837530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:14 | Steps: 10065 | Loss: 73.838574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:14 | Steps: 10066 | Loss: 73.839619\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:15 | Steps: 10067 | Loss: 73.841829\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:15 | Steps: 10068 | Loss: 73.844657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:15 | Steps: 10069 | Loss: 73.845127\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:15 | Steps: 10070 | Loss: 73.844946\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:15 | Steps: 10071 | Loss: 73.848986\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:15 | Steps: 10072 | Loss: 73.850428\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:15 | Steps: 10073 | Loss: 73.851265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:16 | Steps: 10074 | Loss: 73.852811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:16 | Steps: 10075 | Loss: 73.855317\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:16 | Steps: 10076 | Loss: 73.859556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:16 | Steps: 10077 | Loss: 73.862069\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:16 | Steps: 10078 | Loss: 73.863259\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:16 | Steps: 10079 | Loss: 73.863412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:17 | Steps: 10080 | Loss: 73.866656\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:17 | Steps: 10081 | Loss: 73.869553\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:17 | Steps: 10082 | Loss: 73.872041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:17 | Steps: 10083 | Loss: 73.872927\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:17 | Steps: 10084 | Loss: 73.872025\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:17 | Steps: 10085 | Loss: 73.871736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:17 | Steps: 10086 | Loss: 73.873920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:18 | Steps: 10087 | Loss: 73.875771\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:18 | Steps: 10088 | Loss: 73.876933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:18 | Steps: 10089 | Loss: 73.888756\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:18 | Steps: 10090 | Loss: 73.891156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:18 | Steps: 10091 | Loss: 73.896304\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:18 | Steps: 10092 | Loss: 73.897129\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:18 | Steps: 10093 | Loss: 73.897183\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:19 | Steps: 10094 | Loss: 73.897381\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:19 | Steps: 10095 | Loss: 73.903172\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:19 | Steps: 10096 | Loss: 73.904542\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:19 | Steps: 10097 | Loss: 73.905471\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:19 | Steps: 10098 | Loss: 73.907219\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:19 | Steps: 10099 | Loss: 73.908542\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:20 | Steps: 10100 | Loss: 73.909887\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:20 | Steps: 10101 | Loss: 73.915010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:20 | Steps: 10102 | Loss: 73.920668\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:20 | Steps: 10103 | Loss: 73.924683\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:20 | Steps: 10104 | Loss: 73.930613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:20 | Steps: 10105 | Loss: 73.934643\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:20 | Steps: 10106 | Loss: 73.937099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:21 | Steps: 10107 | Loss: 73.941813\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:21 | Steps: 10108 | Loss: 73.942215\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:21 | Steps: 10109 | Loss: 73.945090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:21 | Steps: 10110 | Loss: 73.946755\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:21 | Steps: 10111 | Loss: 73.949124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:21 | Steps: 10112 | Loss: 73.951629\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:22 | Steps: 10113 | Loss: 73.953558\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:22 | Steps: 10114 | Loss: 73.951984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:22 | Steps: 10115 | Loss: 73.950176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:22 | Steps: 10116 | Loss: 73.952057\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:22 | Steps: 10117 | Loss: 73.953139\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:22 | Steps: 10118 | Loss: 73.953484\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:22 | Steps: 10119 | Loss: 73.955815\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:23 | Steps: 10120 | Loss: 73.958891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:23 | Steps: 10121 | Loss: 73.958635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:23 | Steps: 10122 | Loss: 73.959890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:23 | Steps: 10123 | Loss: 73.961155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:23 | Steps: 10124 | Loss: 73.963732\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:23 | Steps: 10125 | Loss: 73.963302\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:23 | Steps: 10126 | Loss: 73.965238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:24 | Steps: 10127 | Loss: 73.966343\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:24 | Steps: 10128 | Loss: 73.965894\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:24 | Steps: 10129 | Loss: 73.965955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:24 | Steps: 10130 | Loss: 73.967938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:24 | Steps: 10131 | Loss: 73.969005\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:24 | Steps: 10132 | Loss: 73.971218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:25 | Steps: 10133 | Loss: 73.975541\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:25 | Steps: 10134 | Loss: 73.976937\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:25 | Steps: 10135 | Loss: 73.977864\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:25 | Steps: 10136 | Loss: 73.980446\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:25 | Steps: 10137 | Loss: 73.983950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:25 | Steps: 10138 | Loss: 73.986337\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:25 | Steps: 10139 | Loss: 73.989524\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:26 | Steps: 10140 | Loss: 73.992538\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:26 | Steps: 10141 | Loss: 73.994677\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:26 | Steps: 10142 | Loss: 73.998291\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:26 | Steps: 10143 | Loss: 73.995831\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:26 | Steps: 10144 | Loss: 73.992967\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:26 | Steps: 10145 | Loss: 73.998310\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:26 | Steps: 10146 | Loss: 74.003599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:27 | Steps: 10147 | Loss: 74.004257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:27 | Steps: 10148 | Loss: 74.007588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:27 | Steps: 10149 | Loss: 74.008568\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:27 | Steps: 10150 | Loss: 74.009461\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:27 | Steps: 10151 | Loss: 74.011830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:27 | Steps: 10152 | Loss: 74.011238\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:28 | Steps: 10153 | Loss: 74.013811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:28 | Steps: 10154 | Loss: 74.020122\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:28 | Steps: 10155 | Loss: 74.021909\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:28 | Steps: 10156 | Loss: 74.023180\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:28 | Steps: 10157 | Loss: 74.024070\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:28 | Steps: 10158 | Loss: 74.025021\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:28 | Steps: 10159 | Loss: 74.033712\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:29 | Steps: 10160 | Loss: 74.034910\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:29 | Steps: 10161 | Loss: 74.037147\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:29 | Steps: 10162 | Loss: 74.042799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:29 | Steps: 10163 | Loss: 74.047159\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:29 | Steps: 10164 | Loss: 74.072938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:29 | Steps: 10165 | Loss: 74.071965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:30 | Steps: 10166 | Loss: 74.072939\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:30 | Steps: 10167 | Loss: 74.071011\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:30 | Steps: 10168 | Loss: 74.071658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:30 | Steps: 10169 | Loss: 74.075401\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:30 | Steps: 10170 | Loss: 74.073425\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:30 | Steps: 10171 | Loss: 74.072852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:30 | Steps: 10172 | Loss: 74.073332\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:31 | Steps: 10173 | Loss: 74.074033\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:31 | Steps: 10174 | Loss: 74.076161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:31 | Steps: 10175 | Loss: 74.077429\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:31 | Steps: 10176 | Loss: 74.081299\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:31 | Steps: 10177 | Loss: 74.082604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:31 | Steps: 10178 | Loss: 74.085182\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:31 | Steps: 10179 | Loss: 74.088952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:32 | Steps: 10180 | Loss: 74.097336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:32 | Steps: 10181 | Loss: 74.105080\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:32 | Steps: 10182 | Loss: 74.105943\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:32 | Steps: 10183 | Loss: 74.106950\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:32 | Steps: 10184 | Loss: 74.109221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:32 | Steps: 10185 | Loss: 74.110412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:33 | Steps: 10186 | Loss: 74.113686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:33 | Steps: 10187 | Loss: 74.117547\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:33 | Steps: 10188 | Loss: 74.118176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:33 | Steps: 10189 | Loss: 74.117906\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:33 | Steps: 10190 | Loss: 74.115287\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:33 | Steps: 10191 | Loss: 74.117769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:33 | Steps: 10192 | Loss: 74.117442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:34 | Steps: 10193 | Loss: 74.120091\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:34 | Steps: 10194 | Loss: 74.121829\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:34 | Steps: 10195 | Loss: 74.122672\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:34 | Steps: 10196 | Loss: 74.124380\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:34 | Steps: 10197 | Loss: 74.126195\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:34 | Steps: 10198 | Loss: 74.126149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:35 | Steps: 10199 | Loss: 74.129265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:35 | Steps: 10200 | Loss: 74.131516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:35 | Steps: 10201 | Loss: 74.135839\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:35 | Steps: 10202 | Loss: 74.137435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:35 | Steps: 10203 | Loss: 74.141978\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:35 | Steps: 10204 | Loss: 74.142477\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:35 | Steps: 10205 | Loss: 74.143986\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:36 | Steps: 10206 | Loss: 74.144225\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:36 | Steps: 10207 | Loss: 74.150176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:36 | Steps: 10208 | Loss: 74.154227\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:36 | Steps: 10209 | Loss: 74.160650\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:36 | Steps: 10210 | Loss: 74.161360\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:36 | Steps: 10211 | Loss: 74.161078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:37 | Steps: 10212 | Loss: 74.162257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:37 | Steps: 10213 | Loss: 74.166964\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:37 | Steps: 10214 | Loss: 74.165391\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:37 | Steps: 10215 | Loss: 74.165576\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:37 | Steps: 10216 | Loss: 74.165783\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:37 | Steps: 10217 | Loss: 74.164548\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:37 | Steps: 10218 | Loss: 74.166206\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:38 | Steps: 10219 | Loss: 74.164850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:38 | Steps: 10220 | Loss: 74.163733\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:38 | Steps: 10221 | Loss: 74.164854\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:38 | Steps: 10222 | Loss: 74.165234\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:38 | Steps: 10223 | Loss: 74.167099\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:38 | Steps: 10224 | Loss: 74.170285\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:38 | Steps: 10225 | Loss: 74.172654\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:39 | Steps: 10226 | Loss: 74.175000\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:39 | Steps: 10227 | Loss: 74.175912\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:39 | Steps: 10228 | Loss: 74.174888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:39 | Steps: 10229 | Loss: 74.176721\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:39 | Steps: 10230 | Loss: 74.179489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:39 | Steps: 10231 | Loss: 74.178168\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:40 | Steps: 10232 | Loss: 74.183984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:40 | Steps: 10233 | Loss: 74.183457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:40 | Steps: 10234 | Loss: 74.186498\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:40 | Steps: 10235 | Loss: 74.188332\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:40 | Steps: 10236 | Loss: 74.189255\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:40 | Steps: 10237 | Loss: 74.191477\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:41 | Steps: 10238 | Loss: 74.193015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:41 | Steps: 10239 | Loss: 74.190614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:41 | Steps: 10240 | Loss: 74.190525\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:41 | Steps: 10241 | Loss: 74.191071\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:41 | Steps: 10242 | Loss: 74.193048\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:41 | Steps: 10243 | Loss: 74.193394\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:41 | Steps: 10244 | Loss: 74.194327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:42 | Steps: 10245 | Loss: 74.195442\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:42 | Steps: 10246 | Loss: 74.198005\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:42 | Steps: 10247 | Loss: 74.199762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:42 | Steps: 10248 | Loss: 74.205137\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:42 | Steps: 10249 | Loss: 74.206274\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:42 | Steps: 10250 | Loss: 74.209610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:43 | Steps: 10251 | Loss: 74.211031\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:43 | Steps: 10252 | Loss: 74.212053\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:43 | Steps: 10253 | Loss: 74.214988\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:43 | Steps: 10254 | Loss: 74.215865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:43 | Steps: 10255 | Loss: 74.217124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:43 | Steps: 10256 | Loss: 74.221962\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:43 | Steps: 10257 | Loss: 74.227024\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:44 | Steps: 10258 | Loss: 74.233346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:44 | Steps: 10259 | Loss: 74.234684\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:44 | Steps: 10260 | Loss: 74.238768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:44 | Steps: 10261 | Loss: 74.238182\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:44 | Steps: 10262 | Loss: 74.239407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:44 | Steps: 10263 | Loss: 74.243007\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:45 | Steps: 10264 | Loss: 74.243096\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:45 | Steps: 10265 | Loss: 74.240852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:45 | Steps: 10266 | Loss: 74.243430\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:45 | Steps: 10267 | Loss: 74.244952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:45 | Steps: 10268 | Loss: 74.246444\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:45 | Steps: 10269 | Loss: 74.248835\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:45 | Steps: 10270 | Loss: 74.249528\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:46 | Steps: 10271 | Loss: 74.248597\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:46 | Steps: 10272 | Loss: 74.251715\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:46 | Steps: 10273 | Loss: 74.252697\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:46 | Steps: 10274 | Loss: 74.253852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:46 | Steps: 10275 | Loss: 74.256177\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:46 | Steps: 10276 | Loss: 74.256783\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:47 | Steps: 10277 | Loss: 74.257614\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:47 | Steps: 10278 | Loss: 74.260508\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:47 | Steps: 10279 | Loss: 74.266662\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:47 | Steps: 10280 | Loss: 74.270072\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:47 | Steps: 10281 | Loss: 74.268707\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:47 | Steps: 10282 | Loss: 74.270919\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:47 | Steps: 10283 | Loss: 74.270963\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:48 | Steps: 10284 | Loss: 74.270616\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:48 | Steps: 10285 | Loss: 74.273493\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:48 | Steps: 10286 | Loss: 74.273777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:48 | Steps: 10287 | Loss: 74.278499\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:48 | Steps: 10288 | Loss: 74.280187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:48 | Steps: 10289 | Loss: 74.279118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:49 | Steps: 10290 | Loss: 74.280574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:49 | Steps: 10291 | Loss: 74.282151\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:49 | Steps: 10292 | Loss: 74.287488\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:49 | Steps: 10293 | Loss: 74.287909\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:49 | Steps: 10294 | Loss: 74.288849\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:49 | Steps: 10295 | Loss: 74.293233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:49 | Steps: 10296 | Loss: 74.295972\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:50 | Steps: 10297 | Loss: 74.293768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:50 | Steps: 10298 | Loss: 74.293642\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:50 | Steps: 10299 | Loss: 74.292822\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:50 | Steps: 10300 | Loss: 74.293884\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:50 | Steps: 10301 | Loss: 74.293087\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:50 | Steps: 10302 | Loss: 74.290836\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:51 | Steps: 10303 | Loss: 74.289250\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:51 | Steps: 10304 | Loss: 74.289488\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:51 | Steps: 10305 | Loss: 74.295491\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:51 | Steps: 10306 | Loss: 74.295709\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:51 | Steps: 10307 | Loss: 74.294360\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:51 | Steps: 10308 | Loss: 74.295244\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:52 | Steps: 10309 | Loss: 74.297062\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:52 | Steps: 10310 | Loss: 74.297211\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:52 | Steps: 10311 | Loss: 74.299445\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:52 | Steps: 10312 | Loss: 74.299480\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:52 | Steps: 10313 | Loss: 74.299335\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:52 | Steps: 10314 | Loss: 74.300032\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:52 | Steps: 10315 | Loss: 74.302307\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:53 | Steps: 10316 | Loss: 74.302418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:53 | Steps: 10317 | Loss: 74.302917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:53 | Steps: 10318 | Loss: 74.304958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:53 | Steps: 10319 | Loss: 74.306883\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:53 | Steps: 10320 | Loss: 74.308412\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:53 | Steps: 10321 | Loss: 74.314282\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:54 | Steps: 10322 | Loss: 74.314762\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:54 | Steps: 10323 | Loss: 74.314424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:54 | Steps: 10324 | Loss: 74.317497\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:54 | Steps: 10325 | Loss: 74.318286\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:54 | Steps: 10326 | Loss: 74.316380\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:54 | Steps: 10327 | Loss: 74.315771\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:54 | Steps: 10328 | Loss: 74.316520\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:55 | Steps: 10329 | Loss: 74.320113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:55 | Steps: 10330 | Loss: 74.322458\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:55 | Steps: 10331 | Loss: 74.322748\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:55 | Steps: 10332 | Loss: 74.321966\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:55 | Steps: 10333 | Loss: 74.327023\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:55 | Steps: 10334 | Loss: 74.332311\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:56 | Steps: 10335 | Loss: 74.337635\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:56 | Steps: 10336 | Loss: 74.339944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:56 | Steps: 10337 | Loss: 74.342689\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:56 | Steps: 10338 | Loss: 74.342807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:56 | Steps: 10339 | Loss: 74.343951\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:56 | Steps: 10340 | Loss: 74.347835\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:56 | Steps: 10341 | Loss: 74.353161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:57 | Steps: 10342 | Loss: 74.358850\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:57 | Steps: 10343 | Loss: 74.364767\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:57 | Steps: 10344 | Loss: 74.370790\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:57 | Steps: 10345 | Loss: 74.375268\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:57 | Steps: 10346 | Loss: 74.379777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:57 | Steps: 10347 | Loss: 74.380491\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:58 | Steps: 10348 | Loss: 74.385201\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:58 | Steps: 10349 | Loss: 74.385815\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:58 | Steps: 10350 | Loss: 74.388988\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:58 | Steps: 10351 | Loss: 74.391113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:58 | Steps: 10352 | Loss: 74.394598\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:58 | Steps: 10353 | Loss: 74.392192\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:58 | Steps: 10354 | Loss: 74.390593\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:59 | Steps: 10355 | Loss: 74.393124\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:59 | Steps: 10356 | Loss: 74.392550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:59 | Steps: 10357 | Loss: 74.393609\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:59 | Steps: 10358 | Loss: 74.395703\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:59 | Steps: 10359 | Loss: 74.398860\n",
      "Epoch 1 |   Training | Elapsed Time: 0:17:59 | Steps: 10360 | Loss: 74.399447\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:00 | Steps: 10361 | Loss: 74.401949\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:00 | Steps: 10362 | Loss: 74.401267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:00 | Steps: 10363 | Loss: 74.404606\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:00 | Steps: 10364 | Loss: 74.412485\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:00 | Steps: 10365 | Loss: 74.416346\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:00 | Steps: 10366 | Loss: 74.418638\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:00 | Steps: 10367 | Loss: 74.423512\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:01 | Steps: 10368 | Loss: 74.423878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:01 | Steps: 10369 | Loss: 74.425974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:01 | Steps: 10370 | Loss: 74.426969\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:01 | Steps: 10371 | Loss: 74.427538\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:01 | Steps: 10372 | Loss: 74.430063\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:01 | Steps: 10373 | Loss: 74.434356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:02 | Steps: 10374 | Loss: 74.435506\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:02 | Steps: 10375 | Loss: 74.439373\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:02 | Steps: 10376 | Loss: 74.439822\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:02 | Steps: 10377 | Loss: 74.442865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:02 | Steps: 10378 | Loss: 74.442988\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:02 | Steps: 10379 | Loss: 74.445582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:03 | Steps: 10380 | Loss: 74.446519\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:03 | Steps: 10381 | Loss: 74.447738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:03 | Steps: 10382 | Loss: 74.449367\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:03 | Steps: 10383 | Loss: 74.450530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:03 | Steps: 10384 | Loss: 74.453821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:03 | Steps: 10385 | Loss: 74.456953\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:03 | Steps: 10386 | Loss: 74.464461\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:04 | Steps: 10387 | Loss: 74.465874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:04 | Steps: 10388 | Loss: 74.466974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:04 | Steps: 10389 | Loss: 74.471306\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:04 | Steps: 10390 | Loss: 74.477472\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:04 | Steps: 10391 | Loss: 74.477325\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:04 | Steps: 10392 | Loss: 74.476432\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:05 | Steps: 10393 | Loss: 74.480746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:05 | Steps: 10394 | Loss: 74.479919\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:05 | Steps: 10395 | Loss: 74.479297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:05 | Steps: 10396 | Loss: 74.480586\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:05 | Steps: 10397 | Loss: 74.484869\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:05 | Steps: 10398 | Loss: 74.485582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:06 | Steps: 10399 | Loss: 74.487236\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:06 | Steps: 10400 | Loss: 74.490686\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:06 | Steps: 10401 | Loss: 74.494089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:06 | Steps: 10402 | Loss: 74.497573\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:06 | Steps: 10403 | Loss: 74.499888\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:06 | Steps: 10404 | Loss: 74.500615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:07 | Steps: 10405 | Loss: 74.500568\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:07 | Steps: 10406 | Loss: 74.498224\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:07 | Steps: 10407 | Loss: 74.497893\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:07 | Steps: 10408 | Loss: 74.499952\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:07 | Steps: 10409 | Loss: 74.503646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:07 | Steps: 10410 | Loss: 74.508814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:07 | Steps: 10411 | Loss: 74.510821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:08 | Steps: 10412 | Loss: 74.511018\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:08 | Steps: 10413 | Loss: 74.513806\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:08 | Steps: 10414 | Loss: 74.517222\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:08 | Steps: 10415 | Loss: 74.521958\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:08 | Steps: 10416 | Loss: 74.527014\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:08 | Steps: 10417 | Loss: 74.527536\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:09 | Steps: 10418 | Loss: 74.527766\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:09 | Steps: 10419 | Loss: 74.531044\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:09 | Steps: 10420 | Loss: 74.534692\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:09 | Steps: 10421 | Loss: 74.537405\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:09 | Steps: 10422 | Loss: 74.537329\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:09 | Steps: 10423 | Loss: 74.537117\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:10 | Steps: 10424 | Loss: 74.539699\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:10 | Steps: 10425 | Loss: 74.540931\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:10 | Steps: 10426 | Loss: 74.543807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:10 | Steps: 10427 | Loss: 74.544688\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:10 | Steps: 10428 | Loss: 74.546981\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:10 | Steps: 10429 | Loss: 74.547865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:10 | Steps: 10430 | Loss: 74.552003\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:11 | Steps: 10431 | Loss: 74.553582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:11 | Steps: 10432 | Loss: 74.554664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:11 | Steps: 10433 | Loss: 74.556769\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:11 | Steps: 10434 | Loss: 74.558644\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:11 | Steps: 10435 | Loss: 74.562085\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:11 | Steps: 10436 | Loss: 74.564624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:12 | Steps: 10437 | Loss: 74.565240\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:12 | Steps: 10438 | Loss: 74.565774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:12 | Steps: 10439 | Loss: 74.564481\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:12 | Steps: 10440 | Loss: 74.564730\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:12 | Steps: 10441 | Loss: 74.565127\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:12 | Steps: 10442 | Loss: 74.566183\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:13 | Steps: 10443 | Loss: 74.571105\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:13 | Steps: 10444 | Loss: 74.574741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:13 | Steps: 10445 | Loss: 74.576079\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:13 | Steps: 10446 | Loss: 74.580504\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:13 | Steps: 10447 | Loss: 74.581130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:13 | Steps: 10448 | Loss: 74.583959\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:13 | Steps: 10449 | Loss: 74.586882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:14 | Steps: 10450 | Loss: 74.591013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:14 | Steps: 10451 | Loss: 74.598426\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:14 | Steps: 10452 | Loss: 74.601169\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:14 | Steps: 10453 | Loss: 74.601010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:14 | Steps: 10454 | Loss: 74.601212\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:14 | Steps: 10455 | Loss: 74.606230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:15 | Steps: 10456 | Loss: 74.607194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:15 | Steps: 10457 | Loss: 74.612872\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:15 | Steps: 10458 | Loss: 74.613156\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:15 | Steps: 10459 | Loss: 74.612277\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:15 | Steps: 10460 | Loss: 74.611843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:15 | Steps: 10461 | Loss: 74.611734\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:16 | Steps: 10462 | Loss: 74.612056\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:16 | Steps: 10463 | Loss: 74.615194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:16 | Steps: 10464 | Loss: 74.616841\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:16 | Steps: 10465 | Loss: 74.620523\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:16 | Steps: 10466 | Loss: 74.622829\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:16 | Steps: 10467 | Loss: 74.622459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:16 | Steps: 10468 | Loss: 74.623266\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:17 | Steps: 10469 | Loss: 74.626622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:17 | Steps: 10470 | Loss: 74.630290\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:17 | Steps: 10471 | Loss: 74.631560\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:17 | Steps: 10472 | Loss: 74.633796\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:17 | Steps: 10473 | Loss: 74.639847\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:17 | Steps: 10474 | Loss: 74.640409\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:18 | Steps: 10475 | Loss: 74.639807\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:18 | Steps: 10476 | Loss: 74.640782\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:18 | Steps: 10477 | Loss: 74.641407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:18 | Steps: 10478 | Loss: 74.641006\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:18 | Steps: 10479 | Loss: 74.641543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:18 | Steps: 10480 | Loss: 74.647013\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:19 | Steps: 10481 | Loss: 74.648613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:19 | Steps: 10482 | Loss: 74.649937\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:19 | Steps: 10483 | Loss: 74.651832\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:19 | Steps: 10484 | Loss: 74.655720\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:19 | Steps: 10485 | Loss: 74.661889\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:19 | Steps: 10486 | Loss: 74.669142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:20 | Steps: 10487 | Loss: 74.669327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:20 | Steps: 10488 | Loss: 74.669325\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:20 | Steps: 10489 | Loss: 74.670587\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:20 | Steps: 10490 | Loss: 74.675230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:20 | Steps: 10491 | Loss: 74.677211\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:20 | Steps: 10492 | Loss: 74.677634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:20 | Steps: 10493 | Loss: 74.675786\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:21 | Steps: 10494 | Loss: 74.677385\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:21 | Steps: 10495 | Loss: 74.678954\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:21 | Steps: 10496 | Loss: 74.678196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:21 | Steps: 10497 | Loss: 74.680425\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:21 | Steps: 10498 | Loss: 74.682933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:21 | Steps: 10499 | Loss: 74.683974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:22 | Steps: 10500 | Loss: 74.685901\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:22 | Steps: 10501 | Loss: 74.687223\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:22 | Steps: 10502 | Loss: 74.690890\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:22 | Steps: 10503 | Loss: 74.691632\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:22 | Steps: 10504 | Loss: 74.693091\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:22 | Steps: 10505 | Loss: 74.693254\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:23 | Steps: 10506 | Loss: 74.696877\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:23 | Steps: 10507 | Loss: 74.695649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:23 | Steps: 10508 | Loss: 74.697571\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:23 | Steps: 10509 | Loss: 74.699021\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:23 | Steps: 10510 | Loss: 74.700502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:23 | Steps: 10511 | Loss: 74.702774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:23 | Steps: 10512 | Loss: 74.703956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:24 | Steps: 10513 | Loss: 74.705166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:24 | Steps: 10514 | Loss: 74.707546\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:24 | Steps: 10515 | Loss: 74.707274\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:24 | Steps: 10516 | Loss: 74.707901\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:24 | Steps: 10517 | Loss: 74.710467\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:24 | Steps: 10518 | Loss: 74.714217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:25 | Steps: 10519 | Loss: 74.718705\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:25 | Steps: 10520 | Loss: 74.721847\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:25 | Steps: 10521 | Loss: 74.722106\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:25 | Steps: 10522 | Loss: 74.722879\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:25 | Steps: 10523 | Loss: 74.726609\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:25 | Steps: 10524 | Loss: 74.727145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:26 | Steps: 10525 | Loss: 74.725882\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:26 | Steps: 10526 | Loss: 74.725777\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:26 | Steps: 10527 | Loss: 74.724968\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:26 | Steps: 10528 | Loss: 74.726798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:26 | Steps: 10529 | Loss: 74.729653\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:26 | Steps: 10530 | Loss: 74.730257\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:26 | Steps: 10531 | Loss: 74.735316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:27 | Steps: 10532 | Loss: 74.738838\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:27 | Steps: 10533 | Loss: 74.738925\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:27 | Steps: 10534 | Loss: 74.739811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:27 | Steps: 10535 | Loss: 74.740490\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:27 | Steps: 10536 | Loss: 74.741010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:27 | Steps: 10537 | Loss: 74.742684\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:28 | Steps: 10538 | Loss: 74.743852\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:28 | Steps: 10539 | Loss: 74.748682\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:28 | Steps: 10540 | Loss: 74.750659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:28 | Steps: 10541 | Loss: 74.748663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:28 | Steps: 10542 | Loss: 74.753068\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:28 | Steps: 10543 | Loss: 74.753865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:29 | Steps: 10544 | Loss: 74.756513\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:29 | Steps: 10545 | Loss: 74.762582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:29 | Steps: 10546 | Loss: 74.763206\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:29 | Steps: 10547 | Loss: 74.765615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:29 | Steps: 10548 | Loss: 74.775624\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:29 | Steps: 10549 | Loss: 74.782128\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:30 | Steps: 10550 | Loss: 74.786973\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:30 | Steps: 10551 | Loss: 74.789247\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:30 | Steps: 10552 | Loss: 74.790554\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:30 | Steps: 10553 | Loss: 74.797961\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:30 | Steps: 10554 | Loss: 74.801509\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:30 | Steps: 10555 | Loss: 74.801843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:31 | Steps: 10556 | Loss: 74.802639\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:31 | Steps: 10557 | Loss: 74.802405\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:31 | Steps: 10558 | Loss: 74.803685\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:31 | Steps: 10559 | Loss: 74.806113\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:31 | Steps: 10560 | Loss: 74.807910\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:31 | Steps: 10561 | Loss: 74.810862\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:31 | Steps: 10562 | Loss: 74.811630\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:32 | Steps: 10563 | Loss: 74.814250\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:32 | Steps: 10564 | Loss: 74.814694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:32 | Steps: 10565 | Loss: 74.817202\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:32 | Steps: 10566 | Loss: 74.819761\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:32 | Steps: 10567 | Loss: 74.820778\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:32 | Steps: 10568 | Loss: 74.819974\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:33 | Steps: 10569 | Loss: 74.822844\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:33 | Steps: 10570 | Loss: 74.822885\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:33 | Steps: 10571 | Loss: 74.823356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:33 | Steps: 10572 | Loss: 74.825818\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:33 | Steps: 10573 | Loss: 74.827810\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:33 | Steps: 10574 | Loss: 74.829160\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:34 | Steps: 10575 | Loss: 74.831437\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:34 | Steps: 10576 | Loss: 74.830189\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:34 | Steps: 10577 | Loss: 74.831891\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:34 | Steps: 10578 | Loss: 74.835989\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:34 | Steps: 10579 | Loss: 74.836400\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:34 | Steps: 10580 | Loss: 74.840089\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:35 | Steps: 10581 | Loss: 74.843502\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:35 | Steps: 10582 | Loss: 74.844261\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:35 | Steps: 10583 | Loss: 74.848903\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:35 | Steps: 10584 | Loss: 74.849436\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:35 | Steps: 10585 | Loss: 74.851676\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:35 | Steps: 10586 | Loss: 74.850896\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:36 | Steps: 10587 | Loss: 74.850937\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:36 | Steps: 10588 | Loss: 74.850704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:36 | Steps: 10589 | Loss: 74.853875\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:36 | Steps: 10590 | Loss: 74.856631\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:36 | Steps: 10591 | Loss: 74.860864\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:36 | Steps: 10592 | Loss: 74.863758\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:37 | Steps: 10593 | Loss: 74.863146\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:37 | Steps: 10594 | Loss: 74.864622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:37 | Steps: 10595 | Loss: 74.867012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:37 | Steps: 10596 | Loss: 74.867100\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:37 | Steps: 10597 | Loss: 74.870722\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:37 | Steps: 10598 | Loss: 74.872166\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:37 | Steps: 10599 | Loss: 74.873904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:38 | Steps: 10600 | Loss: 74.873292\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:38 | Steps: 10601 | Loss: 74.874878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:38 | Steps: 10602 | Loss: 74.877478\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:38 | Steps: 10603 | Loss: 74.877663\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:38 | Steps: 10604 | Loss: 74.876874\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:39 | Steps: 10605 | Loss: 74.876727\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:39 | Steps: 10606 | Loss: 74.883356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:39 | Steps: 10607 | Loss: 74.886327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:39 | Steps: 10608 | Loss: 74.888327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:39 | Steps: 10609 | Loss: 74.894272\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:39 | Steps: 10610 | Loss: 74.894988\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:40 | Steps: 10611 | Loss: 74.898501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:40 | Steps: 10612 | Loss: 74.901944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:40 | Steps: 10613 | Loss: 74.903652\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:40 | Steps: 10614 | Loss: 74.903993\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:40 | Steps: 10615 | Loss: 74.904906\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:40 | Steps: 10616 | Loss: 74.907145\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:40 | Steps: 10617 | Loss: 74.906681\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:41 | Steps: 10618 | Loss: 74.906599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:41 | Steps: 10619 | Loss: 74.907082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:41 | Steps: 10620 | Loss: 74.909415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:41 | Steps: 10621 | Loss: 74.911324\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:41 | Steps: 10622 | Loss: 74.913070\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:41 | Steps: 10623 | Loss: 74.914188\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:42 | Steps: 10624 | Loss: 74.914730\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:42 | Steps: 10625 | Loss: 74.913818\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:42 | Steps: 10626 | Loss: 74.913764\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:42 | Steps: 10627 | Loss: 74.915388\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:42 | Steps: 10628 | Loss: 74.921744\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:43 | Steps: 10629 | Loss: 74.931574\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:43 | Steps: 10630 | Loss: 74.935941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:43 | Steps: 10631 | Loss: 74.936804\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:43 | Steps: 10632 | Loss: 74.938501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:43 | Steps: 10633 | Loss: 74.940233\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:43 | Steps: 10634 | Loss: 74.939822\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:43 | Steps: 10635 | Loss: 74.941322\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:44 | Steps: 10636 | Loss: 74.941619\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:44 | Steps: 10637 | Loss: 74.942194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:44 | Steps: 10638 | Loss: 74.941144\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:44 | Steps: 10639 | Loss: 74.943282\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:44 | Steps: 10640 | Loss: 74.945659\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:44 | Steps: 10641 | Loss: 74.945303\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:45 | Steps: 10642 | Loss: 74.944796\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:45 | Steps: 10643 | Loss: 74.948450\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:45 | Steps: 10644 | Loss: 74.950418\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:45 | Steps: 10645 | Loss: 74.954125\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:45 | Steps: 10646 | Loss: 74.956646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:45 | Steps: 10647 | Loss: 74.960138\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:46 | Steps: 10648 | Loss: 74.963265\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:46 | Steps: 10649 | Loss: 74.964120\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:46 | Steps: 10650 | Loss: 74.966030\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:46 | Steps: 10651 | Loss: 74.969119\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:46 | Steps: 10652 | Loss: 74.970656\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:46 | Steps: 10653 | Loss: 74.970940\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:47 | Steps: 10654 | Loss: 74.972288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:47 | Steps: 10655 | Loss: 74.977531\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:47 | Steps: 10656 | Loss: 74.979731\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:47 | Steps: 10657 | Loss: 74.986599\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:47 | Steps: 10658 | Loss: 74.988550\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:47 | Steps: 10659 | Loss: 74.991563\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:48 | Steps: 10660 | Loss: 74.993866\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:48 | Steps: 10661 | Loss: 74.996741\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:48 | Steps: 10662 | Loss: 74.997533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:48 | Steps: 10663 | Loss: 74.999394\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:48 | Steps: 10664 | Loss: 74.997992\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:49 | Steps: 10665 | Loss: 75.001297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:49 | Steps: 10666 | Loss: 75.003153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:49 | Steps: 10667 | Loss: 75.004556\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:49 | Steps: 10668 | Loss: 75.005869\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:49 | Steps: 10669 | Loss: 75.007657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:49 | Steps: 10670 | Loss: 75.010360\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:50 | Steps: 10671 | Loss: 75.009197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:50 | Steps: 10672 | Loss: 75.009314\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:50 | Steps: 10673 | Loss: 75.009190\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:50 | Steps: 10674 | Loss: 75.010566\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:50 | Steps: 10675 | Loss: 75.011839\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:50 | Steps: 10676 | Loss: 75.013694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:51 | Steps: 10677 | Loss: 75.011582\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:51 | Steps: 10678 | Loss: 75.010094\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:51 | Steps: 10679 | Loss: 75.011956\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:51 | Steps: 10680 | Loss: 75.017795\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:51 | Steps: 10681 | Loss: 75.020982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:51 | Steps: 10682 | Loss: 75.022470\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:52 | Steps: 10683 | Loss: 75.023141\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:52 | Steps: 10684 | Loss: 75.023785\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:52 | Steps: 10685 | Loss: 75.028526\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:52 | Steps: 10686 | Loss: 75.029172\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:52 | Steps: 10687 | Loss: 75.032868\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:52 | Steps: 10688 | Loss: 75.035372\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:53 | Steps: 10689 | Loss: 75.037392\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:53 | Steps: 10690 | Loss: 75.045078\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:53 | Steps: 10691 | Loss: 75.044945\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:53 | Steps: 10692 | Loss: 75.043182\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:53 | Steps: 10693 | Loss: 75.047199\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:53 | Steps: 10694 | Loss: 75.048500\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:54 | Steps: 10695 | Loss: 75.050597\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:54 | Steps: 10696 | Loss: 75.051102\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:54 | Steps: 10697 | Loss: 75.050704\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:54 | Steps: 10698 | Loss: 75.054873\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:54 | Steps: 10699 | Loss: 75.062590\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:54 | Steps: 10700 | Loss: 75.064535\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:55 | Steps: 10701 | Loss: 75.066670\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:55 | Steps: 10702 | Loss: 75.067237\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:55 | Steps: 10703 | Loss: 75.065230\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:55 | Steps: 10704 | Loss: 75.066998\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:55 | Steps: 10705 | Loss: 75.067468\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:55 | Steps: 10706 | Loss: 75.074182\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:56 | Steps: 10707 | Loss: 75.075165\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:56 | Steps: 10708 | Loss: 75.076416\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:56 | Steps: 10709 | Loss: 75.078619\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:56 | Steps: 10710 | Loss: 75.088280\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:56 | Steps: 10711 | Loss: 75.093475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:57 | Steps: 10712 | Loss: 75.097085\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:57 | Steps: 10713 | Loss: 75.097780\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:57 | Steps: 10714 | Loss: 75.101978\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:57 | Steps: 10715 | Loss: 75.102793\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:57 | Steps: 10716 | Loss: 75.105559\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:57 | Steps: 10717 | Loss: 75.106459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:58 | Steps: 10718 | Loss: 75.108938\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:58 | Steps: 10719 | Loss: 75.110615\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:58 | Steps: 10720 | Loss: 75.110953\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:58 | Steps: 10721 | Loss: 75.114002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:58 | Steps: 10722 | Loss: 75.114677\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:58 | Steps: 10723 | Loss: 75.115397\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:59 | Steps: 10724 | Loss: 75.116218\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:59 | Steps: 10725 | Loss: 75.124358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:59 | Steps: 10726 | Loss: 75.125708\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:59 | Steps: 10727 | Loss: 75.124935\n",
      "Epoch 1 |   Training | Elapsed Time: 0:18:59 | Steps: 10728 | Loss: 75.130015\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:00 | Steps: 10729 | Loss: 75.129711\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:00 | Steps: 10730 | Loss: 75.131960\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:00 | Steps: 10731 | Loss: 75.134951\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:00 | Steps: 10732 | Loss: 75.141879\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:00 | Steps: 10733 | Loss: 75.143259\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:00 | Steps: 10734 | Loss: 75.149321\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:01 | Steps: 10735 | Loss: 75.150613\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:01 | Steps: 10736 | Loss: 75.151666\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:01 | Steps: 10737 | Loss: 75.154307\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:01 | Steps: 10738 | Loss: 75.155411\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:01 | Steps: 10739 | Loss: 75.154348\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:01 | Steps: 10740 | Loss: 75.157955\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:02 | Steps: 10741 | Loss: 75.159396\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:02 | Steps: 10742 | Loss: 75.159723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:02 | Steps: 10743 | Loss: 75.159109\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:02 | Steps: 10744 | Loss: 75.161636\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:02 | Steps: 10745 | Loss: 75.163355\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:02 | Steps: 10746 | Loss: 75.164860\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:03 | Steps: 10747 | Loss: 75.166438\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:03 | Steps: 10748 | Loss: 75.167118\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:03 | Steps: 10749 | Loss: 75.170516\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:03 | Steps: 10750 | Loss: 75.174660\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:03 | Steps: 10751 | Loss: 75.177090\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:03 | Steps: 10752 | Loss: 75.178865\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:04 | Steps: 10753 | Loss: 75.180834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:04 | Steps: 10754 | Loss: 75.182082\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:04 | Steps: 10755 | Loss: 75.189918\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:04 | Steps: 10756 | Loss: 75.193944\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:04 | Steps: 10757 | Loss: 75.194155\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:04 | Steps: 10758 | Loss: 75.193881\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:05 | Steps: 10759 | Loss: 75.196575\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:05 | Steps: 10760 | Loss: 75.199489\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:05 | Steps: 10761 | Loss: 75.200507\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:05 | Steps: 10762 | Loss: 75.206194\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:05 | Steps: 10763 | Loss: 75.208351\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:06 | Steps: 10764 | Loss: 75.208382\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:06 | Steps: 10765 | Loss: 75.208811\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:06 | Steps: 10766 | Loss: 75.211924\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:06 | Steps: 10767 | Loss: 75.214581\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:06 | Steps: 10768 | Loss: 75.219675\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:06 | Steps: 10769 | Loss: 75.220664\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:07 | Steps: 10770 | Loss: 75.222077\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:07 | Steps: 10771 | Loss: 75.224904\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:07 | Steps: 10772 | Loss: 75.226146\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:07 | Steps: 10773 | Loss: 75.228074\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:07 | Steps: 10774 | Loss: 75.230542\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:07 | Steps: 10775 | Loss: 75.232459\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:08 | Steps: 10776 | Loss: 75.233846\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:08 | Steps: 10777 | Loss: 75.238225\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:08 | Steps: 10778 | Loss: 75.240206\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:08 | Steps: 10779 | Loss: 75.241433\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:08 | Steps: 10780 | Loss: 75.243513\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:08 | Steps: 10781 | Loss: 75.244379\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:09 | Steps: 10782 | Loss: 75.246411\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:09 | Steps: 10783 | Loss: 75.245142\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:09 | Steps: 10784 | Loss: 75.247849\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:09 | Steps: 10785 | Loss: 75.254204\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:09 | Steps: 10786 | Loss: 75.257103\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:10 | Steps: 10787 | Loss: 75.259878\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:10 | Steps: 10788 | Loss: 75.263553\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:10 | Steps: 10789 | Loss: 75.269217\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:10 | Steps: 10790 | Loss: 75.270625\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:10 | Steps: 10791 | Loss: 75.271501\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:10 | Steps: 10792 | Loss: 75.270825\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:11 | Steps: 10793 | Loss: 75.271822\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:11 | Steps: 10794 | Loss: 75.275746\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:11 | Steps: 10795 | Loss: 75.277244\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:11 | Steps: 10796 | Loss: 75.277843\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:11 | Steps: 10797 | Loss: 75.281002\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:11 | Steps: 10798 | Loss: 75.280720\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:12 | Steps: 10799 | Loss: 75.282770\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:12 | Steps: 10800 | Loss: 75.283595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:12 | Steps: 10801 | Loss: 75.283284\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:12 | Steps: 10802 | Loss: 75.287133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:12 | Steps: 10803 | Loss: 75.286321\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:12 | Steps: 10804 | Loss: 75.287921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:13 | Steps: 10805 | Loss: 75.289210\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:13 | Steps: 10806 | Loss: 75.290821\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:13 | Steps: 10807 | Loss: 75.291567\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:13 | Steps: 10808 | Loss: 75.293332\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:13 | Steps: 10809 | Loss: 75.294093\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:14 | Steps: 10810 | Loss: 75.294244\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:14 | Steps: 10811 | Loss: 75.296937\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:14 | Steps: 10812 | Loss: 75.297176\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:14 | Steps: 10813 | Loss: 75.297827\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:14 | Steps: 10814 | Loss: 75.302158\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:14 | Steps: 10815 | Loss: 75.302221\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:15 | Steps: 10816 | Loss: 75.303770\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:15 | Steps: 10817 | Loss: 75.310359\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:15 | Steps: 10818 | Loss: 75.311010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:15 | Steps: 10819 | Loss: 75.312168\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:15 | Steps: 10820 | Loss: 75.315533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:15 | Steps: 10821 | Loss: 75.317200\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:16 | Steps: 10822 | Loss: 75.319526\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:16 | Steps: 10823 | Loss: 75.324316\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:16 | Steps: 10824 | Loss: 75.326527\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:16 | Steps: 10825 | Loss: 75.328859\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:16 | Steps: 10826 | Loss: 75.330622\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:16 | Steps: 10827 | Loss: 75.336041\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:17 | Steps: 10828 | Loss: 75.336321\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:17 | Steps: 10829 | Loss: 75.337130\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:17 | Steps: 10830 | Loss: 75.336832\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:17 | Steps: 10831 | Loss: 75.339358\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:17 | Steps: 10832 | Loss: 75.340915\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:17 | Steps: 10833 | Loss: 75.343834\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:18 | Steps: 10834 | Loss: 75.346239\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:18 | Steps: 10835 | Loss: 75.350768\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:18 | Steps: 10836 | Loss: 75.352760\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:18 | Steps: 10837 | Loss: 75.355760\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:18 | Steps: 10838 | Loss: 75.356448\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:19 | Steps: 10839 | Loss: 75.355597\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:19 | Steps: 10840 | Loss: 75.357196\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:19 | Steps: 10841 | Loss: 75.357133\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:19 | Steps: 10842 | Loss: 75.358383\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:19 | Steps: 10843 | Loss: 75.359695\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:20 | Steps: 10844 | Loss: 75.362001\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:20 | Steps: 10845 | Loss: 75.364262\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:20 | Steps: 10846 | Loss: 75.367448\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:20 | Steps: 10847 | Loss: 75.370626\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:20 | Steps: 10848 | Loss: 75.374547\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:20 | Steps: 10849 | Loss: 75.376308\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:21 | Steps: 10850 | Loss: 75.382512\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:21 | Steps: 10851 | Loss: 75.385630\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:21 | Steps: 10852 | Loss: 75.387779\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:21 | Steps: 10853 | Loss: 75.388336\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:21 | Steps: 10854 | Loss: 75.387530\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:21 | Steps: 10855 | Loss: 75.390982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:22 | Steps: 10856 | Loss: 75.391791\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:22 | Steps: 10857 | Loss: 75.393789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:22 | Steps: 10858 | Loss: 75.396149\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:22 | Steps: 10859 | Loss: 75.396814\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:22 | Steps: 10860 | Loss: 75.396723\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:23 | Steps: 10861 | Loss: 75.400331\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:23 | Steps: 10862 | Loss: 75.404729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:23 | Steps: 10863 | Loss: 75.409547\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:23 | Steps: 10864 | Loss: 75.414484\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:23 | Steps: 10865 | Loss: 75.418394\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:23 | Steps: 10866 | Loss: 75.418575\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:24 | Steps: 10867 | Loss: 75.421195\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:24 | Steps: 10868 | Loss: 75.422920\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:24 | Steps: 10869 | Loss: 75.424152\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:24 | Steps: 10870 | Loss: 75.426187\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:24 | Steps: 10871 | Loss: 75.427104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:24 | Steps: 10872 | Loss: 75.429251\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:25 | Steps: 10873 | Loss: 75.431701\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:25 | Steps: 10874 | Loss: 75.438244\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:25 | Steps: 10875 | Loss: 75.442774\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:25 | Steps: 10876 | Loss: 75.446798\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:25 | Steps: 10877 | Loss: 75.449933\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:26 | Steps: 10878 | Loss: 75.454297\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:26 | Steps: 10879 | Loss: 75.454175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:26 | Steps: 10880 | Loss: 75.458056\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:26 | Steps: 10881 | Loss: 75.459027\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:26 | Steps: 10882 | Loss: 75.459159\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:26 | Steps: 10883 | Loss: 75.459823\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:27 | Steps: 10884 | Loss: 75.462757\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:27 | Steps: 10885 | Loss: 75.463555\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:27 | Steps: 10886 | Loss: 75.465729\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:27 | Steps: 10887 | Loss: 75.467830\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:27 | Steps: 10888 | Loss: 75.469407\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:28 | Steps: 10889 | Loss: 75.473175\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:28 | Steps: 10890 | Loss: 75.471327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:28 | Steps: 10891 | Loss: 75.473813\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:28 | Steps: 10892 | Loss: 75.474799\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:28 | Steps: 10893 | Loss: 75.477356\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:29 | Steps: 10894 | Loss: 75.477588\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:29 | Steps: 10895 | Loss: 75.477126\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:29 | Steps: 10896 | Loss: 75.483077\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:29 | Steps: 10897 | Loss: 75.486815\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:29 | Steps: 10898 | Loss: 75.486616\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:29 | Steps: 10899 | Loss: 75.490424\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:30 | Steps: 10900 | Loss: 75.491929\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:30 | Steps: 10901 | Loss: 75.492917\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:30 | Steps: 10902 | Loss: 75.494560\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:30 | Steps: 10903 | Loss: 75.495415\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:30 | Steps: 10904 | Loss: 75.498579\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:30 | Steps: 10905 | Loss: 75.498314\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:31 | Steps: 10906 | Loss: 75.498610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:31 | Steps: 10907 | Loss: 75.502569\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:31 | Steps: 10908 | Loss: 75.502710\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:31 | Steps: 10909 | Loss: 75.506104\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:31 | Steps: 10910 | Loss: 75.508311\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:32 | Steps: 10911 | Loss: 75.511908\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:32 | Steps: 10912 | Loss: 75.511116\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:32 | Steps: 10913 | Loss: 75.514326\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:32 | Steps: 10914 | Loss: 75.516010\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:32 | Steps: 10915 | Loss: 75.517092\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:32 | Steps: 10916 | Loss: 75.517017\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:33 | Steps: 10917 | Loss: 75.520976\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:33 | Steps: 10918 | Loss: 75.522832\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:33 | Steps: 10919 | Loss: 75.524435\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:33 | Steps: 10920 | Loss: 75.529249\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:33 | Steps: 10921 | Loss: 75.529545\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:34 | Steps: 10922 | Loss: 75.535984\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:34 | Steps: 10923 | Loss: 75.537823\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:34 | Steps: 10924 | Loss: 75.539581\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:34 | Steps: 10925 | Loss: 75.540604\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:34 | Steps: 10926 | Loss: 75.545736\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:35 | Steps: 10927 | Loss: 75.548698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:35 | Steps: 10928 | Loss: 75.553658\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:35 | Steps: 10929 | Loss: 75.559267\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:35 | Steps: 10930 | Loss: 75.559894\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:35 | Steps: 10931 | Loss: 75.560965\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:35 | Steps: 10932 | Loss: 75.561301\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:36 | Steps: 10933 | Loss: 75.562921\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:36 | Steps: 10934 | Loss: 75.563918\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:36 | Steps: 10935 | Loss: 75.565809\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:36 | Steps: 10936 | Loss: 75.568474\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:36 | Steps: 10937 | Loss: 75.569796\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:37 | Steps: 10938 | Loss: 75.572716\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:37 | Steps: 10939 | Loss: 75.574228\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:37 | Steps: 10940 | Loss: 75.575288\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:37 | Steps: 10941 | Loss: 75.577540\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:37 | Steps: 10942 | Loss: 75.576379\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:37 | Steps: 10943 | Loss: 75.574985\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:38 | Steps: 10944 | Loss: 75.574924\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:38 | Steps: 10945 | Loss: 75.579054\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:38 | Steps: 10946 | Loss: 75.584197\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:38 | Steps: 10947 | Loss: 75.590499\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:38 | Steps: 10948 | Loss: 75.592651\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:39 | Steps: 10949 | Loss: 75.595621\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:39 | Steps: 10950 | Loss: 75.597308\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:39 | Steps: 10951 | Loss: 75.598139\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:39 | Steps: 10952 | Loss: 75.605139\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:39 | Steps: 10953 | Loss: 75.609595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:40 | Steps: 10954 | Loss: 75.611886\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:40 | Steps: 10955 | Loss: 75.613694\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:40 | Steps: 10956 | Loss: 75.619161\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:40 | Steps: 10957 | Loss: 75.622684\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:40 | Steps: 10958 | Loss: 75.623647\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:41 | Steps: 10959 | Loss: 75.628903\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:41 | Steps: 10960 | Loss: 75.628970\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:41 | Steps: 10961 | Loss: 75.631800\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:41 | Steps: 10962 | Loss: 75.633982\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:41 | Steps: 10963 | Loss: 75.635634\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:41 | Steps: 10964 | Loss: 75.635898\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:42 | Steps: 10965 | Loss: 75.641497\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:42 | Steps: 10966 | Loss: 75.643738\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:42 | Steps: 10967 | Loss: 75.645902\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:42 | Steps: 10968 | Loss: 75.645881\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:42 | Steps: 10969 | Loss: 75.655661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:43 | Steps: 10970 | Loss: 75.658753\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:43 | Steps: 10971 | Loss: 75.658690\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:43 | Steps: 10972 | Loss: 75.659277\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:43 | Steps: 10973 | Loss: 75.660661\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:43 | Steps: 10974 | Loss: 75.659610\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:44 | Steps: 10975 | Loss: 75.660657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:44 | Steps: 10976 | Loss: 75.661153\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:44 | Steps: 10977 | Loss: 75.666589\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:44 | Steps: 10978 | Loss: 75.667477\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:44 | Steps: 10979 | Loss: 75.671281\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:45 | Steps: 10980 | Loss: 75.673668\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:45 | Steps: 10981 | Loss: 75.675357\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:45 | Steps: 10982 | Loss: 75.679220\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:45 | Steps: 10983 | Loss: 75.681533\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:45 | Steps: 10984 | Loss: 75.683941\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:46 | Steps: 10985 | Loss: 75.684543\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:46 | Steps: 10986 | Loss: 75.684698\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:46 | Steps: 10987 | Loss: 75.683595\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:46 | Steps: 10988 | Loss: 75.684208\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:46 | Steps: 10989 | Loss: 75.684657\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:46 | Steps: 10990 | Loss: 75.684001\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:47 | Steps: 10991 | Loss: 75.685215\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:47 | Steps: 10992 | Loss: 75.688018\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:47 | Steps: 10993 | Loss: 75.691789\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:47 | Steps: 10994 | Loss: 75.694345\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:47 | Steps: 10995 | Loss: 75.695906\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:48 | Steps: 10996 | Loss: 75.699327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:48 | Steps: 10997 | Loss: 75.697679\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:48 | Steps: 10998 | Loss: 75.702572\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:48 | Steps: 10999 | Loss: 75.703116\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:48 | Steps: 11000 | Loss: 75.706603\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:49 | Steps: 11001 | Loss: 75.705475\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:49 | Steps: 11002 | Loss: 75.707733\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:49 | Steps: 11003 | Loss: 75.709457\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:49 | Steps: 11004 | Loss: 75.711787\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:49 | Steps: 11005 | Loss: 75.713483\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:50 | Steps: 11006 | Loss: 75.718314\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:50 | Steps: 11007 | Loss: 75.719781\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:50 | Steps: 11008 | Loss: 75.722786\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:50 | Steps: 11009 | Loss: 75.729012\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:50 | Steps: 11010 | Loss: 75.729174\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:51 | Steps: 11011 | Loss: 75.730327\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:51 | Steps: 11012 | Loss: 75.732649\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:51 | Steps: 11013 | Loss: 75.736990\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:51 | Steps: 11014 | Loss: 75.739369\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:51 | Steps: 11015 | Loss: 75.742069\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:51 | Steps: 11016 | Loss: 75.750646\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:52 | Steps: 11017 | Loss: 75.750733\n",
      "Epoch 1 |   Training | Elapsed Time: 0:19:52 | Steps: 11017 | Loss: 75.750733\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:01 | Steps: 1 | Loss: 273.856079 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 132.306471 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 112.221331 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 9 | Loss: 101.072861 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 12 | Loss: 88.445820 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 14 | Loss: 85.087248 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 16 | Loss: 81.248755 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 17 | Loss: 77.988238 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 21 | Loss: 74.277922 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 24 | Loss: 69.251887 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 25 | Loss: 69.395161 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:03 | Steps: 28 | Loss: 67.587772 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:03 | Steps: 29 | Loss: 67.654806 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:03 | Steps: 33 | Loss: 65.327512 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:03 | Steps: 35 | Loss: 65.126792 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:03 | Steps: 38 | Loss: 64.608641 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:03 | Steps: 39 | Loss: 64.155351 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:03 | Steps: 42 | Loss: 62.818050 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:03 | Steps: 45 | Loss: 64.382972 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:04 | Steps: 47 | Loss: 62.990967 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:04 | Steps: 50 | Loss: 63.472625 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:04 | Steps: 51 | Loss: 63.958309 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:04 | Steps: 53 | Loss: 63.190172 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:04 | Steps: 55 | Loss: 62.268341 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:04 | Steps: 57 | Loss: 61.250990 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:04 | Steps: 59 | Loss: 60.400233 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:04 | Steps: 63 | Loss: 59.298532 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:05 | Steps: 65 | Loss: 59.251515 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:05 | Steps: 69 | Loss: 58.828761 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:05 | Steps: 71 | Loss: 58.083785 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:05 | Steps: 73 | Loss: 57.690236 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:05 | Steps: 76 | Loss: 57.265027 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:05 | Steps: 79 | Loss: 56.780006 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:05 | Steps: 81 | Loss: 56.284041 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 85 | Loss: 55.733359 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 87 | Loss: 55.580906 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 90 | Loss: 58.270298 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 92 | Loss: 57.990555 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 93 | Loss: 58.346804 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 97 | Loss: 59.615115 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 99 | Loss: 60.027629 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 102 | Loss: 59.350763 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:06 | Steps: 103 | Loss: 59.590627 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:07 | Steps: 107 | Loss: 59.235463 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:07 | Steps: 111 | Loss: 58.753049 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:07 | Steps: 113 | Loss: 58.613056 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:07 | Steps: 115 | Loss: 58.878800 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:07 | Steps: 118 | Loss: 58.771440 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:07 | Steps: 121 | Loss: 58.510748 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:08 | Steps: 125 | Loss: 57.953687 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:08 | Steps: 128 | Loss: 57.812285 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:08 | Steps: 129 | Loss: 57.699314 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:08 | Steps: 133 | Loss: 57.685439 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:08 | Steps: 135 | Loss: 58.009678 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:08 | Steps: 138 | Loss: 57.641555 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:08 | Steps: 140 | Loss: 57.765979 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:08 | Steps: 142 | Loss: 57.650535 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:09 | Steps: 144 | Loss: 57.464956 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:09 | Steps: 147 | Loss: 57.319602 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:09 | Steps: 149 | Loss: 57.924233 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:09 | Steps: 153 | Loss: 57.547619 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:09 | Steps: 155 | Loss: 57.544037 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:09 | Steps: 158 | Loss: 57.192638 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:09 | Steps: 160 | Loss: 57.108954 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:10 | Steps: 161 | Loss: 57.078461 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:10 | Steps: 165 | Loss: 57.457037 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:10 | Steps: 168 | Loss: 58.571994 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:10 | Steps: 170 | Loss: 58.342746 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:10 | Steps: 173 | Loss: 58.034200 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:10 | Steps: 175 | Loss: 58.022804 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:10 | Steps: 179 | Loss: 57.717887 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:10 | Steps: 181 | Loss: 57.909783 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:11 | Steps: 184 | Loss: 58.180116 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:11 | Steps: 186 | Loss: 58.093172 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:11 | Steps: 189 | Loss: 58.048116 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:11 | Steps: 191 | Loss: 57.695115 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:11 | Steps: 193 | Loss: 57.844429 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:11 | Steps: 196 | Loss: 57.670979 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:11 | Steps: 199 | Loss: 57.697357 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:12 | Steps: 202 | Loss: 57.582475 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:12 | Steps: 204 | Loss: 57.543948 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:12 | Steps: 206 | Loss: 57.515096 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:12 | Steps: 209 | Loss: 57.301040 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:12 | Steps: 211 | Loss: 57.239293 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:12 | Steps: 214 | Loss: 56.934960 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:12 | Steps: 216 | Loss: 57.205966 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:12 | Steps: 219 | Loss: 57.098702 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 221 | Loss: 56.887653 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 224 | Loss: 56.920916 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 226 | Loss: 57.055368 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 229 | Loss: 56.944927 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 231 | Loss: 56.832796 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 234 | Loss: 56.783497 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 236 | Loss: 56.707357 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 238 | Loss: 56.637211 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:13 | Steps: 240 | Loss: 56.658009 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 243 | Loss: 56.535267 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 245 | Loss: 56.415981 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 247 | Loss: 56.420723 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 249 | Loss: 56.275950 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 251 | Loss: 56.153630 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 254 | Loss: 56.353840 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 255 | Loss: 56.267831 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 257 | Loss: 56.353255 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:15 | Steps: 260 | Loss: 56.418758 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:15 | Steps: 263 | Loss: 56.383442 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:15 | Steps: 264 | Loss: 56.337934 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:15 | Steps: 268 | Loss: 56.086607 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:15 | Steps: 272 | Loss: 56.052299 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:15 | Steps: 274 | Loss: 55.847094 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:15 | Steps: 276 | Loss: 55.796900 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 278 | Loss: 55.781802 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 281 | Loss: 55.697462 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 284 | Loss: 55.716013 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 286 | Loss: 55.824626 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 288 | Loss: 55.765063 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 290 | Loss: 55.702191 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 293 | Loss: 55.684191 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 295 | Loss: 55.570155 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:16 | Steps: 297 | Loss: 55.615024 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:17 | Steps: 299 | Loss: 55.631396 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:17 | Steps: 301 | Loss: 55.693353 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:17 | Steps: 303 | Loss: 55.608268 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:17 | Steps: 305 | Loss: 55.559100 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:17 | Steps: 307 | Loss: 55.806635 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:17 | Steps: 309 | Loss: 55.760327 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:17 | Steps: 312 | Loss: 55.570012 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:17 | Steps: 315 | Loss: 55.627094 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:18 | Steps: 317 | Loss: 55.577299 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:18 | Steps: 320 | Loss: 55.485728 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:18 | Steps: 322 | Loss: 55.329125 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:18 | Steps: 326 | Loss: 55.467944 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:18 | Steps: 328 | Loss: 55.481974 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:18 | Steps: 331 | Loss: 55.413936 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:18 | Steps: 333 | Loss: 55.412011 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:19 | Steps: 336 | Loss: 55.399229 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:19 | Steps: 339 | Loss: 55.374582 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:19 | Steps: 342 | Loss: 55.206486 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:19 | Steps: 345 | Loss: 55.336051 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:19 | Steps: 348 | Loss: 55.301918 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:19 | Steps: 350 | Loss: 55.322111 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:19 | Steps: 352 | Loss: 55.260976 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:20 | Steps: 355 | Loss: 55.240516 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:20 | Steps: 357 | Loss: 55.133196 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:20 | Steps: 359 | Loss: 55.019681 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:20 | Steps: 362 | Loss: 54.977871 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:20 | Steps: 365 | Loss: 54.908758 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:20 | Steps: 366 | Loss: 54.854981 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:20 | Steps: 368 | Loss: 54.923599 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:20 | Steps: 371 | Loss: 54.949639 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:21 | Steps: 373 | Loss: 55.281616 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:21 | Steps: 375 | Loss: 55.319177 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:21 | Steps: 377 | Loss: 55.237974 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:21 | Steps: 379 | Loss: 55.293005 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:21 | Steps: 381 | Loss: 55.327426 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:21 | Steps: 382 | Loss: 55.386803 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:21 | Steps: 386 | Loss: 55.301360 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:21 | Steps: 389 | Loss: 55.168366 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:22 | Steps: 390 | Loss: 55.254083 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:22 | Steps: 392 | Loss: 55.274334 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:22 | Steps: 394 | Loss: 55.158450 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:22 | Steps: 396 | Loss: 55.161885 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 55.256192 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:22 | Steps: 401 | Loss: 55.534460 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:22 | Steps: 402 | Loss: 55.582226 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:22 | Steps: 405 | Loss: 55.473224 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:23 | Steps: 407 | Loss: 55.457784 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:23 | Steps: 409 | Loss: 55.386357 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:23 | Steps: 412 | Loss: 55.405678 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:23 | Steps: 414 | Loss: 55.462659 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:23 | Steps: 416 | Loss: 55.377837 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:23 | Steps: 420 | Loss: 55.320718 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:23 | Steps: 422 | Loss: 55.261934 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:24 | Steps: 425 | Loss: 55.322381 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:24 | Steps: 427 | Loss: 55.373940 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:24 | Steps: 430 | Loss: 55.383922 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:24 | Steps: 431 | Loss: 55.464790 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:24 | Steps: 433 | Loss: 55.544536 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:24 | Steps: 435 | Loss: 55.533946 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:24 | Steps: 438 | Loss: 55.550568 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:24 | Steps: 440 | Loss: 55.484608 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:25 | Steps: 443 | Loss: 55.517698 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:25 | Steps: 445 | Loss: 55.640685 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:25 | Steps: 448 | Loss: 55.718054 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:25 | Steps: 450 | Loss: 55.662658 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:25 | Steps: 453 | Loss: 55.802326 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:25 | Steps: 455 | Loss: 55.875245 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:25 | Steps: 458 | Loss: 55.873364 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:25 | Steps: 460 | Loss: 55.911989 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:26 | Steps: 463 | Loss: 55.898833 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:26 | Steps: 465 | Loss: 55.900501 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:26 | Steps: 468 | Loss: 55.853652 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:26 | Steps: 471 | Loss: 55.791756 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:26 | Steps: 473 | Loss: 55.910056 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:26 | Steps: 476 | Loss: 55.850243 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:26 | Steps: 478 | Loss: 55.856316 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:27 | Steps: 480 | Loss: 55.810379 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:27 | Steps: 482 | Loss: 55.754935 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:27 | Steps: 484 | Loss: 55.781524 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:27 | Steps: 486 | Loss: 55.803767 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:27 | Steps: 488 | Loss: 55.832348 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:27 | Steps: 491 | Loss: 55.876470 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:27 | Steps: 493 | Loss: 55.903383 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:27 | Steps: 494 | Loss: 56.022566 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:28 | Steps: 497 | Loss: 56.069097 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:28 | Steps: 500 | Loss: 56.105053 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:28 | Steps: 501 | Loss: 56.140021 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:28 | Steps: 503 | Loss: 56.117740 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:28 | Steps: 506 | Loss: 56.115263 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:28 | Steps: 508 | Loss: 56.134384 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:28 | Steps: 510 | Loss: 56.159881 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:28 | Steps: 512 | Loss: 56.205781 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:29 | Steps: 515 | Loss: 56.285446 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:29 | Steps: 517 | Loss: 56.298523 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:29 | Steps: 519 | Loss: 56.417349 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:29 | Steps: 521 | Loss: 56.648708 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:29 | Steps: 523 | Loss: 56.679542 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:29 | Steps: 525 | Loss: 56.624640 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:29 | Steps: 527 | Loss: 56.759093 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:29 | Steps: 529 | Loss: 56.741209 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:30 | Steps: 531 | Loss: 56.677713 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:30 | Steps: 533 | Loss: 56.618515 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:30 | Steps: 535 | Loss: 56.661483 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:30 | Steps: 538 | Loss: 56.586267 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:30 | Steps: 539 | Loss: 56.557982 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:30 | Steps: 542 | Loss: 56.495317 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:30 | Steps: 544 | Loss: 56.564941 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:30 | Steps: 546 | Loss: 56.599407 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:31 | Steps: 548 | Loss: 56.627499 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:31 | Steps: 551 | Loss: 56.694852 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:31 | Steps: 553 | Loss: 56.795729 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:31 | Steps: 555 | Loss: 56.861886 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:31 | Steps: 558 | Loss: 56.983026 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:31 | Steps: 560 | Loss: 56.929254 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:31 | Steps: 562 | Loss: 56.965288 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:31 | Steps: 564 | Loss: 56.974327 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:32 | Steps: 566 | Loss: 57.015656 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:32 | Steps: 568 | Loss: 57.091134 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:32 | Steps: 570 | Loss: 57.116266 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:32 | Steps: 572 | Loss: 57.085591 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:32 | Steps: 574 | Loss: 57.095928 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:32 | Steps: 577 | Loss: 57.151559 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:32 | Steps: 579 | Loss: 57.213760 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:32 | Steps: 582 | Loss: 57.325032 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:33 | Steps: 584 | Loss: 57.346998 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:33 | Steps: 587 | Loss: 57.382211 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:33 | Steps: 588 | Loss: 57.434192 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:33 | Steps: 592 | Loss: 57.537928 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:33 | Steps: 594 | Loss: 57.479856 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:33 | Steps: 597 | Loss: 57.446229 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:34 | Steps: 599 | Loss: 57.386459 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:34 | Steps: 601 | Loss: 57.375825 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:34 | Steps: 603 | Loss: 57.381143 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:34 | Steps: 605 | Loss: 57.322232 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:34 | Steps: 607 | Loss: 57.394017 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:34 | Steps: 610 | Loss: 57.513535 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:34 | Steps: 612 | Loss: 57.550035 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 616 | Loss: 57.794709 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 618 | Loss: 57.778887 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 620 | Loss: 57.808723 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 622 | Loss: 57.796451 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 625 | Loss: 57.777459 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 627 | Loss: 57.858938 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 629 | Loss: 57.814667 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 631 | Loss: 57.934330 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:36 | Steps: 633 | Loss: 57.898875 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:36 | Steps: 636 | Loss: 58.024098 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:36 | Steps: 638 | Loss: 57.995318 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:36 | Steps: 640 | Loss: 58.001890 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:36 | Steps: 642 | Loss: 57.973271 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:36 | Steps: 644 | Loss: 58.014730 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:36 | Steps: 646 | Loss: 58.026637 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:36 | Steps: 648 | Loss: 58.094606 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:37 | Steps: 650 | Loss: 58.131649 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:37 | Steps: 652 | Loss: 58.129447 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:37 | Steps: 655 | Loss: 58.123707 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:37 | Steps: 657 | Loss: 58.101485 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:37 | Steps: 659 | Loss: 58.095080 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:37 | Steps: 661 | Loss: 58.099274 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:37 | Steps: 663 | Loss: 58.057911 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:37 | Steps: 665 | Loss: 58.189879 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:38 | Steps: 667 | Loss: 58.238406 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:38 | Steps: 669 | Loss: 58.373590 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:38 | Steps: 671 | Loss: 58.366081 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:38 | Steps: 673 | Loss: 58.469680 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:38 | Steps: 675 | Loss: 58.459424 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:38 | Steps: 677 | Loss: 58.492430 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:38 | Steps: 680 | Loss: 58.726622 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:39 | Steps: 682 | Loss: 58.753659 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:39 | Steps: 684 | Loss: 58.745988 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:39 | Steps: 686 | Loss: 58.887076 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:39 | Steps: 688 | Loss: 58.916866 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:39 | Steps: 690 | Loss: 58.949015 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:39 | Steps: 692 | Loss: 59.012173 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:39 | Steps: 694 | Loss: 59.018638 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:39 | Steps: 697 | Loss: 59.076348 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 699 | Loss: 59.078532 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 700 | Loss: 59.104819 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 702 | Loss: 59.126173 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 705 | Loss: 59.120353 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 707 | Loss: 59.080813 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 709 | Loss: 59.141187 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 711 | Loss: 59.214913 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 713 | Loss: 59.234787 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:40 | Steps: 715 | Loss: 59.225989 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:41 | Steps: 717 | Loss: 59.297351 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:41 | Steps: 720 | Loss: 59.469115 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:41 | Steps: 722 | Loss: 59.483248 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:41 | Steps: 724 | Loss: 59.563789 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:41 | Steps: 726 | Loss: 59.557048 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:41 | Steps: 728 | Loss: 59.526946 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:41 | Steps: 730 | Loss: 59.576197 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:42 | Steps: 733 | Loss: 59.568370 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:42 | Steps: 736 | Loss: 59.562448 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:42 | Steps: 738 | Loss: 59.585587 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:42 | Steps: 739 | Loss: 59.609310 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:42 | Steps: 741 | Loss: 59.645178 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:42 | Steps: 743 | Loss: 59.665866 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:42 | Steps: 745 | Loss: 59.709260 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:42 | Steps: 748 | Loss: 59.727239 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:43 | Steps: 751 | Loss: 59.762264 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:43 | Steps: 753 | Loss: 59.782201 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:43 | Steps: 755 | Loss: 59.928163 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:43 | Steps: 758 | Loss: 59.889676 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:43 | Steps: 760 | Loss: 59.954563 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:43 | Steps: 763 | Loss: 59.952834 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:43 | Steps: 765 | Loss: 60.008705 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:44 | Steps: 768 | Loss: 59.958420 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:44 | Steps: 770 | Loss: 59.966665 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:44 | Steps: 773 | Loss: 60.098295 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:44 | Steps: 775 | Loss: 60.084836 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:44 | Steps: 777 | Loss: 60.054629 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:44 | Steps: 779 | Loss: 60.004411 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:44 | Steps: 782 | Loss: 60.071164 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:45 | Steps: 785 | Loss: 60.060745 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:45 | Steps: 788 | Loss: 60.048162 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:45 | Steps: 790 | Loss: 60.193698 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:45 | Steps: 793 | Loss: 60.235785 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:45 | Steps: 795 | Loss: 60.298907 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:45 | Steps: 797 | Loss: 60.319860 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:46 | Steps: 799 | Loss: 60.340182 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:46 | Steps: 801 | Loss: 60.363721 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:46 | Steps: 804 | Loss: 60.341774 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:46 | Steps: 806 | Loss: 60.369142 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:46 | Steps: 808 | Loss: 60.356119 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:46 | Steps: 811 | Loss: 60.381048 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:46 | Steps: 813 | Loss: 60.381125 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:47 | Steps: 816 | Loss: 60.371222 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:47 | Steps: 818 | Loss: 60.378907 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:47 | Steps: 820 | Loss: 60.456547 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:47 | Steps: 822 | Loss: 60.445416 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:47 | Steps: 825 | Loss: 60.432449 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:47 | Steps: 827 | Loss: 60.422006 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:47 | Steps: 829 | Loss: 60.439289 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:47 | Steps: 831 | Loss: 60.617955 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:48 | Steps: 834 | Loss: 60.619200 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:48 | Steps: 835 | Loss: 60.609585 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:48 | Steps: 837 | Loss: 60.635529 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:48 | Steps: 840 | Loss: 60.602481 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:48 | Steps: 843 | Loss: 60.556926 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:48 | Steps: 844 | Loss: 60.585853 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:48 | Steps: 846 | Loss: 60.564360 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:48 | Steps: 848 | Loss: 60.559378 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:49 | Steps: 850 | Loss: 60.581427 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:49 | Steps: 853 | Loss: 60.704017 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:49 | Steps: 855 | Loss: 60.675099 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:49 | Steps: 857 | Loss: 60.732066 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:49 | Steps: 860 | Loss: 60.781483 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:49 | Steps: 862 | Loss: 60.767002 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:50 | Steps: 864 | Loss: 60.803603 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:50 | Steps: 866 | Loss: 60.834275 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:50 | Steps: 868 | Loss: 60.865231 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:50 | Steps: 870 | Loss: 60.883693 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:50 | Steps: 873 | Loss: 60.923780 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:50 | Steps: 875 | Loss: 60.947478 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:50 | Steps: 877 | Loss: 60.948737 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:51 | Steps: 880 | Loss: 61.066308 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:51 | Steps: 882 | Loss: 61.103691 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:51 | Steps: 884 | Loss: 61.090317 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:51 | Steps: 886 | Loss: 61.061969 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:51 | Steps: 888 | Loss: 61.008591 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:51 | Steps: 890 | Loss: 60.983954 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:51 | Steps: 892 | Loss: 61.025562 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:51 | Steps: 894 | Loss: 61.020669 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:52 | Steps: 896 | Loss: 61.008874 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:52 | Steps: 898 | Loss: 61.260748 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:52 | Steps: 900 | Loss: 61.272732 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:52 | Steps: 902 | Loss: 61.262280 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:52 | Steps: 904 | Loss: 61.306566 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:52 | Steps: 906 | Loss: 61.414220 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:52 | Steps: 909 | Loss: 61.414829 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:53 | Steps: 911 | Loss: 61.438693 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:53 | Steps: 913 | Loss: 61.483587 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:53 | Steps: 915 | Loss: 61.470052 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:53 | Steps: 918 | Loss: 61.502651 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:53 | Steps: 921 | Loss: 61.492491 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:53 | Steps: 923 | Loss: 61.558135 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:53 | Steps: 925 | Loss: 61.556051 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:54 | Steps: 927 | Loss: 61.525005 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:54 | Steps: 930 | Loss: 61.519345 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:54 | Steps: 932 | Loss: 61.551348 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:54 | Steps: 935 | Loss: 61.632874 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:54 | Steps: 938 | Loss: 61.621198 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:54 | Steps: 940 | Loss: 61.593455 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:54 | Steps: 942 | Loss: 61.632177 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:55 | Steps: 944 | Loss: 61.642224 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:55 | Steps: 947 | Loss: 61.750822 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:55 | Steps: 949 | Loss: 61.767958 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:55 | Steps: 951 | Loss: 61.784720 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:55 | Steps: 953 | Loss: 61.790840 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:55 | Steps: 955 | Loss: 61.775448 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:55 | Steps: 957 | Loss: 61.813724 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:56 | Steps: 960 | Loss: 61.900043 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:56 | Steps: 963 | Loss: 61.926869 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:56 | Steps: 965 | Loss: 61.935644 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:56 | Steps: 967 | Loss: 61.945971 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:56 | Steps: 970 | Loss: 62.005383 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:56 | Steps: 972 | Loss: 62.008697 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:56 | Steps: 974 | Loss: 62.032984 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:57 | Steps: 976 | Loss: 62.105069 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:57 | Steps: 979 | Loss: 62.110348 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:57 | Steps: 981 | Loss: 62.084490 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:57 | Steps: 984 | Loss: 62.093099 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:57 | Steps: 986 | Loss: 62.115803 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:57 | Steps: 989 | Loss: 62.180336 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:58 | Steps: 992 | Loss: 62.226775 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:58 | Steps: 994 | Loss: 62.204377 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:58 | Steps: 997 | Loss: 62.221245 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:58 | Steps: 999 | Loss: 62.293073 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:58 | Steps: 1001 | Loss: 62.288953 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:58 | Steps: 1003 | Loss: 62.270399 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:58 | Steps: 1005 | Loss: 62.284227 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:59 | Steps: 1007 | Loss: 62.306213 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:59 | Steps: 1010 | Loss: 62.314052 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:59 | Steps: 1012 | Loss: 62.314433 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:59 | Steps: 1015 | Loss: 62.323244 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:59 | Steps: 1018 | Loss: 62.309960 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:00:59 | Steps: 1020 | Loss: 62.317944 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:00 | Steps: 1023 | Loss: 62.332255 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:00 | Steps: 1025 | Loss: 62.348498 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:00 | Steps: 1027 | Loss: 62.383547 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:00 | Steps: 1029 | Loss: 62.414269 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:00 | Steps: 1031 | Loss: 62.529934 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:00 | Steps: 1033 | Loss: 62.537696 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:00 | Steps: 1036 | Loss: 62.550438 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:01 | Steps: 1038 | Loss: 62.576110 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:01 | Steps: 1040 | Loss: 62.578138 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:01 | Steps: 1043 | Loss: 62.609093 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:01 | Steps: 1047 | Loss: 62.652235 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:01 | Steps: 1050 | Loss: 62.656896 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:02 | Steps: 1052 | Loss: 62.657656 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:02 | Steps: 1054 | Loss: 62.666500 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:02 | Steps: 1056 | Loss: 62.676165 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:02 | Steps: 1059 | Loss: 62.630383 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:02 | Steps: 1061 | Loss: 62.677919 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:02 | Steps: 1064 | Loss: 62.655975 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:02 | Steps: 1066 | Loss: 62.699838 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:03 | Steps: 1069 | Loss: 62.687604 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:03 | Steps: 1071 | Loss: 62.723459 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:03 | Steps: 1073 | Loss: 62.711504 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:03 | Steps: 1075 | Loss: 62.761236 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:03 | Steps: 1077 | Loss: 62.783510 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:03 | Steps: 1078 | Loss: 62.787850 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:03 | Steps: 1081 | Loss: 62.772928 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:04 | Steps: 1082 | Loss: 62.767217 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:04 | Steps: 1084 | Loss: 62.827643 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:04 | Steps: 1086 | Loss: 62.912875 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:04 | Steps: 1087 | Loss: 62.934831 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:04 | Steps: 1089 | Loss: 62.925447 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:04 | Steps: 1091 | Loss: 62.921914 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:04 | Steps: 1093 | Loss: 62.923678 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:04 | Steps: 1095 | Loss: 62.960303 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:05 | Steps: 1097 | Loss: 62.975738 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:05 | Steps: 1100 | Loss: 62.992769 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:05 | Steps: 1102 | Loss: 62.994621 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:05 | Steps: 1105 | Loss: 63.061342 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:05 | Steps: 1107 | Loss: 63.065908 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:05 | Steps: 1109 | Loss: 63.076312 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:06 | Steps: 1111 | Loss: 63.047415 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:06 | Steps: 1113 | Loss: 63.043966 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:06 | Steps: 1115 | Loss: 63.130498 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:06 | Steps: 1117 | Loss: 63.133129 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:06 | Steps: 1118 | Loss: 63.173342 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:06 | Steps: 1120 | Loss: 63.227661 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:06 | Steps: 1122 | Loss: 63.279261 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:06 | Steps: 1124 | Loss: 63.290205 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:07 | Steps: 1126 | Loss: 63.288943 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:07 | Steps: 1129 | Loss: 63.325290 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:07 | Steps: 1131 | Loss: 63.329454 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:07 | Steps: 1133 | Loss: 63.332145 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:07 | Steps: 1135 | Loss: 63.360715 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:07 | Steps: 1137 | Loss: 63.337058 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:08 | Steps: 1140 | Loss: 63.389413 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:08 | Steps: 1142 | Loss: 63.394049 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:08 | Steps: 1144 | Loss: 63.411283 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:08 | Steps: 1146 | Loss: 63.415066 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:08 | Steps: 1148 | Loss: 63.409072 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:08 | Steps: 1151 | Loss: 63.476622 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:08 | Steps: 1153 | Loss: 63.460974 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:09 | Steps: 1155 | Loss: 63.481507 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:09 | Steps: 1156 | Loss: 63.494398 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:09 | Steps: 1158 | Loss: 63.567863 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:09 | Steps: 1160 | Loss: 63.559926 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:09 | Steps: 1162 | Loss: 63.586687 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:09 | Steps: 1164 | Loss: 63.642950 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:09 | Steps: 1166 | Loss: 63.656782 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:09 | Steps: 1168 | Loss: 63.679916 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:10 | Steps: 1170 | Loss: 63.681705 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:10 | Steps: 1172 | Loss: 63.676256 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:10 | Steps: 1174 | Loss: 63.674102 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:10 | Steps: 1176 | Loss: 63.692308 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:10 | Steps: 1179 | Loss: 63.808052 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:10 | Steps: 1180 | Loss: 63.798612 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:11 | Steps: 1182 | Loss: 63.796668 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:11 | Steps: 1184 | Loss: 63.809561 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:11 | Steps: 1186 | Loss: 63.812242 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:11 | Steps: 1188 | Loss: 63.819203 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:11 | Steps: 1190 | Loss: 63.883254 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:11 | Steps: 1192 | Loss: 63.902623 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:11 | Steps: 1194 | Loss: 63.964814 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:12 | Steps: 1197 | Loss: 64.008830 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:12 | Steps: 1199 | Loss: 64.016712 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:12 | Steps: 1201 | Loss: 64.019986 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:12 | Steps: 1202 | Loss: 64.029006 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:12 | Steps: 1204 | Loss: 64.048206 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:12 | Steps: 1206 | Loss: 64.069232 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:12 | Steps: 1208 | Loss: 64.081504 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:12 | Steps: 1210 | Loss: 64.085520 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:13 | Steps: 1213 | Loss: 64.128100 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:13 | Steps: 1215 | Loss: 64.103449 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:13 | Steps: 1216 | Loss: 64.114348 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:13 | Steps: 1218 | Loss: 64.102934 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:13 | Steps: 1220 | Loss: 64.142355 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:13 | Steps: 1222 | Loss: 64.141328 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:13 | Steps: 1224 | Loss: 64.139926 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:14 | Steps: 1227 | Loss: 64.123410 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:14 | Steps: 1229 | Loss: 64.125156 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:14 | Steps: 1231 | Loss: 64.170931 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:14 | Steps: 1233 | Loss: 64.187140 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:14 | Steps: 1235 | Loss: 64.204738 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:14 | Steps: 1237 | Loss: 64.223182 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:15 | Steps: 1240 | Loss: 64.316761 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:15 | Steps: 1242 | Loss: 64.334100 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:15 | Steps: 1244 | Loss: 64.352623 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:15 | Steps: 1247 | Loss: 64.380565 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:15 | Steps: 1249 | Loss: 64.362865 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:16 | Steps: 1251 | Loss: 64.391485 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:16 | Steps: 1252 | Loss: 64.383717 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:16 | Steps: 1255 | Loss: 64.473382 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:16 | Steps: 1258 | Loss: 64.477666 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:16 | Steps: 1259 | Loss: 64.470555 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:16 | Steps: 1261 | Loss: 64.454740 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:16 | Steps: 1263 | Loss: 64.475712 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:17 | Steps: 1265 | Loss: 64.492265 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:17 | Steps: 1267 | Loss: 64.512051 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:17 | Steps: 1269 | Loss: 64.486275 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:17 | Steps: 1272 | Loss: 64.490055 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:17 | Steps: 1275 | Loss: 64.499894 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:17 | Steps: 1276 | Loss: 64.520523 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:17 | Steps: 1278 | Loss: 64.520125 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:18 | Steps: 1280 | Loss: 64.539565 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:18 | Steps: 1281 | Loss: 64.574871 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:18 | Steps: 1283 | Loss: 64.577974 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:18 | Steps: 1286 | Loss: 64.603526 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:18 | Steps: 1289 | Loss: 64.581692 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:18 | Steps: 1291 | Loss: 64.588885 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:19 | Steps: 1293 | Loss: 64.647581 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:19 | Steps: 1295 | Loss: 64.718773 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:19 | Steps: 1297 | Loss: 64.697584 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:19 | Steps: 1299 | Loss: 64.698261 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:19 | Steps: 1301 | Loss: 64.722021 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:19 | Steps: 1302 | Loss: 64.711049 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:19 | Steps: 1304 | Loss: 64.736716 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:20 | Steps: 1306 | Loss: 64.758402 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:20 | Steps: 1308 | Loss: 64.741199 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:20 | Steps: 1310 | Loss: 64.732965 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:20 | Steps: 1312 | Loss: 64.715858 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:20 | Steps: 1314 | Loss: 64.705477 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:20 | Steps: 1316 | Loss: 64.730565 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:20 | Steps: 1317 | Loss: 64.729515 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:20 | Steps: 1319 | Loss: 64.729358 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:21 | Steps: 1321 | Loss: 64.707600 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:21 | Steps: 1323 | Loss: 64.774539 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:21 | Steps: 1325 | Loss: 64.816448 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:21 | Steps: 1328 | Loss: 64.858135 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:21 | Steps: 1331 | Loss: 64.870424 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:21 | Steps: 1332 | Loss: 64.907834 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:21 | Steps: 1334 | Loss: 64.879298 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:22 | Steps: 1336 | Loss: 64.899614 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:22 | Steps: 1339 | Loss: 64.893183 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:22 | Steps: 1341 | Loss: 64.946396 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:22 | Steps: 1343 | Loss: 64.961718 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:22 | Steps: 1345 | Loss: 64.962091 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:22 | Steps: 1347 | Loss: 64.943412 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:23 | Steps: 1349 | Loss: 64.990059 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:23 | Steps: 1352 | Loss: 65.041391 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:23 | Steps: 1353 | Loss: 65.046896 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:23 | Steps: 1355 | Loss: 65.033057 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:23 | Steps: 1356 | Loss: 65.032922 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:23 | Steps: 1359 | Loss: 65.073285 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:23 | Steps: 1360 | Loss: 65.118042 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:24 | Steps: 1363 | Loss: 65.142554 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:24 | Steps: 1364 | Loss: 65.158420 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:24 | Steps: 1366 | Loss: 65.202544 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:24 | Steps: 1367 | Loss: 65.207098 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:24 | Steps: 1369 | Loss: 65.213459 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:24 | Steps: 1371 | Loss: 65.212637 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:24 | Steps: 1374 | Loss: 65.237947 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:25 | Steps: 1376 | Loss: 65.249516 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:25 | Steps: 1378 | Loss: 65.234146 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:25 | Steps: 1379 | Loss: 65.219738 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:25 | Steps: 1382 | Loss: 65.271902 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:25 | Steps: 1384 | Loss: 65.261933 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:25 | Steps: 1386 | Loss: 65.281008 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:25 | Steps: 1388 | Loss: 65.320336 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:26 | Steps: 1390 | Loss: 65.342616 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:26 | Steps: 1393 | Loss: 65.345512 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:26 | Steps: 1395 | Loss: 65.349701 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:26 | Steps: 1398 | Loss: 65.366627 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:26 | Steps: 1400 | Loss: 65.356027 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:26 | Steps: 1402 | Loss: 65.354609 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:27 | Steps: 1404 | Loss: 65.411253 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:27 | Steps: 1406 | Loss: 65.425184 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:27 | Steps: 1408 | Loss: 65.449611 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:27 | Steps: 1410 | Loss: 65.464295 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:27 | Steps: 1412 | Loss: 65.469797 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:27 | Steps: 1414 | Loss: 65.455521 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:27 | Steps: 1416 | Loss: 65.476282 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:28 | Steps: 1419 | Loss: 65.513696 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:28 | Steps: 1421 | Loss: 65.528211 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:28 | Steps: 1423 | Loss: 65.533162 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:28 | Steps: 1425 | Loss: 65.542295 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:28 | Steps: 1427 | Loss: 65.508933 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:28 | Steps: 1429 | Loss: 65.521596 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:29 | Steps: 1431 | Loss: 65.531484 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:29 | Steps: 1433 | Loss: 65.541109 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:29 | Steps: 1436 | Loss: 65.534166 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:29 | Steps: 1438 | Loss: 65.554922 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:29 | Steps: 1440 | Loss: 65.581991 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:29 | Steps: 1442 | Loss: 65.620350 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:30 | Steps: 1445 | Loss: 65.644453 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:30 | Steps: 1447 | Loss: 65.681976 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:30 | Steps: 1448 | Loss: 65.712268 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:30 | Steps: 1450 | Loss: 65.720387 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:30 | Steps: 1452 | Loss: 65.737612 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:30 | Steps: 1455 | Loss: 65.747784 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:30 | Steps: 1457 | Loss: 65.775658 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:31 | Steps: 1460 | Loss: 65.795215 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:31 | Steps: 1462 | Loss: 65.800136 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:31 | Steps: 1464 | Loss: 65.787399 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:31 | Steps: 1466 | Loss: 65.804406 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:31 | Steps: 1468 | Loss: 65.775055 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:31 | Steps: 1470 | Loss: 65.783669 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:32 | Steps: 1472 | Loss: 65.872423 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:32 | Steps: 1474 | Loss: 65.866387 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:32 | Steps: 1476 | Loss: 65.908627 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:32 | Steps: 1479 | Loss: 65.894244 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:32 | Steps: 1481 | Loss: 65.947028 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:32 | Steps: 1483 | Loss: 65.952170 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:32 | Steps: 1485 | Loss: 65.959251 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:33 | Steps: 1488 | Loss: 65.981299 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:33 | Steps: 1490 | Loss: 65.986129 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:33 | Steps: 1492 | Loss: 66.009608 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:34 | Steps: 1494 | Loss: 66.038787 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:34 | Steps: 1496 | Loss: 66.091794 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:34 | Steps: 1498 | Loss: 66.128288 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:34 | Steps: 1501 | Loss: 66.151220 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:34 | Steps: 1503 | Loss: 66.168185 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:34 | Steps: 1505 | Loss: 66.186303 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:34 | Steps: 1507 | Loss: 66.193210 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:35 | Steps: 1509 | Loss: 66.199140 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:35 | Steps: 1512 | Loss: 66.206871 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:35 | Steps: 1515 | Loss: 66.211949 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:35 | Steps: 1518 | Loss: 66.240684 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:35 | Steps: 1519 | Loss: 66.237193 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:36 | Steps: 1521 | Loss: 66.251026 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:36 | Steps: 1524 | Loss: 66.276703 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:36 | Steps: 1526 | Loss: 66.312267 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:36 | Steps: 1528 | Loss: 66.320200 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:36 | Steps: 1530 | Loss: 66.331418 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:36 | Steps: 1531 | Loss: 66.330064 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:36 | Steps: 1533 | Loss: 66.336094 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:37 | Steps: 1535 | Loss: 66.359360 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:37 | Steps: 1537 | Loss: 66.349236 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:37 | Steps: 1539 | Loss: 66.334450 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:37 | Steps: 1541 | Loss: 66.322518 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:37 | Steps: 1543 | Loss: 66.355286 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:37 | Steps: 1545 | Loss: 66.409674 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:37 | Steps: 1547 | Loss: 66.418358 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:38 | Steps: 1549 | Loss: 66.425584 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:38 | Steps: 1552 | Loss: 66.413670 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:38 | Steps: 1554 | Loss: 66.437451 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:38 | Steps: 1555 | Loss: 66.470685 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:38 | Steps: 1557 | Loss: 66.432988 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:38 | Steps: 1559 | Loss: 66.489220 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:38 | Steps: 1561 | Loss: 66.469874 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:39 | Steps: 1563 | Loss: 66.503661 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:39 | Steps: 1566 | Loss: 66.546701 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:39 | Steps: 1568 | Loss: 66.580881 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:39 | Steps: 1570 | Loss: 66.597642 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:39 | Steps: 1573 | Loss: 66.596414 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:40 | Steps: 1575 | Loss: 66.607291 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:40 | Steps: 1578 | Loss: 66.651876 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:40 | Steps: 1580 | Loss: 66.651763 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:40 | Steps: 1583 | Loss: 66.660378 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:40 | Steps: 1585 | Loss: 66.679534 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:40 | Steps: 1587 | Loss: 66.682997 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:41 | Steps: 1589 | Loss: 66.708424 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:41 | Steps: 1591 | Loss: 66.714405 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:41 | Steps: 1593 | Loss: 66.717084 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:41 | Steps: 1595 | Loss: 66.750114 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:41 | Steps: 1597 | Loss: 66.874897 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:41 | Steps: 1599 | Loss: 66.875515 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:41 | Steps: 1601 | Loss: 66.872710 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:42 | Steps: 1604 | Loss: 66.967998 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:42 | Steps: 1605 | Loss: 66.989897 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:42 | Steps: 1607 | Loss: 67.001885 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:42 | Steps: 1610 | Loss: 67.049182 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:42 | Steps: 1613 | Loss: 67.042200 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:42 | Steps: 1615 | Loss: 67.055350 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:43 | Steps: 1617 | Loss: 67.071786 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:43 | Steps: 1618 | Loss: 67.072062 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:43 | Steps: 1621 | Loss: 67.094676 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:43 | Steps: 1622 | Loss: 67.085401 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:43 | Steps: 1624 | Loss: 67.086291 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:43 | Steps: 1626 | Loss: 67.103900 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:43 | Steps: 1628 | Loss: 67.106213 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:44 | Steps: 1630 | Loss: 67.129960 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:44 | Steps: 1633 | Loss: 67.114004 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:44 | Steps: 1635 | Loss: 67.108911 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:44 | Steps: 1637 | Loss: 67.139234 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:44 | Steps: 1639 | Loss: 67.138021 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:44 | Steps: 1642 | Loss: 67.191654 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:45 | Steps: 1644 | Loss: 67.211763 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:45 | Steps: 1646 | Loss: 67.239290 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:45 | Steps: 1648 | Loss: 67.280727 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:45 | Steps: 1650 | Loss: 67.302995 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:45 | Steps: 1652 | Loss: 67.328653 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:46 | Steps: 1654 | Loss: 67.323346 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:46 | Steps: 1656 | Loss: 67.309273 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:46 | Steps: 1658 | Loss: 67.322205 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:46 | Steps: 1660 | Loss: 67.328955 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:46 | Steps: 1662 | Loss: 67.318022 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:46 | Steps: 1663 | Loss: 67.326373 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:46 | Steps: 1665 | Loss: 67.368070 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:47 | Steps: 1667 | Loss: 67.362030 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:47 | Steps: 1669 | Loss: 67.392905 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:47 | Steps: 1671 | Loss: 67.389332 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:47 | Steps: 1673 | Loss: 67.403767 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:47 | Steps: 1675 | Loss: 67.439433 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:47 | Steps: 1676 | Loss: 67.449729 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:47 | Steps: 1678 | Loss: 67.504643 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:48 | Steps: 1681 | Loss: 67.539110 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:48 | Steps: 1683 | Loss: 67.558496 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:48 | Steps: 1685 | Loss: 67.578605 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:48 | Steps: 1687 | Loss: 67.586338 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:48 | Steps: 1689 | Loss: 67.584528 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:48 | Steps: 1691 | Loss: 67.600693 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:49 | Steps: 1693 | Loss: 67.614891 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:49 | Steps: 1695 | Loss: 67.613111 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:49 | Steps: 1698 | Loss: 67.611503 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:49 | Steps: 1700 | Loss: 67.611464 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:49 | Steps: 1702 | Loss: 67.639951 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:49 | Steps: 1703 | Loss: 67.682715 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:50 | Steps: 1706 | Loss: 67.721706 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:50 | Steps: 1708 | Loss: 67.707183 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:50 | Steps: 1710 | Loss: 67.695530 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:50 | Steps: 1711 | Loss: 67.689485 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:50 | Steps: 1713 | Loss: 67.697532 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:50 | Steps: 1715 | Loss: 67.748336 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:50 | Steps: 1717 | Loss: 67.756325 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:50 | Steps: 1718 | Loss: 67.769578 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:51 | Steps: 1720 | Loss: 67.816103 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:51 | Steps: 1722 | Loss: 67.832495 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:51 | Steps: 1724 | Loss: 67.824724 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:51 | Steps: 1726 | Loss: 67.870858 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:51 | Steps: 1729 | Loss: 67.901390 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:52 | Steps: 1732 | Loss: 67.939269 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:52 | Steps: 1734 | Loss: 67.977267 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:52 | Steps: 1735 | Loss: 67.996851 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:52 | Steps: 1737 | Loss: 68.013639 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:52 | Steps: 1739 | Loss: 68.005366 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:52 | Steps: 1741 | Loss: 68.013523 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:53 | Steps: 1743 | Loss: 68.011441 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:53 | Steps: 1746 | Loss: 68.009540 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:53 | Steps: 1747 | Loss: 68.023136 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:53 | Steps: 1750 | Loss: 68.028127 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:53 | Steps: 1752 | Loss: 68.064751 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:53 | Steps: 1754 | Loss: 68.054568 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:53 | Steps: 1756 | Loss: 68.052404 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:54 | Steps: 1758 | Loss: 68.071201 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:54 | Steps: 1760 | Loss: 68.085229 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:54 | Steps: 1762 | Loss: 68.082172 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:54 | Steps: 1764 | Loss: 68.095708 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:54 | Steps: 1766 | Loss: 68.106544 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:54 | Steps: 1768 | Loss: 68.142100 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:55 | Steps: 1770 | Loss: 68.163089 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:55 | Steps: 1772 | Loss: 68.159951 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:55 | Steps: 1775 | Loss: 68.182872 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:55 | Steps: 1777 | Loss: 68.229987 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:55 | Steps: 1778 | Loss: 68.254870 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:55 | Steps: 1780 | Loss: 68.274807 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:55 | Steps: 1781 | Loss: 68.281313 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:56 | Steps: 1783 | Loss: 68.284037 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:56 | Steps: 1785 | Loss: 68.283831 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:56 | Steps: 1787 | Loss: 68.310711 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:56 | Steps: 1789 | Loss: 68.318762 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:56 | Steps: 1790 | Loss: 68.323193 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:56 | Steps: 1792 | Loss: 68.324664 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:56 | Steps: 1793 | Loss: 68.327388 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:57 | Steps: 1795 | Loss: 68.376688 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:57 | Steps: 1797 | Loss: 68.366663 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:57 | Steps: 1799 | Loss: 68.368518 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:57 | Steps: 1801 | Loss: 68.416939 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:57 | Steps: 1803 | Loss: 68.456322 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:57 | Steps: 1805 | Loss: 68.462514 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:58 | Steps: 1808 | Loss: 68.478367 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:58 | Steps: 1810 | Loss: 68.489229 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:58 | Steps: 1812 | Loss: 68.540420 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:58 | Steps: 1814 | Loss: 68.547613 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:58 | Steps: 1816 | Loss: 68.566151 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:58 | Steps: 1818 | Loss: 68.586292 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:58 | Steps: 1821 | Loss: 68.581581 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:59 | Steps: 1822 | Loss: 68.604532 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:59 | Steps: 1824 | Loss: 68.630504 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:59 | Steps: 1827 | Loss: 68.651551 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:59 | Steps: 1830 | Loss: 68.669652 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:01:59 | Steps: 1833 | Loss: 68.698070 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:00 | Steps: 1836 | Loss: 68.685218 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:00 | Steps: 1838 | Loss: 68.681090 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:00 | Steps: 1840 | Loss: 68.724478 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:00 | Steps: 1843 | Loss: 68.758512 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:00 | Steps: 1845 | Loss: 68.758482 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:01 | Steps: 1847 | Loss: 68.768510 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:01 | Steps: 1849 | Loss: 68.805912 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:01 | Steps: 1850 | Loss: 68.833986 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:01 | Steps: 1853 | Loss: 68.841565 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:01 | Steps: 1855 | Loss: 68.846506 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:01 | Steps: 1857 | Loss: 68.866465 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:02 | Steps: 1859 | Loss: 68.879569 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:02 | Steps: 1861 | Loss: 68.887614 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:02 | Steps: 1864 | Loss: 68.922249 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:02 | Steps: 1866 | Loss: 68.946089 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:02 | Steps: 1868 | Loss: 68.948583 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:02 | Steps: 1870 | Loss: 68.981430 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:03 | Steps: 1872 | Loss: 68.971239 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:03 | Steps: 1874 | Loss: 68.981789 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:03 | Steps: 1876 | Loss: 69.018364 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:03 | Steps: 1879 | Loss: 69.053856 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:03 | Steps: 1881 | Loss: 69.042705 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:03 | Steps: 1883 | Loss: 69.094595 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:04 | Steps: 1886 | Loss: 69.118333 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:04 | Steps: 1888 | Loss: 69.151553 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:04 | Steps: 1890 | Loss: 69.165285 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:04 | Steps: 1892 | Loss: 69.181612 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:04 | Steps: 1894 | Loss: 69.162573 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:05 | Steps: 1897 | Loss: 69.187121 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:05 | Steps: 1899 | Loss: 69.190972 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:05 | Steps: 1900 | Loss: 69.192759 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:05 | Steps: 1902 | Loss: 69.193547 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:05 | Steps: 1905 | Loss: 69.189059 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:05 | Steps: 1907 | Loss: 69.258431 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:05 | Steps: 1908 | Loss: 69.251712 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:06 | Steps: 1910 | Loss: 69.249521 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:06 | Steps: 1912 | Loss: 69.276235 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:06 | Steps: 1914 | Loss: 69.268651 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:06 | Steps: 1916 | Loss: 69.312126 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:06 | Steps: 1918 | Loss: 69.336159 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:07 | Steps: 1920 | Loss: 69.343745 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:07 | Steps: 1922 | Loss: 69.361666 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:07 | Steps: 1924 | Loss: 69.383748 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:07 | Steps: 1926 | Loss: 69.402415 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:07 | Steps: 1928 | Loss: 69.425910 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:07 | Steps: 1929 | Loss: 69.421522 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:07 | Steps: 1931 | Loss: 69.436544 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:07 | Steps: 1932 | Loss: 69.443404 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:08 | Steps: 1934 | Loss: 69.430280 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:08 | Steps: 1936 | Loss: 69.453724 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:08 | Steps: 1939 | Loss: 69.467098 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:08 | Steps: 1941 | Loss: 69.504781 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:08 | Steps: 1943 | Loss: 69.499510 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 1945 | Loss: 69.489621 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 1947 | Loss: 69.511559 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 1949 | Loss: 69.520198 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 1950 | Loss: 69.527011 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 1952 | Loss: 69.550073 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 1953 | Loss: 69.557785 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 1955 | Loss: 69.567493 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 1956 | Loss: 69.582968 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:10 | Steps: 1958 | Loss: 69.589100 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:10 | Steps: 1960 | Loss: 69.623079 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:10 | Steps: 1962 | Loss: 69.618507 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:10 | Steps: 1964 | Loss: 69.632312 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:10 | Steps: 1967 | Loss: 69.654372 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:11 | Steps: 1969 | Loss: 69.661957 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:11 | Steps: 1971 | Loss: 69.673437 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:11 | Steps: 1974 | Loss: 69.674028 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:11 | Steps: 1975 | Loss: 69.668172 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:11 | Steps: 1977 | Loss: 69.668699 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:11 | Steps: 1979 | Loss: 69.663373 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:12 | Steps: 1981 | Loss: 69.659725 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:12 | Steps: 1983 | Loss: 69.676280 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:12 | Steps: 1985 | Loss: 69.697053 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:12 | Steps: 1987 | Loss: 69.692168 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:12 | Steps: 1988 | Loss: 69.697992 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:12 | Steps: 1990 | Loss: 69.710629 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:13 | Steps: 1993 | Loss: 69.769083 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:13 | Steps: 1995 | Loss: 69.787350 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:13 | Steps: 1997 | Loss: 69.810023 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:13 | Steps: 1999 | Loss: 69.831546 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:13 | Steps: 2001 | Loss: 69.839657 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:13 | Steps: 2003 | Loss: 69.871302 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:13 | Steps: 2005 | Loss: 69.901154 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:14 | Steps: 2007 | Loss: 69.904691 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:14 | Steps: 2009 | Loss: 69.939611 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:14 | Steps: 2011 | Loss: 69.953473 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:14 | Steps: 2013 | Loss: 69.958132 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:14 | Steps: 2015 | Loss: 69.951345 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:15 | Steps: 2017 | Loss: 69.997396 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:15 | Steps: 2019 | Loss: 70.013558 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:15 | Steps: 2021 | Loss: 70.053073 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:15 | Steps: 2024 | Loss: 70.069275 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:15 | Steps: 2026 | Loss: 70.104886 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:15 | Steps: 2028 | Loss: 70.115098 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:16 | Steps: 2030 | Loss: 70.140572 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:16 | Steps: 2031 | Loss: 70.142079 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:16 | Steps: 2033 | Loss: 70.131279 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:16 | Steps: 2035 | Loss: 70.133686 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:16 | Steps: 2037 | Loss: 70.132113 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:16 | Steps: 2039 | Loss: 70.137729 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:17 | Steps: 2041 | Loss: 70.135397 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:17 | Steps: 2043 | Loss: 70.155348 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:17 | Steps: 2045 | Loss: 70.174516 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:17 | Steps: 2047 | Loss: 70.182040 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:17 | Steps: 2049 | Loss: 70.182103 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:17 | Steps: 2051 | Loss: 70.215407 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:17 | Steps: 2053 | Loss: 70.244131 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:18 | Steps: 2055 | Loss: 70.277403 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:18 | Steps: 2057 | Loss: 70.288996 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:18 | Steps: 2059 | Loss: 70.295006 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:18 | Steps: 2061 | Loss: 70.334298 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:18 | Steps: 2063 | Loss: 70.344884 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:19 | Steps: 2065 | Loss: 70.345042 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:19 | Steps: 2067 | Loss: 70.358067 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:19 | Steps: 2069 | Loss: 70.360055 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:19 | Steps: 2071 | Loss: 70.373349 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:19 | Steps: 2073 | Loss: 70.402476 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:19 | Steps: 2074 | Loss: 70.395988 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:20 | Steps: 2076 | Loss: 70.393864 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:20 | Steps: 2078 | Loss: 70.422961 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:20 | Steps: 2080 | Loss: 70.449618 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:20 | Steps: 2082 | Loss: 70.461792 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:20 | Steps: 2084 | Loss: 70.455341 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:20 | Steps: 2086 | Loss: 70.476504 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:21 | Steps: 2088 | Loss: 70.510265 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:21 | Steps: 2090 | Loss: 70.527318 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:21 | Steps: 2093 | Loss: 70.554098 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:21 | Steps: 2094 | Loss: 70.568675 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:21 | Steps: 2096 | Loss: 70.581582 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:21 | Steps: 2098 | Loss: 70.604604 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:22 | Steps: 2100 | Loss: 70.600856 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:22 | Steps: 2103 | Loss: 70.638096 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:22 | Steps: 2106 | Loss: 70.658370 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:22 | Steps: 2108 | Loss: 70.650476 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:22 | Steps: 2110 | Loss: 70.671818 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:23 | Steps: 2112 | Loss: 70.697548 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:23 | Steps: 2113 | Loss: 70.709787 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:23 | Steps: 2115 | Loss: 70.712207 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:23 | Steps: 2117 | Loss: 70.730848 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:23 | Steps: 2119 | Loss: 70.759692 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:23 | Steps: 2121 | Loss: 70.780243 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:24 | Steps: 2124 | Loss: 70.807856 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:24 | Steps: 2126 | Loss: 70.809890 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:24 | Steps: 2128 | Loss: 70.808981 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:24 | Steps: 2130 | Loss: 70.821989 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:24 | Steps: 2132 | Loss: 70.819592 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:24 | Steps: 2133 | Loss: 70.848564 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:24 | Steps: 2135 | Loss: 70.852722 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:25 | Steps: 2136 | Loss: 70.869541 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:25 | Steps: 2138 | Loss: 70.856458 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:25 | Steps: 2139 | Loss: 70.857287 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:25 | Steps: 2140 | Loss: 70.861408 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:25 | Steps: 2143 | Loss: 70.900410 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:25 | Steps: 2144 | Loss: 70.905809 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:25 | Steps: 2146 | Loss: 70.917224 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:26 | Steps: 2148 | Loss: 70.910522 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:26 | Steps: 2150 | Loss: 70.924530 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:26 | Steps: 2152 | Loss: 70.944968 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:26 | Steps: 2154 | Loss: 70.987443 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:26 | Steps: 2156 | Loss: 71.011002 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:27 | Steps: 2159 | Loss: 71.040170 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:27 | Steps: 2161 | Loss: 71.068010 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:27 | Steps: 2163 | Loss: 71.080453 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:27 | Steps: 2165 | Loss: 71.082720 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:27 | Steps: 2167 | Loss: 71.098447 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:27 | Steps: 2169 | Loss: 71.151174 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:27 | Steps: 2170 | Loss: 71.163260 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:28 | Steps: 2172 | Loss: 71.180711 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:28 | Steps: 2174 | Loss: 71.189308 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:28 | Steps: 2176 | Loss: 71.194762 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:28 | Steps: 2178 | Loss: 71.248268 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:28 | Steps: 2181 | Loss: 71.289016 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:29 | Steps: 2184 | Loss: 71.327967 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:29 | Steps: 2185 | Loss: 71.344781 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:29 | Steps: 2187 | Loss: 71.351246 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:29 | Steps: 2189 | Loss: 71.378621 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:29 | Steps: 2191 | Loss: 71.395244 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:29 | Steps: 2193 | Loss: 71.444315 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:30 | Steps: 2195 | Loss: 71.443729 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:30 | Steps: 2197 | Loss: 71.441576 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:30 | Steps: 2200 | Loss: 71.472612 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:30 | Steps: 2202 | Loss: 71.473123 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:30 | Steps: 2204 | Loss: 71.474350 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:31 | Steps: 2206 | Loss: 71.484204 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:31 | Steps: 2207 | Loss: 71.486671 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:31 | Steps: 2209 | Loss: 71.512151 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:31 | Steps: 2210 | Loss: 71.517348 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:31 | Steps: 2212 | Loss: 71.534678 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:31 | Steps: 2214 | Loss: 71.553770 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:32 | Steps: 2216 | Loss: 71.569325 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:32 | Steps: 2218 | Loss: 71.571849 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:32 | Steps: 2220 | Loss: 71.574568 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:32 | Steps: 2222 | Loss: 71.603871 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:32 | Steps: 2224 | Loss: 71.624637 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:32 | Steps: 2225 | Loss: 71.633592 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:33 | Steps: 2227 | Loss: 71.653365 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:33 | Steps: 2229 | Loss: 71.662198 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:33 | Steps: 2231 | Loss: 71.665590 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:33 | Steps: 2233 | Loss: 71.677331 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:33 | Steps: 2235 | Loss: 71.721368 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:33 | Steps: 2237 | Loss: 71.760525 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:34 | Steps: 2239 | Loss: 71.814155 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:34 | Steps: 2241 | Loss: 71.851737 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:34 | Steps: 2243 | Loss: 71.889626 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:34 | Steps: 2245 | Loss: 71.900887 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:34 | Steps: 2247 | Loss: 71.938090 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:35 | Steps: 2249 | Loss: 71.966314 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:35 | Steps: 2251 | Loss: 71.998840 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:35 | Steps: 2252 | Loss: 72.012389 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:36 | Steps: 2254 | Loss: 72.047369 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:36 | Steps: 2256 | Loss: 72.040588 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:36 | Steps: 2258 | Loss: 72.056721 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:36 | Steps: 2260 | Loss: 72.068716 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:36 | Steps: 2263 | Loss: 72.101203 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:37 | Steps: 2265 | Loss: 72.108680 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:37 | Steps: 2267 | Loss: 72.110628 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:37 | Steps: 2268 | Loss: 72.120240 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:37 | Steps: 2269 | Loss: 72.128793 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:37 | Steps: 2271 | Loss: 72.132788 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:37 | Steps: 2273 | Loss: 72.159529 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:37 | Steps: 2275 | Loss: 72.163261 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:38 | Steps: 2276 | Loss: 72.190119 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:38 | Steps: 2278 | Loss: 72.227270 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:38 | Steps: 2280 | Loss: 72.227806 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:38 | Steps: 2282 | Loss: 72.246112 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:38 | Steps: 2284 | Loss: 72.244207 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:38 | Steps: 2286 | Loss: 72.252981 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:39 | Steps: 2287 | Loss: 72.245524 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:39 | Steps: 2289 | Loss: 72.255314 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:39 | Steps: 2291 | Loss: 72.277492 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:39 | Steps: 2292 | Loss: 72.286349 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:39 | Steps: 2294 | Loss: 72.273306 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:39 | Steps: 2296 | Loss: 72.300093 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:40 | Steps: 2298 | Loss: 72.322682 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:40 | Steps: 2300 | Loss: 72.352677 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:40 | Steps: 2302 | Loss: 72.368604 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:40 | Steps: 2304 | Loss: 72.396009 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:40 | Steps: 2306 | Loss: 72.401215 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:41 | Steps: 2308 | Loss: 72.447432 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:41 | Steps: 2310 | Loss: 72.469250 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:41 | Steps: 2312 | Loss: 72.474237 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:41 | Steps: 2313 | Loss: 72.472233 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:41 | Steps: 2315 | Loss: 72.463485 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:41 | Steps: 2317 | Loss: 72.468391 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:42 | Steps: 2319 | Loss: 72.473924 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:42 | Steps: 2321 | Loss: 72.477393 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:42 | Steps: 2323 | Loss: 72.527875 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:42 | Steps: 2325 | Loss: 72.547196 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:42 | Steps: 2327 | Loss: 72.575121 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:43 | Steps: 2329 | Loss: 72.603283 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:43 | Steps: 2331 | Loss: 72.624399 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:43 | Steps: 2333 | Loss: 72.634542 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:43 | Steps: 2334 | Loss: 72.669594 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:43 | Steps: 2336 | Loss: 72.664227 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:43 | Steps: 2338 | Loss: 72.687996 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:44 | Steps: 2340 | Loss: 72.716330 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:44 | Steps: 2343 | Loss: 72.722909 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:44 | Steps: 2345 | Loss: 72.743059 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:44 | Steps: 2348 | Loss: 72.732152 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:45 | Steps: 2350 | Loss: 72.758666 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:45 | Steps: 2352 | Loss: 72.771755 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:45 | Steps: 2353 | Loss: 72.783628 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:45 | Steps: 2354 | Loss: 72.800849 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:45 | Steps: 2356 | Loss: 72.833449 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:45 | Steps: 2358 | Loss: 72.847812 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:45 | Steps: 2359 | Loss: 72.846310 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:45 | Steps: 2361 | Loss: 72.877795 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:46 | Steps: 2362 | Loss: 72.868984 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:46 | Steps: 2364 | Loss: 72.886886 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:46 | Steps: 2366 | Loss: 72.906463 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:46 | Steps: 2368 | Loss: 72.913900 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:46 | Steps: 2369 | Loss: 72.915145 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:46 | Steps: 2371 | Loss: 72.934573 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:47 | Steps: 2373 | Loss: 72.942228 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:47 | Steps: 2375 | Loss: 72.995114 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:47 | Steps: 2377 | Loss: 73.040075 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:47 | Steps: 2379 | Loss: 73.049094 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:47 | Steps: 2381 | Loss: 73.063261 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:48 | Steps: 2383 | Loss: 73.066837 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:48 | Steps: 2385 | Loss: 73.089162 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:48 | Steps: 2387 | Loss: 73.098419 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:48 | Steps: 2389 | Loss: 73.103768 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:48 | Steps: 2391 | Loss: 73.100311 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:49 | Steps: 2393 | Loss: 73.102464 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:49 | Steps: 2395 | Loss: 73.117636 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:49 | Steps: 2398 | Loss: 73.151446 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:49 | Steps: 2400 | Loss: 73.180494 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:50 | Steps: 2402 | Loss: 73.195572 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:50 | Steps: 2405 | Loss: 73.234720 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:50 | Steps: 2406 | Loss: 73.248971 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:50 | Steps: 2408 | Loss: 73.275387 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:50 | Steps: 2409 | Loss: 73.274707 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:50 | Steps: 2411 | Loss: 73.306300 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:50 | Steps: 2413 | Loss: 73.334474 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:51 | Steps: 2415 | Loss: 73.341811 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:51 | Steps: 2417 | Loss: 73.348493 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:51 | Steps: 2419 | Loss: 73.356915 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:51 | Steps: 2421 | Loss: 73.383728 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:51 | Steps: 2422 | Loss: 73.382262 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:51 | Steps: 2424 | Loss: 73.385696 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:52 | Steps: 2426 | Loss: 73.403571 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:52 | Steps: 2428 | Loss: 73.415496 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:52 | Steps: 2430 | Loss: 73.433595 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:52 | Steps: 2432 | Loss: 73.456143 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:52 | Steps: 2434 | Loss: 73.476373 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:53 | Steps: 2436 | Loss: 73.487864 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:53 | Steps: 2438 | Loss: 73.507727 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:53 | Steps: 2440 | Loss: 73.549185 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:53 | Steps: 2442 | Loss: 73.567942 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:53 | Steps: 2444 | Loss: 73.597892 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:53 | Steps: 2445 | Loss: 73.609801 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:54 | Steps: 2447 | Loss: 73.619568 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:54 | Steps: 2449 | Loss: 73.672295 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:54 | Steps: 2451 | Loss: 73.688239 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:54 | Steps: 2453 | Loss: 73.686589 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:54 | Steps: 2455 | Loss: 73.704981 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:55 | Steps: 2456 | Loss: 73.713034 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:55 | Steps: 2458 | Loss: 73.736504 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:55 | Steps: 2460 | Loss: 73.723716 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:55 | Steps: 2462 | Loss: 73.732495 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:55 | Steps: 2464 | Loss: 73.776099 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:55 | Steps: 2466 | Loss: 73.795964 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:56 | Steps: 2467 | Loss: 73.804273 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:56 | Steps: 2469 | Loss: 73.817407 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:56 | Steps: 2471 | Loss: 73.839803 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:56 | Steps: 2473 | Loss: 73.834960 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:56 | Steps: 2475 | Loss: 73.879227 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:57 | Steps: 2477 | Loss: 73.914722 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:57 | Steps: 2479 | Loss: 73.957801 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:57 | Steps: 2481 | Loss: 73.975376 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:57 | Steps: 2483 | Loss: 73.982748 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:57 | Steps: 2484 | Loss: 73.990969 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:57 | Steps: 2486 | Loss: 74.001674 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:58 | Steps: 2488 | Loss: 74.027380 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:58 | Steps: 2490 | Loss: 74.037090 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:58 | Steps: 2492 | Loss: 74.047439 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:58 | Steps: 2494 | Loss: 74.052269 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:58 | Steps: 2496 | Loss: 74.058309 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:59 | Steps: 2498 | Loss: 74.084973 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:59 | Steps: 2500 | Loss: 74.085514 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:59 | Steps: 2501 | Loss: 74.082643 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:59 | Steps: 2503 | Loss: 74.084832 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:59 | Steps: 2504 | Loss: 74.086153 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:59 | Steps: 2506 | Loss: 74.217578 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:02:59 | Steps: 2507 | Loss: 74.218041 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:00 | Steps: 2509 | Loss: 74.240903 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:00 | Steps: 2510 | Loss: 74.255561 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:00 | Steps: 2512 | Loss: 74.276155 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:00 | Steps: 2513 | Loss: 74.294333 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:00 | Steps: 2515 | Loss: 74.315017 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:00 | Steps: 2516 | Loss: 74.324175 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:01 | Steps: 2517 | Loss: 74.325860 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:01 | Steps: 2518 | Loss: 74.320307 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:01 | Steps: 2520 | Loss: 74.341160 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:01 | Steps: 2521 | Loss: 74.348095 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:01 | Steps: 2523 | Loss: 74.373490 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:01 | Steps: 2525 | Loss: 74.396738 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:02 | Steps: 2527 | Loss: 74.453842 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:02 | Steps: 2529 | Loss: 74.486814 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:02 | Steps: 2532 | Loss: 74.550493 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:02 | Steps: 2534 | Loss: 74.574911 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:02 | Steps: 2536 | Loss: 74.605969 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:03 | Steps: 2538 | Loss: 74.616558 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:03 | Steps: 2540 | Loss: 74.627706 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:03 | Steps: 2542 | Loss: 74.643861 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:03 | Steps: 2544 | Loss: 74.658007 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:03 | Steps: 2546 | Loss: 74.677837 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:04 | Steps: 2548 | Loss: 74.684380 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:04 | Steps: 2550 | Loss: 74.724267 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:04 | Steps: 2551 | Loss: 74.742771 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:04 | Steps: 2553 | Loss: 74.759864 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:04 | Steps: 2554 | Loss: 74.774001 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:04 | Steps: 2556 | Loss: 74.797712 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:05 | Steps: 2558 | Loss: 74.817313 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:05 | Steps: 2560 | Loss: 74.848392 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:05 | Steps: 2561 | Loss: 74.854234 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:05 | Steps: 2563 | Loss: 74.860850 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:05 | Steps: 2565 | Loss: 74.868705 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:05 | Steps: 2566 | Loss: 74.878042 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:05 | Steps: 2567 | Loss: 74.882165 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:06 | Steps: 2569 | Loss: 74.860156 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:06 | Steps: 2571 | Loss: 74.865620 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:06 | Steps: 2573 | Loss: 74.890081 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:06 | Steps: 2574 | Loss: 74.895541 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:06 | Steps: 2576 | Loss: 74.900371 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:07 | Steps: 2578 | Loss: 74.917027 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:07 | Steps: 2580 | Loss: 74.926054 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:07 | Steps: 2582 | Loss: 74.920462 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:07 | Steps: 2583 | Loss: 74.928431 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:07 | Steps: 2585 | Loss: 74.950635 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:07 | Steps: 2587 | Loss: 74.969732 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:08 | Steps: 2589 | Loss: 74.983826 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:08 | Steps: 2591 | Loss: 75.000288 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:08 | Steps: 2593 | Loss: 75.028076 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:08 | Steps: 2595 | Loss: 75.045458 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:08 | Steps: 2597 | Loss: 75.066704 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:09 | Steps: 2599 | Loss: 75.073207 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:09 | Steps: 2601 | Loss: 75.070729 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:09 | Steps: 2603 | Loss: 75.070483 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:09 | Steps: 2605 | Loss: 75.095543 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:09 | Steps: 2607 | Loss: 75.123668 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:10 | Steps: 2609 | Loss: 75.188568 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:10 | Steps: 2611 | Loss: 75.190090 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:10 | Steps: 2613 | Loss: 75.211954 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:10 | Steps: 2614 | Loss: 75.219510 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:10 | Steps: 2616 | Loss: 75.218643 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:11 | Steps: 2618 | Loss: 75.222671 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:11 | Steps: 2620 | Loss: 75.244434 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:11 | Steps: 2622 | Loss: 75.255933 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:11 | Steps: 2624 | Loss: 75.264979 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:11 | Steps: 2626 | Loss: 75.271376 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:12 | Steps: 2628 | Loss: 75.270738 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:12 | Steps: 2630 | Loss: 75.284272 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:12 | Steps: 2632 | Loss: 75.301615 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:12 | Steps: 2633 | Loss: 75.325082 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:12 | Steps: 2635 | Loss: 75.336336 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:12 | Steps: 2636 | Loss: 75.342997 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:12 | Steps: 2637 | Loss: 75.349107 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:13 | Steps: 2639 | Loss: 75.378619 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:13 | Steps: 2640 | Loss: 75.381586 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:13 | Steps: 2642 | Loss: 75.422933 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:13 | Steps: 2644 | Loss: 75.448615 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:13 | Steps: 2646 | Loss: 75.481516 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:14 | Steps: 2648 | Loss: 75.487334 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:14 | Steps: 2650 | Loss: 75.508883 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:14 | Steps: 2651 | Loss: 75.517470 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:14 | Steps: 2652 | Loss: 75.538564 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:14 | Steps: 2654 | Loss: 75.547468 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:14 | Steps: 2655 | Loss: 75.568245 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:14 | Steps: 2656 | Loss: 75.566111 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:15 | Steps: 2658 | Loss: 75.573692 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:15 | Steps: 2660 | Loss: 75.601654 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:15 | Steps: 2662 | Loss: 75.610457 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:15 | Steps: 2664 | Loss: 75.644786 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:15 | Steps: 2665 | Loss: 75.659016 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:15 | Steps: 2667 | Loss: 75.681322 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:16 | Steps: 2668 | Loss: 75.687572 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:16 | Steps: 2669 | Loss: 75.691017 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:16 | Steps: 2671 | Loss: 75.697110 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:16 | Steps: 2672 | Loss: 75.704830 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:16 | Steps: 2674 | Loss: 75.712367 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:16 | Steps: 2676 | Loss: 75.756659 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:16 | Steps: 2677 | Loss: 75.759937 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:17 | Steps: 2679 | Loss: 75.777979 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:17 | Steps: 2681 | Loss: 75.780960 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:17 | Steps: 2683 | Loss: 75.810507 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:17 | Steps: 2684 | Loss: 75.812636 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:17 | Steps: 2685 | Loss: 75.829648 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:17 | Steps: 2686 | Loss: 75.828773 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:18 | Steps: 2688 | Loss: 75.827305 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:18 | Steps: 2689 | Loss: 75.843059 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:18 | Steps: 2691 | Loss: 75.907996 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:18 | Steps: 2693 | Loss: 75.929026 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:18 | Steps: 2695 | Loss: 75.942947 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:19 | Steps: 2697 | Loss: 75.966234 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:19 | Steps: 2699 | Loss: 75.993109 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:19 | Steps: 2701 | Loss: 75.992820 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:19 | Steps: 2702 | Loss: 75.993134 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:19 | Steps: 2704 | Loss: 76.004218 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:19 | Steps: 2706 | Loss: 76.002544 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:20 | Steps: 2708 | Loss: 76.035727 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:20 | Steps: 2710 | Loss: 76.077099 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:20 | Steps: 2711 | Loss: 76.083963 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:20 | Steps: 2713 | Loss: 76.091684 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:20 | Steps: 2714 | Loss: 76.091618 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:20 | Steps: 2716 | Loss: 76.120191 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:21 | Steps: 2717 | Loss: 76.125964 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:21 | Steps: 2718 | Loss: 76.131361 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:21 | Steps: 2720 | Loss: 76.148208 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:21 | Steps: 2722 | Loss: 76.167984 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:21 | Steps: 2724 | Loss: 76.167897 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:22 | Steps: 2726 | Loss: 76.194870 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:22 | Steps: 2728 | Loss: 76.203764 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:22 | Steps: 2730 | Loss: 76.220379 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:22 | Steps: 2732 | Loss: 76.251073 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:22 | Steps: 2733 | Loss: 76.261068 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:23 | Steps: 2735 | Loss: 76.269753 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:23 | Steps: 2737 | Loss: 76.280725 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:23 | Steps: 2739 | Loss: 76.308831 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:23 | Steps: 2741 | Loss: 76.320752 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:23 | Steps: 2743 | Loss: 76.329355 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:24 | Steps: 2745 | Loss: 76.355895 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:24 | Steps: 2747 | Loss: 76.372750 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:24 | Steps: 2749 | Loss: 76.375297 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:24 | Steps: 2751 | Loss: 76.412422 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:24 | Steps: 2753 | Loss: 76.446707 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:25 | Steps: 2755 | Loss: 76.477409 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:25 | Steps: 2757 | Loss: 76.517929 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:25 | Steps: 2758 | Loss: 76.527096 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:25 | Steps: 2759 | Loss: 76.529671 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:25 | Steps: 2761 | Loss: 76.566390 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:25 | Steps: 2762 | Loss: 76.577323 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:25 | Steps: 2764 | Loss: 76.606735 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:26 | Steps: 2766 | Loss: 76.655802 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:26 | Steps: 2768 | Loss: 76.671903 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:26 | Steps: 2770 | Loss: 76.679064 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:26 | Steps: 2772 | Loss: 76.676839 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:26 | Steps: 2773 | Loss: 76.688312 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:27 | Steps: 2775 | Loss: 76.696184 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:27 | Steps: 2776 | Loss: 76.713058 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:27 | Steps: 2777 | Loss: 76.722245 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:27 | Steps: 2779 | Loss: 76.731211 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:27 | Steps: 2781 | Loss: 76.774472 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:27 | Steps: 2782 | Loss: 76.767817 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:27 | Steps: 2784 | Loss: 76.801187 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:28 | Steps: 2785 | Loss: 76.805158 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:28 | Steps: 2786 | Loss: 76.827855 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:28 | Steps: 2787 | Loss: 76.834446 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:28 | Steps: 2789 | Loss: 76.840564 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:28 | Steps: 2791 | Loss: 76.864610 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:28 | Steps: 2792 | Loss: 76.872256 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:28 | Steps: 2793 | Loss: 76.892262 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:29 | Steps: 2795 | Loss: 76.901971 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:29 | Steps: 2796 | Loss: 76.903688 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:29 | Steps: 2798 | Loss: 76.920412 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:29 | Steps: 2799 | Loss: 76.928663 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:29 | Steps: 2800 | Loss: 76.943463 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:29 | Steps: 2801 | Loss: 77.010152 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:30 | Steps: 2803 | Loss: 77.044757 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:30 | Steps: 2804 | Loss: 77.052943 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:30 | Steps: 2806 | Loss: 77.073271 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:30 | Steps: 2807 | Loss: 77.084936 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:30 | Steps: 2808 | Loss: 77.083118 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:30 | Steps: 2809 | Loss: 77.101529 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:30 | Steps: 2810 | Loss: 77.099485 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:31 | Steps: 2812 | Loss: 77.116316 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:31 | Steps: 2813 | Loss: 77.126709 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:31 | Steps: 2815 | Loss: 77.149312 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:31 | Steps: 2817 | Loss: 77.170019 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:31 | Steps: 2818 | Loss: 77.169719 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:31 | Steps: 2819 | Loss: 77.189690 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:31 | Steps: 2820 | Loss: 77.208576 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:32 | Steps: 2821 | Loss: 77.213145 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:32 | Steps: 2823 | Loss: 77.259951 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:32 | Steps: 2824 | Loss: 77.265403 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:32 | Steps: 2826 | Loss: 77.300578 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:32 | Steps: 2827 | Loss: 77.314343 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:32 | Steps: 2828 | Loss: 77.319685 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:32 | Steps: 2830 | Loss: 77.373454 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:33 | Steps: 2831 | Loss: 77.384285 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:33 | Steps: 2834 | Loss: 77.416669 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:33 | Steps: 2836 | Loss: 77.420017 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:33 | Steps: 2838 | Loss: 77.437450 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:34 | Steps: 2840 | Loss: 77.460016 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:34 | Steps: 2841 | Loss: 77.473775 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:34 | Steps: 2842 | Loss: 77.495472 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:34 | Steps: 2844 | Loss: 77.517369 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:34 | Steps: 2846 | Loss: 77.546488 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:34 | Steps: 2848 | Loss: 77.568844 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:35 | Steps: 2850 | Loss: 77.582213 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:35 | Steps: 2851 | Loss: 77.584179 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:35 | Steps: 2852 | Loss: 77.607668 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:35 | Steps: 2853 | Loss: 77.637373 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:35 | Steps: 2854 | Loss: 77.671861 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:35 | Steps: 2856 | Loss: 77.708539 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:36 | Steps: 2858 | Loss: 77.736175 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:36 | Steps: 2860 | Loss: 77.748926 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:36 | Steps: 2861 | Loss: 77.784525 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:36 | Steps: 2862 | Loss: 77.844138 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:36 | Steps: 2864 | Loss: 77.866923 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:36 | Steps: 2865 | Loss: 77.880932 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:36 | Steps: 2866 | Loss: 77.885972 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:37 | Steps: 2867 | Loss: 77.893525 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:37 | Steps: 2869 | Loss: 77.917394 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:37 | Steps: 2870 | Loss: 77.942527 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:37 | Steps: 2871 | Loss: 77.951146 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:37 | Steps: 2872 | Loss: 77.955833 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:37 | Steps: 2873 | Loss: 77.981579 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:37 | Steps: 2874 | Loss: 78.017798 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:38 | Steps: 2876 | Loss: 78.065217 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:38 | Steps: 2877 | Loss: 78.073447 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:38 | Steps: 2878 | Loss: 78.085229 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:38 | Steps: 2880 | Loss: 78.118839 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:38 | Steps: 2881 | Loss: 78.131675 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:38 | Steps: 2882 | Loss: 78.145323 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:38 | Steps: 2883 | Loss: 78.160174 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:39 | Steps: 2885 | Loss: 78.170426 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:39 | Steps: 2886 | Loss: 78.183856 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:39 | Steps: 2887 | Loss: 78.207317 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:39 | Steps: 2889 | Loss: 78.247792 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:39 | Steps: 2891 | Loss: 78.271483 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:39 | Steps: 2893 | Loss: 78.325849 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:39 | Steps: 2894 | Loss: 78.329086 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:40 | Steps: 2895 | Loss: 78.332799 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:40 | Steps: 2896 | Loss: 78.334872 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:40 | Steps: 2897 | Loss: 78.346356 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:40 | Steps: 2899 | Loss: 78.377156 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:40 | Steps: 2900 | Loss: 78.399197 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:40 | Steps: 2901 | Loss: 78.404853 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:40 | Steps: 2902 | Loss: 78.403466 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:41 | Steps: 2903 | Loss: 78.418424 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:41 | Steps: 2904 | Loss: 78.419891 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:41 | Steps: 2905 | Loss: 78.431956 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:41 | Steps: 2906 | Loss: 78.431406 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:41 | Steps: 2908 | Loss: 78.456417 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:41 | Steps: 2909 | Loss: 78.499589 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:41 | Steps: 2910 | Loss: 78.504407 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:42 | Steps: 2912 | Loss: 78.536036 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:42 | Steps: 2913 | Loss: 78.558370 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:42 | Steps: 2914 | Loss: 78.583469 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:42 | Steps: 2915 | Loss: 78.591402 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:42 | Steps: 2916 | Loss: 78.592552 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:42 | Steps: 2917 | Loss: 78.609860 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:42 | Steps: 2919 | Loss: 78.646853 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:43 | Steps: 2921 | Loss: 78.685379 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:43 | Steps: 2922 | Loss: 78.702309 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:43 | Steps: 2923 | Loss: 78.722196 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:43 | Steps: 2924 | Loss: 78.730187 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:43 | Steps: 2926 | Loss: 78.772900 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:43 | Steps: 2927 | Loss: 78.789779 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:43 | Steps: 2928 | Loss: 78.805589 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:44 | Steps: 2930 | Loss: 78.827514 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:44 | Steps: 2931 | Loss: 78.836411 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:44 | Steps: 2932 | Loss: 78.846874 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:44 | Steps: 2934 | Loss: 78.872151 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:44 | Steps: 2936 | Loss: 78.894157 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:45 | Steps: 2937 | Loss: 78.925870 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:45 | Steps: 2939 | Loss: 78.971724 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:45 | Steps: 2940 | Loss: 78.993995 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:45 | Steps: 2941 | Loss: 79.002423 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:45 | Steps: 2942 | Loss: 79.023772 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:45 | Steps: 2943 | Loss: 79.032493 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:46 | Steps: 2944 | Loss: 79.046004 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:46 | Steps: 2946 | Loss: 79.077260 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:46 | Steps: 2948 | Loss: 79.101917 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:46 | Steps: 2949 | Loss: 79.119608 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:46 | Steps: 2950 | Loss: 79.126539 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:46 | Steps: 2952 | Loss: 79.157617 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:47 | Steps: 2953 | Loss: 79.175647 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:47 | Steps: 2954 | Loss: 79.206219 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:47 | Steps: 2956 | Loss: 79.234826 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:47 | Steps: 2957 | Loss: 79.249384 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:47 | Steps: 2959 | Loss: 79.284301 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:48 | Steps: 2961 | Loss: 79.317576 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:48 | Steps: 2962 | Loss: 79.336846 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:48 | Steps: 2963 | Loss: 79.336755 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:48 | Steps: 2965 | Loss: 79.365221 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:48 | Steps: 2967 | Loss: 79.389190 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:49 | Steps: 2968 | Loss: 79.407183 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:49 | Steps: 2969 | Loss: 79.433897 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:49 | Steps: 2970 | Loss: 79.453103 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:49 | Steps: 2971 | Loss: 79.464907 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:49 | Steps: 2972 | Loss: 79.490046 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:49 | Steps: 2973 | Loss: 79.502969 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:49 | Steps: 2974 | Loss: 79.510801 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:50 | Steps: 2976 | Loss: 79.548782 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:50 | Steps: 2977 | Loss: 79.558868 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:50 | Steps: 2978 | Loss: 79.571583 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:50 | Steps: 2980 | Loss: 79.611561 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:50 | Steps: 2981 | Loss: 79.625194 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:50 | Steps: 2982 | Loss: 79.632938 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:50 | Steps: 2983 | Loss: 79.632947 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:51 | Steps: 2985 | Loss: 79.667676 | Dataset: sw/dev.csv\n",
      "Epoch 1 | Validation | Elapsed Time: 0:03:51 | Steps: 2985 | Loss: 79.667676 | Dataset: sw/dev.csv\n",
      "I Saved new best validating model with loss 79.667676 to: ckpt_dir/best_dev-22034\n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:46:19.768411\n"
     ]
    }
   ],
   "source": [
    "# Kick off training job; configures CUDA to only use one GPU\n",
    "from coqui_stt_training.train import train\n",
    "\n",
    "# use maximum one GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Loading best validating checkpoint from ckpt_dir/best_dev-22034\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on sw/test.csv\n",
      "Test epoch | Steps: 0 | Elapsed Time: 0:00:00\n",
      "Test epoch | Steps: 1 | Elapsed Time: 0:00:02\n",
      "Test epoch | Steps: 2 | Elapsed Time: 0:00:02\n",
      "Test epoch | Steps: 3 | Elapsed Time: 0:00:02\n",
      "Test epoch | Steps: 4 | Elapsed Time: 0:00:03\n",
      "Test epoch | Steps: 5 | Elapsed Time: 0:00:03\n",
      "Test epoch | Steps: 6 | Elapsed Time: 0:00:04\n",
      "Test epoch | Steps: 7 | Elapsed Time: 0:00:04\n",
      "Test epoch | Steps: 8 | Elapsed Time: 0:00:04\n",
      "Test epoch | Steps: 9 | Elapsed Time: 0:00:05\n",
      "Test epoch | Steps: 10 | Elapsed Time: 0:00:05\n",
      "Test epoch | Steps: 11 | Elapsed Time: 0:00:06\n",
      "Test epoch | Steps: 12 | Elapsed Time: 0:00:06\n",
      "Test epoch | Steps: 13 | Elapsed Time: 0:00:07\n",
      "Test epoch | Steps: 14 | Elapsed Time: 0:00:07\n",
      "Test epoch | Steps: 15 | Elapsed Time: 0:00:07\n",
      "Test epoch | Steps: 16 | Elapsed Time: 0:00:08\n",
      "Test epoch | Steps: 17 | Elapsed Time: 0:00:08\n",
      "Test epoch | Steps: 18 | Elapsed Time: 0:00:09\n",
      "Test epoch | Steps: 19 | Elapsed Time: 0:00:09\n",
      "Test epoch | Steps: 20 | Elapsed Time: 0:00:10\n",
      "Test epoch | Steps: 21 | Elapsed Time: 0:00:10\n",
      "Test epoch | Steps: 22 | Elapsed Time: 0:00:11\n",
      "Test epoch | Steps: 23 | Elapsed Time: 0:00:11\n",
      "Test epoch | Steps: 24 | Elapsed Time: 0:00:12\n",
      "Test epoch | Steps: 25 | Elapsed Time: 0:00:12\n",
      "Test epoch | Steps: 26 | Elapsed Time: 0:00:13\n",
      "Test epoch | Steps: 27 | Elapsed Time: 0:00:13\n",
      "Test epoch | Steps: 28 | Elapsed Time: 0:00:14\n",
      "Test epoch | Steps: 29 | Elapsed Time: 0:00:14\n",
      "Test epoch | Steps: 30 | Elapsed Time: 0:00:15\n",
      "Test epoch | Steps: 31 | Elapsed Time: 0:00:15\n",
      "Test epoch | Steps: 32 | Elapsed Time: 0:00:16\n",
      "Test epoch | Steps: 33 | Elapsed Time: 0:00:16\n",
      "Test epoch | Steps: 34 | Elapsed Time: 0:00:17\n",
      "Test epoch | Steps: 35 | Elapsed Time: 0:00:17\n",
      "Test epoch | Steps: 36 | Elapsed Time: 0:00:18\n",
      "Test epoch | Steps: 37 | Elapsed Time: 0:00:18\n",
      "Test epoch | Steps: 38 | Elapsed Time: 0:00:19\n",
      "Test epoch | Steps: 39 | Elapsed Time: 0:00:19\n",
      "Test epoch | Steps: 40 | Elapsed Time: 0:00:20\n",
      "Test epoch | Steps: 41 | Elapsed Time: 0:00:20\n",
      "Test epoch | Steps: 42 | Elapsed Time: 0:00:21\n",
      "Test epoch | Steps: 43 | Elapsed Time: 0:00:22\n",
      "Test epoch | Steps: 44 | Elapsed Time: 0:00:22\n",
      "Test epoch | Steps: 45 | Elapsed Time: 0:00:23\n",
      "Test epoch | Steps: 46 | Elapsed Time: 0:00:23\n",
      "Test epoch | Steps: 47 | Elapsed Time: 0:00:24\n",
      "Test epoch | Steps: 48 | Elapsed Time: 0:00:24\n",
      "Test epoch | Steps: 49 | Elapsed Time: 0:00:25\n",
      "Test epoch | Steps: 50 | Elapsed Time: 0:00:25\n",
      "Test epoch | Steps: 51 | Elapsed Time: 0:00:26\n",
      "Test epoch | Steps: 52 | Elapsed Time: 0:00:27\n",
      "Test epoch | Steps: 53 | Elapsed Time: 0:00:27\n",
      "Test epoch | Steps: 54 | Elapsed Time: 0:00:28\n",
      "Test epoch | Steps: 55 | Elapsed Time: 0:00:28\n",
      "Test epoch | Steps: 56 | Elapsed Time: 0:00:29\n",
      "Test epoch | Steps: 57 | Elapsed Time: 0:00:29\n",
      "Test epoch | Steps: 58 | Elapsed Time: 0:00:30\n",
      "Test epoch | Steps: 59 | Elapsed Time: 0:00:31\n",
      "Test epoch | Steps: 60 | Elapsed Time: 0:00:31\n",
      "Test epoch | Steps: 61 | Elapsed Time: 0:00:32\n",
      "Test epoch | Steps: 62 | Elapsed Time: 0:00:32\n",
      "Test epoch | Steps: 63 | Elapsed Time: 0:00:33\n",
      "Test epoch | Steps: 64 | Elapsed Time: 0:00:33\n",
      "Test epoch | Steps: 65 | Elapsed Time: 0:00:34\n",
      "Test epoch | Steps: 66 | Elapsed Time: 0:00:35\n",
      "Test epoch | Steps: 67 | Elapsed Time: 0:00:35\n",
      "Test epoch | Steps: 68 | Elapsed Time: 0:00:36\n",
      "Test epoch | Steps: 69 | Elapsed Time: 0:00:36\n",
      "Test epoch | Steps: 70 | Elapsed Time: 0:00:37\n",
      "Test epoch | Steps: 71 | Elapsed Time: 0:00:38\n",
      "Test epoch | Steps: 72 | Elapsed Time: 0:00:38\n",
      "Test epoch | Steps: 73 | Elapsed Time: 0:00:39\n",
      "Test epoch | Steps: 74 | Elapsed Time: 0:00:39\n",
      "Test epoch | Steps: 75 | Elapsed Time: 0:00:40\n",
      "Test epoch | Steps: 76 | Elapsed Time: 0:00:41\n",
      "Test epoch | Steps: 77 | Elapsed Time: 0:00:41\n",
      "Test epoch | Steps: 78 | Elapsed Time: 0:00:42\n",
      "Test epoch | Steps: 79 | Elapsed Time: 0:00:43\n",
      "Test epoch | Steps: 80 | Elapsed Time: 0:00:43\n",
      "Test epoch | Steps: 81 | Elapsed Time: 0:00:44\n",
      "Test epoch | Steps: 82 | Elapsed Time: 0:00:45\n",
      "Test epoch | Steps: 83 | Elapsed Time: 0:00:45\n",
      "Test epoch | Steps: 84 | Elapsed Time: 0:00:46\n",
      "Test epoch | Steps: 85 | Elapsed Time: 0:00:46\n",
      "Test epoch | Steps: 86 | Elapsed Time: 0:00:47\n",
      "Test epoch | Steps: 87 | Elapsed Time: 0:00:48\n",
      "Test epoch | Steps: 88 | Elapsed Time: 0:00:48\n",
      "Test epoch | Steps: 89 | Elapsed Time: 0:00:49\n",
      "Test epoch | Steps: 90 | Elapsed Time: 0:00:50\n",
      "Test epoch | Steps: 91 | Elapsed Time: 0:00:50\n",
      "Test epoch | Steps: 92 | Elapsed Time: 0:00:51\n",
      "Test epoch | Steps: 93 | Elapsed Time: 0:00:51\n",
      "Test epoch | Steps: 94 | Elapsed Time: 0:00:52\n",
      "Test epoch | Steps: 95 | Elapsed Time: 0:00:53\n",
      "Test epoch | Steps: 96 | Elapsed Time: 0:00:53\n",
      "Test epoch | Steps: 97 | Elapsed Time: 0:00:54\n",
      "Test epoch | Steps: 98 | Elapsed Time: 0:00:55\n",
      "Test epoch | Steps: 99 | Elapsed Time: 0:00:55\n",
      "Test epoch | Steps: 100 | Elapsed Time: 0:00:56\n",
      "Test epoch | Steps: 101 | Elapsed Time: 0:00:57\n",
      "Test epoch | Steps: 102 | Elapsed Time: 0:00:57\n",
      "Test epoch | Steps: 103 | Elapsed Time: 0:00:58\n",
      "Test epoch | Steps: 104 | Elapsed Time: 0:00:59\n",
      "Test epoch | Steps: 105 | Elapsed Time: 0:00:59\n",
      "Test epoch | Steps: 106 | Elapsed Time: 0:01:00\n",
      "Test epoch | Steps: 107 | Elapsed Time: 0:01:01\n",
      "Test epoch | Steps: 108 | Elapsed Time: 0:01:01\n",
      "Test epoch | Steps: 109 | Elapsed Time: 0:01:02\n",
      "Test epoch | Steps: 110 | Elapsed Time: 0:01:03\n",
      "Test epoch | Steps: 111 | Elapsed Time: 0:01:03\n",
      "Test epoch | Steps: 112 | Elapsed Time: 0:01:04\n",
      "Test epoch | Steps: 113 | Elapsed Time: 0:01:05\n",
      "Test epoch | Steps: 114 | Elapsed Time: 0:01:05\n",
      "Test epoch | Steps: 115 | Elapsed Time: 0:01:06\n",
      "Test epoch | Steps: 116 | Elapsed Time: 0:01:07\n",
      "Test epoch | Steps: 117 | Elapsed Time: 0:01:07\n",
      "Test epoch | Steps: 118 | Elapsed Time: 0:01:08\n",
      "Test epoch | Steps: 119 | Elapsed Time: 0:01:09\n",
      "Test epoch | Steps: 120 | Elapsed Time: 0:01:09\n",
      "Test epoch | Steps: 121 | Elapsed Time: 0:01:10\n",
      "Test epoch | Steps: 122 | Elapsed Time: 0:01:11\n",
      "Test epoch | Steps: 123 | Elapsed Time: 0:01:11\n",
      "Test epoch | Steps: 124 | Elapsed Time: 0:01:12\n",
      "Test epoch | Steps: 125 | Elapsed Time: 0:01:13\n",
      "Test epoch | Steps: 126 | Elapsed Time: 0:01:13\n",
      "Test epoch | Steps: 127 | Elapsed Time: 0:01:14\n",
      "Test epoch | Steps: 128 | Elapsed Time: 0:01:15\n",
      "Test epoch | Steps: 129 | Elapsed Time: 0:01:15\n",
      "Test epoch | Steps: 130 | Elapsed Time: 0:01:16\n",
      "Test epoch | Steps: 131 | Elapsed Time: 0:01:17\n",
      "Test epoch | Steps: 132 | Elapsed Time: 0:01:18\n",
      "Test epoch | Steps: 133 | Elapsed Time: 0:01:18\n",
      "Test epoch | Steps: 134 | Elapsed Time: 0:01:19\n",
      "Test epoch | Steps: 135 | Elapsed Time: 0:01:20\n",
      "Test epoch | Steps: 136 | Elapsed Time: 0:01:20\n",
      "Test epoch | Steps: 137 | Elapsed Time: 0:01:21\n",
      "Test epoch | Steps: 138 | Elapsed Time: 0:01:22\n",
      "Test epoch | Steps: 139 | Elapsed Time: 0:01:22\n",
      "Test epoch | Steps: 140 | Elapsed Time: 0:01:23\n",
      "Test epoch | Steps: 141 | Elapsed Time: 0:01:24\n",
      "Test epoch | Steps: 142 | Elapsed Time: 0:01:25\n",
      "Test epoch | Steps: 143 | Elapsed Time: 0:01:25\n",
      "Test epoch | Steps: 144 | Elapsed Time: 0:01:26\n",
      "Test epoch | Steps: 145 | Elapsed Time: 0:01:27\n",
      "Test epoch | Steps: 146 | Elapsed Time: 0:01:27\n",
      "Test epoch | Steps: 147 | Elapsed Time: 0:01:28\n",
      "Test epoch | Steps: 148 | Elapsed Time: 0:01:29\n",
      "Test epoch | Steps: 149 | Elapsed Time: 0:01:29\n",
      "Test epoch | Steps: 150 | Elapsed Time: 0:01:30\n",
      "Test epoch | Steps: 151 | Elapsed Time: 0:01:31\n",
      "Test epoch | Steps: 152 | Elapsed Time: 0:01:32\n",
      "Test epoch | Steps: 153 | Elapsed Time: 0:01:32\n",
      "Test epoch | Steps: 154 | Elapsed Time: 0:01:33\n",
      "Test epoch | Steps: 155 | Elapsed Time: 0:01:34\n",
      "Test epoch | Steps: 156 | Elapsed Time: 0:01:34\n",
      "Test epoch | Steps: 157 | Elapsed Time: 0:01:35\n",
      "Test epoch | Steps: 158 | Elapsed Time: 0:01:36\n",
      "Test epoch | Steps: 159 | Elapsed Time: 0:01:37\n",
      "Test epoch | Steps: 160 | Elapsed Time: 0:01:37\n",
      "Test epoch | Steps: 161 | Elapsed Time: 0:01:38\n",
      "Test epoch | Steps: 162 | Elapsed Time: 0:01:39\n",
      "Test epoch | Steps: 163 | Elapsed Time: 0:01:39\n",
      "Test epoch | Steps: 164 | Elapsed Time: 0:01:40\n",
      "Test epoch | Steps: 165 | Elapsed Time: 0:01:41\n",
      "Test epoch | Steps: 166 | Elapsed Time: 0:01:42\n",
      "Test epoch | Steps: 167 | Elapsed Time: 0:01:42\n",
      "Test epoch | Steps: 168 | Elapsed Time: 0:01:43\n",
      "Test epoch | Steps: 169 | Elapsed Time: 0:01:44\n",
      "Test epoch | Steps: 170 | Elapsed Time: 0:01:45\n",
      "Test epoch | Steps: 171 | Elapsed Time: 0:01:45\n",
      "Test epoch | Steps: 172 | Elapsed Time: 0:01:46\n",
      "Test epoch | Steps: 173 | Elapsed Time: 0:01:47\n",
      "Test epoch | Steps: 174 | Elapsed Time: 0:01:48\n",
      "Test epoch | Steps: 175 | Elapsed Time: 0:01:48\n",
      "Test epoch | Steps: 176 | Elapsed Time: 0:01:49\n",
      "Test epoch | Steps: 177 | Elapsed Time: 0:01:50\n",
      "Test epoch | Steps: 178 | Elapsed Time: 0:01:50\n",
      "Test epoch | Steps: 179 | Elapsed Time: 0:01:51\n",
      "Test epoch | Steps: 180 | Elapsed Time: 0:01:52\n",
      "Test epoch | Steps: 181 | Elapsed Time: 0:01:53\n",
      "Test epoch | Steps: 182 | Elapsed Time: 0:01:53\n",
      "Test epoch | Steps: 183 | Elapsed Time: 0:01:54\n",
      "Test epoch | Steps: 184 | Elapsed Time: 0:01:55\n",
      "Test epoch | Steps: 185 | Elapsed Time: 0:01:56\n",
      "Test epoch | Steps: 186 | Elapsed Time: 0:01:56\n",
      "Test epoch | Steps: 187 | Elapsed Time: 0:01:57\n",
      "Test epoch | Steps: 188 | Elapsed Time: 0:01:58\n",
      "Test epoch | Steps: 189 | Elapsed Time: 0:01:59\n",
      "Test epoch | Steps: 190 | Elapsed Time: 0:01:59\n",
      "Test epoch | Steps: 191 | Elapsed Time: 0:02:00\n",
      "Test epoch | Steps: 192 | Elapsed Time: 0:02:01\n",
      "Test epoch | Steps: 193 | Elapsed Time: 0:02:02\n",
      "Test epoch | Steps: 194 | Elapsed Time: 0:02:02\n",
      "Test epoch | Steps: 195 | Elapsed Time: 0:02:03\n",
      "Test epoch | Steps: 196 | Elapsed Time: 0:02:04\n",
      "Test epoch | Steps: 197 | Elapsed Time: 0:02:05\n",
      "Test epoch | Steps: 198 | Elapsed Time: 0:02:06\n",
      "Test epoch | Steps: 199 | Elapsed Time: 0:02:06\n",
      "Test epoch | Steps: 200 | Elapsed Time: 0:02:07\n",
      "Test epoch | Steps: 201 | Elapsed Time: 0:02:08\n",
      "Test epoch | Steps: 202 | Elapsed Time: 0:02:09\n",
      "Test epoch | Steps: 203 | Elapsed Time: 0:02:09\n",
      "Test epoch | Steps: 204 | Elapsed Time: 0:02:10\n",
      "Test epoch | Steps: 205 | Elapsed Time: 0:02:11\n",
      "Test epoch | Steps: 206 | Elapsed Time: 0:02:12\n",
      "Test epoch | Steps: 207 | Elapsed Time: 0:02:12\n",
      "Test epoch | Steps: 208 | Elapsed Time: 0:02:13\n",
      "Test epoch | Steps: 209 | Elapsed Time: 0:02:14\n",
      "Test epoch | Steps: 210 | Elapsed Time: 0:02:15\n",
      "Test epoch | Steps: 211 | Elapsed Time: 0:02:15\n",
      "Test epoch | Steps: 212 | Elapsed Time: 0:02:16\n",
      "Test epoch | Steps: 213 | Elapsed Time: 0:02:17\n",
      "Test epoch | Steps: 214 | Elapsed Time: 0:02:18\n",
      "Test epoch | Steps: 215 | Elapsed Time: 0:02:19\n",
      "Test epoch | Steps: 216 | Elapsed Time: 0:02:19\n",
      "Test epoch | Steps: 217 | Elapsed Time: 0:02:20\n",
      "Test epoch | Steps: 218 | Elapsed Time: 0:02:21\n",
      "Test epoch | Steps: 219 | Elapsed Time: 0:02:22\n",
      "Test epoch | Steps: 220 | Elapsed Time: 0:02:23\n",
      "Test epoch | Steps: 221 | Elapsed Time: 0:02:23\n",
      "Test epoch | Steps: 222 | Elapsed Time: 0:02:24\n",
      "Test epoch | Steps: 223 | Elapsed Time: 0:02:25\n",
      "Test epoch | Steps: 224 | Elapsed Time: 0:02:26\n",
      "Test epoch | Steps: 225 | Elapsed Time: 0:02:26\n",
      "Test epoch | Steps: 226 | Elapsed Time: 0:02:27\n",
      "Test epoch | Steps: 227 | Elapsed Time: 0:02:28\n",
      "Test epoch | Steps: 228 | Elapsed Time: 0:02:29\n",
      "Test epoch | Steps: 229 | Elapsed Time: 0:02:29\n",
      "Test epoch | Steps: 230 | Elapsed Time: 0:02:30\n",
      "Test epoch | Steps: 231 | Elapsed Time: 0:02:31\n",
      "Test epoch | Steps: 232 | Elapsed Time: 0:02:32\n",
      "Test epoch | Steps: 233 | Elapsed Time: 0:02:33\n",
      "Test epoch | Steps: 234 | Elapsed Time: 0:02:33\n",
      "Test epoch | Steps: 235 | Elapsed Time: 0:02:34\n",
      "Test epoch | Steps: 236 | Elapsed Time: 0:02:35\n",
      "Test epoch | Steps: 237 | Elapsed Time: 0:02:36\n",
      "Test epoch | Steps: 238 | Elapsed Time: 0:02:37\n",
      "Test epoch | Steps: 239 | Elapsed Time: 0:02:37\n",
      "Test epoch | Steps: 240 | Elapsed Time: 0:02:38\n",
      "Test epoch | Steps: 241 | Elapsed Time: 0:02:39\n",
      "Test epoch | Steps: 242 | Elapsed Time: 0:02:40\n",
      "Test epoch | Steps: 243 | Elapsed Time: 0:02:41\n",
      "Test epoch | Steps: 244 | Elapsed Time: 0:02:41\n",
      "Test epoch | Steps: 245 | Elapsed Time: 0:02:42\n",
      "Test epoch | Steps: 246 | Elapsed Time: 0:02:43\n",
      "Test epoch | Steps: 247 | Elapsed Time: 0:02:44\n",
      "Test epoch | Steps: 248 | Elapsed Time: 0:02:45\n",
      "Test epoch | Steps: 249 | Elapsed Time: 0:02:45\n",
      "Test epoch | Steps: 250 | Elapsed Time: 0:02:46\n",
      "Test epoch | Steps: 251 | Elapsed Time: 0:02:47\n",
      "Test epoch | Steps: 252 | Elapsed Time: 0:02:48\n",
      "Test epoch | Steps: 253 | Elapsed Time: 0:02:48\n",
      "Test epoch | Steps: 254 | Elapsed Time: 0:02:49\n",
      "Test epoch | Steps: 255 | Elapsed Time: 0:02:50\n",
      "Test epoch | Steps: 256 | Elapsed Time: 0:02:51\n",
      "Test epoch | Steps: 257 | Elapsed Time: 0:02:52\n",
      "Test epoch | Steps: 258 | Elapsed Time: 0:02:53\n",
      "Test epoch | Steps: 259 | Elapsed Time: 0:02:53\n",
      "Test epoch | Steps: 260 | Elapsed Time: 0:02:54\n",
      "Test epoch | Steps: 261 | Elapsed Time: 0:02:55\n",
      "Test epoch | Steps: 262 | Elapsed Time: 0:02:56\n",
      "Test epoch | Steps: 263 | Elapsed Time: 0:02:57\n",
      "Test epoch | Steps: 264 | Elapsed Time: 0:02:58\n",
      "Test epoch | Steps: 265 | Elapsed Time: 0:02:58\n",
      "Test epoch | Steps: 266 | Elapsed Time: 0:02:59\n",
      "Test epoch | Steps: 267 | Elapsed Time: 0:03:00\n",
      "Test epoch | Steps: 268 | Elapsed Time: 0:03:01\n",
      "Test epoch | Steps: 269 | Elapsed Time: 0:03:02\n",
      "Test epoch | Steps: 270 | Elapsed Time: 0:03:03\n",
      "Test epoch | Steps: 271 | Elapsed Time: 0:03:04\n",
      "Test epoch | Steps: 272 | Elapsed Time: 0:03:04\n",
      "Test epoch | Steps: 273 | Elapsed Time: 0:03:05\n",
      "Test epoch | Steps: 274 | Elapsed Time: 0:03:06\n",
      "Test epoch | Steps: 275 | Elapsed Time: 0:03:07\n",
      "Test epoch | Steps: 276 | Elapsed Time: 0:03:07\n",
      "Test epoch | Steps: 277 | Elapsed Time: 0:03:08\n",
      "Test epoch | Steps: 278 | Elapsed Time: 0:03:09\n",
      "Test epoch | Steps: 279 | Elapsed Time: 0:03:10\n",
      "Test epoch | Steps: 280 | Elapsed Time: 0:03:11\n",
      "Test epoch | Steps: 281 | Elapsed Time: 0:03:12\n",
      "Test epoch | Steps: 282 | Elapsed Time: 0:03:12\n",
      "Test epoch | Steps: 283 | Elapsed Time: 0:03:13\n",
      "Test epoch | Steps: 284 | Elapsed Time: 0:03:14\n",
      "Test epoch | Steps: 285 | Elapsed Time: 0:03:15\n",
      "Test epoch | Steps: 286 | Elapsed Time: 0:03:16\n",
      "Test epoch | Steps: 287 | Elapsed Time: 0:03:17\n",
      "Test epoch | Steps: 288 | Elapsed Time: 0:03:17\n",
      "Test epoch | Steps: 289 | Elapsed Time: 0:03:18\n",
      "Test epoch | Steps: 290 | Elapsed Time: 0:03:19\n",
      "Test epoch | Steps: 291 | Elapsed Time: 0:03:20\n",
      "Test epoch | Steps: 292 | Elapsed Time: 0:03:21\n",
      "Test epoch | Steps: 293 | Elapsed Time: 0:03:22\n",
      "Test epoch | Steps: 294 | Elapsed Time: 0:03:23\n",
      "Test epoch | Steps: 295 | Elapsed Time: 0:03:23\n",
      "Test epoch | Steps: 296 | Elapsed Time: 0:03:24\n",
      "Test epoch | Steps: 297 | Elapsed Time: 0:03:25\n",
      "Test epoch | Steps: 298 | Elapsed Time: 0:03:26\n",
      "Test epoch | Steps: 299 | Elapsed Time: 0:03:27\n",
      "Test epoch | Steps: 300 | Elapsed Time: 0:03:27\n",
      "Test epoch | Steps: 301 | Elapsed Time: 0:03:28\n",
      "Test epoch | Steps: 302 | Elapsed Time: 0:03:29\n",
      "Test epoch | Steps: 303 | Elapsed Time: 0:03:30\n",
      "Test epoch | Steps: 304 | Elapsed Time: 0:03:31\n",
      "Test epoch | Steps: 305 | Elapsed Time: 0:03:32\n",
      "Test epoch | Steps: 306 | Elapsed Time: 0:03:32\n",
      "Test epoch | Steps: 307 | Elapsed Time: 0:03:33\n",
      "Test epoch | Steps: 308 | Elapsed Time: 0:03:34\n",
      "Test epoch | Steps: 309 | Elapsed Time: 0:03:35\n",
      "Test epoch | Steps: 310 | Elapsed Time: 0:03:36\n",
      "Test epoch | Steps: 311 | Elapsed Time: 0:03:37\n",
      "Test epoch | Steps: 312 | Elapsed Time: 0:03:38\n",
      "Test epoch | Steps: 313 | Elapsed Time: 0:03:38\n",
      "Test epoch | Steps: 314 | Elapsed Time: 0:03:39\n",
      "Test epoch | Steps: 315 | Elapsed Time: 0:03:40\n",
      "Test epoch | Steps: 316 | Elapsed Time: 0:03:41\n",
      "Test epoch | Steps: 317 | Elapsed Time: 0:03:41\n",
      "Test epoch | Steps: 318 | Elapsed Time: 0:03:42\n",
      "Test epoch | Steps: 319 | Elapsed Time: 0:03:43\n",
      "Test epoch | Steps: 320 | Elapsed Time: 0:03:44\n",
      "Test epoch | Steps: 321 | Elapsed Time: 0:03:45\n",
      "Test epoch | Steps: 322 | Elapsed Time: 0:03:46\n",
      "Test epoch | Steps: 323 | Elapsed Time: 0:03:46\n",
      "Test epoch | Steps: 324 | Elapsed Time: 0:03:47\n",
      "Test epoch | Steps: 325 | Elapsed Time: 0:03:48\n",
      "Test epoch | Steps: 326 | Elapsed Time: 0:03:49\n",
      "Test epoch | Steps: 327 | Elapsed Time: 0:03:50\n",
      "Test epoch | Steps: 328 | Elapsed Time: 0:03:51\n",
      "Test epoch | Steps: 329 | Elapsed Time: 0:03:52\n",
      "Test epoch | Steps: 330 | Elapsed Time: 0:03:53\n",
      "Test epoch | Steps: 331 | Elapsed Time: 0:03:54\n",
      "Test epoch | Steps: 332 | Elapsed Time: 0:03:54\n",
      "Test epoch | Steps: 333 | Elapsed Time: 0:03:55\n",
      "Test epoch | Steps: 334 | Elapsed Time: 0:03:56\n",
      "Test epoch | Steps: 335 | Elapsed Time: 0:03:57\n",
      "Test epoch | Steps: 336 | Elapsed Time: 0:03:58\n",
      "Test epoch | Steps: 337 | Elapsed Time: 0:03:59\n",
      "Test epoch | Steps: 338 | Elapsed Time: 0:04:00\n",
      "Test epoch | Steps: 339 | Elapsed Time: 0:04:00\n",
      "Test epoch | Steps: 340 | Elapsed Time: 0:04:01\n",
      "Test epoch | Steps: 341 | Elapsed Time: 0:04:02\n",
      "Test epoch | Steps: 342 | Elapsed Time: 0:04:03\n",
      "Test epoch | Steps: 343 | Elapsed Time: 0:04:04\n",
      "Test epoch | Steps: 344 | Elapsed Time: 0:04:05\n",
      "Test epoch | Steps: 345 | Elapsed Time: 0:04:06\n",
      "Test epoch | Steps: 346 | Elapsed Time: 0:04:07\n",
      "Test epoch | Steps: 347 | Elapsed Time: 0:04:08\n",
      "Test epoch | Steps: 348 | Elapsed Time: 0:04:08\n",
      "Test epoch | Steps: 349 | Elapsed Time: 0:04:09\n",
      "Test epoch | Steps: 350 | Elapsed Time: 0:04:10\n",
      "Test epoch | Steps: 351 | Elapsed Time: 0:04:11\n",
      "Test epoch | Steps: 352 | Elapsed Time: 0:04:12\n",
      "Test epoch | Steps: 353 | Elapsed Time: 0:04:13\n",
      "Test epoch | Steps: 354 | Elapsed Time: 0:04:14\n",
      "Test epoch | Steps: 355 | Elapsed Time: 0:04:15\n",
      "Test epoch | Steps: 356 | Elapsed Time: 0:04:16\n",
      "Test epoch | Steps: 357 | Elapsed Time: 0:04:16\n",
      "Test epoch | Steps: 358 | Elapsed Time: 0:04:17\n",
      "Test epoch | Steps: 359 | Elapsed Time: 0:04:18\n",
      "Test epoch | Steps: 360 | Elapsed Time: 0:04:19\n",
      "Test epoch | Steps: 361 | Elapsed Time: 0:04:20\n",
      "Test epoch | Steps: 362 | Elapsed Time: 0:04:21\n",
      "Test epoch | Steps: 363 | Elapsed Time: 0:04:21\n",
      "Test epoch | Steps: 364 | Elapsed Time: 0:04:22\n",
      "Test epoch | Steps: 365 | Elapsed Time: 0:04:23\n",
      "Test epoch | Steps: 366 | Elapsed Time: 0:04:24\n",
      "Test epoch | Steps: 367 | Elapsed Time: 0:04:25\n",
      "Test epoch | Steps: 368 | Elapsed Time: 0:04:26\n",
      "Test epoch | Steps: 369 | Elapsed Time: 0:04:26\n",
      "Test epoch | Steps: 370 | Elapsed Time: 0:04:27\n",
      "Test epoch | Steps: 371 | Elapsed Time: 0:04:28\n",
      "Test epoch | Steps: 372 | Elapsed Time: 0:04:29\n",
      "Test epoch | Steps: 373 | Elapsed Time: 0:04:30\n",
      "Test epoch | Steps: 374 | Elapsed Time: 0:04:31\n",
      "Test epoch | Steps: 375 | Elapsed Time: 0:04:32\n",
      "Test epoch | Steps: 376 | Elapsed Time: 0:04:33\n",
      "Test epoch | Steps: 377 | Elapsed Time: 0:04:33\n",
      "Test epoch | Steps: 378 | Elapsed Time: 0:04:34\n",
      "Test epoch | Steps: 379 | Elapsed Time: 0:04:35\n",
      "Test epoch | Steps: 380 | Elapsed Time: 0:04:36\n",
      "Test epoch | Steps: 381 | Elapsed Time: 0:04:37\n",
      "Test epoch | Steps: 382 | Elapsed Time: 0:04:38\n",
      "Test epoch | Steps: 383 | Elapsed Time: 0:04:39\n",
      "Test epoch | Steps: 384 | Elapsed Time: 0:04:40\n",
      "Test epoch | Steps: 385 | Elapsed Time: 0:04:41\n",
      "Test epoch | Steps: 386 | Elapsed Time: 0:04:42\n",
      "Test epoch | Steps: 387 | Elapsed Time: 0:04:43\n",
      "Test epoch | Steps: 388 | Elapsed Time: 0:04:44\n",
      "Test epoch | Steps: 389 | Elapsed Time: 0:04:45\n",
      "Test epoch | Steps: 390 | Elapsed Time: 0:04:46\n",
      "Test epoch | Steps: 391 | Elapsed Time: 0:04:47\n",
      "Test epoch | Steps: 392 | Elapsed Time: 0:04:48\n",
      "Test epoch | Steps: 393 | Elapsed Time: 0:04:49\n",
      "Test epoch | Steps: 394 | Elapsed Time: 0:04:50\n",
      "Test epoch | Steps: 395 | Elapsed Time: 0:04:50\n",
      "Test epoch | Steps: 396 | Elapsed Time: 0:04:51\n",
      "Test epoch | Steps: 397 | Elapsed Time: 0:04:52\n",
      "Test epoch | Steps: 398 | Elapsed Time: 0:04:53\n",
      "Test epoch | Steps: 399 | Elapsed Time: 0:04:54\n",
      "Test epoch | Steps: 400 | Elapsed Time: 0:04:55\n",
      "Test epoch | Steps: 401 | Elapsed Time: 0:04:56\n",
      "Test epoch | Steps: 402 | Elapsed Time: 0:04:57\n",
      "Test epoch | Steps: 403 | Elapsed Time: 0:04:58\n",
      "Test epoch | Steps: 404 | Elapsed Time: 0:04:59\n",
      "Test epoch | Steps: 405 | Elapsed Time: 0:04:59\n",
      "Test epoch | Steps: 406 | Elapsed Time: 0:05:00\n",
      "Test epoch | Steps: 407 | Elapsed Time: 0:05:01\n",
      "Test epoch | Steps: 408 | Elapsed Time: 0:05:02\n",
      "Test epoch | Steps: 409 | Elapsed Time: 0:05:03\n",
      "Test epoch | Steps: 410 | Elapsed Time: 0:05:04\n",
      "Test epoch | Steps: 411 | Elapsed Time: 0:05:05\n",
      "Test epoch | Steps: 412 | Elapsed Time: 0:05:06\n",
      "Test epoch | Steps: 413 | Elapsed Time: 0:05:07\n",
      "Test epoch | Steps: 414 | Elapsed Time: 0:05:08\n",
      "Test epoch | Steps: 415 | Elapsed Time: 0:05:09\n",
      "Test epoch | Steps: 416 | Elapsed Time: 0:05:10\n",
      "Test epoch | Steps: 417 | Elapsed Time: 0:05:11\n",
      "Test epoch | Steps: 418 | Elapsed Time: 0:05:12\n",
      "Test epoch | Steps: 419 | Elapsed Time: 0:05:13\n",
      "Test epoch | Steps: 420 | Elapsed Time: 0:05:14\n",
      "Test epoch | Steps: 421 | Elapsed Time: 0:05:15\n",
      "Test epoch | Steps: 422 | Elapsed Time: 0:05:16\n",
      "Test epoch | Steps: 423 | Elapsed Time: 0:05:17\n",
      "Test epoch | Steps: 424 | Elapsed Time: 0:05:18\n",
      "Test epoch | Steps: 425 | Elapsed Time: 0:05:19\n",
      "Test epoch | Steps: 426 | Elapsed Time: 0:05:20\n",
      "Test epoch | Steps: 427 | Elapsed Time: 0:05:20\n",
      "Test epoch | Steps: 428 | Elapsed Time: 0:05:21\n",
      "Test epoch | Steps: 429 | Elapsed Time: 0:05:22\n",
      "Test epoch | Steps: 430 | Elapsed Time: 0:05:23\n",
      "Test epoch | Steps: 431 | Elapsed Time: 0:05:24\n",
      "Test epoch | Steps: 432 | Elapsed Time: 0:05:25\n",
      "Test epoch | Steps: 433 | Elapsed Time: 0:05:26\n",
      "Test epoch | Steps: 434 | Elapsed Time: 0:05:27\n",
      "Test epoch | Steps: 435 | Elapsed Time: 0:05:28\n",
      "Test epoch | Steps: 436 | Elapsed Time: 0:05:29\n",
      "Test epoch | Steps: 437 | Elapsed Time: 0:05:30\n",
      "Test epoch | Steps: 438 | Elapsed Time: 0:05:31\n",
      "Test epoch | Steps: 439 | Elapsed Time: 0:05:32\n",
      "Test epoch | Steps: 440 | Elapsed Time: 0:05:33\n",
      "Test epoch | Steps: 441 | Elapsed Time: 0:05:34\n",
      "Test epoch | Steps: 442 | Elapsed Time: 0:05:35\n",
      "Test epoch | Steps: 443 | Elapsed Time: 0:05:36\n",
      "Test epoch | Steps: 444 | Elapsed Time: 0:05:37\n",
      "Test epoch | Steps: 445 | Elapsed Time: 0:05:38\n",
      "Test epoch | Steps: 446 | Elapsed Time: 0:05:39\n",
      "Test epoch | Steps: 447 | Elapsed Time: 0:05:40\n",
      "Test epoch | Steps: 448 | Elapsed Time: 0:05:41\n",
      "Test epoch | Steps: 449 | Elapsed Time: 0:05:42\n",
      "Test epoch | Steps: 450 | Elapsed Time: 0:05:42\n",
      "Test epoch | Steps: 451 | Elapsed Time: 0:05:43\n",
      "Test epoch | Steps: 452 | Elapsed Time: 0:05:44\n",
      "Test epoch | Steps: 453 | Elapsed Time: 0:05:45\n",
      "Test epoch | Steps: 454 | Elapsed Time: 0:05:46\n",
      "Test epoch | Steps: 455 | Elapsed Time: 0:05:47\n",
      "Test epoch | Steps: 456 | Elapsed Time: 0:05:48\n",
      "Test epoch | Steps: 457 | Elapsed Time: 0:05:49\n",
      "Test epoch | Steps: 458 | Elapsed Time: 0:05:50\n",
      "Test epoch | Steps: 459 | Elapsed Time: 0:05:51\n",
      "Test epoch | Steps: 460 | Elapsed Time: 0:05:52\n",
      "Test epoch | Steps: 461 | Elapsed Time: 0:05:53\n",
      "Test epoch | Steps: 462 | Elapsed Time: 0:05:54\n",
      "Test epoch | Steps: 463 | Elapsed Time: 0:05:55\n",
      "Test epoch | Steps: 464 | Elapsed Time: 0:05:56\n",
      "Test epoch | Steps: 465 | Elapsed Time: 0:05:56\n",
      "Test epoch | Steps: 466 | Elapsed Time: 0:05:57\n",
      "Test epoch | Steps: 467 | Elapsed Time: 0:05:58\n",
      "Test epoch | Steps: 468 | Elapsed Time: 0:05:59\n",
      "Test epoch | Steps: 469 | Elapsed Time: 0:06:00\n",
      "Test epoch | Steps: 470 | Elapsed Time: 0:06:01\n",
      "Test epoch | Steps: 471 | Elapsed Time: 0:06:02\n",
      "Test epoch | Steps: 472 | Elapsed Time: 0:06:03\n",
      "Test epoch | Steps: 473 | Elapsed Time: 0:06:04\n",
      "Test epoch | Steps: 474 | Elapsed Time: 0:06:05\n",
      "Test epoch | Steps: 475 | Elapsed Time: 0:06:06\n",
      "Test epoch | Steps: 476 | Elapsed Time: 0:06:07\n",
      "Test epoch | Steps: 477 | Elapsed Time: 0:06:08\n",
      "Test epoch | Steps: 478 | Elapsed Time: 0:06:09\n",
      "Test epoch | Steps: 479 | Elapsed Time: 0:06:10\n",
      "Test epoch | Steps: 480 | Elapsed Time: 0:06:11\n",
      "Test epoch | Steps: 481 | Elapsed Time: 0:06:12\n",
      "Test epoch | Steps: 482 | Elapsed Time: 0:06:13\n",
      "Test epoch | Steps: 483 | Elapsed Time: 0:06:14\n",
      "Test epoch | Steps: 484 | Elapsed Time: 0:06:15\n",
      "Test epoch | Steps: 485 | Elapsed Time: 0:06:16\n",
      "Test epoch | Steps: 486 | Elapsed Time: 0:06:17\n",
      "Test epoch | Steps: 487 | Elapsed Time: 0:06:18\n",
      "Test epoch | Steps: 488 | Elapsed Time: 0:06:18\n",
      "Test epoch | Steps: 489 | Elapsed Time: 0:06:19\n",
      "Test epoch | Steps: 490 | Elapsed Time: 0:06:20\n",
      "Test epoch | Steps: 491 | Elapsed Time: 0:06:21\n",
      "Test epoch | Steps: 492 | Elapsed Time: 0:06:22\n",
      "Test epoch | Steps: 493 | Elapsed Time: 0:06:23\n",
      "Test epoch | Steps: 494 | Elapsed Time: 0:06:24\n",
      "Test epoch | Steps: 495 | Elapsed Time: 0:06:25\n",
      "Test epoch | Steps: 496 | Elapsed Time: 0:06:26\n",
      "Test epoch | Steps: 497 | Elapsed Time: 0:06:27\n",
      "Test epoch | Steps: 498 | Elapsed Time: 0:06:27\n",
      "Test epoch | Steps: 499 | Elapsed Time: 0:06:28\n",
      "Test epoch | Steps: 500 | Elapsed Time: 0:06:29\n",
      "Test epoch | Steps: 501 | Elapsed Time: 0:06:30\n",
      "Test epoch | Steps: 502 | Elapsed Time: 0:06:31\n",
      "Test epoch | Steps: 503 | Elapsed Time: 0:06:32\n",
      "Test epoch | Steps: 504 | Elapsed Time: 0:06:33\n",
      "Test epoch | Steps: 505 | Elapsed Time: 0:06:34\n",
      "Test epoch | Steps: 506 | Elapsed Time: 0:06:35\n",
      "Test epoch | Steps: 507 | Elapsed Time: 0:06:36\n",
      "Test epoch | Steps: 508 | Elapsed Time: 0:06:37\n",
      "Test epoch | Steps: 509 | Elapsed Time: 0:06:38\n",
      "Test epoch | Steps: 510 | Elapsed Time: 0:06:39\n",
      "Test epoch | Steps: 511 | Elapsed Time: 0:06:40\n",
      "Test epoch | Steps: 512 | Elapsed Time: 0:06:41\n",
      "Test epoch | Steps: 513 | Elapsed Time: 0:06:42\n",
      "Test epoch | Steps: 514 | Elapsed Time: 0:06:43\n",
      "Test epoch | Steps: 515 | Elapsed Time: 0:06:44\n",
      "Test epoch | Steps: 516 | Elapsed Time: 0:06:45\n",
      "Test epoch | Steps: 517 | Elapsed Time: 0:06:46\n",
      "Test epoch | Steps: 518 | Elapsed Time: 0:06:47\n",
      "Test epoch | Steps: 519 | Elapsed Time: 0:06:48\n",
      "Test epoch | Steps: 520 | Elapsed Time: 0:06:49\n",
      "Test epoch | Steps: 521 | Elapsed Time: 0:06:50\n",
      "Test epoch | Steps: 522 | Elapsed Time: 0:06:51\n",
      "Test epoch | Steps: 523 | Elapsed Time: 0:06:52\n",
      "Test epoch | Steps: 524 | Elapsed Time: 0:06:53\n",
      "Test epoch | Steps: 525 | Elapsed Time: 0:06:54\n",
      "Test epoch | Steps: 526 | Elapsed Time: 0:06:55\n",
      "Test epoch | Steps: 527 | Elapsed Time: 0:06:56\n",
      "Test epoch | Steps: 528 | Elapsed Time: 0:06:57\n",
      "Test epoch | Steps: 529 | Elapsed Time: 0:06:58\n",
      "Test epoch | Steps: 530 | Elapsed Time: 0:06:59\n",
      "Test epoch | Steps: 531 | Elapsed Time: 0:07:00\n",
      "Test epoch | Steps: 532 | Elapsed Time: 0:07:00\n",
      "Test epoch | Steps: 533 | Elapsed Time: 0:07:01\n",
      "Test epoch | Steps: 534 | Elapsed Time: 0:07:02\n",
      "Test epoch | Steps: 535 | Elapsed Time: 0:07:04\n",
      "Test epoch | Steps: 536 | Elapsed Time: 0:07:05\n",
      "Test epoch | Steps: 537 | Elapsed Time: 0:07:05\n",
      "Test epoch | Steps: 538 | Elapsed Time: 0:07:06\n",
      "Test epoch | Steps: 539 | Elapsed Time: 0:07:07\n",
      "Test epoch | Steps: 540 | Elapsed Time: 0:07:08\n",
      "Test epoch | Steps: 541 | Elapsed Time: 0:07:09\n",
      "Test epoch | Steps: 542 | Elapsed Time: 0:07:10\n",
      "Test epoch | Steps: 543 | Elapsed Time: 0:07:11\n",
      "Test epoch | Steps: 544 | Elapsed Time: 0:07:12\n",
      "Test epoch | Steps: 545 | Elapsed Time: 0:07:13\n",
      "Test epoch | Steps: 546 | Elapsed Time: 0:07:14\n",
      "Test epoch | Steps: 547 | Elapsed Time: 0:07:15\n",
      "Test epoch | Steps: 548 | Elapsed Time: 0:07:16\n",
      "Test epoch | Steps: 549 | Elapsed Time: 0:07:17\n",
      "Test epoch | Steps: 550 | Elapsed Time: 0:07:18\n",
      "Test epoch | Steps: 551 | Elapsed Time: 0:07:19\n",
      "Test epoch | Steps: 552 | Elapsed Time: 0:07:20\n",
      "Test epoch | Steps: 553 | Elapsed Time: 0:07:21\n",
      "Test epoch | Steps: 554 | Elapsed Time: 0:07:22\n",
      "Test epoch | Steps: 555 | Elapsed Time: 0:07:24\n",
      "Test epoch | Steps: 556 | Elapsed Time: 0:07:25\n",
      "Test epoch | Steps: 557 | Elapsed Time: 0:07:26\n",
      "Test epoch | Steps: 558 | Elapsed Time: 0:07:27\n",
      "Test epoch | Steps: 559 | Elapsed Time: 0:07:28\n",
      "Test epoch | Steps: 560 | Elapsed Time: 0:07:29\n",
      "Test epoch | Steps: 561 | Elapsed Time: 0:07:30\n",
      "Test epoch | Steps: 562 | Elapsed Time: 0:07:31\n",
      "Test epoch | Steps: 563 | Elapsed Time: 0:07:32\n",
      "Test epoch | Steps: 564 | Elapsed Time: 0:07:33\n",
      "Test epoch | Steps: 565 | Elapsed Time: 0:07:34\n",
      "Test epoch | Steps: 566 | Elapsed Time: 0:07:35\n",
      "Test epoch | Steps: 567 | Elapsed Time: 0:07:36\n",
      "Test epoch | Steps: 568 | Elapsed Time: 0:07:37\n",
      "Test epoch | Steps: 569 | Elapsed Time: 0:07:38\n",
      "Test epoch | Steps: 570 | Elapsed Time: 0:07:39\n",
      "Test epoch | Steps: 571 | Elapsed Time: 0:07:40\n",
      "Test epoch | Steps: 572 | Elapsed Time: 0:07:41\n",
      "Test epoch | Steps: 573 | Elapsed Time: 0:07:42\n",
      "Test epoch | Steps: 574 | Elapsed Time: 0:07:43\n",
      "Test epoch | Steps: 575 | Elapsed Time: 0:07:44\n",
      "Test epoch | Steps: 576 | Elapsed Time: 0:07:45\n",
      "Test epoch | Steps: 577 | Elapsed Time: 0:07:46\n",
      "Test epoch | Steps: 578 | Elapsed Time: 0:07:47\n",
      "Test epoch | Steps: 579 | Elapsed Time: 0:07:48\n",
      "Test epoch | Steps: 580 | Elapsed Time: 0:07:49\n",
      "Test epoch | Steps: 581 | Elapsed Time: 0:07:50\n",
      "Test epoch | Steps: 582 | Elapsed Time: 0:07:51\n",
      "Test epoch | Steps: 583 | Elapsed Time: 0:07:52\n",
      "Test epoch | Steps: 584 | Elapsed Time: 0:07:53\n",
      "Test epoch | Steps: 585 | Elapsed Time: 0:07:55\n",
      "Test epoch | Steps: 586 | Elapsed Time: 0:07:55\n",
      "Test epoch | Steps: 587 | Elapsed Time: 0:07:56\n",
      "Test epoch | Steps: 588 | Elapsed Time: 0:07:57\n",
      "Test epoch | Steps: 589 | Elapsed Time: 0:07:58\n",
      "Test epoch | Steps: 590 | Elapsed Time: 0:07:59\n",
      "Test epoch | Steps: 591 | Elapsed Time: 0:08:01\n",
      "Test epoch | Steps: 592 | Elapsed Time: 0:08:02\n",
      "Test epoch | Steps: 593 | Elapsed Time: 0:08:03\n",
      "Test epoch | Steps: 594 | Elapsed Time: 0:08:04\n",
      "Test epoch | Steps: 595 | Elapsed Time: 0:08:05\n",
      "Test epoch | Steps: 596 | Elapsed Time: 0:08:06\n",
      "Test epoch | Steps: 597 | Elapsed Time: 0:08:07\n",
      "Test epoch | Steps: 598 | Elapsed Time: 0:08:08\n",
      "Test epoch | Steps: 599 | Elapsed Time: 0:08:09\n",
      "Test epoch | Steps: 600 | Elapsed Time: 0:08:11\n",
      "Test epoch | Steps: 601 | Elapsed Time: 0:08:12\n",
      "Test epoch | Steps: 602 | Elapsed Time: 0:08:13\n",
      "Test epoch | Steps: 603 | Elapsed Time: 0:08:14\n",
      "Test epoch | Steps: 604 | Elapsed Time: 0:08:15\n",
      "Test epoch | Steps: 605 | Elapsed Time: 0:08:16\n",
      "Test epoch | Steps: 606 | Elapsed Time: 0:08:17\n",
      "Test epoch | Steps: 607 | Elapsed Time: 0:08:18\n",
      "Test epoch | Steps: 608 | Elapsed Time: 0:08:19\n",
      "Test epoch | Steps: 609 | Elapsed Time: 0:08:20\n",
      "Test epoch | Steps: 610 | Elapsed Time: 0:08:21\n",
      "Test epoch | Steps: 611 | Elapsed Time: 0:08:22\n",
      "Test epoch | Steps: 612 | Elapsed Time: 0:08:24\n",
      "Test epoch | Steps: 613 | Elapsed Time: 0:08:25\n",
      "Test epoch | Steps: 614 | Elapsed Time: 0:08:26\n",
      "Test epoch | Steps: 615 | Elapsed Time: 0:08:27\n",
      "Test epoch | Steps: 616 | Elapsed Time: 0:08:28\n",
      "Test epoch | Steps: 617 | Elapsed Time: 0:08:29\n",
      "Test epoch | Steps: 618 | Elapsed Time: 0:08:30\n",
      "Test epoch | Steps: 619 | Elapsed Time: 0:08:31\n",
      "Test epoch | Steps: 620 | Elapsed Time: 0:08:33\n",
      "Test epoch | Steps: 621 | Elapsed Time: 0:08:34\n",
      "Test epoch | Steps: 622 | Elapsed Time: 0:08:35\n",
      "Test epoch | Steps: 623 | Elapsed Time: 0:08:36\n",
      "Test epoch | Steps: 624 | Elapsed Time: 0:08:37\n",
      "Test epoch | Steps: 625 | Elapsed Time: 0:08:38\n",
      "Test epoch | Steps: 626 | Elapsed Time: 0:08:39\n",
      "Test epoch | Steps: 627 | Elapsed Time: 0:08:40\n",
      "Test epoch | Steps: 628 | Elapsed Time: 0:08:41\n",
      "Test epoch | Steps: 629 | Elapsed Time: 0:08:43\n",
      "Test epoch | Steps: 630 | Elapsed Time: 0:08:44\n",
      "Test epoch | Steps: 631 | Elapsed Time: 0:08:45\n",
      "Test epoch | Steps: 632 | Elapsed Time: 0:08:46\n",
      "Test epoch | Steps: 633 | Elapsed Time: 0:08:47\n",
      "Test epoch | Steps: 634 | Elapsed Time: 0:08:48\n",
      "Test epoch | Steps: 635 | Elapsed Time: 0:08:49\n",
      "Test epoch | Steps: 636 | Elapsed Time: 0:08:50\n",
      "Test epoch | Steps: 637 | Elapsed Time: 0:08:51\n",
      "Test epoch | Steps: 638 | Elapsed Time: 0:08:53\n",
      "Test epoch | Steps: 639 | Elapsed Time: 0:08:54\n",
      "Test epoch | Steps: 640 | Elapsed Time: 0:08:55\n",
      "Test epoch | Steps: 641 | Elapsed Time: 0:08:56\n",
      "Test epoch | Steps: 642 | Elapsed Time: 0:08:57\n",
      "Test epoch | Steps: 643 | Elapsed Time: 0:08:58\n",
      "Test epoch | Steps: 644 | Elapsed Time: 0:08:59\n",
      "Test epoch | Steps: 645 | Elapsed Time: 0:09:00\n",
      "Test epoch | Steps: 646 | Elapsed Time: 0:09:01\n",
      "Test epoch | Steps: 647 | Elapsed Time: 0:09:03\n",
      "Test epoch | Steps: 648 | Elapsed Time: 0:09:04\n",
      "Test epoch | Steps: 649 | Elapsed Time: 0:09:05\n",
      "Test epoch | Steps: 650 | Elapsed Time: 0:09:06\n",
      "Test epoch | Steps: 651 | Elapsed Time: 0:09:07\n",
      "Test epoch | Steps: 652 | Elapsed Time: 0:09:08\n",
      "Test epoch | Steps: 653 | Elapsed Time: 0:09:09\n",
      "Test epoch | Steps: 654 | Elapsed Time: 0:09:10\n",
      "Test epoch | Steps: 655 | Elapsed Time: 0:09:12\n",
      "Test epoch | Steps: 656 | Elapsed Time: 0:09:13\n",
      "Test epoch | Steps: 657 | Elapsed Time: 0:09:14\n",
      "Test epoch | Steps: 658 | Elapsed Time: 0:09:15\n",
      "Test epoch | Steps: 659 | Elapsed Time: 0:09:16\n",
      "Test epoch | Steps: 660 | Elapsed Time: 0:09:17\n",
      "Test epoch | Steps: 661 | Elapsed Time: 0:09:18\n",
      "Test epoch | Steps: 662 | Elapsed Time: 0:09:19\n",
      "Test epoch | Steps: 663 | Elapsed Time: 0:09:20\n",
      "Test epoch | Steps: 664 | Elapsed Time: 0:09:21\n",
      "Test epoch | Steps: 665 | Elapsed Time: 0:09:23\n",
      "Test epoch | Steps: 666 | Elapsed Time: 0:09:24\n",
      "Test epoch | Steps: 667 | Elapsed Time: 0:09:25\n",
      "Test epoch | Steps: 668 | Elapsed Time: 0:09:26\n",
      "Test epoch | Steps: 669 | Elapsed Time: 0:09:27\n",
      "Test epoch | Steps: 670 | Elapsed Time: 0:09:28\n",
      "Test epoch | Steps: 671 | Elapsed Time: 0:09:29\n",
      "Test epoch | Steps: 672 | Elapsed Time: 0:09:30\n",
      "Test epoch | Steps: 673 | Elapsed Time: 0:09:31\n",
      "Test epoch | Steps: 674 | Elapsed Time: 0:09:32\n",
      "Test epoch | Steps: 675 | Elapsed Time: 0:09:34\n",
      "Test epoch | Steps: 676 | Elapsed Time: 0:09:35\n",
      "Test epoch | Steps: 677 | Elapsed Time: 0:09:36\n",
      "Test epoch | Steps: 678 | Elapsed Time: 0:09:37\n",
      "Test epoch | Steps: 679 | Elapsed Time: 0:09:38\n",
      "Test epoch | Steps: 680 | Elapsed Time: 0:09:39\n",
      "Test epoch | Steps: 681 | Elapsed Time: 0:09:40\n",
      "Test epoch | Steps: 682 | Elapsed Time: 0:09:41\n",
      "Test epoch | Steps: 683 | Elapsed Time: 0:09:43\n",
      "Test epoch | Steps: 684 | Elapsed Time: 0:09:44\n",
      "Test epoch | Steps: 685 | Elapsed Time: 0:09:45\n",
      "Test epoch | Steps: 686 | Elapsed Time: 0:09:46\n",
      "Test epoch | Steps: 687 | Elapsed Time: 0:09:47\n",
      "Test epoch | Steps: 688 | Elapsed Time: 0:09:48\n",
      "Test epoch | Steps: 689 | Elapsed Time: 0:09:49\n",
      "Test epoch | Steps: 690 | Elapsed Time: 0:09:50\n",
      "Test epoch | Steps: 691 | Elapsed Time: 0:09:52\n",
      "Test epoch | Steps: 692 | Elapsed Time: 0:09:53\n",
      "Test epoch | Steps: 693 | Elapsed Time: 0:09:54\n",
      "Test epoch | Steps: 694 | Elapsed Time: 0:09:55\n",
      "Test epoch | Steps: 695 | Elapsed Time: 0:09:56\n",
      "Test epoch | Steps: 696 | Elapsed Time: 0:09:57\n",
      "Test epoch | Steps: 697 | Elapsed Time: 0:09:58\n",
      "Test epoch | Steps: 698 | Elapsed Time: 0:10:00\n",
      "Test epoch | Steps: 699 | Elapsed Time: 0:10:01\n",
      "Test epoch | Steps: 700 | Elapsed Time: 0:10:02\n",
      "Test epoch | Steps: 701 | Elapsed Time: 0:10:03\n",
      "Test epoch | Steps: 702 | Elapsed Time: 0:10:04\n",
      "Test epoch | Steps: 703 | Elapsed Time: 0:10:05\n",
      "Test epoch | Steps: 704 | Elapsed Time: 0:10:06\n",
      "Test epoch | Steps: 705 | Elapsed Time: 0:10:07\n",
      "Test epoch | Steps: 706 | Elapsed Time: 0:10:09\n",
      "Test epoch | Steps: 707 | Elapsed Time: 0:10:10\n",
      "Test epoch | Steps: 708 | Elapsed Time: 0:10:11\n",
      "Test epoch | Steps: 709 | Elapsed Time: 0:10:12\n",
      "Test epoch | Steps: 710 | Elapsed Time: 0:10:13\n",
      "Test epoch | Steps: 711 | Elapsed Time: 0:10:15\n",
      "Test epoch | Steps: 712 | Elapsed Time: 0:10:16\n",
      "Test epoch | Steps: 713 | Elapsed Time: 0:10:17\n",
      "Test epoch | Steps: 714 | Elapsed Time: 0:10:18\n",
      "Test epoch | Steps: 715 | Elapsed Time: 0:10:19\n",
      "Test epoch | Steps: 716 | Elapsed Time: 0:10:20\n",
      "Test epoch | Steps: 717 | Elapsed Time: 0:10:22\n",
      "Test epoch | Steps: 718 | Elapsed Time: 0:10:23\n",
      "Test epoch | Steps: 719 | Elapsed Time: 0:10:24\n",
      "Test epoch | Steps: 720 | Elapsed Time: 0:10:25\n",
      "Test epoch | Steps: 721 | Elapsed Time: 0:10:26\n",
      "Test epoch | Steps: 722 | Elapsed Time: 0:10:27\n",
      "Test epoch | Steps: 723 | Elapsed Time: 0:10:28\n",
      "Test epoch | Steps: 724 | Elapsed Time: 0:10:30\n",
      "Test epoch | Steps: 725 | Elapsed Time: 0:10:31\n",
      "Test epoch | Steps: 726 | Elapsed Time: 0:10:32\n",
      "Test epoch | Steps: 727 | Elapsed Time: 0:10:33\n",
      "Test epoch | Steps: 728 | Elapsed Time: 0:10:34\n",
      "Test epoch | Steps: 729 | Elapsed Time: 0:10:35\n",
      "Test epoch | Steps: 730 | Elapsed Time: 0:10:37\n",
      "Test epoch | Steps: 731 | Elapsed Time: 0:10:38\n",
      "Test epoch | Steps: 732 | Elapsed Time: 0:10:39\n",
      "Test epoch | Steps: 733 | Elapsed Time: 0:10:40\n",
      "Test epoch | Steps: 734 | Elapsed Time: 0:10:41\n",
      "Test epoch | Steps: 735 | Elapsed Time: 0:10:42\n",
      "Test epoch | Steps: 736 | Elapsed Time: 0:10:43\n",
      "Test epoch | Steps: 737 | Elapsed Time: 0:10:45\n",
      "Test epoch | Steps: 738 | Elapsed Time: 0:10:46\n",
      "Test epoch | Steps: 739 | Elapsed Time: 0:10:47\n",
      "Test epoch | Steps: 740 | Elapsed Time: 0:10:48\n",
      "Test epoch | Steps: 741 | Elapsed Time: 0:10:49\n",
      "Test epoch | Steps: 742 | Elapsed Time: 0:10:50\n",
      "Test epoch | Steps: 743 | Elapsed Time: 0:10:51\n",
      "Test epoch | Steps: 744 | Elapsed Time: 0:10:53\n",
      "Test epoch | Steps: 745 | Elapsed Time: 0:10:54\n",
      "Test epoch | Steps: 746 | Elapsed Time: 0:10:55\n",
      "Test epoch | Steps: 747 | Elapsed Time: 0:10:56\n",
      "Test epoch | Steps: 748 | Elapsed Time: 0:10:57\n",
      "Test epoch | Steps: 749 | Elapsed Time: 0:10:58\n",
      "Test epoch | Steps: 750 | Elapsed Time: 0:11:00\n",
      "Test epoch | Steps: 751 | Elapsed Time: 0:11:01\n",
      "Test epoch | Steps: 752 | Elapsed Time: 0:11:02\n",
      "Test epoch | Steps: 753 | Elapsed Time: 0:11:03\n",
      "Test epoch | Steps: 754 | Elapsed Time: 0:11:04\n",
      "Test epoch | Steps: 755 | Elapsed Time: 0:11:06\n",
      "Test epoch | Steps: 756 | Elapsed Time: 0:11:07\n",
      "Test epoch | Steps: 757 | Elapsed Time: 0:11:08\n",
      "Test epoch | Steps: 758 | Elapsed Time: 0:11:09\n",
      "Test epoch | Steps: 759 | Elapsed Time: 0:11:10\n",
      "Test epoch | Steps: 760 | Elapsed Time: 0:11:12\n",
      "Test epoch | Steps: 761 | Elapsed Time: 0:11:13\n",
      "Test epoch | Steps: 762 | Elapsed Time: 0:11:14\n",
      "Test epoch | Steps: 763 | Elapsed Time: 0:11:15\n",
      "Test epoch | Steps: 764 | Elapsed Time: 0:11:16\n",
      "Test epoch | Steps: 765 | Elapsed Time: 0:11:17\n",
      "Test epoch | Steps: 766 | Elapsed Time: 0:11:18\n",
      "Test epoch | Steps: 767 | Elapsed Time: 0:11:20\n",
      "Test epoch | Steps: 768 | Elapsed Time: 0:11:21\n",
      "Test epoch | Steps: 769 | Elapsed Time: 0:11:22\n",
      "Test epoch | Steps: 770 | Elapsed Time: 0:11:23\n",
      "Test epoch | Steps: 771 | Elapsed Time: 0:11:24\n",
      "Test epoch | Steps: 772 | Elapsed Time: 0:11:26\n",
      "Test epoch | Steps: 773 | Elapsed Time: 0:11:27\n",
      "Test epoch | Steps: 774 | Elapsed Time: 0:11:28\n",
      "Test epoch | Steps: 775 | Elapsed Time: 0:11:29\n",
      "Test epoch | Steps: 776 | Elapsed Time: 0:11:30\n",
      "Test epoch | Steps: 777 | Elapsed Time: 0:11:31\n",
      "Test epoch | Steps: 778 | Elapsed Time: 0:11:32\n",
      "Test epoch | Steps: 779 | Elapsed Time: 0:11:34\n",
      "Test epoch | Steps: 780 | Elapsed Time: 0:11:35\n",
      "Test epoch | Steps: 781 | Elapsed Time: 0:11:36\n",
      "Test epoch | Steps: 782 | Elapsed Time: 0:11:37\n",
      "Test epoch | Steps: 783 | Elapsed Time: 0:11:38\n",
      "Test epoch | Steps: 784 | Elapsed Time: 0:11:39\n",
      "Test epoch | Steps: 785 | Elapsed Time: 0:11:41\n",
      "Test epoch | Steps: 786 | Elapsed Time: 0:11:42\n",
      "Test epoch | Steps: 787 | Elapsed Time: 0:11:43\n",
      "Test epoch | Steps: 788 | Elapsed Time: 0:11:44\n",
      "Test epoch | Steps: 789 | Elapsed Time: 0:11:45\n",
      "Test epoch | Steps: 790 | Elapsed Time: 0:11:47\n",
      "Test epoch | Steps: 791 | Elapsed Time: 0:11:48\n",
      "Test epoch | Steps: 792 | Elapsed Time: 0:11:49\n",
      "Test epoch | Steps: 793 | Elapsed Time: 0:11:50\n",
      "Test epoch | Steps: 794 | Elapsed Time: 0:11:52\n",
      "Test epoch | Steps: 795 | Elapsed Time: 0:11:53\n",
      "Test epoch | Steps: 796 | Elapsed Time: 0:11:54\n",
      "Test epoch | Steps: 797 | Elapsed Time: 0:11:55\n",
      "Test epoch | Steps: 798 | Elapsed Time: 0:11:56\n",
      "Test epoch | Steps: 799 | Elapsed Time: 0:11:58\n",
      "Test epoch | Steps: 800 | Elapsed Time: 0:11:59\n",
      "Test epoch | Steps: 801 | Elapsed Time: 0:12:00\n",
      "Test epoch | Steps: 802 | Elapsed Time: 0:12:01\n",
      "Test epoch | Steps: 803 | Elapsed Time: 0:12:02\n",
      "Test epoch | Steps: 804 | Elapsed Time: 0:12:04\n",
      "Test epoch | Steps: 805 | Elapsed Time: 0:12:05\n",
      "Test epoch | Steps: 806 | Elapsed Time: 0:12:06\n",
      "Test epoch | Steps: 807 | Elapsed Time: 0:12:07\n",
      "Test epoch | Steps: 808 | Elapsed Time: 0:12:08\n",
      "Test epoch | Steps: 809 | Elapsed Time: 0:12:10\n",
      "Test epoch | Steps: 810 | Elapsed Time: 0:12:11\n",
      "Test epoch | Steps: 811 | Elapsed Time: 0:12:12\n",
      "Test epoch | Steps: 812 | Elapsed Time: 0:12:13\n",
      "Test epoch | Steps: 813 | Elapsed Time: 0:12:15\n",
      "Test epoch | Steps: 814 | Elapsed Time: 0:12:16\n",
      "Test epoch | Steps: 815 | Elapsed Time: 0:12:17\n",
      "Test epoch | Steps: 816 | Elapsed Time: 0:12:18\n",
      "Test epoch | Steps: 817 | Elapsed Time: 0:12:19\n",
      "Test epoch | Steps: 818 | Elapsed Time: 0:12:21\n",
      "Test epoch | Steps: 819 | Elapsed Time: 0:12:22\n",
      "Test epoch | Steps: 820 | Elapsed Time: 0:12:23\n",
      "Test epoch | Steps: 821 | Elapsed Time: 0:12:24\n",
      "Test epoch | Steps: 822 | Elapsed Time: 0:12:26\n",
      "Test epoch | Steps: 823 | Elapsed Time: 0:12:27\n",
      "Test epoch | Steps: 824 | Elapsed Time: 0:12:28\n",
      "Test epoch | Steps: 825 | Elapsed Time: 0:12:29\n",
      "Test epoch | Steps: 826 | Elapsed Time: 0:12:30\n",
      "Test epoch | Steps: 827 | Elapsed Time: 0:12:32\n",
      "Test epoch | Steps: 828 | Elapsed Time: 0:12:33\n",
      "Test epoch | Steps: 829 | Elapsed Time: 0:12:34\n",
      "Test epoch | Steps: 830 | Elapsed Time: 0:12:36\n",
      "Test epoch | Steps: 831 | Elapsed Time: 0:12:37\n",
      "Test epoch | Steps: 832 | Elapsed Time: 0:12:38\n",
      "Test epoch | Steps: 833 | Elapsed Time: 0:12:39\n",
      "Test epoch | Steps: 834 | Elapsed Time: 0:12:40\n",
      "Test epoch | Steps: 835 | Elapsed Time: 0:12:41\n",
      "Test epoch | Steps: 836 | Elapsed Time: 0:12:43\n",
      "Test epoch | Steps: 837 | Elapsed Time: 0:12:44\n",
      "Test epoch | Steps: 838 | Elapsed Time: 0:12:45\n",
      "Test epoch | Steps: 839 | Elapsed Time: 0:12:46\n",
      "Test epoch | Steps: 840 | Elapsed Time: 0:12:47\n",
      "Test epoch | Steps: 841 | Elapsed Time: 0:12:49\n",
      "Test epoch | Steps: 842 | Elapsed Time: 0:12:50\n",
      "Test epoch | Steps: 843 | Elapsed Time: 0:12:51\n",
      "Test epoch | Steps: 844 | Elapsed Time: 0:12:52\n",
      "Test epoch | Steps: 845 | Elapsed Time: 0:12:54\n",
      "Test epoch | Steps: 846 | Elapsed Time: 0:12:55\n",
      "Test epoch | Steps: 847 | Elapsed Time: 0:12:56\n",
      "Test epoch | Steps: 848 | Elapsed Time: 0:12:57\n",
      "Test epoch | Steps: 849 | Elapsed Time: 0:12:58\n",
      "Test epoch | Steps: 850 | Elapsed Time: 0:13:00\n",
      "Test epoch | Steps: 851 | Elapsed Time: 0:13:01\n",
      "Test epoch | Steps: 852 | Elapsed Time: 0:13:02\n",
      "Test epoch | Steps: 853 | Elapsed Time: 0:13:03\n",
      "Test epoch | Steps: 854 | Elapsed Time: 0:13:05\n",
      "Test epoch | Steps: 855 | Elapsed Time: 0:13:06\n",
      "Test epoch | Steps: 856 | Elapsed Time: 0:13:07\n",
      "Test epoch | Steps: 857 | Elapsed Time: 0:13:08\n",
      "Test epoch | Steps: 858 | Elapsed Time: 0:13:10\n",
      "Test epoch | Steps: 859 | Elapsed Time: 0:13:11\n",
      "Test epoch | Steps: 860 | Elapsed Time: 0:13:12\n",
      "Test epoch | Steps: 861 | Elapsed Time: 0:13:13\n",
      "Test epoch | Steps: 862 | Elapsed Time: 0:13:14\n",
      "Test epoch | Steps: 863 | Elapsed Time: 0:13:16\n",
      "Test epoch | Steps: 864 | Elapsed Time: 0:13:17\n",
      "Test epoch | Steps: 865 | Elapsed Time: 0:13:18\n",
      "Test epoch | Steps: 866 | Elapsed Time: 0:13:20\n",
      "Test epoch | Steps: 867 | Elapsed Time: 0:13:21\n",
      "Test epoch | Steps: 868 | Elapsed Time: 0:13:22\n",
      "Test epoch | Steps: 869 | Elapsed Time: 0:13:23\n",
      "Test epoch | Steps: 870 | Elapsed Time: 0:13:25\n",
      "Test epoch | Steps: 871 | Elapsed Time: 0:13:26\n",
      "Test epoch | Steps: 872 | Elapsed Time: 0:13:27\n",
      "Test epoch | Steps: 873 | Elapsed Time: 0:13:28\n",
      "Test epoch | Steps: 874 | Elapsed Time: 0:13:30\n",
      "Test epoch | Steps: 875 | Elapsed Time: 0:13:31\n",
      "Test epoch | Steps: 876 | Elapsed Time: 0:13:32\n",
      "Test epoch | Steps: 877 | Elapsed Time: 0:13:33\n",
      "Test epoch | Steps: 878 | Elapsed Time: 0:13:34\n",
      "Test epoch | Steps: 879 | Elapsed Time: 0:13:36\n",
      "Test epoch | Steps: 880 | Elapsed Time: 0:13:37\n",
      "Test epoch | Steps: 881 | Elapsed Time: 0:13:38\n",
      "Test epoch | Steps: 882 | Elapsed Time: 0:13:40\n",
      "Test epoch | Steps: 883 | Elapsed Time: 0:13:41\n",
      "Test epoch | Steps: 884 | Elapsed Time: 0:13:42\n",
      "Test epoch | Steps: 885 | Elapsed Time: 0:13:43\n",
      "Test epoch | Steps: 886 | Elapsed Time: 0:13:45\n",
      "Test epoch | Steps: 887 | Elapsed Time: 0:13:46\n",
      "Test epoch | Steps: 888 | Elapsed Time: 0:13:47\n",
      "Test epoch | Steps: 889 | Elapsed Time: 0:13:49\n",
      "Test epoch | Steps: 890 | Elapsed Time: 0:13:50\n",
      "Test epoch | Steps: 891 | Elapsed Time: 0:13:51\n",
      "Test epoch | Steps: 892 | Elapsed Time: 0:13:52\n",
      "Test epoch | Steps: 893 | Elapsed Time: 0:13:54\n",
      "Test epoch | Steps: 894 | Elapsed Time: 0:13:55\n",
      "Test epoch | Steps: 895 | Elapsed Time: 0:13:56\n",
      "Test epoch | Steps: 896 | Elapsed Time: 0:13:57\n",
      "Test epoch | Steps: 897 | Elapsed Time: 0:13:59\n",
      "Test epoch | Steps: 898 | Elapsed Time: 0:14:00\n",
      "Test epoch | Steps: 899 | Elapsed Time: 0:14:01\n",
      "Test epoch | Steps: 900 | Elapsed Time: 0:14:02\n",
      "Test epoch | Steps: 901 | Elapsed Time: 0:14:04\n",
      "Test epoch | Steps: 902 | Elapsed Time: 0:14:05\n",
      "Test epoch | Steps: 903 | Elapsed Time: 0:14:06\n",
      "Test epoch | Steps: 904 | Elapsed Time: 0:14:07\n",
      "Test epoch | Steps: 905 | Elapsed Time: 0:14:09\n",
      "Test epoch | Steps: 906 | Elapsed Time: 0:14:10\n",
      "Test epoch | Steps: 907 | Elapsed Time: 0:14:11\n",
      "Test epoch | Steps: 908 | Elapsed Time: 0:14:13\n",
      "Test epoch | Steps: 909 | Elapsed Time: 0:14:14\n",
      "Test epoch | Steps: 910 | Elapsed Time: 0:14:15\n",
      "Test epoch | Steps: 911 | Elapsed Time: 0:14:17\n",
      "Test epoch | Steps: 912 | Elapsed Time: 0:14:18\n",
      "Test epoch | Steps: 913 | Elapsed Time: 0:14:19\n",
      "Test epoch | Steps: 914 | Elapsed Time: 0:14:20\n",
      "Test epoch | Steps: 915 | Elapsed Time: 0:14:22\n",
      "Test epoch | Steps: 916 | Elapsed Time: 0:14:23\n",
      "Test epoch | Steps: 917 | Elapsed Time: 0:14:24\n",
      "Test epoch | Steps: 918 | Elapsed Time: 0:14:26\n",
      "Test epoch | Steps: 919 | Elapsed Time: 0:14:27\n",
      "Test epoch | Steps: 920 | Elapsed Time: 0:14:28\n",
      "Test epoch | Steps: 921 | Elapsed Time: 0:14:29\n",
      "Test epoch | Steps: 922 | Elapsed Time: 0:14:31\n",
      "Test epoch | Steps: 923 | Elapsed Time: 0:14:32\n",
      "Test epoch | Steps: 924 | Elapsed Time: 0:14:33\n",
      "Test epoch | Steps: 925 | Elapsed Time: 0:14:35\n",
      "Test epoch | Steps: 926 | Elapsed Time: 0:14:36\n",
      "Test epoch | Steps: 927 | Elapsed Time: 0:14:37\n",
      "Test epoch | Steps: 928 | Elapsed Time: 0:14:39\n",
      "Test epoch | Steps: 929 | Elapsed Time: 0:14:40\n",
      "Test epoch | Steps: 930 | Elapsed Time: 0:14:41\n",
      "Test epoch | Steps: 931 | Elapsed Time: 0:14:42\n",
      "Test epoch | Steps: 932 | Elapsed Time: 0:14:44\n",
      "Test epoch | Steps: 933 | Elapsed Time: 0:14:45\n",
      "Test epoch | Steps: 934 | Elapsed Time: 0:14:46\n",
      "Test epoch | Steps: 935 | Elapsed Time: 0:14:47\n",
      "Test epoch | Steps: 936 | Elapsed Time: 0:14:49\n",
      "Test epoch | Steps: 937 | Elapsed Time: 0:14:50\n",
      "Test epoch | Steps: 938 | Elapsed Time: 0:14:51\n",
      "Test epoch | Steps: 939 | Elapsed Time: 0:14:53\n",
      "Test epoch | Steps: 940 | Elapsed Time: 0:14:54\n",
      "Test epoch | Steps: 941 | Elapsed Time: 0:14:55\n",
      "Test epoch | Steps: 942 | Elapsed Time: 0:14:56\n",
      "Test epoch | Steps: 943 | Elapsed Time: 0:14:58\n",
      "Test epoch | Steps: 944 | Elapsed Time: 0:14:59\n",
      "Test epoch | Steps: 945 | Elapsed Time: 0:15:00\n",
      "Test epoch | Steps: 946 | Elapsed Time: 0:15:01\n",
      "Test epoch | Steps: 947 | Elapsed Time: 0:15:03\n",
      "Test epoch | Steps: 948 | Elapsed Time: 0:15:04\n",
      "Test epoch | Steps: 949 | Elapsed Time: 0:15:06\n",
      "Test epoch | Steps: 950 | Elapsed Time: 0:15:07\n",
      "Test epoch | Steps: 951 | Elapsed Time: 0:15:08\n",
      "Test epoch | Steps: 952 | Elapsed Time: 0:15:10\n",
      "Test epoch | Steps: 953 | Elapsed Time: 0:15:11\n",
      "Test epoch | Steps: 954 | Elapsed Time: 0:15:13\n",
      "Test epoch | Steps: 955 | Elapsed Time: 0:15:14\n",
      "Test epoch | Steps: 956 | Elapsed Time: 0:15:15\n",
      "Test epoch | Steps: 957 | Elapsed Time: 0:15:16\n",
      "Test epoch | Steps: 958 | Elapsed Time: 0:15:17\n",
      "Test epoch | Steps: 959 | Elapsed Time: 0:15:17\n",
      "Test epoch | Steps: 960 | Elapsed Time: 0:15:18\n",
      "Test epoch | Steps: 961 | Elapsed Time: 0:15:19\n",
      "Test epoch | Steps: 962 | Elapsed Time: 0:15:20\n",
      "Test epoch | Steps: 963 | Elapsed Time: 0:15:21\n",
      "Test epoch | Steps: 964 | Elapsed Time: 0:15:22\n",
      "Test epoch | Steps: 965 | Elapsed Time: 0:15:23\n",
      "Test epoch | Steps: 966 | Elapsed Time: 0:15:23\n",
      "Test epoch | Steps: 967 | Elapsed Time: 0:15:24\n",
      "Test epoch | Steps: 968 | Elapsed Time: 0:15:25\n",
      "Test epoch | Steps: 969 | Elapsed Time: 0:15:26\n",
      "Test epoch | Steps: 970 | Elapsed Time: 0:15:27\n",
      "Test epoch | Steps: 971 | Elapsed Time: 0:15:28\n",
      "Test epoch | Steps: 972 | Elapsed Time: 0:15:28\n",
      "Test epoch | Steps: 973 | Elapsed Time: 0:15:29\n",
      "Test epoch | Steps: 974 | Elapsed Time: 0:15:30\n",
      "Test epoch | Steps: 975 | Elapsed Time: 0:15:31\n",
      "Test epoch | Steps: 976 | Elapsed Time: 0:15:32\n",
      "Test epoch | Steps: 977 | Elapsed Time: 0:15:33\n",
      "Test epoch | Steps: 978 | Elapsed Time: 0:15:33\n",
      "Test epoch | Steps: 979 | Elapsed Time: 0:15:34\n",
      "Test epoch | Steps: 980 | Elapsed Time: 0:15:35\n",
      "Test epoch | Steps: 981 | Elapsed Time: 0:15:36\n",
      "Test epoch | Steps: 982 | Elapsed Time: 0:15:37\n",
      "Test epoch | Steps: 983 | Elapsed Time: 0:15:38\n",
      "Test epoch | Steps: 984 | Elapsed Time: 0:15:39\n",
      "Test epoch | Steps: 985 | Elapsed Time: 0:15:39\n",
      "Test epoch | Steps: 986 | Elapsed Time: 0:15:40\n",
      "Test epoch | Steps: 987 | Elapsed Time: 0:15:41\n",
      "Test epoch | Steps: 988 | Elapsed Time: 0:15:42\n",
      "Test epoch | Steps: 989 | Elapsed Time: 0:15:43\n",
      "Test epoch | Steps: 990 | Elapsed Time: 0:15:43\n",
      "Test epoch | Steps: 991 | Elapsed Time: 0:15:44\n",
      "Test epoch | Steps: 992 | Elapsed Time: 0:15:45\n",
      "Test epoch | Steps: 993 | Elapsed Time: 0:15:46\n",
      "Test epoch | Steps: 994 | Elapsed Time: 0:15:47\n",
      "Test epoch | Steps: 995 | Elapsed Time: 0:15:48\n",
      "Test epoch | Steps: 996 | Elapsed Time: 0:15:48\n",
      "Test epoch | Steps: 997 | Elapsed Time: 0:15:49\n",
      "Test epoch | Steps: 998 | Elapsed Time: 0:15:50\n",
      "Test epoch | Steps: 999 | Elapsed Time: 0:15:51\n",
      "Test epoch | Steps: 1000 | Elapsed Time: 0:15:52\n",
      "Test epoch | Steps: 1001 | Elapsed Time: 0:15:53\n",
      "Test epoch | Steps: 1002 | Elapsed Time: 0:15:53\n",
      "Test epoch | Steps: 1003 | Elapsed Time: 0:15:54\n",
      "Test epoch | Steps: 1004 | Elapsed Time: 0:15:55\n",
      "Test epoch | Steps: 1005 | Elapsed Time: 0:15:56\n",
      "Test epoch | Steps: 1006 | Elapsed Time: 0:15:57\n",
      "Test epoch | Steps: 1007 | Elapsed Time: 0:15:58\n",
      "Test epoch | Steps: 1008 | Elapsed Time: 0:15:59\n",
      "Test epoch | Steps: 1009 | Elapsed Time: 0:16:00\n",
      "Test epoch | Steps: 1010 | Elapsed Time: 0:16:00\n",
      "Test epoch | Steps: 1011 | Elapsed Time: 0:16:01\n",
      "Test epoch | Steps: 1012 | Elapsed Time: 0:16:02\n",
      "Test epoch | Steps: 1013 | Elapsed Time: 0:16:03\n",
      "Test epoch | Steps: 1014 | Elapsed Time: 0:16:04\n",
      "Test epoch | Steps: 1015 | Elapsed Time: 0:16:05\n",
      "Test epoch | Steps: 1016 | Elapsed Time: 0:16:06\n",
      "Test epoch | Steps: 1017 | Elapsed Time: 0:16:06\n",
      "Test epoch | Steps: 1018 | Elapsed Time: 0:16:07\n",
      "Test epoch | Steps: 1019 | Elapsed Time: 0:16:08\n",
      "Test epoch | Steps: 1020 | Elapsed Time: 0:16:09\n",
      "Test epoch | Steps: 1021 | Elapsed Time: 0:16:10\n",
      "Test epoch | Steps: 1022 | Elapsed Time: 0:16:11\n",
      "Test epoch | Steps: 1023 | Elapsed Time: 0:16:11\n",
      "Test epoch | Steps: 1024 | Elapsed Time: 0:16:12\n",
      "Test epoch | Steps: 1025 | Elapsed Time: 0:16:13\n",
      "Test epoch | Steps: 1026 | Elapsed Time: 0:16:14\n",
      "Test epoch | Steps: 1027 | Elapsed Time: 0:16:15\n",
      "Test epoch | Steps: 1028 | Elapsed Time: 0:16:16\n",
      "Test epoch | Steps: 1029 | Elapsed Time: 0:16:16\n",
      "Test epoch | Steps: 1030 | Elapsed Time: 0:16:17\n",
      "Test epoch | Steps: 1031 | Elapsed Time: 0:16:18\n",
      "Test epoch | Steps: 1032 | Elapsed Time: 0:16:19\n",
      "Test epoch | Steps: 1033 | Elapsed Time: 0:16:20\n",
      "Test epoch | Steps: 1034 | Elapsed Time: 0:16:21\n",
      "Test epoch | Steps: 1035 | Elapsed Time: 0:16:22\n",
      "Test epoch | Steps: 1036 | Elapsed Time: 0:16:23\n",
      "Test epoch | Steps: 1037 | Elapsed Time: 0:16:23\n",
      "Test epoch | Steps: 1038 | Elapsed Time: 0:16:24\n",
      "Test epoch | Steps: 1039 | Elapsed Time: 0:16:25\n",
      "Test epoch | Steps: 1040 | Elapsed Time: 0:16:26\n",
      "Test epoch | Steps: 1041 | Elapsed Time: 0:16:27\n",
      "Test epoch | Steps: 1042 | Elapsed Time: 0:16:28\n",
      "Test epoch | Steps: 1043 | Elapsed Time: 0:16:29\n",
      "Test epoch | Steps: 1044 | Elapsed Time: 0:16:29\n",
      "Test epoch | Steps: 1045 | Elapsed Time: 0:16:30\n",
      "Test epoch | Steps: 1046 | Elapsed Time: 0:16:31\n",
      "Test epoch | Steps: 1047 | Elapsed Time: 0:16:32\n",
      "Test epoch | Steps: 1048 | Elapsed Time: 0:16:33\n",
      "Test epoch | Steps: 1049 | Elapsed Time: 0:16:34\n",
      "Test epoch | Steps: 1050 | Elapsed Time: 0:16:35\n",
      "Test epoch | Steps: 1051 | Elapsed Time: 0:16:35\n",
      "Test epoch | Steps: 1052 | Elapsed Time: 0:16:36\n",
      "Test epoch | Steps: 1053 | Elapsed Time: 0:16:37\n",
      "Test epoch | Steps: 1054 | Elapsed Time: 0:16:38\n",
      "Test epoch | Steps: 1055 | Elapsed Time: 0:16:39\n",
      "Test epoch | Steps: 1056 | Elapsed Time: 0:16:40\n",
      "Test epoch | Steps: 1057 | Elapsed Time: 0:16:41\n",
      "Test epoch | Steps: 1058 | Elapsed Time: 0:16:41\n",
      "Test epoch | Steps: 1059 | Elapsed Time: 0:16:42\n",
      "Test epoch | Steps: 1060 | Elapsed Time: 0:16:43\n",
      "Test epoch | Steps: 1061 | Elapsed Time: 0:16:44\n",
      "Test epoch | Steps: 1062 | Elapsed Time: 0:16:45\n",
      "Test epoch | Steps: 1063 | Elapsed Time: 0:16:46\n",
      "Test epoch | Steps: 1064 | Elapsed Time: 0:16:46\n",
      "Test epoch | Steps: 1065 | Elapsed Time: 0:16:47\n",
      "Test epoch | Steps: 1066 | Elapsed Time: 0:16:48\n",
      "Test epoch | Steps: 1067 | Elapsed Time: 0:16:49\n",
      "Test epoch | Steps: 1068 | Elapsed Time: 0:16:50\n",
      "Test epoch | Steps: 1069 | Elapsed Time: 0:16:51\n",
      "Test epoch | Steps: 1070 | Elapsed Time: 0:16:51\n",
      "Test epoch | Steps: 1071 | Elapsed Time: 0:16:52\n",
      "Test epoch | Steps: 1072 | Elapsed Time: 0:16:53\n",
      "Test epoch | Steps: 1073 | Elapsed Time: 0:16:54\n",
      "Test epoch | Steps: 1074 | Elapsed Time: 0:16:55\n",
      "Test epoch | Steps: 1075 | Elapsed Time: 0:16:56\n",
      "Test epoch | Steps: 1076 | Elapsed Time: 0:16:57\n",
      "Test epoch | Steps: 1077 | Elapsed Time: 0:16:57\n",
      "Test epoch | Steps: 1078 | Elapsed Time: 0:16:58\n",
      "Test epoch | Steps: 1079 | Elapsed Time: 0:16:59\n",
      "Test epoch | Steps: 1080 | Elapsed Time: 0:17:00\n",
      "Test epoch | Steps: 1081 | Elapsed Time: 0:17:01\n",
      "Test epoch | Steps: 1082 | Elapsed Time: 0:17:02\n",
      "Test epoch | Steps: 1083 | Elapsed Time: 0:17:03\n",
      "Test epoch | Steps: 1084 | Elapsed Time: 0:17:03\n",
      "Test epoch | Steps: 1085 | Elapsed Time: 0:17:04\n",
      "Test epoch | Steps: 1086 | Elapsed Time: 0:17:05\n",
      "Test epoch | Steps: 1087 | Elapsed Time: 0:17:06\n",
      "Test epoch | Steps: 1088 | Elapsed Time: 0:17:07\n",
      "Test epoch | Steps: 1089 | Elapsed Time: 0:17:08\n",
      "Test epoch | Steps: 1090 | Elapsed Time: 0:17:09\n",
      "Test epoch | Steps: 1091 | Elapsed Time: 0:17:10\n",
      "Test epoch | Steps: 1092 | Elapsed Time: 0:17:10\n",
      "Test epoch | Steps: 1093 | Elapsed Time: 0:17:11\n",
      "Test epoch | Steps: 1094 | Elapsed Time: 0:17:12\n",
      "Test epoch | Steps: 1095 | Elapsed Time: 0:17:13\n",
      "Test epoch | Steps: 1096 | Elapsed Time: 0:17:14\n",
      "Test epoch | Steps: 1097 | Elapsed Time: 0:17:15\n",
      "Test epoch | Steps: 1098 | Elapsed Time: 0:17:16\n",
      "Test epoch | Steps: 1099 | Elapsed Time: 0:17:16\n",
      "Test epoch | Steps: 1100 | Elapsed Time: 0:17:17\n",
      "Test epoch | Steps: 1101 | Elapsed Time: 0:17:18\n",
      "Test epoch | Steps: 1102 | Elapsed Time: 0:17:19\n",
      "Test epoch | Steps: 1103 | Elapsed Time: 0:17:20\n",
      "Test epoch | Steps: 1104 | Elapsed Time: 0:17:21\n",
      "Test epoch | Steps: 1105 | Elapsed Time: 0:17:22\n",
      "Test epoch | Steps: 1106 | Elapsed Time: 0:17:23\n",
      "Test epoch | Steps: 1107 | Elapsed Time: 0:17:23\n",
      "Test epoch | Steps: 1108 | Elapsed Time: 0:17:24\n",
      "Test epoch | Steps: 1109 | Elapsed Time: 0:17:25\n",
      "Test epoch | Steps: 1110 | Elapsed Time: 0:17:26\n",
      "Test epoch | Steps: 1111 | Elapsed Time: 0:17:27\n",
      "Test epoch | Steps: 1112 | Elapsed Time: 0:17:28\n",
      "Test epoch | Steps: 1113 | Elapsed Time: 0:17:29\n",
      "Test epoch | Steps: 1114 | Elapsed Time: 0:17:30\n",
      "Test epoch | Steps: 1115 | Elapsed Time: 0:17:30\n",
      "Test epoch | Steps: 1116 | Elapsed Time: 0:17:31\n",
      "Test epoch | Steps: 1117 | Elapsed Time: 0:17:32\n",
      "Test epoch | Steps: 1118 | Elapsed Time: 0:17:33\n",
      "Test epoch | Steps: 1119 | Elapsed Time: 0:17:34\n",
      "Test epoch | Steps: 1120 | Elapsed Time: 0:17:35\n",
      "Test epoch | Steps: 1121 | Elapsed Time: 0:17:36\n",
      "Test epoch | Steps: 1122 | Elapsed Time: 0:17:37\n",
      "Test epoch | Steps: 1123 | Elapsed Time: 0:17:38\n",
      "Test epoch | Steps: 1124 | Elapsed Time: 0:17:38\n",
      "Test epoch | Steps: 1125 | Elapsed Time: 0:17:39\n",
      "Test epoch | Steps: 1126 | Elapsed Time: 0:17:40\n",
      "Test epoch | Steps: 1127 | Elapsed Time: 0:17:41\n",
      "Test epoch | Steps: 1128 | Elapsed Time: 0:17:42\n",
      "Test epoch | Steps: 1129 | Elapsed Time: 0:17:43\n",
      "Test epoch | Steps: 1130 | Elapsed Time: 0:17:44\n",
      "Test epoch | Steps: 1131 | Elapsed Time: 0:17:45\n",
      "Test epoch | Steps: 1132 | Elapsed Time: 0:17:46\n",
      "Test epoch | Steps: 1133 | Elapsed Time: 0:17:47\n",
      "Test epoch | Steps: 1134 | Elapsed Time: 0:17:48\n",
      "Test epoch | Steps: 1135 | Elapsed Time: 0:17:48\n",
      "Test epoch | Steps: 1136 | Elapsed Time: 0:17:49\n",
      "Test epoch | Steps: 1137 | Elapsed Time: 0:17:50\n",
      "Test epoch | Steps: 1138 | Elapsed Time: 0:17:51\n",
      "Test epoch | Steps: 1139 | Elapsed Time: 0:17:52\n",
      "Test epoch | Steps: 1140 | Elapsed Time: 0:17:53\n",
      "Test epoch | Steps: 1141 | Elapsed Time: 0:17:54\n",
      "Test epoch | Steps: 1142 | Elapsed Time: 0:17:55\n",
      "Test epoch | Steps: 1143 | Elapsed Time: 0:17:56\n",
      "Test epoch | Steps: 1144 | Elapsed Time: 0:17:56\n",
      "Test epoch | Steps: 1145 | Elapsed Time: 0:17:57\n",
      "Test epoch | Steps: 1146 | Elapsed Time: 0:17:58\n",
      "Test epoch | Steps: 1147 | Elapsed Time: 0:17:59\n",
      "Test epoch | Steps: 1148 | Elapsed Time: 0:18:00\n",
      "Test epoch | Steps: 1149 | Elapsed Time: 0:18:01\n",
      "Test epoch | Steps: 1150 | Elapsed Time: 0:18:02\n",
      "Test epoch | Steps: 1151 | Elapsed Time: 0:18:03\n",
      "Test epoch | Steps: 1152 | Elapsed Time: 0:18:03\n",
      "Test epoch | Steps: 1153 | Elapsed Time: 0:18:04\n",
      "Test epoch | Steps: 1154 | Elapsed Time: 0:18:05\n",
      "Test epoch | Steps: 1155 | Elapsed Time: 0:18:06\n",
      "Test epoch | Steps: 1156 | Elapsed Time: 0:18:07\n",
      "Test epoch | Steps: 1157 | Elapsed Time: 0:18:08\n",
      "Test epoch | Steps: 1158 | Elapsed Time: 0:18:09\n",
      "Test epoch | Steps: 1159 | Elapsed Time: 0:18:10\n",
      "Test epoch | Steps: 1160 | Elapsed Time: 0:18:10\n",
      "Test epoch | Steps: 1161 | Elapsed Time: 0:18:11\n",
      "Test epoch | Steps: 1162 | Elapsed Time: 0:18:12\n",
      "Test epoch | Steps: 1163 | Elapsed Time: 0:18:13\n",
      "Test epoch | Steps: 1164 | Elapsed Time: 0:18:14\n",
      "Test epoch | Steps: 1165 | Elapsed Time: 0:18:15\n",
      "Test epoch | Steps: 1166 | Elapsed Time: 0:18:16\n",
      "Test epoch | Steps: 1167 | Elapsed Time: 0:18:17\n",
      "Test epoch | Steps: 1168 | Elapsed Time: 0:18:18\n",
      "Test epoch | Steps: 1169 | Elapsed Time: 0:18:18\n",
      "Test epoch | Steps: 1170 | Elapsed Time: 0:18:19\n",
      "Test epoch | Steps: 1171 | Elapsed Time: 0:18:20\n",
      "Test epoch | Steps: 1172 | Elapsed Time: 0:18:21\n",
      "Test epoch | Steps: 1173 | Elapsed Time: 0:18:22\n",
      "Test epoch | Steps: 1174 | Elapsed Time: 0:18:23\n",
      "Test epoch | Steps: 1175 | Elapsed Time: 0:18:24\n",
      "Test epoch | Steps: 1176 | Elapsed Time: 0:18:25\n",
      "Test epoch | Steps: 1177 | Elapsed Time: 0:18:25\n",
      "Test epoch | Steps: 1178 | Elapsed Time: 0:18:26\n",
      "Test epoch | Steps: 1179 | Elapsed Time: 0:18:27\n",
      "Test epoch | Steps: 1180 | Elapsed Time: 0:18:28\n",
      "Test epoch | Steps: 1181 | Elapsed Time: 0:18:29\n",
      "Test epoch | Steps: 1182 | Elapsed Time: 0:18:30\n",
      "Test epoch | Steps: 1183 | Elapsed Time: 0:18:31\n",
      "Test epoch | Steps: 1184 | Elapsed Time: 0:18:31\n",
      "Test epoch | Steps: 1185 | Elapsed Time: 0:18:32\n",
      "Test epoch | Steps: 1186 | Elapsed Time: 0:18:33\n",
      "Test epoch | Steps: 1187 | Elapsed Time: 0:18:34\n",
      "Test epoch | Steps: 1188 | Elapsed Time: 0:18:35\n",
      "Test epoch | Steps: 1189 | Elapsed Time: 0:18:36\n",
      "Test epoch | Steps: 1190 | Elapsed Time: 0:18:37\n",
      "Test epoch | Steps: 1191 | Elapsed Time: 0:18:38\n",
      "Test epoch | Steps: 1192 | Elapsed Time: 0:18:39\n",
      "Test epoch | Steps: 1193 | Elapsed Time: 0:18:40\n",
      "Test epoch | Steps: 1194 | Elapsed Time: 0:18:40\n",
      "Test epoch | Steps: 1195 | Elapsed Time: 0:18:41\n",
      "Test epoch | Steps: 1196 | Elapsed Time: 0:18:42\n",
      "Test epoch | Steps: 1197 | Elapsed Time: 0:18:43\n",
      "Test epoch | Steps: 1198 | Elapsed Time: 0:18:44\n",
      "Test epoch | Steps: 1199 | Elapsed Time: 0:18:45\n",
      "Test epoch | Steps: 1200 | Elapsed Time: 0:18:46\n",
      "Test epoch | Steps: 1201 | Elapsed Time: 0:18:46\n",
      "Test epoch | Steps: 1202 | Elapsed Time: 0:18:47\n",
      "Test epoch | Steps: 1203 | Elapsed Time: 0:18:48\n",
      "Test epoch | Steps: 1204 | Elapsed Time: 0:18:49\n",
      "Test epoch | Steps: 1205 | Elapsed Time: 0:18:50\n",
      "Test epoch | Steps: 1206 | Elapsed Time: 0:18:51\n",
      "Test epoch | Steps: 1207 | Elapsed Time: 0:18:52\n",
      "Test epoch | Steps: 1208 | Elapsed Time: 0:18:53\n",
      "Test epoch | Steps: 1209 | Elapsed Time: 0:18:54\n",
      "Test epoch | Steps: 1210 | Elapsed Time: 0:18:54\n",
      "Test epoch | Steps: 1211 | Elapsed Time: 0:18:55\n",
      "Test epoch | Steps: 1212 | Elapsed Time: 0:18:56\n",
      "Test epoch | Steps: 1213 | Elapsed Time: 0:18:57\n",
      "Test epoch | Steps: 1214 | Elapsed Time: 0:18:58\n",
      "Test epoch | Steps: 1215 | Elapsed Time: 0:18:59\n",
      "Test epoch | Steps: 1216 | Elapsed Time: 0:19:00\n",
      "Test epoch | Steps: 1217 | Elapsed Time: 0:19:01\n",
      "Test epoch | Steps: 1218 | Elapsed Time: 0:19:02\n",
      "Test epoch | Steps: 1219 | Elapsed Time: 0:19:03\n",
      "Test epoch | Steps: 1220 | Elapsed Time: 0:19:03\n",
      "Test epoch | Steps: 1221 | Elapsed Time: 0:19:04\n",
      "Test epoch | Steps: 1222 | Elapsed Time: 0:19:05\n",
      "Test epoch | Steps: 1223 | Elapsed Time: 0:19:06\n",
      "Test epoch | Steps: 1224 | Elapsed Time: 0:19:07\n",
      "Test epoch | Steps: 1225 | Elapsed Time: 0:19:08\n",
      "Test epoch | Steps: 1226 | Elapsed Time: 0:19:09\n",
      "Test epoch | Steps: 1227 | Elapsed Time: 0:19:10\n",
      "Test epoch | Steps: 1228 | Elapsed Time: 0:19:11\n",
      "Test epoch | Steps: 1229 | Elapsed Time: 0:19:12\n",
      "Test epoch | Steps: 1230 | Elapsed Time: 0:19:13\n",
      "Test epoch | Steps: 1231 | Elapsed Time: 0:19:14\n",
      "Test epoch | Steps: 1232 | Elapsed Time: 0:19:15\n",
      "Test epoch | Steps: 1233 | Elapsed Time: 0:19:15\n",
      "Test epoch | Steps: 1234 | Elapsed Time: 0:19:16\n",
      "Test epoch | Steps: 1235 | Elapsed Time: 0:19:17\n",
      "Test epoch | Steps: 1236 | Elapsed Time: 0:19:18\n",
      "Test epoch | Steps: 1237 | Elapsed Time: 0:19:19\n",
      "Test epoch | Steps: 1238 | Elapsed Time: 0:19:20\n",
      "Test epoch | Steps: 1239 | Elapsed Time: 0:19:21\n",
      "Test epoch | Steps: 1240 | Elapsed Time: 0:19:22\n",
      "Test epoch | Steps: 1241 | Elapsed Time: 0:19:23\n",
      "Test epoch | Steps: 1242 | Elapsed Time: 0:19:24\n",
      "Test epoch | Steps: 1243 | Elapsed Time: 0:19:25\n",
      "Test epoch | Steps: 1244 | Elapsed Time: 0:19:26\n",
      "Test epoch | Steps: 1245 | Elapsed Time: 0:19:26\n",
      "Test epoch | Steps: 1246 | Elapsed Time: 0:19:27\n",
      "Test epoch | Steps: 1247 | Elapsed Time: 0:19:28\n",
      "Test epoch | Steps: 1248 | Elapsed Time: 0:19:29\n",
      "Test epoch | Steps: 1249 | Elapsed Time: 0:19:30\n",
      "Test epoch | Steps: 1250 | Elapsed Time: 0:19:31\n",
      "Test epoch | Steps: 1251 | Elapsed Time: 0:19:32\n",
      "Test epoch | Steps: 1252 | Elapsed Time: 0:19:33\n",
      "Test epoch | Steps: 1253 | Elapsed Time: 0:19:34\n",
      "Test epoch | Steps: 1254 | Elapsed Time: 0:19:35\n",
      "Test epoch | Steps: 1255 | Elapsed Time: 0:19:35\n",
      "Test epoch | Steps: 1256 | Elapsed Time: 0:19:36\n",
      "Test epoch | Steps: 1257 | Elapsed Time: 0:19:37\n",
      "Test epoch | Steps: 1258 | Elapsed Time: 0:19:38\n",
      "Test epoch | Steps: 1259 | Elapsed Time: 0:19:39\n",
      "Test epoch | Steps: 1260 | Elapsed Time: 0:19:40\n",
      "Test epoch | Steps: 1261 | Elapsed Time: 0:19:41\n",
      "Test epoch | Steps: 1262 | Elapsed Time: 0:19:42\n",
      "Test epoch | Steps: 1263 | Elapsed Time: 0:19:43\n",
      "Test epoch | Steps: 1264 | Elapsed Time: 0:19:44\n",
      "Test epoch | Steps: 1265 | Elapsed Time: 0:19:45\n",
      "Test epoch | Steps: 1266 | Elapsed Time: 0:19:46\n",
      "Test epoch | Steps: 1267 | Elapsed Time: 0:19:47\n",
      "Test epoch | Steps: 1268 | Elapsed Time: 0:19:48\n",
      "Test epoch | Steps: 1269 | Elapsed Time: 0:19:48\n",
      "Test epoch | Steps: 1270 | Elapsed Time: 0:19:49\n",
      "Test epoch | Steps: 1271 | Elapsed Time: 0:19:50\n",
      "Test epoch | Steps: 1272 | Elapsed Time: 0:19:51\n",
      "Test epoch | Steps: 1273 | Elapsed Time: 0:19:52\n",
      "Test epoch | Steps: 1274 | Elapsed Time: 0:19:53\n",
      "Test epoch | Steps: 1275 | Elapsed Time: 0:19:54\n",
      "Test epoch | Steps: 1276 | Elapsed Time: 0:19:55\n",
      "Test epoch | Steps: 1277 | Elapsed Time: 0:19:56\n",
      "Test epoch | Steps: 1278 | Elapsed Time: 0:19:57\n",
      "Test epoch | Steps: 1279 | Elapsed Time: 0:19:58\n",
      "Test epoch | Steps: 1280 | Elapsed Time: 0:19:59\n",
      "Test epoch | Steps: 1281 | Elapsed Time: 0:19:59\n",
      "Test epoch | Steps: 1282 | Elapsed Time: 0:20:00\n",
      "Test epoch | Steps: 1283 | Elapsed Time: 0:20:01\n",
      "Test epoch | Steps: 1284 | Elapsed Time: 0:20:02\n",
      "Test epoch | Steps: 1285 | Elapsed Time: 0:20:03\n",
      "Test epoch | Steps: 1286 | Elapsed Time: 0:20:04\n",
      "Test epoch | Steps: 1287 | Elapsed Time: 0:20:05\n",
      "Test epoch | Steps: 1288 | Elapsed Time: 0:20:06\n",
      "Test epoch | Steps: 1289 | Elapsed Time: 0:20:07\n",
      "Test epoch | Steps: 1290 | Elapsed Time: 0:20:08\n",
      "Test epoch | Steps: 1291 | Elapsed Time: 0:20:09\n",
      "Test epoch | Steps: 1292 | Elapsed Time: 0:20:10\n",
      "Test epoch | Steps: 1293 | Elapsed Time: 0:20:10\n",
      "Test epoch | Steps: 1294 | Elapsed Time: 0:20:11\n",
      "Test epoch | Steps: 1295 | Elapsed Time: 0:20:12\n",
      "Test epoch | Steps: 1296 | Elapsed Time: 0:20:13\n",
      "Test epoch | Steps: 1297 | Elapsed Time: 0:20:14\n",
      "Test epoch | Steps: 1298 | Elapsed Time: 0:20:15\n",
      "Test epoch | Steps: 1299 | Elapsed Time: 0:20:16\n",
      "Test epoch | Steps: 1300 | Elapsed Time: 0:20:17\n",
      "Test epoch | Steps: 1301 | Elapsed Time: 0:20:18\n",
      "Test epoch | Steps: 1302 | Elapsed Time: 0:20:19\n",
      "Test epoch | Steps: 1303 | Elapsed Time: 0:20:20\n",
      "Test epoch | Steps: 1304 | Elapsed Time: 0:20:21\n",
      "Test epoch | Steps: 1305 | Elapsed Time: 0:20:22\n",
      "Test epoch | Steps: 1306 | Elapsed Time: 0:20:23\n",
      "Test epoch | Steps: 1307 | Elapsed Time: 0:20:24\n",
      "Test epoch | Steps: 1308 | Elapsed Time: 0:20:25\n",
      "Test epoch | Steps: 1309 | Elapsed Time: 0:20:26\n",
      "Test epoch | Steps: 1310 | Elapsed Time: 0:20:26\n",
      "Test epoch | Steps: 1311 | Elapsed Time: 0:20:27\n",
      "Test epoch | Steps: 1312 | Elapsed Time: 0:20:28\n",
      "Test epoch | Steps: 1313 | Elapsed Time: 0:20:29\n",
      "Test epoch | Steps: 1314 | Elapsed Time: 0:20:30\n",
      "Test epoch | Steps: 1315 | Elapsed Time: 0:20:31\n",
      "Test epoch | Steps: 1316 | Elapsed Time: 0:20:32\n",
      "Test epoch | Steps: 1317 | Elapsed Time: 0:20:33\n",
      "Test epoch | Steps: 1318 | Elapsed Time: 0:20:34\n",
      "Test epoch | Steps: 1319 | Elapsed Time: 0:20:35\n",
      "Test epoch | Steps: 1320 | Elapsed Time: 0:20:36\n",
      "Test epoch | Steps: 1321 | Elapsed Time: 0:20:37\n",
      "Test epoch | Steps: 1322 | Elapsed Time: 0:20:38\n",
      "Test epoch | Steps: 1323 | Elapsed Time: 0:20:38\n",
      "Test epoch | Steps: 1324 | Elapsed Time: 0:20:39\n",
      "Test epoch | Steps: 1325 | Elapsed Time: 0:20:40\n",
      "Test epoch | Steps: 1326 | Elapsed Time: 0:20:41\n",
      "Test epoch | Steps: 1327 | Elapsed Time: 0:20:42\n",
      "Test epoch | Steps: 1328 | Elapsed Time: 0:20:43\n",
      "Test epoch | Steps: 1329 | Elapsed Time: 0:20:44\n",
      "Test epoch | Steps: 1330 | Elapsed Time: 0:20:45\n",
      "Test epoch | Steps: 1331 | Elapsed Time: 0:20:46\n",
      "Test epoch | Steps: 1332 | Elapsed Time: 0:20:47\n",
      "Test epoch | Steps: 1333 | Elapsed Time: 0:20:48\n",
      "Test epoch | Steps: 1334 | Elapsed Time: 0:20:49\n",
      "Test epoch | Steps: 1335 | Elapsed Time: 0:20:49\n",
      "Test epoch | Steps: 1336 | Elapsed Time: 0:20:50\n",
      "Test epoch | Steps: 1337 | Elapsed Time: 0:20:51\n",
      "Test epoch | Steps: 1338 | Elapsed Time: 0:20:52\n",
      "Test epoch | Steps: 1339 | Elapsed Time: 0:20:53\n",
      "Test epoch | Steps: 1340 | Elapsed Time: 0:20:54\n",
      "Test epoch | Steps: 1341 | Elapsed Time: 0:20:55\n",
      "Test epoch | Steps: 1342 | Elapsed Time: 0:20:56\n",
      "Test epoch | Steps: 1343 | Elapsed Time: 0:20:57\n",
      "Test epoch | Steps: 1344 | Elapsed Time: 0:20:58\n",
      "Test epoch | Steps: 1345 | Elapsed Time: 0:20:59\n",
      "Test epoch | Steps: 1346 | Elapsed Time: 0:21:00\n",
      "Test epoch | Steps: 1347 | Elapsed Time: 0:21:01\n",
      "Test epoch | Steps: 1348 | Elapsed Time: 0:21:02\n",
      "Test epoch | Steps: 1349 | Elapsed Time: 0:21:03\n",
      "Test epoch | Steps: 1350 | Elapsed Time: 0:21:04\n",
      "Test epoch | Steps: 1351 | Elapsed Time: 0:21:05\n",
      "Test epoch | Steps: 1352 | Elapsed Time: 0:21:06\n",
      "Test epoch | Steps: 1353 | Elapsed Time: 0:21:06\n",
      "Test epoch | Steps: 1354 | Elapsed Time: 0:21:07\n",
      "Test epoch | Steps: 1355 | Elapsed Time: 0:21:08\n",
      "Test epoch | Steps: 1356 | Elapsed Time: 0:21:09\n",
      "Test epoch | Steps: 1357 | Elapsed Time: 0:21:10\n",
      "Test epoch | Steps: 1358 | Elapsed Time: 0:21:11\n",
      "Test epoch | Steps: 1359 | Elapsed Time: 0:21:12\n",
      "Test epoch | Steps: 1360 | Elapsed Time: 0:21:13\n",
      "Test epoch | Steps: 1361 | Elapsed Time: 0:21:14\n",
      "Test epoch | Steps: 1362 | Elapsed Time: 0:21:15\n",
      "Test epoch | Steps: 1363 | Elapsed Time: 0:21:16\n",
      "Test epoch | Steps: 1364 | Elapsed Time: 0:21:17\n",
      "Test epoch | Steps: 1365 | Elapsed Time: 0:21:18\n",
      "Test epoch | Steps: 1366 | Elapsed Time: 0:21:19\n",
      "Test epoch | Steps: 1367 | Elapsed Time: 0:21:20\n",
      "Test epoch | Steps: 1368 | Elapsed Time: 0:21:21\n",
      "Test epoch | Steps: 1369 | Elapsed Time: 0:21:22\n",
      "Test epoch | Steps: 1370 | Elapsed Time: 0:21:23\n",
      "Test epoch | Steps: 1371 | Elapsed Time: 0:21:24\n",
      "Test epoch | Steps: 1372 | Elapsed Time: 0:21:25\n",
      "Test epoch | Steps: 1373 | Elapsed Time: 0:21:26\n",
      "Test epoch | Steps: 1374 | Elapsed Time: 0:21:27\n",
      "Test epoch | Steps: 1375 | Elapsed Time: 0:21:28\n",
      "Test epoch | Steps: 1376 | Elapsed Time: 0:21:29\n",
      "Test epoch | Steps: 1377 | Elapsed Time: 0:21:30\n",
      "Test epoch | Steps: 1378 | Elapsed Time: 0:21:31\n",
      "Test epoch | Steps: 1379 | Elapsed Time: 0:21:32\n",
      "Test epoch | Steps: 1380 | Elapsed Time: 0:21:32\n",
      "Test epoch | Steps: 1381 | Elapsed Time: 0:21:33\n",
      "Test epoch | Steps: 1382 | Elapsed Time: 0:21:34\n",
      "Test epoch | Steps: 1383 | Elapsed Time: 0:21:35\n",
      "Test epoch | Steps: 1384 | Elapsed Time: 0:21:36\n",
      "Test epoch | Steps: 1385 | Elapsed Time: 0:21:37\n",
      "Test epoch | Steps: 1386 | Elapsed Time: 0:21:38\n",
      "Test epoch | Steps: 1387 | Elapsed Time: 0:21:39\n",
      "Test epoch | Steps: 1388 | Elapsed Time: 0:21:40\n",
      "Test epoch | Steps: 1389 | Elapsed Time: 0:21:41\n",
      "Test epoch | Steps: 1390 | Elapsed Time: 0:21:42\n",
      "Test epoch | Steps: 1391 | Elapsed Time: 0:21:43\n",
      "Test epoch | Steps: 1392 | Elapsed Time: 0:21:44\n",
      "Test epoch | Steps: 1393 | Elapsed Time: 0:21:45\n",
      "Test epoch | Steps: 1394 | Elapsed Time: 0:21:46\n",
      "Test epoch | Steps: 1395 | Elapsed Time: 0:21:47\n",
      "Test epoch | Steps: 1396 | Elapsed Time: 0:21:48\n",
      "Test epoch | Steps: 1397 | Elapsed Time: 0:21:49\n",
      "Test epoch | Steps: 1398 | Elapsed Time: 0:21:50\n",
      "Test epoch | Steps: 1399 | Elapsed Time: 0:21:51\n",
      "Test epoch | Steps: 1400 | Elapsed Time: 0:21:52\n",
      "Test epoch | Steps: 1401 | Elapsed Time: 0:21:53\n",
      "Test epoch | Steps: 1402 | Elapsed Time: 0:21:54\n",
      "Test epoch | Steps: 1403 | Elapsed Time: 0:21:55\n",
      "Test epoch | Steps: 1404 | Elapsed Time: 0:21:56\n",
      "Test epoch | Steps: 1405 | Elapsed Time: 0:21:57\n",
      "Test epoch | Steps: 1406 | Elapsed Time: 0:21:58\n",
      "Test epoch | Steps: 1407 | Elapsed Time: 0:21:59\n",
      "Test epoch | Steps: 1408 | Elapsed Time: 0:22:00\n",
      "Test epoch | Steps: 1409 | Elapsed Time: 0:22:01\n",
      "Test epoch | Steps: 1410 | Elapsed Time: 0:22:02\n",
      "Test epoch | Steps: 1411 | Elapsed Time: 0:22:03\n",
      "Test epoch | Steps: 1412 | Elapsed Time: 0:22:04\n",
      "Test epoch | Steps: 1413 | Elapsed Time: 0:22:05\n",
      "Test epoch | Steps: 1414 | Elapsed Time: 0:22:06\n",
      "Test epoch | Steps: 1415 | Elapsed Time: 0:22:07\n",
      "Test epoch | Steps: 1416 | Elapsed Time: 0:22:08\n",
      "Test epoch | Steps: 1417 | Elapsed Time: 0:22:09\n",
      "Test epoch | Steps: 1418 | Elapsed Time: 0:22:10\n",
      "Test epoch | Steps: 1419 | Elapsed Time: 0:22:11\n",
      "Test epoch | Steps: 1420 | Elapsed Time: 0:22:12\n",
      "Test epoch | Steps: 1421 | Elapsed Time: 0:22:13\n",
      "Test epoch | Steps: 1422 | Elapsed Time: 0:22:14\n",
      "Test epoch | Steps: 1423 | Elapsed Time: 0:22:15\n",
      "Test epoch | Steps: 1424 | Elapsed Time: 0:22:16\n",
      "Test epoch | Steps: 1425 | Elapsed Time: 0:22:17\n",
      "Test epoch | Steps: 1426 | Elapsed Time: 0:22:18\n",
      "Test epoch | Steps: 1427 | Elapsed Time: 0:22:19\n",
      "Test epoch | Steps: 1428 | Elapsed Time: 0:22:20\n",
      "Test epoch | Steps: 1429 | Elapsed Time: 0:22:21\n",
      "Test epoch | Steps: 1430 | Elapsed Time: 0:22:22\n",
      "Test epoch | Steps: 1431 | Elapsed Time: 0:22:23\n",
      "Test epoch | Steps: 1432 | Elapsed Time: 0:22:24\n",
      "Test epoch | Steps: 1433 | Elapsed Time: 0:22:25\n",
      "Test epoch | Steps: 1434 | Elapsed Time: 0:22:26\n",
      "Test epoch | Steps: 1435 | Elapsed Time: 0:22:27\n",
      "Test epoch | Steps: 1436 | Elapsed Time: 0:22:28\n",
      "Test epoch | Steps: 1437 | Elapsed Time: 0:22:29\n",
      "Test epoch | Steps: 1438 | Elapsed Time: 0:22:30\n",
      "Test epoch | Steps: 1439 | Elapsed Time: 0:22:31\n",
      "Test epoch | Steps: 1440 | Elapsed Time: 0:22:32\n",
      "Test epoch | Steps: 1441 | Elapsed Time: 0:22:33\n",
      "Test epoch | Steps: 1442 | Elapsed Time: 0:22:34\n",
      "Test epoch | Steps: 1443 | Elapsed Time: 0:22:35\n",
      "Test epoch | Steps: 1444 | Elapsed Time: 0:22:36\n",
      "Test epoch | Steps: 1445 | Elapsed Time: 0:22:37\n",
      "Test epoch | Steps: 1446 | Elapsed Time: 0:22:38\n",
      "Test epoch | Steps: 1447 | Elapsed Time: 0:22:39\n",
      "Test epoch | Steps: 1448 | Elapsed Time: 0:22:40\n",
      "Test epoch | Steps: 1449 | Elapsed Time: 0:22:41\n",
      "Test epoch | Steps: 1450 | Elapsed Time: 0:22:42\n",
      "Test epoch | Steps: 1451 | Elapsed Time: 0:22:43\n",
      "Test epoch | Steps: 1452 | Elapsed Time: 0:22:44\n",
      "Test epoch | Steps: 1453 | Elapsed Time: 0:22:45\n",
      "Test epoch | Steps: 1454 | Elapsed Time: 0:22:46\n",
      "Test epoch | Steps: 1455 | Elapsed Time: 0:22:47\n",
      "Test epoch | Steps: 1456 | Elapsed Time: 0:22:48\n",
      "Test epoch | Steps: 1457 | Elapsed Time: 0:22:49\n",
      "Test epoch | Steps: 1458 | Elapsed Time: 0:22:50\n",
      "Test epoch | Steps: 1459 | Elapsed Time: 0:22:51\n",
      "Test epoch | Steps: 1460 | Elapsed Time: 0:22:52\n",
      "Test epoch | Steps: 1461 | Elapsed Time: 0:22:53\n",
      "Test epoch | Steps: 1462 | Elapsed Time: 0:22:54\n",
      "Test epoch | Steps: 1463 | Elapsed Time: 0:22:55\n",
      "Test epoch | Steps: 1464 | Elapsed Time: 0:22:56\n",
      "Test epoch | Steps: 1465 | Elapsed Time: 0:22:57\n",
      "Test epoch | Steps: 1466 | Elapsed Time: 0:22:58\n",
      "Test epoch | Steps: 1467 | Elapsed Time: 0:22:59\n",
      "Test epoch | Steps: 1468 | Elapsed Time: 0:23:00\n",
      "Test epoch | Steps: 1469 | Elapsed Time: 0:23:01\n",
      "Test epoch | Steps: 1470 | Elapsed Time: 0:23:02\n",
      "Test epoch | Steps: 1471 | Elapsed Time: 0:23:03\n",
      "Test epoch | Steps: 1472 | Elapsed Time: 0:23:04\n",
      "Test epoch | Steps: 1473 | Elapsed Time: 0:23:05\n",
      "Test epoch | Steps: 1474 | Elapsed Time: 0:23:06\n",
      "Test epoch | Steps: 1475 | Elapsed Time: 0:23:07\n",
      "Test epoch | Steps: 1476 | Elapsed Time: 0:23:08\n",
      "Test epoch | Steps: 1477 | Elapsed Time: 0:23:09\n",
      "Test epoch | Steps: 1478 | Elapsed Time: 0:23:10\n",
      "Test epoch | Steps: 1479 | Elapsed Time: 0:23:11\n",
      "Test epoch | Steps: 1480 | Elapsed Time: 0:23:12\n",
      "Test epoch | Steps: 1481 | Elapsed Time: 0:23:13\n",
      "Test epoch | Steps: 1482 | Elapsed Time: 0:23:15\n",
      "Test epoch | Steps: 1483 | Elapsed Time: 0:23:16\n",
      "Test epoch | Steps: 1484 | Elapsed Time: 0:23:17\n",
      "Test epoch | Steps: 1485 | Elapsed Time: 0:23:18\n",
      "Test epoch | Steps: 1486 | Elapsed Time: 0:23:19\n",
      "Test epoch | Steps: 1487 | Elapsed Time: 0:23:20\n",
      "Test epoch | Steps: 1488 | Elapsed Time: 0:23:21\n",
      "Test epoch | Steps: 1489 | Elapsed Time: 0:23:22\n",
      "Test epoch | Steps: 1490 | Elapsed Time: 0:23:23\n",
      "Test epoch | Steps: 1491 | Elapsed Time: 0:23:24\n",
      "Test epoch | Steps: 1492 | Elapsed Time: 0:23:25\n",
      "Test epoch | Steps: 1493 | Elapsed Time: 0:23:26\n",
      "Test epoch | Steps: 1494 | Elapsed Time: 0:23:27\n",
      "Test epoch | Steps: 1495 | Elapsed Time: 0:23:28\n",
      "Test epoch | Steps: 1496 | Elapsed Time: 0:23:29\n",
      "Test epoch | Steps: 1497 | Elapsed Time: 0:23:30\n",
      "Test epoch | Steps: 1498 | Elapsed Time: 0:23:31\n",
      "Test epoch | Steps: 1499 | Elapsed Time: 0:23:32\n",
      "Test epoch | Steps: 1500 | Elapsed Time: 0:23:33\n",
      "Test epoch | Steps: 1501 | Elapsed Time: 0:23:34\n",
      "Test epoch | Steps: 1502 | Elapsed Time: 0:23:35\n",
      "Test epoch | Steps: 1503 | Elapsed Time: 0:23:36\n",
      "Test epoch | Steps: 1504 | Elapsed Time: 0:23:37\n",
      "Test epoch | Steps: 1505 | Elapsed Time: 0:23:38\n",
      "Test epoch | Steps: 1506 | Elapsed Time: 0:23:39\n",
      "Test epoch | Steps: 1507 | Elapsed Time: 0:23:40\n",
      "Test epoch | Steps: 1508 | Elapsed Time: 0:23:41\n",
      "Test epoch | Steps: 1509 | Elapsed Time: 0:23:42\n",
      "Test epoch | Steps: 1510 | Elapsed Time: 0:23:43\n",
      "Test epoch | Steps: 1511 | Elapsed Time: 0:23:44\n",
      "Test epoch | Steps: 1512 | Elapsed Time: 0:23:45\n",
      "Test epoch | Steps: 1513 | Elapsed Time: 0:23:46\n",
      "Test epoch | Steps: 1514 | Elapsed Time: 0:23:47\n",
      "Test epoch | Steps: 1515 | Elapsed Time: 0:23:48\n",
      "Test epoch | Steps: 1516 | Elapsed Time: 0:23:49\n",
      "Test epoch | Steps: 1517 | Elapsed Time: 0:23:50\n",
      "Test epoch | Steps: 1518 | Elapsed Time: 0:23:51\n",
      "Test epoch | Steps: 1519 | Elapsed Time: 0:23:52\n",
      "Test epoch | Steps: 1520 | Elapsed Time: 0:23:53\n",
      "Test epoch | Steps: 1521 | Elapsed Time: 0:23:54\n",
      "Test epoch | Steps: 1522 | Elapsed Time: 0:23:55\n",
      "Test epoch | Steps: 1523 | Elapsed Time: 0:23:56\n",
      "Test epoch | Steps: 1524 | Elapsed Time: 0:23:57\n",
      "Test epoch | Steps: 1525 | Elapsed Time: 0:23:58\n",
      "Test epoch | Steps: 1526 | Elapsed Time: 0:23:59\n",
      "Test epoch | Steps: 1527 | Elapsed Time: 0:24:00\n",
      "Test epoch | Steps: 1528 | Elapsed Time: 0:24:01\n",
      "Test epoch | Steps: 1529 | Elapsed Time: 0:24:02\n",
      "Test epoch | Steps: 1530 | Elapsed Time: 0:24:03\n",
      "Test epoch | Steps: 1531 | Elapsed Time: 0:24:04\n",
      "Test epoch | Steps: 1532 | Elapsed Time: 0:24:05\n",
      "Test epoch | Steps: 1533 | Elapsed Time: 0:24:06\n",
      "Test epoch | Steps: 1534 | Elapsed Time: 0:24:07\n",
      "Test epoch | Steps: 1535 | Elapsed Time: 0:24:08\n",
      "Test epoch | Steps: 1536 | Elapsed Time: 0:24:09\n",
      "Test epoch | Steps: 1537 | Elapsed Time: 0:24:10\n",
      "Test epoch | Steps: 1538 | Elapsed Time: 0:24:11\n",
      "Test epoch | Steps: 1539 | Elapsed Time: 0:24:13\n",
      "Test epoch | Steps: 1540 | Elapsed Time: 0:24:14\n",
      "Test epoch | Steps: 1541 | Elapsed Time: 0:24:15\n",
      "Test epoch | Steps: 1542 | Elapsed Time: 0:24:16\n",
      "Test epoch | Steps: 1543 | Elapsed Time: 0:24:17\n",
      "Test epoch | Steps: 1544 | Elapsed Time: 0:24:18\n",
      "Test epoch | Steps: 1545 | Elapsed Time: 0:24:19\n",
      "Test epoch | Steps: 1546 | Elapsed Time: 0:24:20\n",
      "Test epoch | Steps: 1547 | Elapsed Time: 0:24:21\n",
      "Test epoch | Steps: 1548 | Elapsed Time: 0:24:22\n",
      "Test epoch | Steps: 1549 | Elapsed Time: 0:24:23\n",
      "Test epoch | Steps: 1550 | Elapsed Time: 0:24:24\n",
      "Test epoch | Steps: 1551 | Elapsed Time: 0:24:25\n",
      "Test epoch | Steps: 1552 | Elapsed Time: 0:24:26\n",
      "Test epoch | Steps: 1553 | Elapsed Time: 0:24:27\n",
      "Test epoch | Steps: 1554 | Elapsed Time: 0:24:28\n",
      "Test epoch | Steps: 1555 | Elapsed Time: 0:24:29\n",
      "Test epoch | Steps: 1556 | Elapsed Time: 0:24:30\n",
      "Test epoch | Steps: 1557 | Elapsed Time: 0:24:31\n",
      "Test epoch | Steps: 1558 | Elapsed Time: 0:24:32\n",
      "Test epoch | Steps: 1559 | Elapsed Time: 0:24:33\n",
      "Test epoch | Steps: 1560 | Elapsed Time: 0:24:34\n",
      "Test epoch | Steps: 1561 | Elapsed Time: 0:24:35\n",
      "Test epoch | Steps: 1562 | Elapsed Time: 0:24:36\n",
      "Test epoch | Steps: 1563 | Elapsed Time: 0:24:37\n",
      "Test epoch | Steps: 1564 | Elapsed Time: 0:24:38\n",
      "Test epoch | Steps: 1565 | Elapsed Time: 0:24:40\n",
      "Test epoch | Steps: 1566 | Elapsed Time: 0:24:41\n",
      "Test epoch | Steps: 1567 | Elapsed Time: 0:24:42\n",
      "Test epoch | Steps: 1568 | Elapsed Time: 0:24:43\n",
      "Test epoch | Steps: 1569 | Elapsed Time: 0:24:44\n",
      "Test epoch | Steps: 1570 | Elapsed Time: 0:24:45\n",
      "Test epoch | Steps: 1571 | Elapsed Time: 0:24:46\n",
      "Test epoch | Steps: 1572 | Elapsed Time: 0:24:47\n",
      "Test epoch | Steps: 1573 | Elapsed Time: 0:24:48\n",
      "Test epoch | Steps: 1574 | Elapsed Time: 0:24:49\n",
      "Test epoch | Steps: 1575 | Elapsed Time: 0:24:50\n",
      "Test epoch | Steps: 1576 | Elapsed Time: 0:24:51\n",
      "Test epoch | Steps: 1577 | Elapsed Time: 0:24:52\n",
      "Test epoch | Steps: 1578 | Elapsed Time: 0:24:54\n",
      "Test epoch | Steps: 1579 | Elapsed Time: 0:24:55\n",
      "Test epoch | Steps: 1580 | Elapsed Time: 0:24:56\n",
      "Test epoch | Steps: 1581 | Elapsed Time: 0:24:57\n",
      "Test epoch | Steps: 1582 | Elapsed Time: 0:24:58\n",
      "Test epoch | Steps: 1583 | Elapsed Time: 0:24:59\n",
      "Test epoch | Steps: 1584 | Elapsed Time: 0:25:00\n",
      "Test epoch | Steps: 1585 | Elapsed Time: 0:25:01\n",
      "Test epoch | Steps: 1586 | Elapsed Time: 0:25:02\n",
      "Test epoch | Steps: 1587 | Elapsed Time: 0:25:03\n",
      "Test epoch | Steps: 1588 | Elapsed Time: 0:25:05\n",
      "Test epoch | Steps: 1589 | Elapsed Time: 0:25:06\n",
      "Test epoch | Steps: 1590 | Elapsed Time: 0:25:07\n",
      "Test epoch | Steps: 1591 | Elapsed Time: 0:25:08\n",
      "Test epoch | Steps: 1592 | Elapsed Time: 0:25:09\n",
      "Test epoch | Steps: 1593 | Elapsed Time: 0:25:10\n",
      "Test epoch | Steps: 1594 | Elapsed Time: 0:25:11\n",
      "Test epoch | Steps: 1595 | Elapsed Time: 0:25:12\n",
      "Test epoch | Steps: 1596 | Elapsed Time: 0:25:13\n",
      "Test epoch | Steps: 1597 | Elapsed Time: 0:25:14\n",
      "Test epoch | Steps: 1598 | Elapsed Time: 0:25:15\n",
      "Test epoch | Steps: 1599 | Elapsed Time: 0:25:16\n",
      "Test epoch | Steps: 1600 | Elapsed Time: 0:25:17\n",
      "Test epoch | Steps: 1601 | Elapsed Time: 0:25:18\n",
      "Test epoch | Steps: 1602 | Elapsed Time: 0:25:19\n",
      "Test epoch | Steps: 1603 | Elapsed Time: 0:25:20\n",
      "Test epoch | Steps: 1604 | Elapsed Time: 0:25:21\n",
      "Test epoch | Steps: 1605 | Elapsed Time: 0:25:22\n",
      "Test epoch | Steps: 1606 | Elapsed Time: 0:25:24\n",
      "Test epoch | Steps: 1607 | Elapsed Time: 0:25:25\n",
      "Test epoch | Steps: 1608 | Elapsed Time: 0:25:26\n",
      "Test epoch | Steps: 1609 | Elapsed Time: 0:25:27\n",
      "Test epoch | Steps: 1610 | Elapsed Time: 0:25:28\n",
      "Test epoch | Steps: 1611 | Elapsed Time: 0:25:29\n",
      "Test epoch | Steps: 1612 | Elapsed Time: 0:25:30\n",
      "Test epoch | Steps: 1613 | Elapsed Time: 0:25:31\n",
      "Test epoch | Steps: 1614 | Elapsed Time: 0:25:32\n",
      "Test epoch | Steps: 1615 | Elapsed Time: 0:25:33\n",
      "Test epoch | Steps: 1616 | Elapsed Time: 0:25:35\n",
      "Test epoch | Steps: 1617 | Elapsed Time: 0:25:36\n",
      "Test epoch | Steps: 1618 | Elapsed Time: 0:25:37\n",
      "Test epoch | Steps: 1619 | Elapsed Time: 0:25:38\n",
      "Test epoch | Steps: 1620 | Elapsed Time: 0:25:39\n",
      "Test epoch | Steps: 1621 | Elapsed Time: 0:25:40\n",
      "Test epoch | Steps: 1622 | Elapsed Time: 0:25:41\n",
      "Test epoch | Steps: 1623 | Elapsed Time: 0:25:42\n",
      "Test epoch | Steps: 1624 | Elapsed Time: 0:25:43\n",
      "Test epoch | Steps: 1625 | Elapsed Time: 0:25:44\n",
      "Test epoch | Steps: 1626 | Elapsed Time: 0:25:45\n",
      "Test epoch | Steps: 1627 | Elapsed Time: 0:25:46\n",
      "Test epoch | Steps: 1628 | Elapsed Time: 0:25:47\n",
      "Test epoch | Steps: 1629 | Elapsed Time: 0:25:49\n",
      "Test epoch | Steps: 1630 | Elapsed Time: 0:25:50\n",
      "Test epoch | Steps: 1631 | Elapsed Time: 0:25:51\n",
      "Test epoch | Steps: 1632 | Elapsed Time: 0:25:52\n",
      "Test epoch | Steps: 1633 | Elapsed Time: 0:25:53\n",
      "Test epoch | Steps: 1634 | Elapsed Time: 0:25:54\n",
      "Test epoch | Steps: 1635 | Elapsed Time: 0:25:55\n",
      "Test epoch | Steps: 1636 | Elapsed Time: 0:25:56\n",
      "Test epoch | Steps: 1637 | Elapsed Time: 0:25:57\n",
      "Test epoch | Steps: 1638 | Elapsed Time: 0:25:58\n",
      "Test epoch | Steps: 1639 | Elapsed Time: 0:26:00\n",
      "Test epoch | Steps: 1640 | Elapsed Time: 0:26:01\n",
      "Test epoch | Steps: 1641 | Elapsed Time: 0:26:02\n",
      "Test epoch | Steps: 1642 | Elapsed Time: 0:26:03\n",
      "Test epoch | Steps: 1643 | Elapsed Time: 0:26:04\n",
      "Test epoch | Steps: 1644 | Elapsed Time: 0:26:05\n",
      "Test epoch | Steps: 1645 | Elapsed Time: 0:26:06\n",
      "Test epoch | Steps: 1646 | Elapsed Time: 0:26:08\n",
      "Test epoch | Steps: 1647 | Elapsed Time: 0:26:09\n",
      "Test epoch | Steps: 1648 | Elapsed Time: 0:26:10\n",
      "Test epoch | Steps: 1649 | Elapsed Time: 0:26:11\n",
      "Test epoch | Steps: 1650 | Elapsed Time: 0:26:12\n",
      "Test epoch | Steps: 1651 | Elapsed Time: 0:26:13\n",
      "Test epoch | Steps: 1652 | Elapsed Time: 0:26:14\n",
      "Test epoch | Steps: 1653 | Elapsed Time: 0:26:15\n",
      "Test epoch | Steps: 1654 | Elapsed Time: 0:26:17\n",
      "Test epoch | Steps: 1655 | Elapsed Time: 0:26:18\n",
      "Test epoch | Steps: 1656 | Elapsed Time: 0:26:19\n",
      "Test epoch | Steps: 1657 | Elapsed Time: 0:26:20\n",
      "Test epoch | Steps: 1658 | Elapsed Time: 0:26:21\n",
      "Test epoch | Steps: 1659 | Elapsed Time: 0:26:22\n",
      "Test epoch | Steps: 1660 | Elapsed Time: 0:26:24\n",
      "Test epoch | Steps: 1661 | Elapsed Time: 0:26:25\n",
      "Test epoch | Steps: 1662 | Elapsed Time: 0:26:26\n",
      "Test epoch | Steps: 1663 | Elapsed Time: 0:26:27\n",
      "Test epoch | Steps: 1664 | Elapsed Time: 0:26:28\n",
      "Test epoch | Steps: 1665 | Elapsed Time: 0:26:29\n",
      "Test epoch | Steps: 1666 | Elapsed Time: 0:26:30\n",
      "Test epoch | Steps: 1667 | Elapsed Time: 0:26:31\n",
      "Test epoch | Steps: 1668 | Elapsed Time: 0:26:32\n",
      "Test epoch | Steps: 1669 | Elapsed Time: 0:26:33\n",
      "Test epoch | Steps: 1670 | Elapsed Time: 0:26:34\n",
      "Test epoch | Steps: 1671 | Elapsed Time: 0:26:35\n",
      "Test epoch | Steps: 1672 | Elapsed Time: 0:26:36\n",
      "Test epoch | Steps: 1673 | Elapsed Time: 0:26:37\n",
      "Test epoch | Steps: 1674 | Elapsed Time: 0:26:39\n",
      "Test epoch | Steps: 1675 | Elapsed Time: 0:26:40\n",
      "Test epoch | Steps: 1676 | Elapsed Time: 0:26:41\n",
      "Test epoch | Steps: 1677 | Elapsed Time: 0:26:42\n",
      "Test epoch | Steps: 1678 | Elapsed Time: 0:26:43\n",
      "Test epoch | Steps: 1679 | Elapsed Time: 0:26:44\n",
      "Test epoch | Steps: 1680 | Elapsed Time: 0:26:45\n",
      "Test epoch | Steps: 1681 | Elapsed Time: 0:26:46\n",
      "Test epoch | Steps: 1682 | Elapsed Time: 0:26:48\n",
      "Test epoch | Steps: 1683 | Elapsed Time: 0:26:49\n",
      "Test epoch | Steps: 1684 | Elapsed Time: 0:26:50\n",
      "Test epoch | Steps: 1685 | Elapsed Time: 0:26:51\n",
      "Test epoch | Steps: 1686 | Elapsed Time: 0:26:52\n",
      "Test epoch | Steps: 1687 | Elapsed Time: 0:26:53\n",
      "Test epoch | Steps: 1688 | Elapsed Time: 0:26:54\n",
      "Test epoch | Steps: 1689 | Elapsed Time: 0:26:55\n",
      "Test epoch | Steps: 1690 | Elapsed Time: 0:26:56\n",
      "Test epoch | Steps: 1691 | Elapsed Time: 0:26:57\n",
      "Test epoch | Steps: 1692 | Elapsed Time: 0:26:59\n",
      "Test epoch | Steps: 1693 | Elapsed Time: 0:27:00\n",
      "Test epoch | Steps: 1694 | Elapsed Time: 0:27:01\n",
      "Test epoch | Steps: 1695 | Elapsed Time: 0:27:02\n",
      "Test epoch | Steps: 1696 | Elapsed Time: 0:27:04\n",
      "Test epoch | Steps: 1697 | Elapsed Time: 0:27:05\n",
      "Test epoch | Steps: 1698 | Elapsed Time: 0:27:06\n",
      "Test epoch | Steps: 1699 | Elapsed Time: 0:27:07\n",
      "Test epoch | Steps: 1700 | Elapsed Time: 0:27:08\n",
      "Test epoch | Steps: 1701 | Elapsed Time: 0:27:09\n",
      "Test epoch | Steps: 1702 | Elapsed Time: 0:27:10\n",
      "Test epoch | Steps: 1703 | Elapsed Time: 0:27:11\n",
      "Test epoch | Steps: 1704 | Elapsed Time: 0:27:12\n",
      "Test epoch | Steps: 1705 | Elapsed Time: 0:27:14\n",
      "Test epoch | Steps: 1706 | Elapsed Time: 0:27:15\n",
      "Test epoch | Steps: 1707 | Elapsed Time: 0:27:16\n",
      "Test epoch | Steps: 1708 | Elapsed Time: 0:27:17\n",
      "Test epoch | Steps: 1709 | Elapsed Time: 0:27:18\n",
      "Test epoch | Steps: 1710 | Elapsed Time: 0:27:19\n",
      "Test epoch | Steps: 1711 | Elapsed Time: 0:27:20\n",
      "Test epoch | Steps: 1712 | Elapsed Time: 0:27:22\n",
      "Test epoch | Steps: 1713 | Elapsed Time: 0:27:23\n",
      "Test epoch | Steps: 1714 | Elapsed Time: 0:27:24\n",
      "Test epoch | Steps: 1715 | Elapsed Time: 0:27:25\n",
      "Test epoch | Steps: 1716 | Elapsed Time: 0:27:26\n",
      "Test epoch | Steps: 1717 | Elapsed Time: 0:27:27\n",
      "Test epoch | Steps: 1718 | Elapsed Time: 0:27:29\n",
      "Test epoch | Steps: 1719 | Elapsed Time: 0:27:30\n",
      "Test epoch | Steps: 1720 | Elapsed Time: 0:27:31\n",
      "Test epoch | Steps: 1721 | Elapsed Time: 0:27:32\n",
      "Test epoch | Steps: 1722 | Elapsed Time: 0:27:33\n",
      "Test epoch | Steps: 1723 | Elapsed Time: 0:27:34\n",
      "Test epoch | Steps: 1724 | Elapsed Time: 0:27:35\n",
      "Test epoch | Steps: 1725 | Elapsed Time: 0:27:36\n",
      "Test epoch | Steps: 1726 | Elapsed Time: 0:27:38\n",
      "Test epoch | Steps: 1727 | Elapsed Time: 0:27:39\n",
      "Test epoch | Steps: 1728 | Elapsed Time: 0:27:40\n",
      "Test epoch | Steps: 1729 | Elapsed Time: 0:27:41\n",
      "Test epoch | Steps: 1730 | Elapsed Time: 0:27:42\n",
      "Test epoch | Steps: 1731 | Elapsed Time: 0:27:43\n",
      "Test epoch | Steps: 1732 | Elapsed Time: 0:27:45\n",
      "Test epoch | Steps: 1733 | Elapsed Time: 0:27:46\n",
      "Test epoch | Steps: 1734 | Elapsed Time: 0:27:47\n",
      "Test epoch | Steps: 1735 | Elapsed Time: 0:27:48\n",
      "Test epoch | Steps: 1736 | Elapsed Time: 0:27:49\n",
      "Test epoch | Steps: 1737 | Elapsed Time: 0:27:50\n",
      "Test epoch | Steps: 1738 | Elapsed Time: 0:27:51\n",
      "Test epoch | Steps: 1739 | Elapsed Time: 0:27:52\n",
      "Test epoch | Steps: 1740 | Elapsed Time: 0:27:53\n",
      "Test epoch | Steps: 1741 | Elapsed Time: 0:27:54\n",
      "Test epoch | Steps: 1742 | Elapsed Time: 0:27:55\n",
      "Test epoch | Steps: 1743 | Elapsed Time: 0:27:56\n",
      "Test epoch | Steps: 1744 | Elapsed Time: 0:27:58\n",
      "Test epoch | Steps: 1745 | Elapsed Time: 0:27:59\n",
      "Test epoch | Steps: 1746 | Elapsed Time: 0:28:00\n",
      "Test epoch | Steps: 1747 | Elapsed Time: 0:28:01\n",
      "Test epoch | Steps: 1748 | Elapsed Time: 0:28:02\n",
      "Test epoch | Steps: 1749 | Elapsed Time: 0:28:03\n",
      "Test epoch | Steps: 1750 | Elapsed Time: 0:28:04\n",
      "Test epoch | Steps: 1751 | Elapsed Time: 0:28:06\n",
      "Test epoch | Steps: 1752 | Elapsed Time: 0:28:07\n",
      "Test epoch | Steps: 1753 | Elapsed Time: 0:28:08\n",
      "Test epoch | Steps: 1754 | Elapsed Time: 0:28:09\n",
      "Test epoch | Steps: 1755 | Elapsed Time: 0:28:10\n",
      "Test epoch | Steps: 1756 | Elapsed Time: 0:28:12\n",
      "Test epoch | Steps: 1757 | Elapsed Time: 0:28:13\n",
      "Test epoch | Steps: 1758 | Elapsed Time: 0:28:14\n",
      "Test epoch | Steps: 1759 | Elapsed Time: 0:28:15\n",
      "Test epoch | Steps: 1760 | Elapsed Time: 0:28:16\n",
      "Test epoch | Steps: 1761 | Elapsed Time: 0:28:17\n",
      "Test epoch | Steps: 1762 | Elapsed Time: 0:28:18\n",
      "Test epoch | Steps: 1763 | Elapsed Time: 0:28:20\n",
      "Test epoch | Steps: 1764 | Elapsed Time: 0:28:21\n",
      "Test epoch | Steps: 1765 | Elapsed Time: 0:28:22\n",
      "Test epoch | Steps: 1766 | Elapsed Time: 0:28:23\n",
      "Test epoch | Steps: 1767 | Elapsed Time: 0:28:24\n",
      "Test epoch | Steps: 1768 | Elapsed Time: 0:28:25\n",
      "Test epoch | Steps: 1769 | Elapsed Time: 0:28:26\n",
      "Test epoch | Steps: 1770 | Elapsed Time: 0:28:27\n",
      "Test epoch | Steps: 1771 | Elapsed Time: 0:28:28\n",
      "Test epoch | Steps: 1772 | Elapsed Time: 0:28:30\n",
      "Test epoch | Steps: 1773 | Elapsed Time: 0:28:31\n",
      "Test epoch | Steps: 1774 | Elapsed Time: 0:28:32\n",
      "Test epoch | Steps: 1775 | Elapsed Time: 0:28:33\n",
      "Test epoch | Steps: 1776 | Elapsed Time: 0:28:34\n",
      "Test epoch | Steps: 1777 | Elapsed Time: 0:28:35\n",
      "Test epoch | Steps: 1778 | Elapsed Time: 0:28:37\n",
      "Test epoch | Steps: 1779 | Elapsed Time: 0:28:38\n",
      "Test epoch | Steps: 1780 | Elapsed Time: 0:28:39\n",
      "Test epoch | Steps: 1781 | Elapsed Time: 0:28:40\n",
      "Test epoch | Steps: 1782 | Elapsed Time: 0:28:41\n",
      "Test epoch | Steps: 1783 | Elapsed Time: 0:28:42\n",
      "Test epoch | Steps: 1784 | Elapsed Time: 0:28:43\n",
      "Test epoch | Steps: 1785 | Elapsed Time: 0:28:45\n",
      "Test epoch | Steps: 1786 | Elapsed Time: 0:28:46\n",
      "Test epoch | Steps: 1787 | Elapsed Time: 0:28:47\n",
      "Test epoch | Steps: 1788 | Elapsed Time: 0:28:48\n",
      "Test epoch | Steps: 1789 | Elapsed Time: 0:28:49\n",
      "Test epoch | Steps: 1790 | Elapsed Time: 0:28:50\n",
      "Test epoch | Steps: 1791 | Elapsed Time: 0:28:51\n",
      "Test epoch | Steps: 1792 | Elapsed Time: 0:28:52\n",
      "Test epoch | Steps: 1793 | Elapsed Time: 0:28:54\n",
      "Test epoch | Steps: 1794 | Elapsed Time: 0:28:55\n",
      "Test epoch | Steps: 1795 | Elapsed Time: 0:28:56\n",
      "Test epoch | Steps: 1796 | Elapsed Time: 0:28:57\n",
      "Test epoch | Steps: 1797 | Elapsed Time: 0:28:58\n",
      "Test epoch | Steps: 1798 | Elapsed Time: 0:29:00\n",
      "Test epoch | Steps: 1799 | Elapsed Time: 0:29:01\n",
      "Test epoch | Steps: 1800 | Elapsed Time: 0:29:02\n",
      "Test epoch | Steps: 1801 | Elapsed Time: 0:29:03\n",
      "Test epoch | Steps: 1802 | Elapsed Time: 0:29:04\n",
      "Test epoch | Steps: 1803 | Elapsed Time: 0:29:05\n",
      "Test epoch | Steps: 1804 | Elapsed Time: 0:29:07\n",
      "Test epoch | Steps: 1805 | Elapsed Time: 0:29:08\n",
      "Test epoch | Steps: 1806 | Elapsed Time: 0:29:09\n",
      "Test epoch | Steps: 1807 | Elapsed Time: 0:29:10\n",
      "Test epoch | Steps: 1808 | Elapsed Time: 0:29:11\n",
      "Test epoch | Steps: 1809 | Elapsed Time: 0:29:12\n",
      "Test epoch | Steps: 1810 | Elapsed Time: 0:29:14\n",
      "Test epoch | Steps: 1811 | Elapsed Time: 0:29:15\n",
      "Test epoch | Steps: 1812 | Elapsed Time: 0:29:16\n",
      "Test epoch | Steps: 1813 | Elapsed Time: 0:29:17\n",
      "Test epoch | Steps: 1814 | Elapsed Time: 0:29:18\n",
      "Test epoch | Steps: 1815 | Elapsed Time: 0:29:20\n",
      "Test epoch | Steps: 1816 | Elapsed Time: 0:29:21\n",
      "Test epoch | Steps: 1817 | Elapsed Time: 0:29:22\n",
      "Test epoch | Steps: 1818 | Elapsed Time: 0:29:23\n",
      "Test epoch | Steps: 1819 | Elapsed Time: 0:29:24\n",
      "Test epoch | Steps: 1820 | Elapsed Time: 0:29:26\n",
      "Test epoch | Steps: 1821 | Elapsed Time: 0:29:27\n",
      "Test epoch | Steps: 1822 | Elapsed Time: 0:29:28\n",
      "Test epoch | Steps: 1823 | Elapsed Time: 0:29:29\n",
      "Test epoch | Steps: 1824 | Elapsed Time: 0:29:30\n",
      "Test epoch | Steps: 1825 | Elapsed Time: 0:29:31\n",
      "Test epoch | Steps: 1826 | Elapsed Time: 0:29:33\n",
      "Test epoch | Steps: 1827 | Elapsed Time: 0:29:34\n",
      "Test epoch | Steps: 1828 | Elapsed Time: 0:29:35\n",
      "Test epoch | Steps: 1829 | Elapsed Time: 0:29:36\n",
      "Test epoch | Steps: 1830 | Elapsed Time: 0:29:37\n",
      "Test epoch | Steps: 1831 | Elapsed Time: 0:29:38\n",
      "Test epoch | Steps: 1832 | Elapsed Time: 0:29:39\n",
      "Test epoch | Steps: 1833 | Elapsed Time: 0:29:41\n",
      "Test epoch | Steps: 1834 | Elapsed Time: 0:29:42\n",
      "Test epoch | Steps: 1835 | Elapsed Time: 0:29:43\n",
      "Test epoch | Steps: 1836 | Elapsed Time: 0:29:44\n",
      "Test epoch | Steps: 1837 | Elapsed Time: 0:29:45\n",
      "Test epoch | Steps: 1838 | Elapsed Time: 0:29:47\n",
      "Test epoch | Steps: 1839 | Elapsed Time: 0:29:48\n",
      "Test epoch | Steps: 1840 | Elapsed Time: 0:29:49\n",
      "Test epoch | Steps: 1841 | Elapsed Time: 0:29:50\n",
      "Test epoch | Steps: 1842 | Elapsed Time: 0:29:51\n",
      "Test epoch | Steps: 1843 | Elapsed Time: 0:29:53\n",
      "Test epoch | Steps: 1844 | Elapsed Time: 0:29:54\n",
      "Test epoch | Steps: 1845 | Elapsed Time: 0:29:55\n",
      "Test epoch | Steps: 1846 | Elapsed Time: 0:29:56\n",
      "Test epoch | Steps: 1847 | Elapsed Time: 0:29:57\n",
      "Test epoch | Steps: 1848 | Elapsed Time: 0:29:59\n",
      "Test epoch | Steps: 1849 | Elapsed Time: 0:30:00\n",
      "Test epoch | Steps: 1850 | Elapsed Time: 0:30:01\n",
      "Test epoch | Steps: 1851 | Elapsed Time: 0:30:02\n",
      "Test epoch | Steps: 1852 | Elapsed Time: 0:30:03\n",
      "Test epoch | Steps: 1853 | Elapsed Time: 0:30:05\n",
      "Test epoch | Steps: 1854 | Elapsed Time: 0:30:06\n",
      "Test epoch | Steps: 1855 | Elapsed Time: 0:30:07\n",
      "Test epoch | Steps: 1856 | Elapsed Time: 0:30:08\n",
      "Test epoch | Steps: 1857 | Elapsed Time: 0:30:09\n",
      "Test epoch | Steps: 1858 | Elapsed Time: 0:30:10\n",
      "Test epoch | Steps: 1859 | Elapsed Time: 0:30:11\n",
      "Test epoch | Steps: 1860 | Elapsed Time: 0:30:13\n",
      "Test epoch | Steps: 1861 | Elapsed Time: 0:30:14\n",
      "Test epoch | Steps: 1862 | Elapsed Time: 0:30:15\n",
      "Test epoch | Steps: 1863 | Elapsed Time: 0:30:16\n",
      "Test epoch | Steps: 1864 | Elapsed Time: 0:30:17\n",
      "Test epoch | Steps: 1865 | Elapsed Time: 0:30:19\n",
      "Test epoch | Steps: 1866 | Elapsed Time: 0:30:20\n",
      "Test epoch | Steps: 1867 | Elapsed Time: 0:30:21\n",
      "Test epoch | Steps: 1868 | Elapsed Time: 0:30:22\n",
      "Test epoch | Steps: 1869 | Elapsed Time: 0:30:23\n",
      "Test epoch | Steps: 1870 | Elapsed Time: 0:30:24\n",
      "Test epoch | Steps: 1871 | Elapsed Time: 0:30:26\n",
      "Test epoch | Steps: 1872 | Elapsed Time: 0:30:27\n",
      "Test epoch | Steps: 1873 | Elapsed Time: 0:30:28\n",
      "Test epoch | Steps: 1874 | Elapsed Time: 0:30:30\n",
      "Test epoch | Steps: 1875 | Elapsed Time: 0:30:31\n",
      "Test epoch | Steps: 1876 | Elapsed Time: 0:30:32\n",
      "Test epoch | Steps: 1877 | Elapsed Time: 0:30:33\n",
      "Test epoch | Steps: 1878 | Elapsed Time: 0:30:34\n",
      "Test epoch | Steps: 1879 | Elapsed Time: 0:30:36\n",
      "Test epoch | Steps: 1880 | Elapsed Time: 0:30:37\n",
      "Test epoch | Steps: 1881 | Elapsed Time: 0:30:38\n",
      "Test epoch | Steps: 1882 | Elapsed Time: 0:30:39\n",
      "Test epoch | Steps: 1883 | Elapsed Time: 0:30:40\n",
      "Test epoch | Steps: 1884 | Elapsed Time: 0:30:42\n",
      "Test epoch | Steps: 1885 | Elapsed Time: 0:30:43\n",
      "Test epoch | Steps: 1886 | Elapsed Time: 0:30:44\n",
      "Test epoch | Steps: 1887 | Elapsed Time: 0:30:45\n",
      "Test epoch | Steps: 1888 | Elapsed Time: 0:30:46\n",
      "Test epoch | Steps: 1889 | Elapsed Time: 0:30:47\n",
      "Test epoch | Steps: 1890 | Elapsed Time: 0:30:49\n",
      "Test epoch | Steps: 1891 | Elapsed Time: 0:30:50\n",
      "Test epoch | Steps: 1892 | Elapsed Time: 0:30:51\n",
      "Test epoch | Steps: 1893 | Elapsed Time: 0:30:52\n",
      "Test epoch | Steps: 1894 | Elapsed Time: 0:30:54\n",
      "Test epoch | Steps: 1895 | Elapsed Time: 0:30:55\n",
      "Test epoch | Steps: 1896 | Elapsed Time: 0:30:56\n",
      "Test epoch | Steps: 1897 | Elapsed Time: 0:30:57\n",
      "Test epoch | Steps: 1898 | Elapsed Time: 0:30:58\n",
      "Test epoch | Steps: 1899 | Elapsed Time: 0:31:00\n",
      "Test epoch | Steps: 1900 | Elapsed Time: 0:31:01\n",
      "Test epoch | Steps: 1901 | Elapsed Time: 0:31:02\n",
      "Test epoch | Steps: 1902 | Elapsed Time: 0:31:03\n",
      "Test epoch | Steps: 1903 | Elapsed Time: 0:31:05\n",
      "Test epoch | Steps: 1904 | Elapsed Time: 0:31:06\n",
      "Test epoch | Steps: 1905 | Elapsed Time: 0:31:07\n",
      "Test epoch | Steps: 1906 | Elapsed Time: 0:31:08\n",
      "Test epoch | Steps: 1907 | Elapsed Time: 0:31:09\n",
      "Test epoch | Steps: 1908 | Elapsed Time: 0:31:10\n",
      "Test epoch | Steps: 1909 | Elapsed Time: 0:31:12\n",
      "Test epoch | Steps: 1910 | Elapsed Time: 0:31:13\n",
      "Test epoch | Steps: 1911 | Elapsed Time: 0:31:14\n",
      "Test epoch | Steps: 1912 | Elapsed Time: 0:31:15\n",
      "Test epoch | Steps: 1913 | Elapsed Time: 0:31:16\n",
      "Test epoch | Steps: 1914 | Elapsed Time: 0:31:18\n",
      "Test epoch | Steps: 1915 | Elapsed Time: 0:31:19\n",
      "Test epoch | Steps: 1916 | Elapsed Time: 0:31:20\n",
      "Test epoch | Steps: 1917 | Elapsed Time: 0:31:21\n",
      "Test epoch | Steps: 1918 | Elapsed Time: 0:31:22\n",
      "Test epoch | Steps: 1919 | Elapsed Time: 0:31:23\n",
      "Test epoch | Steps: 1920 | Elapsed Time: 0:31:25\n",
      "Test epoch | Steps: 1921 | Elapsed Time: 0:31:26\n",
      "Test epoch | Steps: 1922 | Elapsed Time: 0:31:27\n",
      "Test epoch | Steps: 1923 | Elapsed Time: 0:31:28\n",
      "Test epoch | Steps: 1924 | Elapsed Time: 0:31:30\n",
      "Test epoch | Steps: 1925 | Elapsed Time: 0:31:31\n",
      "Test epoch | Steps: 1926 | Elapsed Time: 0:31:32\n",
      "Test epoch | Steps: 1927 | Elapsed Time: 0:31:33\n",
      "Test epoch | Steps: 1928 | Elapsed Time: 0:31:34\n",
      "Test epoch | Steps: 1929 | Elapsed Time: 0:31:36\n",
      "Test epoch | Steps: 1930 | Elapsed Time: 0:31:37\n",
      "Test epoch | Steps: 1931 | Elapsed Time: 0:31:38\n",
      "Test epoch | Steps: 1932 | Elapsed Time: 0:31:39\n",
      "Test epoch | Steps: 1933 | Elapsed Time: 0:31:40\n",
      "Test epoch | Steps: 1934 | Elapsed Time: 0:31:42\n",
      "Test epoch | Steps: 1935 | Elapsed Time: 0:31:43\n",
      "Test epoch | Steps: 1936 | Elapsed Time: 0:31:44\n",
      "Test epoch | Steps: 1937 | Elapsed Time: 0:31:45\n",
      "Test epoch | Steps: 1938 | Elapsed Time: 0:31:46\n",
      "Test epoch | Steps: 1939 | Elapsed Time: 0:31:47\n",
      "Test epoch | Steps: 1940 | Elapsed Time: 0:31:49\n",
      "Test epoch | Steps: 1941 | Elapsed Time: 0:31:50\n",
      "Test epoch | Steps: 1942 | Elapsed Time: 0:31:51\n",
      "Test epoch | Steps: 1943 | Elapsed Time: 0:31:52\n",
      "Test epoch | Steps: 1944 | Elapsed Time: 0:31:54\n",
      "Test epoch | Steps: 1945 | Elapsed Time: 0:31:55\n",
      "Test epoch | Steps: 1946 | Elapsed Time: 0:31:56\n",
      "Test epoch | Steps: 1947 | Elapsed Time: 0:31:57\n",
      "Test epoch | Steps: 1948 | Elapsed Time: 0:31:59\n",
      "Test epoch | Steps: 1949 | Elapsed Time: 0:32:00\n",
      "Test epoch | Steps: 1950 | Elapsed Time: 0:32:01\n",
      "Test epoch | Steps: 1951 | Elapsed Time: 0:32:02\n",
      "Test epoch | Steps: 1952 | Elapsed Time: 0:32:03\n",
      "Test epoch | Steps: 1953 | Elapsed Time: 0:32:05\n",
      "Test epoch | Steps: 1954 | Elapsed Time: 0:32:06\n",
      "Test epoch | Steps: 1955 | Elapsed Time: 0:32:07\n",
      "Test epoch | Steps: 1956 | Elapsed Time: 0:32:08\n",
      "Test epoch | Steps: 1957 | Elapsed Time: 0:32:10\n",
      "Test epoch | Steps: 1958 | Elapsed Time: 0:32:11\n",
      "Test epoch | Steps: 1959 | Elapsed Time: 0:32:12\n",
      "Test epoch | Steps: 1960 | Elapsed Time: 0:32:13\n",
      "Test epoch | Steps: 1961 | Elapsed Time: 0:32:15\n",
      "Test epoch | Steps: 1962 | Elapsed Time: 0:32:16\n",
      "Test epoch | Steps: 1963 | Elapsed Time: 0:32:17\n",
      "Test epoch | Steps: 1964 | Elapsed Time: 0:32:18\n",
      "Test epoch | Steps: 1965 | Elapsed Time: 0:32:19\n",
      "Test epoch | Steps: 1966 | Elapsed Time: 0:32:21\n",
      "Test epoch | Steps: 1967 | Elapsed Time: 0:32:22\n",
      "Test epoch | Steps: 1968 | Elapsed Time: 0:32:23\n",
      "Test epoch | Steps: 1969 | Elapsed Time: 0:32:24\n",
      "Test epoch | Steps: 1970 | Elapsed Time: 0:32:26\n",
      "Test epoch | Steps: 1971 | Elapsed Time: 0:32:27\n",
      "Test epoch | Steps: 1972 | Elapsed Time: 0:32:28\n",
      "Test epoch | Steps: 1973 | Elapsed Time: 0:32:29\n",
      "Test epoch | Steps: 1974 | Elapsed Time: 0:32:31\n",
      "Test epoch | Steps: 1975 | Elapsed Time: 0:32:32\n",
      "Test epoch | Steps: 1976 | Elapsed Time: 0:32:33\n",
      "Test epoch | Steps: 1977 | Elapsed Time: 0:32:34\n",
      "Test epoch | Steps: 1978 | Elapsed Time: 0:32:35\n",
      "Test epoch | Steps: 1979 | Elapsed Time: 0:32:37\n",
      "Test epoch | Steps: 1980 | Elapsed Time: 0:32:38\n",
      "Test epoch | Steps: 1981 | Elapsed Time: 0:32:39\n",
      "Test epoch | Steps: 1982 | Elapsed Time: 0:32:40\n",
      "Test epoch | Steps: 1983 | Elapsed Time: 0:32:42\n",
      "Test epoch | Steps: 1984 | Elapsed Time: 0:32:43\n",
      "Test epoch | Steps: 1985 | Elapsed Time: 0:32:44\n",
      "Test epoch | Steps: 1986 | Elapsed Time: 0:32:45\n",
      "Test epoch | Steps: 1987 | Elapsed Time: 0:32:47\n",
      "Test epoch | Steps: 1988 | Elapsed Time: 0:32:48\n",
      "Test epoch | Steps: 1989 | Elapsed Time: 0:32:49\n",
      "Test epoch | Steps: 1990 | Elapsed Time: 0:32:50\n",
      "Test epoch | Steps: 1991 | Elapsed Time: 0:32:51\n",
      "Test epoch | Steps: 1992 | Elapsed Time: 0:32:53\n",
      "Test epoch | Steps: 1993 | Elapsed Time: 0:32:54\n",
      "Test epoch | Steps: 1994 | Elapsed Time: 0:32:55\n",
      "Test epoch | Steps: 1995 | Elapsed Time: 0:32:57\n",
      "Test epoch | Steps: 1996 | Elapsed Time: 0:32:58\n",
      "Test epoch | Steps: 1997 | Elapsed Time: 0:32:59\n",
      "Test epoch | Steps: 1998 | Elapsed Time: 0:33:00\n",
      "Test epoch | Steps: 1999 | Elapsed Time: 0:33:01\n",
      "Test epoch | Steps: 2000 | Elapsed Time: 0:33:03\n",
      "Test epoch | Steps: 2001 | Elapsed Time: 0:33:04\n",
      "Test epoch | Steps: 2002 | Elapsed Time: 0:33:05\n",
      "Test epoch | Steps: 2003 | Elapsed Time: 0:33:06\n",
      "Test epoch | Steps: 2004 | Elapsed Time: 0:33:07\n",
      "Test epoch | Steps: 2005 | Elapsed Time: 0:33:09\n",
      "Test epoch | Steps: 2006 | Elapsed Time: 0:33:10\n",
      "Test epoch | Steps: 2007 | Elapsed Time: 0:33:11\n",
      "Test epoch | Steps: 2008 | Elapsed Time: 0:33:12\n",
      "Test epoch | Steps: 2009 | Elapsed Time: 0:33:14\n",
      "Test epoch | Steps: 2010 | Elapsed Time: 0:33:15\n",
      "Test epoch | Steps: 2011 | Elapsed Time: 0:33:16\n",
      "Test epoch | Steps: 2012 | Elapsed Time: 0:33:17\n",
      "Test epoch | Steps: 2013 | Elapsed Time: 0:33:19\n",
      "Test epoch | Steps: 2014 | Elapsed Time: 0:33:20\n",
      "Test epoch | Steps: 2015 | Elapsed Time: 0:33:21\n",
      "Test epoch | Steps: 2016 | Elapsed Time: 0:33:22\n",
      "Test epoch | Steps: 2017 | Elapsed Time: 0:33:24\n",
      "Test epoch | Steps: 2018 | Elapsed Time: 0:33:25\n",
      "Test epoch | Steps: 2019 | Elapsed Time: 0:33:26\n",
      "Test epoch | Steps: 2020 | Elapsed Time: 0:33:27\n",
      "Test epoch | Steps: 2021 | Elapsed Time: 0:33:29\n",
      "Test epoch | Steps: 2022 | Elapsed Time: 0:33:30\n",
      "Test epoch | Steps: 2023 | Elapsed Time: 0:33:31\n",
      "Test epoch | Steps: 2024 | Elapsed Time: 0:33:32\n",
      "Test epoch | Steps: 2025 | Elapsed Time: 0:33:34\n",
      "Test epoch | Steps: 2026 | Elapsed Time: 0:33:35\n",
      "Test epoch | Steps: 2027 | Elapsed Time: 0:33:36\n",
      "Test epoch | Steps: 2028 | Elapsed Time: 0:33:38\n",
      "Test epoch | Steps: 2029 | Elapsed Time: 0:33:39\n",
      "Test epoch | Steps: 2030 | Elapsed Time: 0:33:40\n",
      "Test epoch | Steps: 2031 | Elapsed Time: 0:33:41\n",
      "Test epoch | Steps: 2032 | Elapsed Time: 0:33:43\n",
      "Test epoch | Steps: 2033 | Elapsed Time: 0:33:44\n",
      "Test epoch | Steps: 2034 | Elapsed Time: 0:33:45\n",
      "Test epoch | Steps: 2035 | Elapsed Time: 0:33:46\n",
      "Test epoch | Steps: 2036 | Elapsed Time: 0:33:48\n",
      "Test epoch | Steps: 2037 | Elapsed Time: 0:33:49\n",
      "Test epoch | Steps: 2038 | Elapsed Time: 0:33:50\n",
      "Test epoch | Steps: 2039 | Elapsed Time: 0:33:51\n",
      "Test epoch | Steps: 2040 | Elapsed Time: 0:33:53\n",
      "Test epoch | Steps: 2041 | Elapsed Time: 0:33:54\n",
      "Test epoch | Steps: 2042 | Elapsed Time: 0:33:55\n",
      "Test epoch | Steps: 2043 | Elapsed Time: 0:33:57\n",
      "Test epoch | Steps: 2044 | Elapsed Time: 0:33:58\n",
      "Test epoch | Steps: 2045 | Elapsed Time: 0:33:59\n",
      "Test epoch | Steps: 2046 | Elapsed Time: 0:34:00\n",
      "Test epoch | Steps: 2047 | Elapsed Time: 0:34:01\n",
      "Test epoch | Steps: 2048 | Elapsed Time: 0:34:03\n",
      "Test epoch | Steps: 2049 | Elapsed Time: 0:34:04\n",
      "Test epoch | Steps: 2050 | Elapsed Time: 0:34:05\n",
      "Test epoch | Steps: 2051 | Elapsed Time: 0:34:06\n",
      "Test epoch | Steps: 2052 | Elapsed Time: 0:34:08\n",
      "Test epoch | Steps: 2053 | Elapsed Time: 0:34:09\n",
      "Test epoch | Steps: 2054 | Elapsed Time: 0:34:10\n",
      "Test epoch | Steps: 2055 | Elapsed Time: 0:34:11\n",
      "Test epoch | Steps: 2056 | Elapsed Time: 0:34:13\n",
      "Test epoch | Steps: 2057 | Elapsed Time: 0:34:14\n",
      "Test epoch | Steps: 2058 | Elapsed Time: 0:34:15\n",
      "Test epoch | Steps: 2059 | Elapsed Time: 0:34:16\n",
      "Test epoch | Steps: 2060 | Elapsed Time: 0:34:18\n",
      "Test epoch | Steps: 2061 | Elapsed Time: 0:34:19\n",
      "Test epoch | Steps: 2062 | Elapsed Time: 0:34:20\n",
      "Test epoch | Steps: 2063 | Elapsed Time: 0:34:21\n",
      "Test epoch | Steps: 2064 | Elapsed Time: 0:34:23\n",
      "Test epoch | Steps: 2065 | Elapsed Time: 0:34:24\n",
      "Test epoch | Steps: 2066 | Elapsed Time: 0:34:25\n",
      "Test epoch | Steps: 2067 | Elapsed Time: 0:34:26\n",
      "Test epoch | Steps: 2068 | Elapsed Time: 0:34:28\n",
      "Test epoch | Steps: 2069 | Elapsed Time: 0:34:29\n",
      "Test epoch | Steps: 2070 | Elapsed Time: 0:34:30\n",
      "Test epoch | Steps: 2071 | Elapsed Time: 0:34:31\n",
      "Test epoch | Steps: 2072 | Elapsed Time: 0:34:33\n",
      "Test epoch | Steps: 2073 | Elapsed Time: 0:34:34\n",
      "Test epoch | Steps: 2074 | Elapsed Time: 0:34:35\n",
      "Test epoch | Steps: 2075 | Elapsed Time: 0:34:36\n",
      "Test epoch | Steps: 2076 | Elapsed Time: 0:34:38\n",
      "Test epoch | Steps: 2077 | Elapsed Time: 0:34:39\n",
      "Test epoch | Steps: 2078 | Elapsed Time: 0:34:40\n",
      "Test epoch | Steps: 2079 | Elapsed Time: 0:34:42\n",
      "Test epoch | Steps: 2080 | Elapsed Time: 0:34:43\n",
      "Test epoch | Steps: 2081 | Elapsed Time: 0:34:44\n",
      "Test epoch | Steps: 2082 | Elapsed Time: 0:34:45\n",
      "Test epoch | Steps: 2083 | Elapsed Time: 0:34:47\n",
      "Test epoch | Steps: 2084 | Elapsed Time: 0:34:48\n",
      "Test epoch | Steps: 2085 | Elapsed Time: 0:34:49\n",
      "Test epoch | Steps: 2086 | Elapsed Time: 0:34:51\n",
      "Test epoch | Steps: 2087 | Elapsed Time: 0:34:52\n",
      "Test epoch | Steps: 2088 | Elapsed Time: 0:34:53\n",
      "Test epoch | Steps: 2089 | Elapsed Time: 0:34:54\n",
      "Test epoch | Steps: 2090 | Elapsed Time: 0:34:56\n",
      "Test epoch | Steps: 2091 | Elapsed Time: 0:34:57\n",
      "Test epoch | Steps: 2092 | Elapsed Time: 0:34:58\n",
      "Test epoch | Steps: 2093 | Elapsed Time: 0:35:00\n",
      "Test epoch | Steps: 2094 | Elapsed Time: 0:35:01\n",
      "Test epoch | Steps: 2095 | Elapsed Time: 0:35:02\n",
      "Test epoch | Steps: 2096 | Elapsed Time: 0:35:03\n",
      "Test epoch | Steps: 2097 | Elapsed Time: 0:35:05\n",
      "Test epoch | Steps: 2098 | Elapsed Time: 0:35:06\n",
      "Test epoch | Steps: 2099 | Elapsed Time: 0:35:07\n",
      "Test epoch | Steps: 2100 | Elapsed Time: 0:35:09\n",
      "Test epoch | Steps: 2101 | Elapsed Time: 0:35:10\n",
      "Test epoch | Steps: 2102 | Elapsed Time: 0:35:11\n",
      "Test epoch | Steps: 2103 | Elapsed Time: 0:35:12\n",
      "Test epoch | Steps: 2104 | Elapsed Time: 0:35:14\n",
      "Test epoch | Steps: 2105 | Elapsed Time: 0:35:15\n",
      "Test epoch | Steps: 2106 | Elapsed Time: 0:35:16\n",
      "Test epoch | Steps: 2107 | Elapsed Time: 0:35:18\n",
      "Test epoch | Steps: 2108 | Elapsed Time: 0:35:19\n",
      "Test epoch | Steps: 2109 | Elapsed Time: 0:35:20\n",
      "Test epoch | Steps: 2110 | Elapsed Time: 0:35:21\n",
      "Test epoch | Steps: 2111 | Elapsed Time: 0:35:23\n",
      "Test epoch | Steps: 2112 | Elapsed Time: 0:35:24\n",
      "Test epoch | Steps: 2113 | Elapsed Time: 0:35:25\n",
      "Test epoch | Steps: 2114 | Elapsed Time: 0:35:27\n",
      "Test epoch | Steps: 2115 | Elapsed Time: 0:35:28\n",
      "Test epoch | Steps: 2116 | Elapsed Time: 0:35:29\n",
      "Test epoch | Steps: 2117 | Elapsed Time: 0:35:31\n",
      "Test epoch | Steps: 2118 | Elapsed Time: 0:35:32\n",
      "Test epoch | Steps: 2119 | Elapsed Time: 0:35:33\n",
      "Test epoch | Steps: 2120 | Elapsed Time: 0:35:34\n",
      "Test epoch | Steps: 2121 | Elapsed Time: 0:35:36\n",
      "Test epoch | Steps: 2122 | Elapsed Time: 0:35:37\n",
      "Test epoch | Steps: 2123 | Elapsed Time: 0:35:38\n",
      "Test epoch | Steps: 2124 | Elapsed Time: 0:35:40\n",
      "Test epoch | Steps: 2125 | Elapsed Time: 0:35:41\n",
      "Test epoch | Steps: 2126 | Elapsed Time: 0:35:42\n",
      "Test epoch | Steps: 2127 | Elapsed Time: 0:35:44\n",
      "Test epoch | Steps: 2128 | Elapsed Time: 0:35:45\n",
      "Test epoch | Steps: 2129 | Elapsed Time: 0:35:46\n",
      "Test epoch | Steps: 2130 | Elapsed Time: 0:35:47\n",
      "Test epoch | Steps: 2131 | Elapsed Time: 0:35:49\n",
      "Test epoch | Steps: 2132 | Elapsed Time: 0:35:50\n",
      "Test epoch | Steps: 2133 | Elapsed Time: 0:35:51\n",
      "Test epoch | Steps: 2134 | Elapsed Time: 0:35:52\n",
      "Test epoch | Steps: 2135 | Elapsed Time: 0:35:54\n",
      "Test epoch | Steps: 2136 | Elapsed Time: 0:35:55\n",
      "Test epoch | Steps: 2137 | Elapsed Time: 0:35:56\n",
      "Test epoch | Steps: 2138 | Elapsed Time: 0:35:58\n",
      "Test epoch | Steps: 2139 | Elapsed Time: 0:35:59\n",
      "Test epoch | Steps: 2140 | Elapsed Time: 0:36:00\n",
      "Test epoch | Steps: 2141 | Elapsed Time: 0:36:02\n",
      "Test epoch | Steps: 2142 | Elapsed Time: 0:36:03\n",
      "Test epoch | Steps: 2143 | Elapsed Time: 0:36:04\n",
      "Test epoch | Steps: 2144 | Elapsed Time: 0:36:05\n",
      "Test epoch | Steps: 2145 | Elapsed Time: 0:36:07\n",
      "Test epoch | Steps: 2146 | Elapsed Time: 0:36:08\n",
      "Test epoch | Steps: 2147 | Elapsed Time: 0:36:09\n",
      "Test epoch | Steps: 2148 | Elapsed Time: 0:36:11\n",
      "Test epoch | Steps: 2149 | Elapsed Time: 0:36:12\n",
      "Test epoch | Steps: 2150 | Elapsed Time: 0:36:13\n",
      "Test epoch | Steps: 2151 | Elapsed Time: 0:36:14\n",
      "Test epoch | Steps: 2152 | Elapsed Time: 0:36:16\n",
      "Test epoch | Steps: 2153 | Elapsed Time: 0:36:17\n",
      "Test epoch | Steps: 2154 | Elapsed Time: 0:36:18\n",
      "Test epoch | Steps: 2155 | Elapsed Time: 0:36:20\n",
      "Test epoch | Steps: 2156 | Elapsed Time: 0:36:21\n",
      "Test epoch | Steps: 2157 | Elapsed Time: 0:36:22\n",
      "Test epoch | Steps: 2158 | Elapsed Time: 0:36:24\n",
      "Test epoch | Steps: 2159 | Elapsed Time: 0:36:25\n",
      "Test epoch | Steps: 2160 | Elapsed Time: 0:36:26\n",
      "Test epoch | Steps: 2161 | Elapsed Time: 0:36:27\n",
      "Test epoch | Steps: 2162 | Elapsed Time: 0:36:29\n",
      "Test epoch | Steps: 2163 | Elapsed Time: 0:36:30\n",
      "Test epoch | Steps: 2164 | Elapsed Time: 0:36:31\n",
      "Test epoch | Steps: 2165 | Elapsed Time: 0:36:33\n",
      "Test epoch | Steps: 2166 | Elapsed Time: 0:36:34\n",
      "Test epoch | Steps: 2167 | Elapsed Time: 0:36:35\n",
      "Test epoch | Steps: 2168 | Elapsed Time: 0:36:37\n",
      "Test epoch | Steps: 2169 | Elapsed Time: 0:36:38\n",
      "Test epoch | Steps: 2170 | Elapsed Time: 0:36:39\n",
      "Test epoch | Steps: 2171 | Elapsed Time: 0:36:40\n",
      "Test epoch | Steps: 2172 | Elapsed Time: 0:36:42\n",
      "Test epoch | Steps: 2173 | Elapsed Time: 0:36:43\n",
      "Test epoch | Steps: 2174 | Elapsed Time: 0:36:44\n",
      "Test epoch | Steps: 2175 | Elapsed Time: 0:36:46\n",
      "Test epoch | Steps: 2176 | Elapsed Time: 0:36:47\n",
      "Test epoch | Steps: 2177 | Elapsed Time: 0:36:48\n",
      "Test epoch | Steps: 2178 | Elapsed Time: 0:36:50\n",
      "Test epoch | Steps: 2179 | Elapsed Time: 0:36:51\n",
      "Test epoch | Steps: 2180 | Elapsed Time: 0:36:52\n",
      "Test epoch | Steps: 2181 | Elapsed Time: 0:36:54\n",
      "Test epoch | Steps: 2182 | Elapsed Time: 0:36:55\n",
      "Test epoch | Steps: 2183 | Elapsed Time: 0:36:57\n",
      "Test epoch | Steps: 2184 | Elapsed Time: 0:36:58\n",
      "Test epoch | Steps: 2185 | Elapsed Time: 0:36:59\n",
      "Test epoch | Steps: 2186 | Elapsed Time: 0:37:01\n",
      "Test epoch | Steps: 2187 | Elapsed Time: 0:37:02\n",
      "Test epoch | Steps: 2188 | Elapsed Time: 0:37:03\n",
      "Test epoch | Steps: 2189 | Elapsed Time: 0:37:04\n",
      "Test epoch | Steps: 2190 | Elapsed Time: 0:37:06\n",
      "Test epoch | Steps: 2191 | Elapsed Time: 0:37:07\n",
      "Test epoch | Steps: 2192 | Elapsed Time: 0:37:08\n",
      "Test epoch | Steps: 2193 | Elapsed Time: 0:37:10\n",
      "Test epoch | Steps: 2194 | Elapsed Time: 0:37:11\n",
      "Test epoch | Steps: 2195 | Elapsed Time: 0:37:13\n",
      "Test epoch | Steps: 2196 | Elapsed Time: 0:37:14\n",
      "Test epoch | Steps: 2197 | Elapsed Time: 0:37:15\n",
      "Test epoch | Steps: 2198 | Elapsed Time: 0:37:17\n",
      "Test epoch | Steps: 2199 | Elapsed Time: 0:37:18\n",
      "Test epoch | Steps: 2200 | Elapsed Time: 0:37:19\n",
      "Test epoch | Steps: 2201 | Elapsed Time: 0:37:21\n",
      "Test epoch | Steps: 2202 | Elapsed Time: 0:37:22\n",
      "Test epoch | Steps: 2203 | Elapsed Time: 0:37:23\n",
      "Test epoch | Steps: 2204 | Elapsed Time: 0:37:25\n",
      "Test epoch | Steps: 2205 | Elapsed Time: 0:37:26\n",
      "Test epoch | Steps: 2206 | Elapsed Time: 0:37:27\n",
      "Test epoch | Steps: 2207 | Elapsed Time: 0:37:29\n",
      "Test epoch | Steps: 2208 | Elapsed Time: 0:37:30\n",
      "Test epoch | Steps: 2209 | Elapsed Time: 0:37:31\n",
      "Test epoch | Steps: 2210 | Elapsed Time: 0:37:33\n",
      "Test epoch | Steps: 2211 | Elapsed Time: 0:37:34\n",
      "Test epoch | Steps: 2212 | Elapsed Time: 0:37:35\n",
      "Test epoch | Steps: 2213 | Elapsed Time: 0:37:37\n",
      "Test epoch | Steps: 2214 | Elapsed Time: 0:37:38\n",
      "Test epoch | Steps: 2215 | Elapsed Time: 0:37:39\n",
      "Test epoch | Steps: 2216 | Elapsed Time: 0:37:41\n",
      "Test epoch | Steps: 2217 | Elapsed Time: 0:37:42\n",
      "Test epoch | Steps: 2218 | Elapsed Time: 0:37:43\n",
      "Test epoch | Steps: 2219 | Elapsed Time: 0:37:45\n",
      "Test epoch | Steps: 2220 | Elapsed Time: 0:37:46\n",
      "Test epoch | Steps: 2221 | Elapsed Time: 0:37:47\n",
      "Test epoch | Steps: 2222 | Elapsed Time: 0:37:49\n",
      "Test epoch | Steps: 2223 | Elapsed Time: 0:37:50\n",
      "Test epoch | Steps: 2224 | Elapsed Time: 0:37:52\n",
      "Test epoch | Steps: 2225 | Elapsed Time: 0:37:53\n",
      "Test epoch | Steps: 2226 | Elapsed Time: 0:37:54\n",
      "Test epoch | Steps: 2227 | Elapsed Time: 0:37:56\n",
      "Test epoch | Steps: 2228 | Elapsed Time: 0:37:57\n",
      "Test epoch | Steps: 2229 | Elapsed Time: 0:37:58\n",
      "Test epoch | Steps: 2230 | Elapsed Time: 0:38:00\n",
      "Test epoch | Steps: 2231 | Elapsed Time: 0:38:01\n",
      "Test epoch | Steps: 2232 | Elapsed Time: 0:38:02\n",
      "Test epoch | Steps: 2233 | Elapsed Time: 0:38:04\n",
      "Test epoch | Steps: 2234 | Elapsed Time: 0:38:05\n",
      "Test epoch | Steps: 2235 | Elapsed Time: 0:38:06\n",
      "Test epoch | Steps: 2236 | Elapsed Time: 0:38:08\n",
      "Test epoch | Steps: 2237 | Elapsed Time: 0:38:09\n",
      "Test epoch | Steps: 2238 | Elapsed Time: 0:38:10\n",
      "Test epoch | Steps: 2239 | Elapsed Time: 0:38:12\n",
      "Test epoch | Steps: 2240 | Elapsed Time: 0:38:13\n",
      "Test epoch | Steps: 2241 | Elapsed Time: 0:38:14\n",
      "Test epoch | Steps: 2242 | Elapsed Time: 0:38:16\n",
      "Test epoch | Steps: 2243 | Elapsed Time: 0:38:17\n",
      "Test epoch | Steps: 2244 | Elapsed Time: 0:38:18\n",
      "Test epoch | Steps: 2245 | Elapsed Time: 0:38:20\n",
      "Test epoch | Steps: 2246 | Elapsed Time: 0:38:21\n",
      "Test epoch | Steps: 2247 | Elapsed Time: 0:38:23\n",
      "Test epoch | Steps: 2248 | Elapsed Time: 0:38:24\n",
      "Test epoch | Steps: 2249 | Elapsed Time: 0:38:25\n",
      "Test epoch | Steps: 2250 | Elapsed Time: 0:38:27\n",
      "Test epoch | Steps: 2251 | Elapsed Time: 0:38:28\n",
      "Test epoch | Steps: 2252 | Elapsed Time: 0:38:29\n",
      "Test epoch | Steps: 2253 | Elapsed Time: 0:38:31\n",
      "Test epoch | Steps: 2254 | Elapsed Time: 0:38:32\n",
      "Test epoch | Steps: 2255 | Elapsed Time: 0:38:33\n",
      "Test epoch | Steps: 2256 | Elapsed Time: 0:38:35\n",
      "Test epoch | Steps: 2257 | Elapsed Time: 0:38:36\n",
      "Test epoch | Steps: 2258 | Elapsed Time: 0:38:37\n",
      "Test epoch | Steps: 2259 | Elapsed Time: 0:38:39\n",
      "Test epoch | Steps: 2260 | Elapsed Time: 0:38:40\n",
      "Test epoch | Steps: 2261 | Elapsed Time: 0:38:41\n",
      "Test epoch | Steps: 2262 | Elapsed Time: 0:38:43\n",
      "Test epoch | Steps: 2263 | Elapsed Time: 0:38:44\n",
      "Test epoch | Steps: 2264 | Elapsed Time: 0:38:46\n",
      "Test epoch | Steps: 2265 | Elapsed Time: 0:38:47\n",
      "Test epoch | Steps: 2266 | Elapsed Time: 0:38:48\n",
      "Test epoch | Steps: 2267 | Elapsed Time: 0:38:50\n",
      "Test epoch | Steps: 2268 | Elapsed Time: 0:38:51\n",
      "Test epoch | Steps: 2269 | Elapsed Time: 0:38:52\n",
      "Test epoch | Steps: 2270 | Elapsed Time: 0:38:54\n",
      "Test epoch | Steps: 2271 | Elapsed Time: 0:38:55\n",
      "Test epoch | Steps: 2272 | Elapsed Time: 0:38:56\n",
      "Test epoch | Steps: 2273 | Elapsed Time: 0:38:58\n",
      "Test epoch | Steps: 2274 | Elapsed Time: 0:38:59\n",
      "Test epoch | Steps: 2275 | Elapsed Time: 0:39:00\n",
      "Test epoch | Steps: 2276 | Elapsed Time: 0:39:02\n",
      "Test epoch | Steps: 2277 | Elapsed Time: 0:39:03\n",
      "Test epoch | Steps: 2278 | Elapsed Time: 0:39:04\n",
      "Test epoch | Steps: 2279 | Elapsed Time: 0:39:06\n",
      "Test epoch | Steps: 2280 | Elapsed Time: 0:39:07\n",
      "Test epoch | Steps: 2281 | Elapsed Time: 0:39:08\n",
      "Test epoch | Steps: 2282 | Elapsed Time: 0:39:10\n",
      "Test epoch | Steps: 2283 | Elapsed Time: 0:39:11\n",
      "Test epoch | Steps: 2284 | Elapsed Time: 0:39:13\n",
      "Test epoch | Steps: 2285 | Elapsed Time: 0:39:14\n",
      "Test epoch | Steps: 2286 | Elapsed Time: 0:39:16\n",
      "Test epoch | Steps: 2287 | Elapsed Time: 0:39:17\n",
      "Test epoch | Steps: 2288 | Elapsed Time: 0:39:18\n",
      "Test epoch | Steps: 2289 | Elapsed Time: 0:39:20\n",
      "Test epoch | Steps: 2290 | Elapsed Time: 0:39:21\n",
      "Test epoch | Steps: 2291 | Elapsed Time: 0:39:22\n",
      "Test epoch | Steps: 2292 | Elapsed Time: 0:39:24\n",
      "Test epoch | Steps: 2293 | Elapsed Time: 0:39:25\n",
      "Test epoch | Steps: 2294 | Elapsed Time: 0:39:27\n",
      "Test epoch | Steps: 2295 | Elapsed Time: 0:39:28\n",
      "Test epoch | Steps: 2296 | Elapsed Time: 0:39:29\n",
      "Test epoch | Steps: 2297 | Elapsed Time: 0:39:31\n",
      "Test epoch | Steps: 2298 | Elapsed Time: 0:39:32\n",
      "Test epoch | Steps: 2299 | Elapsed Time: 0:39:33\n",
      "Test epoch | Steps: 2300 | Elapsed Time: 0:39:35\n",
      "Test epoch | Steps: 2301 | Elapsed Time: 0:39:36\n",
      "Test epoch | Steps: 2302 | Elapsed Time: 0:39:38\n",
      "Test epoch | Steps: 2303 | Elapsed Time: 0:39:39\n",
      "Test epoch | Steps: 2304 | Elapsed Time: 0:39:40\n",
      "Test epoch | Steps: 2305 | Elapsed Time: 0:39:42\n",
      "Test epoch | Steps: 2306 | Elapsed Time: 0:39:43\n",
      "Test epoch | Steps: 2307 | Elapsed Time: 0:39:45\n",
      "Test epoch | Steps: 2308 | Elapsed Time: 0:39:46\n",
      "Test epoch | Steps: 2309 | Elapsed Time: 0:39:47\n",
      "Test epoch | Steps: 2310 | Elapsed Time: 0:39:49\n",
      "Test epoch | Steps: 2311 | Elapsed Time: 0:39:50\n",
      "Test epoch | Steps: 2312 | Elapsed Time: 0:39:52\n",
      "Test epoch | Steps: 2313 | Elapsed Time: 0:39:53\n",
      "Test epoch | Steps: 2314 | Elapsed Time: 0:39:54\n",
      "Test epoch | Steps: 2315 | Elapsed Time: 0:39:56\n",
      "Test epoch | Steps: 2316 | Elapsed Time: 0:39:57\n",
      "Test epoch | Steps: 2317 | Elapsed Time: 0:39:59\n",
      "Test epoch | Steps: 2318 | Elapsed Time: 0:40:00\n",
      "Test epoch | Steps: 2319 | Elapsed Time: 0:40:01\n",
      "Test epoch | Steps: 2320 | Elapsed Time: 0:40:03\n",
      "Test epoch | Steps: 2321 | Elapsed Time: 0:40:04\n",
      "Test epoch | Steps: 2322 | Elapsed Time: 0:40:05\n",
      "Test epoch | Steps: 2323 | Elapsed Time: 0:40:07\n",
      "Test epoch | Steps: 2324 | Elapsed Time: 0:40:08\n",
      "Test epoch | Steps: 2325 | Elapsed Time: 0:40:10\n",
      "Test epoch | Steps: 2326 | Elapsed Time: 0:40:11\n",
      "Test epoch | Steps: 2327 | Elapsed Time: 0:40:13\n",
      "Test epoch | Steps: 2328 | Elapsed Time: 0:40:14\n",
      "Test epoch | Steps: 2329 | Elapsed Time: 0:40:15\n",
      "Test epoch | Steps: 2330 | Elapsed Time: 0:40:17\n",
      "Test epoch | Steps: 2331 | Elapsed Time: 0:40:18\n",
      "Test epoch | Steps: 2332 | Elapsed Time: 0:40:20\n",
      "Test epoch | Steps: 2333 | Elapsed Time: 0:40:21\n",
      "Test epoch | Steps: 2334 | Elapsed Time: 0:40:22\n",
      "Test epoch | Steps: 2335 | Elapsed Time: 0:40:24\n",
      "Test epoch | Steps: 2336 | Elapsed Time: 0:40:25\n",
      "Test epoch | Steps: 2337 | Elapsed Time: 0:40:27\n",
      "Test epoch | Steps: 2338 | Elapsed Time: 0:40:28\n",
      "Test epoch | Steps: 2339 | Elapsed Time: 0:40:29\n",
      "Test epoch | Steps: 2340 | Elapsed Time: 0:40:31\n",
      "Test epoch | Steps: 2341 | Elapsed Time: 0:40:32\n",
      "Test epoch | Steps: 2342 | Elapsed Time: 0:40:34\n",
      "Test epoch | Steps: 2343 | Elapsed Time: 0:40:35\n",
      "Test epoch | Steps: 2344 | Elapsed Time: 0:40:36\n",
      "Test epoch | Steps: 2345 | Elapsed Time: 0:40:38\n",
      "Test epoch | Steps: 2346 | Elapsed Time: 0:40:39\n",
      "Test epoch | Steps: 2347 | Elapsed Time: 0:40:41\n",
      "Test epoch | Steps: 2348 | Elapsed Time: 0:40:42\n",
      "Test epoch | Steps: 2349 | Elapsed Time: 0:40:43\n",
      "Test epoch | Steps: 2350 | Elapsed Time: 0:40:45\n",
      "Test epoch | Steps: 2351 | Elapsed Time: 0:40:46\n",
      "Test epoch | Steps: 2352 | Elapsed Time: 0:40:48\n",
      "Test epoch | Steps: 2353 | Elapsed Time: 0:40:49\n",
      "Test epoch | Steps: 2354 | Elapsed Time: 0:40:50\n",
      "Test epoch | Steps: 2355 | Elapsed Time: 0:40:52\n",
      "Test epoch | Steps: 2356 | Elapsed Time: 0:40:54\n",
      "Test epoch | Steps: 2357 | Elapsed Time: 0:40:55\n",
      "Test epoch | Steps: 2358 | Elapsed Time: 0:40:56\n",
      "Test epoch | Steps: 2359 | Elapsed Time: 0:40:58\n",
      "Test epoch | Steps: 2360 | Elapsed Time: 0:40:59\n",
      "Test epoch | Steps: 2361 | Elapsed Time: 0:41:01\n",
      "Test epoch | Steps: 2362 | Elapsed Time: 0:41:02\n",
      "Test epoch | Steps: 2363 | Elapsed Time: 0:41:03\n",
      "Test epoch | Steps: 2364 | Elapsed Time: 0:41:05\n",
      "Test epoch | Steps: 2365 | Elapsed Time: 0:41:06\n",
      "Test epoch | Steps: 2366 | Elapsed Time: 0:41:08\n",
      "Test epoch | Steps: 2367 | Elapsed Time: 0:41:09\n",
      "Test epoch | Steps: 2368 | Elapsed Time: 0:41:11\n",
      "Test epoch | Steps: 2369 | Elapsed Time: 0:41:12\n",
      "Test epoch | Steps: 2370 | Elapsed Time: 0:41:13\n",
      "Test epoch | Steps: 2371 | Elapsed Time: 0:41:15\n",
      "Test epoch | Steps: 2372 | Elapsed Time: 0:41:16\n",
      "Test epoch | Steps: 2373 | Elapsed Time: 0:41:18\n",
      "Test epoch | Steps: 2374 | Elapsed Time: 0:41:19\n",
      "Test epoch | Steps: 2375 | Elapsed Time: 0:41:21\n",
      "Test epoch | Steps: 2376 | Elapsed Time: 0:41:22\n",
      "Test epoch | Steps: 2377 | Elapsed Time: 0:41:23\n",
      "Test epoch | Steps: 2378 | Elapsed Time: 0:41:25\n",
      "Test epoch | Steps: 2379 | Elapsed Time: 0:41:26\n",
      "Test epoch | Steps: 2380 | Elapsed Time: 0:41:28\n",
      "Test epoch | Steps: 2381 | Elapsed Time: 0:41:29\n",
      "Test epoch | Steps: 2382 | Elapsed Time: 0:41:31\n",
      "Test epoch | Steps: 2383 | Elapsed Time: 0:41:32\n",
      "Test epoch | Steps: 2384 | Elapsed Time: 0:41:33\n",
      "Test epoch | Steps: 2385 | Elapsed Time: 0:41:35\n",
      "Test epoch | Steps: 2386 | Elapsed Time: 0:41:36\n",
      "Test epoch | Steps: 2387 | Elapsed Time: 0:41:38\n",
      "Test epoch | Steps: 2388 | Elapsed Time: 0:41:39\n",
      "Test epoch | Steps: 2389 | Elapsed Time: 0:41:41\n",
      "Test epoch | Steps: 2390 | Elapsed Time: 0:41:42\n",
      "Test epoch | Steps: 2391 | Elapsed Time: 0:41:43\n",
      "Test epoch | Steps: 2392 | Elapsed Time: 0:41:45\n",
      "Test epoch | Steps: 2393 | Elapsed Time: 0:41:46\n",
      "Test epoch | Steps: 2394 | Elapsed Time: 0:41:48\n",
      "Test epoch | Steps: 2395 | Elapsed Time: 0:41:49\n",
      "Test epoch | Steps: 2396 | Elapsed Time: 0:41:51\n",
      "Test epoch | Steps: 2397 | Elapsed Time: 0:41:52\n",
      "Test epoch | Steps: 2398 | Elapsed Time: 0:41:54\n",
      "Test epoch | Steps: 2399 | Elapsed Time: 0:41:55\n",
      "Test epoch | Steps: 2400 | Elapsed Time: 0:41:56\n",
      "Test epoch | Steps: 2401 | Elapsed Time: 0:41:58\n",
      "Test epoch | Steps: 2402 | Elapsed Time: 0:41:59\n",
      "Test epoch | Steps: 2403 | Elapsed Time: 0:42:01\n",
      "Test epoch | Steps: 2404 | Elapsed Time: 0:42:02\n",
      "Test epoch | Steps: 2405 | Elapsed Time: 0:42:04\n",
      "Test epoch | Steps: 2406 | Elapsed Time: 0:42:05\n",
      "Test epoch | Steps: 2407 | Elapsed Time: 0:42:07\n",
      "Test epoch | Steps: 2408 | Elapsed Time: 0:42:08\n",
      "Test epoch | Steps: 2409 | Elapsed Time: 0:42:10\n",
      "Test epoch | Steps: 2410 | Elapsed Time: 0:42:11\n",
      "Test epoch | Steps: 2411 | Elapsed Time: 0:42:13\n",
      "Test epoch | Steps: 2412 | Elapsed Time: 0:42:14\n",
      "Test epoch | Steps: 2413 | Elapsed Time: 0:42:15\n",
      "Test epoch | Steps: 2414 | Elapsed Time: 0:42:17\n",
      "Test epoch | Steps: 2415 | Elapsed Time: 0:42:18\n",
      "Test epoch | Steps: 2416 | Elapsed Time: 0:42:20\n",
      "Test epoch | Steps: 2417 | Elapsed Time: 0:42:21\n",
      "Test epoch | Steps: 2418 | Elapsed Time: 0:42:22\n",
      "Test epoch | Steps: 2419 | Elapsed Time: 0:42:24\n",
      "Test epoch | Steps: 2420 | Elapsed Time: 0:42:25\n",
      "Test epoch | Steps: 2421 | Elapsed Time: 0:42:27\n",
      "Test epoch | Steps: 2422 | Elapsed Time: 0:42:28\n",
      "Test epoch | Steps: 2423 | Elapsed Time: 0:42:30\n",
      "Test epoch | Steps: 2424 | Elapsed Time: 0:42:31\n",
      "Test epoch | Steps: 2425 | Elapsed Time: 0:42:33\n",
      "Test epoch | Steps: 2426 | Elapsed Time: 0:42:34\n",
      "Test epoch | Steps: 2427 | Elapsed Time: 0:42:35\n",
      "Test epoch | Steps: 2428 | Elapsed Time: 0:42:37\n",
      "Test epoch | Steps: 2429 | Elapsed Time: 0:42:38\n",
      "Test epoch | Steps: 2430 | Elapsed Time: 0:42:40\n",
      "Test epoch | Steps: 2431 | Elapsed Time: 0:42:41\n",
      "Test epoch | Steps: 2432 | Elapsed Time: 0:42:43\n",
      "Test epoch | Steps: 2433 | Elapsed Time: 0:42:44\n",
      "Test epoch | Steps: 2434 | Elapsed Time: 0:42:46\n",
      "Test epoch | Steps: 2435 | Elapsed Time: 0:42:47\n",
      "Test epoch | Steps: 2436 | Elapsed Time: 0:42:48\n",
      "Test epoch | Steps: 2437 | Elapsed Time: 0:42:50\n",
      "Test epoch | Steps: 2438 | Elapsed Time: 0:42:51\n",
      "Test epoch | Steps: 2439 | Elapsed Time: 0:42:53\n",
      "Test epoch | Steps: 2440 | Elapsed Time: 0:42:54\n",
      "Test epoch | Steps: 2441 | Elapsed Time: 0:42:56\n",
      "Test epoch | Steps: 2442 | Elapsed Time: 0:42:57\n",
      "Test epoch | Steps: 2443 | Elapsed Time: 0:42:59\n",
      "Test epoch | Steps: 2444 | Elapsed Time: 0:43:00\n",
      "Test epoch | Steps: 2445 | Elapsed Time: 0:43:02\n",
      "Test epoch | Steps: 2446 | Elapsed Time: 0:43:03\n",
      "Test epoch | Steps: 2447 | Elapsed Time: 0:43:05\n",
      "Test epoch | Steps: 2448 | Elapsed Time: 0:43:06\n",
      "Test epoch | Steps: 2449 | Elapsed Time: 0:43:08\n",
      "Test epoch | Steps: 2450 | Elapsed Time: 0:43:09\n",
      "Test epoch | Steps: 2451 | Elapsed Time: 0:43:11\n",
      "Test epoch | Steps: 2452 | Elapsed Time: 0:43:12\n",
      "Test epoch | Steps: 2453 | Elapsed Time: 0:43:13\n",
      "Test epoch | Steps: 2454 | Elapsed Time: 0:43:15\n",
      "Test epoch | Steps: 2455 | Elapsed Time: 0:43:16\n",
      "Test epoch | Steps: 2456 | Elapsed Time: 0:43:18\n",
      "Test epoch | Steps: 2457 | Elapsed Time: 0:43:19\n",
      "Test epoch | Steps: 2458 | Elapsed Time: 0:43:21\n",
      "Test epoch | Steps: 2459 | Elapsed Time: 0:43:22\n",
      "Test epoch | Steps: 2460 | Elapsed Time: 0:43:24\n",
      "Test epoch | Steps: 2461 | Elapsed Time: 0:43:25\n",
      "Test epoch | Steps: 2462 | Elapsed Time: 0:43:27\n",
      "Test epoch | Steps: 2463 | Elapsed Time: 0:43:28\n",
      "Test epoch | Steps: 2464 | Elapsed Time: 0:43:30\n",
      "Test epoch | Steps: 2465 | Elapsed Time: 0:43:31\n",
      "Test epoch | Steps: 2466 | Elapsed Time: 0:43:33\n",
      "Test epoch | Steps: 2467 | Elapsed Time: 0:43:34\n",
      "Test epoch | Steps: 2468 | Elapsed Time: 0:43:36\n",
      "Test epoch | Steps: 2469 | Elapsed Time: 0:43:37\n",
      "Test epoch | Steps: 2470 | Elapsed Time: 0:43:39\n",
      "Test epoch | Steps: 2471 | Elapsed Time: 0:43:40\n",
      "Test epoch | Steps: 2472 | Elapsed Time: 0:43:41\n",
      "Test epoch | Steps: 2473 | Elapsed Time: 0:43:43\n",
      "Test epoch | Steps: 2474 | Elapsed Time: 0:43:44\n",
      "Test epoch | Steps: 2475 | Elapsed Time: 0:43:46\n",
      "Test epoch | Steps: 2476 | Elapsed Time: 0:43:47\n",
      "Test epoch | Steps: 2477 | Elapsed Time: 0:43:49\n",
      "Test epoch | Steps: 2478 | Elapsed Time: 0:43:50\n",
      "Test epoch | Steps: 2479 | Elapsed Time: 0:43:52\n",
      "Test epoch | Steps: 2480 | Elapsed Time: 0:43:53\n",
      "Test epoch | Steps: 2481 | Elapsed Time: 0:43:55\n",
      "Test epoch | Steps: 2482 | Elapsed Time: 0:43:56\n",
      "Test epoch | Steps: 2483 | Elapsed Time: 0:43:58\n",
      "Test epoch | Steps: 2484 | Elapsed Time: 0:43:59\n",
      "Test epoch | Steps: 2485 | Elapsed Time: 0:44:01\n",
      "Test epoch | Steps: 2486 | Elapsed Time: 0:44:02\n",
      "Test epoch | Steps: 2487 | Elapsed Time: 0:44:04\n",
      "Test epoch | Steps: 2488 | Elapsed Time: 0:44:05\n",
      "Test epoch | Steps: 2489 | Elapsed Time: 0:44:07\n",
      "Test epoch | Steps: 2490 | Elapsed Time: 0:44:08\n",
      "Test epoch | Steps: 2491 | Elapsed Time: 0:44:10\n",
      "Test epoch | Steps: 2492 | Elapsed Time: 0:44:11\n",
      "Test epoch | Steps: 2493 | Elapsed Time: 0:44:13\n",
      "Test epoch | Steps: 2494 | Elapsed Time: 0:44:14\n",
      "Test epoch | Steps: 2495 | Elapsed Time: 0:44:16\n",
      "Test epoch | Steps: 2496 | Elapsed Time: 0:44:17\n",
      "Test epoch | Steps: 2497 | Elapsed Time: 0:44:19\n",
      "Test epoch | Steps: 2498 | Elapsed Time: 0:44:20\n",
      "Test epoch | Steps: 2499 | Elapsed Time: 0:44:22\n",
      "Test epoch | Steps: 2500 | Elapsed Time: 0:44:23\n",
      "Test epoch | Steps: 2501 | Elapsed Time: 0:44:25\n",
      "Test epoch | Steps: 2502 | Elapsed Time: 0:44:26\n",
      "Test epoch | Steps: 2503 | Elapsed Time: 0:44:28\n",
      "Test epoch | Steps: 2504 | Elapsed Time: 0:44:29\n",
      "Test epoch | Steps: 2505 | Elapsed Time: 0:44:31\n",
      "Test epoch | Steps: 2506 | Elapsed Time: 0:44:32\n",
      "Test epoch | Steps: 2507 | Elapsed Time: 0:44:34\n",
      "Test epoch | Steps: 2508 | Elapsed Time: 0:44:35\n",
      "Test epoch | Steps: 2509 | Elapsed Time: 0:44:37\n",
      "Test epoch | Steps: 2510 | Elapsed Time: 0:44:38\n",
      "Test epoch | Steps: 2511 | Elapsed Time: 0:44:40\n",
      "Test epoch | Steps: 2512 | Elapsed Time: 0:44:42\n",
      "Test epoch | Steps: 2513 | Elapsed Time: 0:44:43\n",
      "Test epoch | Steps: 2514 | Elapsed Time: 0:44:45\n",
      "Test epoch | Steps: 2515 | Elapsed Time: 0:44:46\n",
      "Test epoch | Steps: 2516 | Elapsed Time: 0:44:48\n",
      "Test epoch | Steps: 2517 | Elapsed Time: 0:44:49\n",
      "Test epoch | Steps: 2518 | Elapsed Time: 0:44:51\n",
      "Test epoch | Steps: 2519 | Elapsed Time: 0:44:52\n",
      "Test epoch | Steps: 2520 | Elapsed Time: 0:44:54\n",
      "Test epoch | Steps: 2521 | Elapsed Time: 0:44:55\n",
      "Test epoch | Steps: 2522 | Elapsed Time: 0:44:57\n",
      "Test epoch | Steps: 2523 | Elapsed Time: 0:44:58\n",
      "Test epoch | Steps: 2524 | Elapsed Time: 0:45:00\n",
      "Test epoch | Steps: 2525 | Elapsed Time: 0:45:01\n",
      "Test epoch | Steps: 2526 | Elapsed Time: 0:45:03\n",
      "Test epoch | Steps: 2527 | Elapsed Time: 0:45:05\n",
      "Test epoch | Steps: 2528 | Elapsed Time: 0:45:06\n",
      "Test epoch | Steps: 2529 | Elapsed Time: 0:45:08\n",
      "Test epoch | Steps: 2530 | Elapsed Time: 0:45:09\n",
      "Test epoch | Steps: 2531 | Elapsed Time: 0:45:10\n",
      "Test epoch | Steps: 2532 | Elapsed Time: 0:45:12\n",
      "Test epoch | Steps: 2533 | Elapsed Time: 0:45:14\n",
      "Test epoch | Steps: 2534 | Elapsed Time: 0:45:15\n",
      "Test epoch | Steps: 2535 | Elapsed Time: 0:45:17\n",
      "Test epoch | Steps: 2536 | Elapsed Time: 0:45:18\n",
      "Test epoch | Steps: 2537 | Elapsed Time: 0:45:20\n",
      "Test epoch | Steps: 2538 | Elapsed Time: 0:45:21\n",
      "Test epoch | Steps: 2539 | Elapsed Time: 0:45:23\n",
      "Test epoch | Steps: 2540 | Elapsed Time: 0:45:24\n",
      "Test epoch | Steps: 2541 | Elapsed Time: 0:45:26\n",
      "Test epoch | Steps: 2542 | Elapsed Time: 0:45:27\n",
      "Test epoch | Steps: 2543 | Elapsed Time: 0:45:29\n",
      "Test epoch | Steps: 2544 | Elapsed Time: 0:45:30\n",
      "Test epoch | Steps: 2545 | Elapsed Time: 0:45:32\n",
      "Test epoch | Steps: 2546 | Elapsed Time: 0:45:33\n",
      "Test epoch | Steps: 2547 | Elapsed Time: 0:45:35\n",
      "Test epoch | Steps: 2548 | Elapsed Time: 0:45:36\n",
      "Test epoch | Steps: 2549 | Elapsed Time: 0:45:38\n",
      "Test epoch | Steps: 2550 | Elapsed Time: 0:45:40\n",
      "Test epoch | Steps: 2551 | Elapsed Time: 0:45:41\n",
      "Test epoch | Steps: 2552 | Elapsed Time: 0:45:42\n",
      "Test epoch | Steps: 2553 | Elapsed Time: 0:45:44\n",
      "Test epoch | Steps: 2554 | Elapsed Time: 0:45:45\n",
      "Test epoch | Steps: 2555 | Elapsed Time: 0:45:47\n",
      "Test epoch | Steps: 2556 | Elapsed Time: 0:45:49\n",
      "Test epoch | Steps: 2557 | Elapsed Time: 0:45:50\n",
      "Test epoch | Steps: 2558 | Elapsed Time: 0:45:52\n",
      "Test epoch | Steps: 2559 | Elapsed Time: 0:45:53\n",
      "Test epoch | Steps: 2560 | Elapsed Time: 0:45:55\n",
      "Test epoch | Steps: 2561 | Elapsed Time: 0:45:56\n",
      "Test epoch | Steps: 2562 | Elapsed Time: 0:45:58\n",
      "Test epoch | Steps: 2563 | Elapsed Time: 0:45:59\n",
      "Test epoch | Steps: 2564 | Elapsed Time: 0:46:01\n",
      "Test epoch | Steps: 2565 | Elapsed Time: 0:46:02\n",
      "Test epoch | Steps: 2566 | Elapsed Time: 0:46:04\n",
      "Test epoch | Steps: 2567 | Elapsed Time: 0:46:05\n",
      "Test epoch | Steps: 2568 | Elapsed Time: 0:46:07\n",
      "Test epoch | Steps: 2569 | Elapsed Time: 0:46:09\n",
      "Test epoch | Steps: 2570 | Elapsed Time: 0:46:10\n",
      "Test epoch | Steps: 2571 | Elapsed Time: 0:46:12\n",
      "Test epoch | Steps: 2572 | Elapsed Time: 0:46:13\n",
      "Test epoch | Steps: 2573 | Elapsed Time: 0:46:15\n",
      "Test epoch | Steps: 2574 | Elapsed Time: 0:46:16\n",
      "Test epoch | Steps: 2575 | Elapsed Time: 0:46:18\n",
      "Test epoch | Steps: 2576 | Elapsed Time: 0:46:19\n",
      "Test epoch | Steps: 2577 | Elapsed Time: 0:46:21\n",
      "Test epoch | Steps: 2578 | Elapsed Time: 0:46:22\n",
      "Test epoch | Steps: 2579 | Elapsed Time: 0:46:24\n",
      "Test epoch | Steps: 2580 | Elapsed Time: 0:46:25\n",
      "Test epoch | Steps: 2581 | Elapsed Time: 0:46:27\n",
      "Test epoch | Steps: 2582 | Elapsed Time: 0:46:29\n",
      "Test epoch | Steps: 2583 | Elapsed Time: 0:46:30\n",
      "Test epoch | Steps: 2584 | Elapsed Time: 0:46:32\n",
      "Test epoch | Steps: 2585 | Elapsed Time: 0:46:33\n",
      "Test epoch | Steps: 2586 | Elapsed Time: 0:46:35\n",
      "Test epoch | Steps: 2587 | Elapsed Time: 0:46:36\n",
      "Test epoch | Steps: 2588 | Elapsed Time: 0:46:38\n",
      "Test epoch | Steps: 2589 | Elapsed Time: 0:46:40\n",
      "Test epoch | Steps: 2590 | Elapsed Time: 0:46:41\n",
      "Test epoch | Steps: 2591 | Elapsed Time: 0:46:43\n",
      "Test epoch | Steps: 2592 | Elapsed Time: 0:46:44\n",
      "Test epoch | Steps: 2593 | Elapsed Time: 0:46:46\n",
      "Test epoch | Steps: 2594 | Elapsed Time: 0:46:47\n",
      "Test epoch | Steps: 2595 | Elapsed Time: 0:46:49\n",
      "Test epoch | Steps: 2596 | Elapsed Time: 0:46:51\n",
      "Test epoch | Steps: 2597 | Elapsed Time: 0:46:52\n",
      "Test epoch | Steps: 2598 | Elapsed Time: 0:46:54\n",
      "Test epoch | Steps: 2599 | Elapsed Time: 0:46:55\n",
      "Test epoch | Steps: 2600 | Elapsed Time: 0:46:57\n",
      "Test epoch | Steps: 2601 | Elapsed Time: 0:46:59\n",
      "Test epoch | Steps: 2602 | Elapsed Time: 0:47:00\n",
      "Test epoch | Steps: 2603 | Elapsed Time: 0:47:02\n",
      "Test epoch | Steps: 2604 | Elapsed Time: 0:47:03\n",
      "Test epoch | Steps: 2605 | Elapsed Time: 0:47:05\n",
      "Test epoch | Steps: 2606 | Elapsed Time: 0:47:06\n",
      "Test epoch | Steps: 2607 | Elapsed Time: 0:47:08\n",
      "Test epoch | Steps: 2608 | Elapsed Time: 0:47:10\n",
      "Test epoch | Steps: 2609 | Elapsed Time: 0:47:11\n",
      "Test epoch | Steps: 2610 | Elapsed Time: 0:47:13\n",
      "Test epoch | Steps: 2611 | Elapsed Time: 0:47:14\n",
      "Test epoch | Steps: 2612 | Elapsed Time: 0:47:16\n",
      "Test epoch | Steps: 2613 | Elapsed Time: 0:47:18\n",
      "Test epoch | Steps: 2614 | Elapsed Time: 0:47:19\n",
      "Test epoch | Steps: 2615 | Elapsed Time: 0:47:21\n",
      "Test epoch | Steps: 2616 | Elapsed Time: 0:47:23\n",
      "Test epoch | Steps: 2617 | Elapsed Time: 0:47:24\n",
      "Test epoch | Steps: 2618 | Elapsed Time: 0:47:26\n",
      "Test epoch | Steps: 2619 | Elapsed Time: 0:47:28\n",
      "Test epoch | Steps: 2620 | Elapsed Time: 0:47:31\n",
      "Test epoch | Steps: 2621 | Elapsed Time: 0:47:33\n",
      "Test epoch | Steps: 2622 | Elapsed Time: 0:47:35\n",
      "Test epoch | Steps: 2623 | Elapsed Time: 0:47:38\n",
      "Test epoch | Steps: 2624 | Elapsed Time: 0:47:40\n",
      "Test epoch | Steps: 2625 | Elapsed Time: 0:47:42\n",
      "Test epoch | Steps: 2626 | Elapsed Time: 0:47:44\n",
      "Test epoch | Steps: 2627 | Elapsed Time: 0:47:47\n",
      "Test epoch | Steps: 2628 | Elapsed Time: 0:47:49\n",
      "Test epoch | Steps: 2629 | Elapsed Time: 0:47:51\n",
      "Test epoch | Steps: 2630 | Elapsed Time: 0:47:54\n",
      "Test epoch | Steps: 2631 | Elapsed Time: 0:47:56\n",
      "Test epoch | Steps: 2632 | Elapsed Time: 0:47:58\n",
      "Test epoch | Steps: 2633 | Elapsed Time: 0:48:01\n",
      "Test epoch | Steps: 2634 | Elapsed Time: 0:48:03\n",
      "Test epoch | Steps: 2635 | Elapsed Time: 0:48:06\n",
      "Test epoch | Steps: 2636 | Elapsed Time: 0:48:08\n",
      "Test epoch | Steps: 2637 | Elapsed Time: 0:48:10\n",
      "Test epoch | Steps: 2638 | Elapsed Time: 0:48:13\n",
      "Test epoch | Steps: 2639 | Elapsed Time: 0:48:15\n",
      "Test epoch | Steps: 2640 | Elapsed Time: 0:48:18\n",
      "Test epoch | Steps: 2641 | Elapsed Time: 0:48:20\n",
      "Test epoch | Steps: 2642 | Elapsed Time: 0:48:22\n",
      "Test epoch | Steps: 2643 | Elapsed Time: 0:48:25\n",
      "Test epoch | Steps: 2644 | Elapsed Time: 0:48:27\n",
      "Test epoch | Steps: 2645 | Elapsed Time: 0:48:30\n",
      "Test epoch | Steps: 2646 | Elapsed Time: 0:48:32\n",
      "Test epoch | Steps: 2647 | Elapsed Time: 0:48:34\n",
      "Test epoch | Steps: 2648 | Elapsed Time: 0:48:37\n",
      "Test epoch | Steps: 2649 | Elapsed Time: 0:48:39\n",
      "Test epoch | Steps: 2650 | Elapsed Time: 0:48:41\n",
      "Test epoch | Steps: 2651 | Elapsed Time: 0:48:44\n",
      "Test epoch | Steps: 2652 | Elapsed Time: 0:48:46\n",
      "Test epoch | Steps: 2653 | Elapsed Time: 0:48:48\n",
      "Test epoch | Steps: 2654 | Elapsed Time: 0:48:51\n",
      "Test epoch | Steps: 2655 | Elapsed Time: 0:48:53\n",
      "Test epoch | Steps: 2656 | Elapsed Time: 0:48:56\n",
      "Test epoch | Steps: 2657 | Elapsed Time: 0:48:58\n",
      "Test epoch | Steps: 2658 | Elapsed Time: 0:49:01\n",
      "Test epoch | Steps: 2659 | Elapsed Time: 0:49:04\n",
      "Test epoch | Steps: 2660 | Elapsed Time: 0:49:07\n",
      "Test epoch | Steps: 2661 | Elapsed Time: 0:49:09\n",
      "Test epoch | Steps: 2662 | Elapsed Time: 0:49:12\n",
      "Test epoch | Steps: 2663 | Elapsed Time: 0:49:15\n",
      "Test epoch | Steps: 2664 | Elapsed Time: 0:49:17\n",
      "Test epoch | Steps: 2665 | Elapsed Time: 0:49:20\n",
      "Test epoch | Steps: 2666 | Elapsed Time: 0:49:23\n",
      "Test epoch | Steps: 2667 | Elapsed Time: 0:49:26\n",
      "Test epoch | Steps: 2668 | Elapsed Time: 0:49:28\n",
      "Test epoch | Steps: 2669 | Elapsed Time: 0:49:31\n",
      "Test epoch | Steps: 2670 | Elapsed Time: 0:49:34\n",
      "Test epoch | Steps: 2671 | Elapsed Time: 0:49:37\n",
      "Test epoch | Steps: 2672 | Elapsed Time: 0:49:40\n",
      "Test epoch | Steps: 2673 | Elapsed Time: 0:49:42\n",
      "Test epoch | Steps: 2674 | Elapsed Time: 0:49:45\n",
      "Test epoch | Steps: 2675 | Elapsed Time: 0:49:48\n",
      "Test epoch | Steps: 2676 | Elapsed Time: 0:49:51\n",
      "Test epoch | Steps: 2677 | Elapsed Time: 0:49:53\n",
      "Test epoch | Steps: 2678 | Elapsed Time: 0:49:56\n",
      "Test epoch | Steps: 2679 | Elapsed Time: 0:49:59\n",
      "Test epoch | Steps: 2680 | Elapsed Time: 0:50:02\n",
      "Test epoch | Steps: 2681 | Elapsed Time: 0:50:05\n",
      "Test epoch | Steps: 2682 | Elapsed Time: 0:50:07\n",
      "Test epoch | Steps: 2683 | Elapsed Time: 0:50:10\n",
      "Test epoch | Steps: 2684 | Elapsed Time: 0:50:13\n",
      "Test epoch | Steps: 2685 | Elapsed Time: 0:50:16\n",
      "Test epoch | Steps: 2686 | Elapsed Time: 0:50:18\n",
      "Test epoch | Steps: 2687 | Elapsed Time: 0:50:21\n",
      "Test epoch | Steps: 2688 | Elapsed Time: 0:50:24\n",
      "Test epoch | Steps: 2689 | Elapsed Time: 0:50:27\n",
      "Test epoch | Steps: 2690 | Elapsed Time: 0:50:29\n",
      "Test epoch | Steps: 2691 | Elapsed Time: 0:50:32\n",
      "Test epoch | Steps: 2692 | Elapsed Time: 0:50:35\n",
      "Test epoch | Steps: 2693 | Elapsed Time: 0:50:38\n",
      "Test epoch | Steps: 2694 | Elapsed Time: 0:50:41\n",
      "Test epoch | Steps: 2695 | Elapsed Time: 0:50:44\n",
      "Test epoch | Steps: 2696 | Elapsed Time: 0:50:46\n",
      "Test epoch | Steps: 2697 | Elapsed Time: 0:50:49\n",
      "Test epoch | Steps: 2698 | Elapsed Time: 0:50:52\n",
      "Test epoch | Steps: 2699 | Elapsed Time: 0:50:55\n",
      "Test epoch | Steps: 2700 | Elapsed Time: 0:50:58\n",
      "Test epoch | Steps: 2701 | Elapsed Time: 0:51:00\n",
      "Test epoch | Steps: 2702 | Elapsed Time: 0:51:03\n",
      "Test epoch | Steps: 2703 | Elapsed Time: 0:51:05\n",
      "Test epoch | Steps: 2704 | Elapsed Time: 0:51:08\n",
      "Test epoch | Steps: 2705 | Elapsed Time: 0:51:10\n",
      "Test epoch | Steps: 2706 | Elapsed Time: 0:51:13\n",
      "Test epoch | Steps: 2707 | Elapsed Time: 0:51:15\n",
      "Test epoch | Steps: 2708 | Elapsed Time: 0:51:18\n",
      "Test epoch | Steps: 2709 | Elapsed Time: 0:51:20\n",
      "Test epoch | Steps: 2710 | Elapsed Time: 0:51:22\n",
      "Test epoch | Steps: 2711 | Elapsed Time: 0:51:25\n",
      "Test epoch | Steps: 2712 | Elapsed Time: 0:51:27\n",
      "Test epoch | Steps: 2713 | Elapsed Time: 0:51:29\n",
      "Test epoch | Steps: 2714 | Elapsed Time: 0:51:32\n",
      "Test epoch | Steps: 2715 | Elapsed Time: 0:51:34\n",
      "Test epoch | Steps: 2716 | Elapsed Time: 0:51:37\n",
      "Test epoch | Steps: 2717 | Elapsed Time: 0:51:39\n",
      "Test epoch | Steps: 2718 | Elapsed Time: 0:51:41\n",
      "Test epoch | Steps: 2719 | Elapsed Time: 0:51:44\n",
      "Test epoch | Steps: 2720 | Elapsed Time: 0:51:46\n",
      "Test epoch | Steps: 2721 | Elapsed Time: 0:51:49\n",
      "Test epoch | Steps: 2722 | Elapsed Time: 0:51:51\n",
      "Test epoch | Steps: 2723 | Elapsed Time: 0:51:54\n",
      "Test epoch | Steps: 2724 | Elapsed Time: 0:51:56\n",
      "Test epoch | Steps: 2725 | Elapsed Time: 0:51:59\n",
      "Test epoch | Steps: 2726 | Elapsed Time: 0:52:01\n",
      "Test epoch | Steps: 2727 | Elapsed Time: 0:52:03\n",
      "Test epoch | Steps: 2728 | Elapsed Time: 0:52:06\n",
      "Test epoch | Steps: 2729 | Elapsed Time: 0:52:08\n",
      "Test epoch | Steps: 2730 | Elapsed Time: 0:52:11\n",
      "Test epoch | Steps: 2731 | Elapsed Time: 0:52:14\n",
      "Test epoch | Steps: 2732 | Elapsed Time: 0:52:17\n",
      "Test epoch | Steps: 2733 | Elapsed Time: 0:52:20\n",
      "Test epoch | Steps: 2734 | Elapsed Time: 0:52:22\n",
      "Test epoch | Steps: 2735 | Elapsed Time: 0:52:25\n",
      "Test epoch | Steps: 2736 | Elapsed Time: 0:52:27\n",
      "Test epoch | Steps: 2737 | Elapsed Time: 0:52:30\n",
      "Test epoch | Steps: 2738 | Elapsed Time: 0:52:33\n",
      "Test epoch | Steps: 2739 | Elapsed Time: 0:52:35\n",
      "Test epoch | Steps: 2740 | Elapsed Time: 0:52:38\n",
      "Test epoch | Steps: 2741 | Elapsed Time: 0:52:40\n",
      "Test epoch | Steps: 2742 | Elapsed Time: 0:52:43\n",
      "Test epoch | Steps: 2743 | Elapsed Time: 0:52:45\n",
      "Test epoch | Steps: 2744 | Elapsed Time: 0:52:48\n",
      "Test epoch | Steps: 2745 | Elapsed Time: 0:52:51\n",
      "Test epoch | Steps: 2746 | Elapsed Time: 0:52:53\n",
      "Test epoch | Steps: 2747 | Elapsed Time: 0:52:56\n",
      "Test epoch | Steps: 2748 | Elapsed Time: 0:52:59\n",
      "Test epoch | Steps: 2749 | Elapsed Time: 0:53:01\n",
      "Test epoch | Steps: 2750 | Elapsed Time: 0:53:04\n",
      "Test epoch | Steps: 2751 | Elapsed Time: 0:53:07\n",
      "Test epoch | Steps: 2752 | Elapsed Time: 0:53:09\n",
      "Test epoch | Steps: 2753 | Elapsed Time: 0:53:12\n",
      "Test epoch | Steps: 2754 | Elapsed Time: 0:53:15\n",
      "Test epoch | Steps: 2755 | Elapsed Time: 0:53:18\n",
      "Test epoch | Steps: 2756 | Elapsed Time: 0:53:20\n",
      "Test epoch | Steps: 2757 | Elapsed Time: 0:53:23\n",
      "Test epoch | Steps: 2758 | Elapsed Time: 0:53:25\n",
      "Test epoch | Steps: 2759 | Elapsed Time: 0:53:28\n",
      "Test epoch | Steps: 2760 | Elapsed Time: 0:53:31\n",
      "Test epoch | Steps: 2761 | Elapsed Time: 0:53:34\n",
      "Test epoch | Steps: 2762 | Elapsed Time: 0:53:36\n",
      "Test epoch | Steps: 2763 | Elapsed Time: 0:53:39\n",
      "Test epoch | Steps: 2764 | Elapsed Time: 0:53:41\n",
      "Test epoch | Steps: 2765 | Elapsed Time: 0:53:44\n",
      "Test epoch | Steps: 2766 | Elapsed Time: 0:53:47\n",
      "Test epoch | Steps: 2767 | Elapsed Time: 0:53:49\n",
      "Test epoch | Steps: 2768 | Elapsed Time: 0:53:52\n",
      "Test epoch | Steps: 2769 | Elapsed Time: 0:53:54\n",
      "Test epoch | Steps: 2770 | Elapsed Time: 0:53:57\n",
      "Test epoch | Steps: 2771 | Elapsed Time: 0:54:00\n",
      "Test epoch | Steps: 2772 | Elapsed Time: 0:54:02\n",
      "Test epoch | Steps: 2773 | Elapsed Time: 0:54:05\n",
      "Test epoch | Steps: 2774 | Elapsed Time: 0:54:08\n",
      "Test epoch | Steps: 2775 | Elapsed Time: 0:54:10\n",
      "Test epoch | Steps: 2776 | Elapsed Time: 0:54:13\n",
      "Test epoch | Steps: 2777 | Elapsed Time: 0:54:16\n",
      "Test epoch | Steps: 2778 | Elapsed Time: 0:54:19\n",
      "Test epoch | Steps: 2779 | Elapsed Time: 0:54:21\n",
      "Test epoch | Steps: 2780 | Elapsed Time: 0:54:24\n",
      "Test epoch | Steps: 2781 | Elapsed Time: 0:54:27\n",
      "Test epoch | Steps: 2782 | Elapsed Time: 0:54:29\n",
      "Test epoch | Steps: 2783 | Elapsed Time: 0:54:32\n",
      "Test epoch | Steps: 2784 | Elapsed Time: 0:54:35\n",
      "Test epoch | Steps: 2785 | Elapsed Time: 0:54:37\n",
      "Test epoch | Steps: 2786 | Elapsed Time: 0:54:40\n",
      "Test epoch | Steps: 2787 | Elapsed Time: 0:54:43\n",
      "Test epoch | Steps: 2788 | Elapsed Time: 0:54:46\n",
      "Test epoch | Steps: 2789 | Elapsed Time: 0:54:48\n",
      "Test epoch | Steps: 2790 | Elapsed Time: 0:54:51\n",
      "Test epoch | Steps: 2791 | Elapsed Time: 0:54:54\n",
      "Test epoch | Steps: 2792 | Elapsed Time: 0:54:57\n",
      "Test epoch | Steps: 2793 | Elapsed Time: 0:54:59\n",
      "Test epoch | Steps: 2794 | Elapsed Time: 0:55:02\n",
      "Test epoch | Steps: 2795 | Elapsed Time: 0:55:05\n",
      "Test epoch | Steps: 2796 | Elapsed Time: 0:55:07\n",
      "Test epoch | Steps: 2797 | Elapsed Time: 0:55:10\n",
      "Test epoch | Steps: 2798 | Elapsed Time: 0:55:13\n",
      "Test epoch | Steps: 2799 | Elapsed Time: 0:55:16\n",
      "Test epoch | Steps: 2800 | Elapsed Time: 0:55:19\n",
      "Test epoch | Steps: 2801 | Elapsed Time: 0:55:22\n",
      "Test epoch | Steps: 2802 | Elapsed Time: 0:55:25\n",
      "Test epoch | Steps: 2803 | Elapsed Time: 0:55:27\n",
      "Test epoch | Steps: 2804 | Elapsed Time: 0:55:30\n",
      "Test epoch | Steps: 2805 | Elapsed Time: 0:55:33\n",
      "Test epoch | Steps: 2806 | Elapsed Time: 0:55:36\n",
      "Test epoch | Steps: 2807 | Elapsed Time: 0:55:39\n",
      "Test epoch | Steps: 2808 | Elapsed Time: 0:55:41\n",
      "Test epoch | Steps: 2809 | Elapsed Time: 0:55:44\n",
      "Test epoch | Steps: 2810 | Elapsed Time: 0:55:47\n",
      "Test epoch | Steps: 2811 | Elapsed Time: 0:55:50\n",
      "Test epoch | Steps: 2812 | Elapsed Time: 0:55:53\n",
      "Test epoch | Steps: 2813 | Elapsed Time: 0:55:55\n",
      "Test epoch | Steps: 2814 | Elapsed Time: 0:55:58\n",
      "Test epoch | Steps: 2815 | Elapsed Time: 0:56:01\n",
      "Test epoch | Steps: 2816 | Elapsed Time: 0:56:04\n",
      "Test epoch | Steps: 2817 | Elapsed Time: 0:56:07\n",
      "Test epoch | Steps: 2818 | Elapsed Time: 0:56:09\n",
      "Test epoch | Steps: 2819 | Elapsed Time: 0:56:12\n",
      "Test epoch | Steps: 2820 | Elapsed Time: 0:56:15\n",
      "Test epoch | Steps: 2821 | Elapsed Time: 0:56:18\n",
      "Test epoch | Steps: 2822 | Elapsed Time: 0:56:21\n",
      "Test epoch | Steps: 2823 | Elapsed Time: 0:56:24\n",
      "Test epoch | Steps: 2824 | Elapsed Time: 0:56:26\n",
      "Test epoch | Steps: 2825 | Elapsed Time: 0:56:29\n",
      "Test epoch | Steps: 2826 | Elapsed Time: 0:56:31\n",
      "Test epoch | Steps: 2827 | Elapsed Time: 0:56:34\n",
      "Test epoch | Steps: 2828 | Elapsed Time: 0:56:37\n",
      "Test epoch | Steps: 2829 | Elapsed Time: 0:56:39\n",
      "Test epoch | Steps: 2830 | Elapsed Time: 0:56:42\n",
      "Test epoch | Steps: 2831 | Elapsed Time: 0:56:45\n",
      "Test epoch | Steps: 2832 | Elapsed Time: 0:56:48\n",
      "Test epoch | Steps: 2833 | Elapsed Time: 0:56:51\n",
      "Test epoch | Steps: 2834 | Elapsed Time: 0:56:53\n",
      "Test epoch | Steps: 2835 | Elapsed Time: 0:56:56\n",
      "Test epoch | Steps: 2836 | Elapsed Time: 0:56:59\n",
      "Test epoch | Steps: 2837 | Elapsed Time: 0:57:01\n",
      "Test epoch | Steps: 2838 | Elapsed Time: 0:57:04\n",
      "Test epoch | Steps: 2839 | Elapsed Time: 0:57:07\n",
      "Test epoch | Steps: 2840 | Elapsed Time: 0:57:10\n",
      "Test epoch | Steps: 2841 | Elapsed Time: 0:57:13\n",
      "Test epoch | Steps: 2842 | Elapsed Time: 0:57:16\n",
      "Test epoch | Steps: 2843 | Elapsed Time: 0:57:18\n",
      "Test epoch | Steps: 2844 | Elapsed Time: 0:57:21\n",
      "Test epoch | Steps: 2845 | Elapsed Time: 0:57:24\n",
      "Test epoch | Steps: 2846 | Elapsed Time: 0:57:27\n",
      "Test epoch | Steps: 2847 | Elapsed Time: 0:57:30\n",
      "Test epoch | Steps: 2848 | Elapsed Time: 0:57:32\n",
      "Test epoch | Steps: 2849 | Elapsed Time: 0:57:35\n",
      "Test epoch | Steps: 2850 | Elapsed Time: 0:57:38\n",
      "Test epoch | Steps: 2851 | Elapsed Time: 0:57:41\n",
      "Test epoch | Steps: 2852 | Elapsed Time: 0:57:44\n",
      "Test epoch | Steps: 2853 | Elapsed Time: 0:57:47\n",
      "Test epoch | Steps: 2854 | Elapsed Time: 0:57:49\n",
      "Test epoch | Steps: 2855 | Elapsed Time: 0:57:52\n",
      "Test epoch | Steps: 2856 | Elapsed Time: 0:57:55\n",
      "Test epoch | Steps: 2857 | Elapsed Time: 0:57:58\n",
      "Test epoch | Steps: 2858 | Elapsed Time: 0:58:01\n",
      "Test epoch | Steps: 2859 | Elapsed Time: 0:58:04\n",
      "Test epoch | Steps: 2860 | Elapsed Time: 0:58:07\n",
      "Test epoch | Steps: 2861 | Elapsed Time: 0:58:10\n",
      "Test epoch | Steps: 2862 | Elapsed Time: 0:58:12\n",
      "Test epoch | Steps: 2863 | Elapsed Time: 0:58:15\n",
      "Test epoch | Steps: 2864 | Elapsed Time: 0:58:18\n",
      "Test epoch | Steps: 2865 | Elapsed Time: 0:58:21\n",
      "Test epoch | Steps: 2866 | Elapsed Time: 0:58:23\n",
      "Test epoch | Steps: 2867 | Elapsed Time: 0:58:26\n",
      "Test epoch | Steps: 2868 | Elapsed Time: 0:58:29\n",
      "Test epoch | Steps: 2869 | Elapsed Time: 0:58:32\n",
      "Test epoch | Steps: 2870 | Elapsed Time: 0:58:35\n",
      "Test epoch | Steps: 2871 | Elapsed Time: 0:58:38\n",
      "Test epoch | Steps: 2872 | Elapsed Time: 0:58:40\n",
      "Test epoch | Steps: 2873 | Elapsed Time: 0:58:43\n",
      "Test epoch | Steps: 2874 | Elapsed Time: 0:58:46\n",
      "Test epoch | Steps: 2875 | Elapsed Time: 0:58:49\n",
      "Test epoch | Steps: 2876 | Elapsed Time: 0:58:52\n",
      "Test epoch | Steps: 2877 | Elapsed Time: 0:58:55\n",
      "Test epoch | Steps: 2878 | Elapsed Time: 0:58:58\n",
      "Test epoch | Steps: 2879 | Elapsed Time: 0:59:01\n",
      "Test epoch | Steps: 2880 | Elapsed Time: 0:59:04\n",
      "Test epoch | Steps: 2881 | Elapsed Time: 0:59:07\n",
      "Test epoch | Steps: 2882 | Elapsed Time: 0:59:10\n",
      "Test epoch | Steps: 2883 | Elapsed Time: 0:59:13\n",
      "Test epoch | Steps: 2884 | Elapsed Time: 0:59:16\n",
      "Test epoch | Steps: 2885 | Elapsed Time: 0:59:19\n",
      "Test epoch | Steps: 2886 | Elapsed Time: 0:59:22\n",
      "Test epoch | Steps: 2887 | Elapsed Time: 0:59:24\n",
      "Test epoch | Steps: 2888 | Elapsed Time: 0:59:27\n",
      "Test epoch | Steps: 2889 | Elapsed Time: 0:59:30\n",
      "Test epoch | Steps: 2890 | Elapsed Time: 0:59:33\n",
      "Test epoch | Steps: 2891 | Elapsed Time: 0:59:36\n",
      "Test epoch | Steps: 2892 | Elapsed Time: 0:59:39\n",
      "Test epoch | Steps: 2893 | Elapsed Time: 0:59:41\n",
      "Test epoch | Steps: 2894 | Elapsed Time: 0:59:44\n",
      "Test epoch | Steps: 2895 | Elapsed Time: 0:59:47\n",
      "Test epoch | Steps: 2896 | Elapsed Time: 0:59:50\n",
      "Test epoch | Steps: 2897 | Elapsed Time: 0:59:53\n",
      "Test epoch | Steps: 2898 | Elapsed Time: 0:59:56\n",
      "Test epoch | Steps: 2899 | Elapsed Time: 0:59:59\n",
      "Test epoch | Steps: 2900 | Elapsed Time: 1:00:02\n",
      "Test epoch | Steps: 2901 | Elapsed Time: 1:00:05\n",
      "Test epoch | Steps: 2902 | Elapsed Time: 1:00:08\n",
      "Test epoch | Steps: 2903 | Elapsed Time: 1:00:11\n",
      "Test epoch | Steps: 2904 | Elapsed Time: 1:00:14\n",
      "Test epoch | Steps: 2905 | Elapsed Time: 1:00:18\n",
      "Test epoch | Steps: 2906 | Elapsed Time: 1:00:21\n",
      "Test epoch | Steps: 2907 | Elapsed Time: 1:00:23\n",
      "Test epoch | Steps: 2908 | Elapsed Time: 1:00:27\n",
      "Test epoch | Steps: 2909 | Elapsed Time: 1:00:30\n",
      "Test epoch | Steps: 2910 | Elapsed Time: 1:00:33\n",
      "Test epoch | Steps: 2911 | Elapsed Time: 1:00:36\n",
      "Test epoch | Steps: 2912 | Elapsed Time: 1:00:39\n",
      "Test epoch | Steps: 2913 | Elapsed Time: 1:00:42\n",
      "Test epoch | Steps: 2914 | Elapsed Time: 1:00:45\n",
      "Test epoch | Steps: 2915 | Elapsed Time: 1:00:48\n",
      "Test epoch | Steps: 2916 | Elapsed Time: 1:00:51\n",
      "Test epoch | Steps: 2917 | Elapsed Time: 1:00:54\n",
      "Test epoch | Steps: 2918 | Elapsed Time: 1:00:57\n",
      "Test epoch | Steps: 2919 | Elapsed Time: 1:01:00\n",
      "Test epoch | Steps: 2920 | Elapsed Time: 1:01:03\n",
      "Test epoch | Steps: 2921 | Elapsed Time: 1:01:06\n",
      "Test epoch | Steps: 2922 | Elapsed Time: 1:01:09\n",
      "Test epoch | Steps: 2923 | Elapsed Time: 1:01:12\n",
      "Test epoch | Steps: 2924 | Elapsed Time: 1:01:15\n",
      "Test epoch | Steps: 2925 | Elapsed Time: 1:01:18\n",
      "Test epoch | Steps: 2926 | Elapsed Time: 1:01:21\n",
      "Test epoch | Steps: 2927 | Elapsed Time: 1:01:24\n",
      "Test epoch | Steps: 2928 | Elapsed Time: 1:01:27\n",
      "Test epoch | Steps: 2929 | Elapsed Time: 1:01:30\n",
      "Test epoch | Steps: 2930 | Elapsed Time: 1:01:33\n",
      "Test epoch | Steps: 2931 | Elapsed Time: 1:01:36\n",
      "Test epoch | Steps: 2932 | Elapsed Time: 1:01:40\n",
      "Test epoch | Steps: 2933 | Elapsed Time: 1:01:43\n",
      "Test epoch | Steps: 2934 | Elapsed Time: 1:01:46\n",
      "Test epoch | Steps: 2935 | Elapsed Time: 1:01:49\n",
      "Test epoch | Steps: 2936 | Elapsed Time: 1:01:52\n",
      "Test epoch | Steps: 2937 | Elapsed Time: 1:01:55\n",
      "Test epoch | Steps: 2938 | Elapsed Time: 1:01:58\n",
      "Test epoch | Steps: 2939 | Elapsed Time: 1:02:02\n",
      "Test epoch | Steps: 2940 | Elapsed Time: 1:02:05\n",
      "Test epoch | Steps: 2941 | Elapsed Time: 1:02:08\n",
      "Test epoch | Steps: 2942 | Elapsed Time: 1:02:11\n",
      "Test epoch | Steps: 2943 | Elapsed Time: 1:02:14\n",
      "Test epoch | Steps: 2944 | Elapsed Time: 1:02:17\n",
      "Test epoch | Steps: 2945 | Elapsed Time: 1:02:21\n",
      "Test epoch | Steps: 2946 | Elapsed Time: 1:02:24\n",
      "Test epoch | Steps: 2947 | Elapsed Time: 1:02:27\n",
      "Test epoch | Steps: 2948 | Elapsed Time: 1:02:30\n",
      "Test epoch | Steps: 2949 | Elapsed Time: 1:02:33\n",
      "Test epoch | Steps: 2950 | Elapsed Time: 1:02:36\n",
      "Test epoch | Steps: 2951 | Elapsed Time: 1:02:40\n",
      "Test epoch | Steps: 2952 | Elapsed Time: 1:02:43\n",
      "Test epoch | Steps: 2953 | Elapsed Time: 1:02:46\n",
      "Test epoch | Steps: 2954 | Elapsed Time: 1:02:49\n",
      "Test epoch | Steps: 2955 | Elapsed Time: 1:02:53\n",
      "Test epoch | Steps: 2956 | Elapsed Time: 1:02:56\n",
      "Test epoch | Steps: 2957 | Elapsed Time: 1:02:59\n",
      "Test epoch | Steps: 2958 | Elapsed Time: 1:03:02\n",
      "Test epoch | Steps: 2959 | Elapsed Time: 1:03:05\n",
      "Test epoch | Steps: 2960 | Elapsed Time: 1:03:09\n",
      "Test epoch | Steps: 2961 | Elapsed Time: 1:03:12\n",
      "Test epoch | Steps: 2962 | Elapsed Time: 1:03:15\n",
      "Test epoch | Steps: 2963 | Elapsed Time: 1:03:18\n",
      "Test epoch | Steps: 2964 | Elapsed Time: 1:03:22\n",
      "Test epoch | Steps: 2965 | Elapsed Time: 1:03:25\n",
      "Test epoch | Steps: 2966 | Elapsed Time: 1:03:29\n",
      "Test epoch | Steps: 2967 | Elapsed Time: 1:03:32\n",
      "Test epoch | Steps: 2968 | Elapsed Time: 1:03:36\n",
      "Test epoch | Steps: 2969 | Elapsed Time: 1:03:39\n",
      "Test epoch | Steps: 2970 | Elapsed Time: 1:03:42\n",
      "Test epoch | Steps: 2971 | Elapsed Time: 1:03:45\n",
      "Test epoch | Steps: 2972 | Elapsed Time: 1:03:48\n",
      "Test epoch | Steps: 2973 | Elapsed Time: 1:03:52\n",
      "Test epoch | Steps: 2974 | Elapsed Time: 1:03:55\n",
      "Test epoch | Steps: 2975 | Elapsed Time: 1:03:59\n",
      "Test epoch | Steps: 2976 | Elapsed Time: 1:04:02\n",
      "Test epoch | Steps: 2977 | Elapsed Time: 1:04:05\n",
      "Test epoch | Steps: 2978 | Elapsed Time: 1:04:08\n",
      "Test epoch | Steps: 2979 | Elapsed Time: 1:04:11\n",
      "Test epoch | Steps: 2980 | Elapsed Time: 1:04:14\n",
      "Test epoch | Steps: 2981 | Elapsed Time: 1:04:18\n",
      "Test epoch | Steps: 2982 | Elapsed Time: 1:04:21\n",
      "Test epoch | Steps: 2983 | Elapsed Time: 1:04:24\n",
      "Test epoch | Steps: 2984 | Elapsed Time: 1:04:27\n",
      "Test epoch | Steps: 2985 | Elapsed Time: 1:04:31\n",
      "Test epoch | Steps: 2986 | Elapsed Time: 1:04:34\n",
      "Test epoch | Steps: 2987 | Elapsed Time: 1:04:38\n",
      "Test epoch | Steps: 2988 | Elapsed Time: 1:04:41\n",
      "Test epoch | Steps: 2989 | Elapsed Time: 1:04:44\n",
      "Test epoch | Steps: 2990 | Elapsed Time: 1:04:47\n",
      "Test epoch | Steps: 2991 | Elapsed Time: 1:04:51\n",
      "Test epoch | Steps: 2992 | Elapsed Time: 1:04:54\n",
      "Test epoch | Steps: 2993 | Elapsed Time: 1:04:58\n",
      "Test epoch | Steps: 2994 | Elapsed Time: 1:05:01\n",
      "Test epoch | Steps: 2995 | Elapsed Time: 1:05:04\n",
      "Test epoch | Steps: 2996 | Elapsed Time: 1:05:07\n",
      "Test epoch | Steps: 2997 | Elapsed Time: 1:05:10\n",
      "Test epoch | Steps: 2998 | Elapsed Time: 1:05:14\n",
      "Test epoch | Steps: 2999 | Elapsed Time: 1:05:17\n",
      "Test epoch | Steps: 3000 | Elapsed Time: 1:05:20\n",
      "Test epoch | Steps: 3001 | Elapsed Time: 1:05:24\n",
      "Test epoch | Steps: 3002 | Elapsed Time: 1:05:27\n",
      "Test epoch | Steps: 3003 | Elapsed Time: 1:05:30\n",
      "Test epoch | Steps: 3004 | Elapsed Time: 1:05:34\n",
      "Test epoch | Steps: 3005 | Elapsed Time: 1:05:37\n",
      "Test epoch | Steps: 3006 | Elapsed Time: 1:05:39\n",
      "Test epoch | Steps: 3006 | Elapsed Time: 1:05:39\n",
      "Test on sw/test.csv - WER: 0.943372, CER: 0.456068, loss: 83.733955\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 8.293964\n",
      " - wav: sw/test/common_voice_sw_30563097.wav\n",
      " - src: \"aliamka mapema sana jana\"\n",
      " - res: \"aliamka mapema sana jana\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 1.976095\n",
      " - wav: sw/test/common_voice_sw_36374719.wav\n",
      " - src: \"tukala sana\"\n",
      " - res: \"tukala sana\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.088889, loss: 22.152025\n",
      " - wav: sw/test/common_voice_sw_36010670.wav\n",
      " - src: \"mpakani kwa kanada na kuishia katika ghuba ya\"\n",
      " - res: \"mpakani kwa kanada na kushhia katika kuba ya\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.080000, loss: 12.574053\n",
      " - wav: sw/test/common_voice_sw_36299910.wav\n",
      " - src: \"aliiba kazi ya mwanafunzi\"\n",
      " - res: \"aliiba kazi ya manafumzi\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.040000, loss: 9.482208\n",
      " - wav: sw/test/common_voice_sw_32312027.wav\n",
      " - src: \"wika mipaka katika shamba\"\n",
      " - res: \"mika mipaka katika shamba\"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.731707, loss: 114.744881\n",
      " - wav: sw/test/common_voice_sw_29293734.wav\n",
      " - src: \"fannin alikua msanii wa kujifunza mwenyew\"\n",
      " - res: \"ade aikwaaeakwejekwakagaje wani\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.711111, loss: 114.730270\n",
      " - wav: sw/test/common_voice_sw_35990817.wav\n",
      " - src: \"vilivyo kuanguka kwa ndege mayday mayday papa\"\n",
      " - res: \"bizokwa mugafandeni ni ineneak\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.469697, loss: 114.726433\n",
      " - wav: sw/test/common_voice_sw_35170639.wav\n",
      " - src: \"kuhitilafiana na shughuli za kawaida kama vile kazi na majukumu ya\"\n",
      " - res: \"kwiika haiana shungoi kakaina kaakii kasa mamalikumia\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.544118, loss: 114.701675\n",
      " - wav: sw/test/common_voice_sw_30718389.wav\n",
      " - src: \"hii ni kwa faida yetu wenyewe inatusaidia hata kupata mvua kwa wingi\"\n",
      " - res: \"ii ka haidaekola mea ikafava hatafufatamga kamu a\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.424658, loss: 114.649445\n",
      " - wav: sw/test/common_voice_sw_37663982.wav\n",
      " - src: \"hili ni zao ambalo mizizi na majani yake huliwa na lina virutubishi vingi\"\n",
      " - res: \"ininiza wambao mizeza majenia keuliwa nanejetubishi jini al\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.076923, loss: 5.660091\n",
      " - wav: sw/test/common_voice_sw_32167854.wav\n",
      " - src: \"tumekubaliana\"\n",
      " - res: \"tumekubali ana\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.500000, CER: 2.000000, loss: 101.650482\n",
      " - wav: sw/test/common_voice_sw_35146416.wav\n",
      " - src: \"ameenda msalani\"\n",
      " - res: \"aziosadani na kinaskafilii kwazia kazga\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.500000, CER: 1.818182, loss: 47.264072\n",
      " - wav: sw/test/common_voice_sw_31229281.wav\n",
      " - src: \"penye wazee\"\n",
      " - res: \"ena wabilia waze wa hilila\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 3.000000, CER: 0.434783, loss: 37.973175\n",
      " - wav: sw/test/common_voice_sw_32210642.wav\n",
      " - src: \"kujengakutomeakukandika\"\n",
      " - res: \"uliala utomea kamika\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 3.000000, CER: 0.583333, loss: 19.964119\n",
      " - wav: sw/test/common_voice_sw_30623628.wav\n",
      " - src: \"wadakiadakia\"\n",
      " - res: \"wadake yavatia m\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from coqui_stt_training.evaluate import test\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcribe for submission.\n",
    "# !python scripts/transcribe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format submission\n",
    "# !python scripts/format_sub.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34692</td>\n",
       "      <td>34666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>34692</td>\n",
       "      <td>34665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>common_voice_sw_30519925.mp3</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                path sentence\n",
       "count                          34692    34666\n",
       "unique                         34692    34665\n",
       "top     common_voice_sw_30519925.mp3        i\n",
       "freq                               1        2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view submission file\n",
    "sub_df = pd.read_csv('sw/submission.csv')\n",
    "sub_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34692</td>\n",
       "      <td>34692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>34692</td>\n",
       "      <td>34666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>common_voice_sw_30519925.mp3</td>\n",
       "      <td>placeholder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                path     sentence\n",
       "count                          34692        34692\n",
       "unique                         34692        34666\n",
       "top     common_voice_sw_30519925.mp3  placeholder\n",
       "freq                               1           26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute missing values in sentence\n",
    "sub_df['sentence'] = sub_df['sentence'].fillna('placeholder')\n",
    "sub_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new submission csv\n",
    "sub_df.to_csv('sub_csv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temporary fn to clear mp3 files from eval set after conversion \n",
    "# def delete_mp3_files(directory):\n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename.endswith(\".mp3\") or filename.endswith(\".tlog\"):\n",
    "#             file_path = os.path.join(directory, filename)\n",
    "#             os.remove(file_path)\n",
    "\n",
    "# # Usage example\n",
    "# directory = 'sw/eval/'\n",
    "# delete_mp3_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
