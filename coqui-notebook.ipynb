{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Africas Talking-Mozilla Common Voice Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main notebook used in model development. For experimentation use notebooks in the `misc_notebooks` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is originally a submission to the Africa's Talking x Mozilla Common Voice Hackathon, from October 13th through November"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objectives\n",
    ">> The main objective is to build a deep learning model that is capable of inferring `text` having been conditioned on `voice` sequences.\n",
    "\n",
    "The model is expected to achieve best performance on the selected evaluation metrics:\n",
    "* Character Error Rate\n",
    "* Word Error Rate\n",
    "* Phone Error Rate\n",
    "* Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used is sourced from Mozilla's site [here](https://commonvoice.mozilla.org/en/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# import scripts/to_csv.py as to_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read `tsv` files\n",
    "test_df = pd.read_csv('sw/test.tsv', delimiter='\\t')\n",
    "train_df = pd.read_csv('sw/train.tsv', delimiter='\\t')\n",
    "# reported_df = pd.read_csv('sw/reported.tsv', engine='c', delimiter='\\t') # causing EOF error in reading, possibly corrupt or inconsistent\n",
    "# others_df = pd.read_csv('sw/other.tsv', delimiter='\\t') # causing EOF error in reading, possibly corrupt or inconsistent\n",
    "invalidated_df = pd.read_csv('sw/invalidated.tsv', delimiter='\\t')\n",
    "dev_df = pd.read_csv('sw/dev.tsv', delimiter='\\t')\n",
    "durations_df = pd.read_csv('sw/clip_durations.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect some of these DataFrames to get our bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37083656.mp3</td>\n",
       "      <td>yeyote yule atakaepatikana akiandamana katika ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085166.mp3</td>\n",
       "      <td>kwa ujumla kwenye kwenye sehemu za wilaya ama ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085182.mp3</td>\n",
       "      <td>Hawai ni kuzuri</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085525.mp3</td>\n",
       "      <td>na kuhatarisha mifumo mizima ya uhai katika se...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...</td>\n",
       "      <td>common_voice_sw_37085535.mp3</td>\n",
       "      <td>kundi zima lililosababisha mauaji lilitakiwa k...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "1  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "2  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "3  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "4  70c2b9896ca6150002ef6e888a3f7788e49e61aef85ec8...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_37083656.mp3   \n",
       "1  common_voice_sw_37085166.mp3   \n",
       "2  common_voice_sw_37085182.mp3   \n",
       "3  common_voice_sw_37085525.mp3   \n",
       "4  common_voice_sw_37085535.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  yeyote yule atakaepatikana akiandamana katika ...         2           0   \n",
       "1  kwa ujumla kwenye kwenye sehemu za wilaya ama ...         3           1   \n",
       "2                                    Hawai ni kuzuri         2           0   \n",
       "3  na kuhatarisha mifumo mizima ya uhai katika se...        13           3   \n",
       "4  kundi zima lililosababisha mauaji lilitakiwa k...         2           1   \n",
       "\n",
       "        age  gender accents variant locale  segment  \n",
       "0  twenties  female     NaN     NaN     sw      NaN  \n",
       "1  twenties  female     NaN     NaN     sw      NaN  \n",
       "2  twenties  female     NaN     NaN     sw      NaN  \n",
       "3  twenties  female     NaN     NaN     sw      NaN  \n",
       "4  twenties  female     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011544b78c18417a5869b8e70ebc7675c7eb3b517754b8...</td>\n",
       "      <td>common_voice_sw_37190902.mp3</td>\n",
       "      <td>Tuma pesa sahii.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0133d8ddf5c1a3c678fde017e0b07d2835bfd707d5b3ec...</td>\n",
       "      <td>common_voice_sw_31428161.mp3</td>\n",
       "      <td>wachambuzi wa soka wanamtaja Messi kama nyota ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01c95772efd3fbe4a1122206c7474c77ed6591c8c9fb00...</td>\n",
       "      <td>common_voice_sw_30317714.mp3</td>\n",
       "      <td>romario aliingia kwenye orodha ya wachezaji wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023711185d4404ff398c2697f2e72868d1ecf69a92b581...</td>\n",
       "      <td>common_voice_sw_32116997.mp3</td>\n",
       "      <td>Sote twesangaa twelipomuona mwalimu Ali apika</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0244639ffd7ec755a01b21ea204735ca3c44443e9cf46c...</td>\n",
       "      <td>common_voice_sw_29002392.mp3</td>\n",
       "      <td>Inajulikana kama shina la Warangi.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  011544b78c18417a5869b8e70ebc7675c7eb3b517754b8...   \n",
       "1  0133d8ddf5c1a3c678fde017e0b07d2835bfd707d5b3ec...   \n",
       "2  01c95772efd3fbe4a1122206c7474c77ed6591c8c9fb00...   \n",
       "3  023711185d4404ff398c2697f2e72868d1ecf69a92b581...   \n",
       "4  0244639ffd7ec755a01b21ea204735ca3c44443e9cf46c...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_37190902.mp3   \n",
       "1  common_voice_sw_31428161.mp3   \n",
       "2  common_voice_sw_30317714.mp3   \n",
       "3  common_voice_sw_32116997.mp3   \n",
       "4  common_voice_sw_29002392.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0                                   Tuma pesa sahii.         2           0   \n",
       "1  wachambuzi wa soka wanamtaja Messi kama nyota ...         2           0   \n",
       "2  romario aliingia kwenye orodha ya wachezaji wa...         2           1   \n",
       "3      Sote twesangaa twelipomuona mwalimu Ali apika         2           1   \n",
       "4                 Inajulikana kama shina la Warangi.         2           0   \n",
       "\n",
       "        age  gender accents variant locale  segment  \n",
       "0       NaN     NaN     NaN     NaN     sw      NaN  \n",
       "1  twenties  female     NaN     NaN     sw      NaN  \n",
       "2       NaN     NaN     NaN     NaN     sw      NaN  \n",
       "3  twenties    male     NaN     NaN     sw      NaN  \n",
       "4       NaN     NaN     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628088.mp3</td>\n",
       "      <td>Mbali na kuwa afisa wa serikali Jokate pia ni ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628121.mp3</td>\n",
       "      <td>Kukosa pesa ni hatari sana</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628126.mp3</td>\n",
       "      <td>Jina Karagwe linatokana na kilima kinachopatik...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628160.mp3</td>\n",
       "      <td>sokwe wanaopatikana mahale ni aina adimu zaidi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...</td>\n",
       "      <td>common_voice_sw_30628161.mp3</td>\n",
       "      <td>mamba wa mto naili wana sumu kali inayoozesha ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "1  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "2  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "3  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "4  8ed66acaaecf3d1ffd887ed5af76a220976a8b3dd1209f...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_sw_30628088.mp3   \n",
       "1  common_voice_sw_30628121.mp3   \n",
       "2  common_voice_sw_30628126.mp3   \n",
       "3  common_voice_sw_30628160.mp3   \n",
       "4  common_voice_sw_30628161.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  Mbali na kuwa afisa wa serikali Jokate pia ni ...         2           0   \n",
       "1                         Kukosa pesa ni hatari sana         3           1   \n",
       "2  Jina Karagwe linatokana na kilima kinachopatik...         2           0   \n",
       "3  sokwe wanaopatikana mahale ni aina adimu zaidi...         2           0   \n",
       "4  mamba wa mto naili wana sumu kali inayoozesha ...         3           0   \n",
       "\n",
       "        age gender accents variant locale  segment  \n",
       "0  twenties   male     NaN     NaN     sw      NaN  \n",
       "1  twenties   male     NaN     NaN     sw      NaN  \n",
       "2  twenties   male     NaN     NaN     sw      NaN  \n",
       "3  twenties   male     NaN     NaN     sw      NaN  \n",
       "4  twenties   male     NaN     NaN     sw      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev_df\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to change `sentence` column to `transcript`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of Pandas DataFrames\n",
    "df_list = [train_df, dev_df, test_df]\n",
    "\n",
    "# Create the sw/ directory if it does not exist\n",
    "csv_directory_path = \"sw/\"\n",
    "if not os.path.exists(csv_directory_path):\n",
    "    os.makedirs(csv_directory_path)\n",
    "\n",
    "# Iterate over the list of DataFrames and save each DataFrame to a CSV file\n",
    "for df, df_name in zip(df_list, [\"train\", \"dev\", \"test\"]):\n",
    "\n",
    "    # Join the DataFrame name with the CSV directory path\n",
    "    csv_file_path = os.path.join(csv_directory_path, df_name + \".csv\")\n",
    "\n",
    "    # Save the DataFrame to the CSV file\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement wave tokenizer to obtain feature table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZE DEFAULT HYPERPARAMETERS (Coqui-stt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 12:27:16.583535: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-10-14 12:27:16.609092: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz\n",
      "2023-10-14 12:27:16.610181: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x211e4a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-14 12:27:16.610218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "from coqui_stt_training.util.config import initialize_globals_from_args\n",
    "\n",
    "initialize_globals_from_args(\n",
    "    alphabet_config_path=\"sw/alphabet.txt\",\n",
    "    checkpoint_dir=\"ckpt_dir\",\n",
    "    train_files=[\"sw/train.csv\"],\n",
    "    dev_files=[\"sw/dev.csv\"],\n",
    "    test_files=[\"sw/test.csv\"],\n",
    "    load_train=\"init\",\n",
    "    n_hidden=200,\n",
    "    epochs=100,\n",
    "    train_batch_size=2,\n",
    "    dev_batch_size=2,\n",
    "    test_batch_size= 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Performing dummy training to check for memory problems.\n",
      "I If the following process crashes, you likely have batch sizes that are too big for your available system memory (or GPU memory).\n",
      "I Initializing all variables.\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000\n",
      "Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: sw/dev.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 12:27:19.604910: W tensorflow/core/framework/op_kernel.cc:1639] Unknown: RuntimeError: No transcript data (missing CSV column)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 160, in generate_values\n",
      "    sources, buffering=buffering, labeled=True, reverse=reverse\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 722, in samples_from_sources\n",
      "    sample_sources[0], buffering=buffering, labeled=labeled, reverse=reverse\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 681, in samples_from_source\n",
      "    return CSV(sample_source, labeled=labeled, reverse=reverse)\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 545, in __init__\n",
      "    raise RuntimeError(\"No transcript data (missing CSV column)\")\n",
      "\n",
      "RuntimeError: No transcript data (missing CSV column)\n",
      "\n",
      "\n",
      "2023-10-14 12:27:19.747459: W tensorflow/core/framework/op_kernel.cc:1639] Unknown: RuntimeError: No transcript data (missing CSV column)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 160, in generate_values\n",
      "    sources, buffering=buffering, labeled=True, reverse=reverse\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 722, in samples_from_sources\n",
      "    sample_sources[0], buffering=buffering, labeled=labeled, reverse=reverse\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 681, in samples_from_source\n",
      "    return CSV(sample_source, labeled=labeled, reverse=reverse)\n",
      "\n",
      "  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 545, in __init__\n",
      "    raise RuntimeError(\"No transcript data (missing CSV column)\")\n",
      "\n",
      "RuntimeError: No transcript data (missing CSV column)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "RuntimeError: No transcript data (missing CSV column)\nTraceback (most recent call last):\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n    ret = func(*args)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 160, in generate_values\n    sources, buffering=buffering, labeled=True, reverse=reverse\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 722, in samples_from_sources\n    sample_sources[0], buffering=buffering, labeled=labeled, reverse=reverse\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 681, in samples_from_source\n    return CSV(sample_source, labeled=labeled, reverse=reverse)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 545, in __init__\n    raise RuntimeError(\"No transcript data (missing CSV column)\")\n\nRuntimeError: No transcript data (missing CSV column)\n\n\n\t [[{{node PyFunc}}]]\n\t [[tower_0/IteratorGetNext]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: RuntimeError: No transcript data (missing CSV column)\nTraceback (most recent call last):\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n    ret = func(*args)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 160, in generate_values\n    sources, buffering=buffering, labeled=True, reverse=reverse\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 722, in samples_from_sources\n    sample_sources[0], buffering=buffering, labeled=labeled, reverse=reverse\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 681, in samples_from_source\n    return CSV(sample_source, labeled=labeled, reverse=reverse)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 545, in __init__\n    raise RuntimeError(\"No transcript data (missing CSV column)\")\n\nRuntimeError: No transcript data (missing CSV column)\n\n\n\t [[{{node PyFunc}}]]\n\t [[tower_0/IteratorGetNext]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_121155/1933779721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m         train_impl(\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/train.py\u001b[0m in \u001b[0;36mtrain_impl\u001b[0;34m(epochs, reverse, limit, write, silent_load)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_init_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                         \u001b[0mlog_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validating epoch %d on %s...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                         \u001b[0mset_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                         \u001b[0mdev_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mset_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                         \u001b[0mtotal_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/train.py\u001b[0m in \u001b[0;36mrun_set\u001b[0;34m(set_name, epoch, init_op, dataset)\u001b[0m\n\u001b[1;32m    526\u001b[0m                             \u001b[0mstep_summaries_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                         ],\n\u001b[0;32m--> 528\u001b[0;31m                         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mepoch_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m                     )\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: RuntimeError: No transcript data (missing CSV column)\nTraceback (most recent call last):\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n    ret = func(*args)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 594, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/feeding.py\", line 160, in generate_values\n    sources, buffering=buffering, labeled=True, reverse=reverse\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 722, in samples_from_sources\n    sample_sources[0], buffering=buffering, labeled=labeled, reverse=reverse\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 681, in samples_from_source\n    return CSV(sample_source, labeled=labeled, reverse=reverse)\n\n  File \"/home/josh/Desktop/proj/mcv-stt-hackathon/mcv-stt-env/lib/python3.7/site-packages/coqui_stt_training/util/sample_collections.py\", line 545, in __init__\n    raise RuntimeError(\"No transcript data (missing CSV column)\")\n\nRuntimeError: No transcript data (missing CSV column)\n\n\n\t [[{{node PyFunc}}]]\n\t [[tower_0/IteratorGetNext]]"
     ]
    }
   ],
   "source": [
    "# Kick off training job; configures CUDA to only use one GPU\n",
    "from coqui_stt_training.train import train\n",
    "\n",
    "# use maximum one GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pretrained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
